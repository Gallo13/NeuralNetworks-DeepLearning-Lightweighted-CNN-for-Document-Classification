{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jessica Gallo\n",
    "# CSC767 Neural Networks & Deep Learning\n",
    "# Project 2\n",
    "# Part E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the original code with RMSProp\n",
    "# This was run with the original dataset under limited data files:\n",
    "# 0.txt, 6.txt and 8.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from helper import data_helpers\n",
    "from text_cnn.LW_text_cnn import TextCNN\n",
    "from tensorflow.contrib import learn\n",
    "import yaml\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x27274e8a2c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data loading params\n",
    "tf.compat.v1.flags.DEFINE_float(\"dev_sample_percentage\", 0.2, \"Percentage of the training data to use for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x27274e858c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Hyperparameters\n",
    "tf.compat.v1.flags.DEFINE_boolean(\"enable_word_embeddings\", False, \"Enable/disable the word embedding (default: True)\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"embedding_dim\", 200, \"Dimensionality of character embedding (default: 128)\")\n",
    "tf.compat.v1.flags.DEFINE_string(\"filter_sizes\", \"2,3,5\", \"Comma-separated filter sizes (default: '2,3,5')\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"num_filters\", 128, \"Number of filters per filter size (default: 120)\")\n",
    "tf.compat.v1.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n",
    "tf.compat.v1.flags.DEFINE_float(\"l2_reg_lambda\", 0.0001, \"L2 regularization lambda (default: 0.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x2726911d208>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training parameters\n",
    "tf.compat.v1.flags.DEFINE_integer(\"batch_size\", 32, \"Batch Size (default: 64)\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"num_epochs\",10, \"Number of training epochs (default: 10)\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"evaluate_every\", 50, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"checkpoint_every\", 50, \"Save model after this many steps (default: 100)\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"num_checkpoints\", 5, \"Number of checkpoints to store (default: 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x27274ea0948>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Misc Parameters\n",
    "tf.compat.v1.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.compat.v1.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "tf.compat.v1.flags.DEFINE_float(\"decay_coefficient\", 2.5, \"Decay coefficient (default: 2.5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.compat.v1.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************YML_PATH C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train/helper/config.yml\n"
     ]
    }
   ],
   "source": [
    "YML_PATH = os.path.join(ROOT_DIR, \"train/helper/config.yml\")\n",
    "print(\"***********************YML_PATH\", YML_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(YML_PATH, 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# added this because of 'Unrecognizable flag error: Unknown command line flag f'\n",
    "tf.compat.v1.flags.DEFINE_string('f','','')\n",
    "# ===================================================================================\n",
    "\n",
    "dataset_name = cfg[\"datasets\"][\"default\"]\n",
    "if FLAGS.enable_word_embeddings and cfg['word_embeddings']['default'] is not None:\n",
    "    embedding_name = cfg['word_embeddings']['default']\n",
    "    embedding_dimension = cfg['word_embeddings'][embedding_name]['dimension']\n",
    "else:\n",
    "    embedding_dimension = FLAGS.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "*************data_path C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\data/tobacco-data/\n",
      "['0.txt', '6.txt', '8.txt']\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "# ==================================================\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "datasets = None\n",
    "if dataset_name == \"tobacco\":\n",
    "    data_path = os.path.join(ROOT_DIR, cfg[\"datasets\"][dataset_name]['parent_dir'] +'/')\n",
    "    print(\"*************data_path\", data_path)    \n",
    "    datasets = data_helpers.get_datasets_tobacco(data_path)\n",
    "\n",
    "elif dataset_name == \"localdata\":\n",
    "    datasets = data_helpers.get_datasets_localdata(container_path=cfg[\"datasets\"][dataset_name][\"container_path\"],\n",
    "                                                     categories=cfg[\"datasets\"][dataset_name][\"categories\"],\n",
    "                                                     shuffle=cfg[\"datasets\"][dataset_name][\"shuffle\"],\n",
    "                                                     random_state=cfg[\"datasets\"][dataset_name][\"random_state\"])\n",
    "\n",
    "x_text, y = data_helpers.load_data_labels(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-59011e463631>:3: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\preprocessing\\text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\preprocessing\\text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "Vocabulary Size: 16099\n",
      "Train/Dev split: 9549/2387\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text)))\n",
    "\n",
    "# Randomly shuffle data\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "# Split train/test set\n",
    "# TODO: This is very crude, should use cross-validation\n",
    "dev_sample_index = -1 * int(FLAGS.dev_sample_percentage * float(len(y)))\n",
    "x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 41, 1, 1)\n",
      "(?, 40, 1, 1)\n",
      "(?, 42, 200, 1)\n",
      "(?, 40, 1, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Writing to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\n",
      "\n",
      "Trainning input set: x_train, y_train 9549\n",
      "*********Trainable PARAMETERS*********** 3224697\n",
      "2020-12-09T16:10:31.615780: step 1, loss 1.13073, acc 0.3125, learning_rate 0.004\n",
      "2020-12-09T16:10:32.212946: step 2, loss 1.04619, acc 0.4375, learning_rate 0.00399478\n",
      "2020-12-09T16:10:32.784926: step 3, loss 1.03975, acc 0.34375, learning_rate 0.00398956\n",
      "2020-12-09T16:10:33.377740: step 4, loss 1.14058, acc 0.375, learning_rate 0.00398435\n",
      "2020-12-09T16:10:33.981153: step 5, loss 1.21297, acc 0.5, learning_rate 0.00397914\n",
      "2020-12-09T16:10:34.568613: step 6, loss 1.09681, acc 0.4375, learning_rate 0.00397395\n",
      "2020-12-09T16:10:35.168644: step 7, loss 1.08035, acc 0.34375, learning_rate 0.00396876\n",
      "2020-12-09T16:10:35.758335: step 8, loss 1.02677, acc 0.46875, learning_rate 0.00396358\n",
      "2020-12-09T16:10:36.350121: step 9, loss 1.02321, acc 0.5625, learning_rate 0.0039584\n",
      "2020-12-09T16:10:36.947009: step 10, loss 1.13054, acc 0.25, learning_rate 0.00395323\n",
      "2020-12-09T16:10:37.542979: step 11, loss 1.09744, acc 0.34375, learning_rate 0.00394807\n",
      "2020-12-09T16:10:38.128980: step 12, loss 1.06045, acc 0.375, learning_rate 0.00394292\n",
      "2020-12-09T16:10:38.714901: step 13, loss 1.1816, acc 0.40625, learning_rate 0.00393777\n",
      "2020-12-09T16:10:39.318173: step 14, loss 0.97256, acc 0.5, learning_rate 0.00393263\n",
      "2020-12-09T16:10:39.916887: step 15, loss 1.05309, acc 0.40625, learning_rate 0.00392749\n",
      "2020-12-09T16:10:40.504877: step 16, loss 1.07489, acc 0.375, learning_rate 0.00392237\n",
      "2020-12-09T16:10:41.087604: step 17, loss 1.05906, acc 0.46875, learning_rate 0.00391725\n",
      "2020-12-09T16:10:41.703778: step 18, loss 0.919651, acc 0.53125, learning_rate 0.00391213\n",
      "2020-12-09T16:10:42.289276: step 19, loss 1.21915, acc 0.3125, learning_rate 0.00390703\n",
      "2020-12-09T16:10:42.884289: step 20, loss 1.12263, acc 0.3125, learning_rate 0.00390193\n",
      "2020-12-09T16:10:43.550151: step 21, loss 1.18689, acc 0.375, learning_rate 0.00389683\n",
      "2020-12-09T16:10:44.135538: step 22, loss 1.28428, acc 0.375, learning_rate 0.00389175\n",
      "2020-12-09T16:10:44.741433: step 23, loss 0.959683, acc 0.53125, learning_rate 0.00388667\n",
      "2020-12-09T16:10:45.332347: step 24, loss 1.19538, acc 0.25, learning_rate 0.0038816\n",
      "2020-12-09T16:10:45.907975: step 25, loss 1.0277, acc 0.5625, learning_rate 0.00387653\n",
      "2020-12-09T16:10:46.490972: step 26, loss 1.0351, acc 0.46875, learning_rate 0.00387147\n",
      "2020-12-09T16:10:47.066972: step 27, loss 1.05236, acc 0.4375, learning_rate 0.00386642\n",
      "2020-12-09T16:10:47.660473: step 28, loss 1.04437, acc 0.46875, learning_rate 0.00386137\n",
      "2020-12-09T16:10:48.267973: step 29, loss 0.99481, acc 0.5, learning_rate 0.00385634\n",
      "2020-12-09T16:10:48.867474: step 30, loss 1.05861, acc 0.4375, learning_rate 0.0038513\n",
      "2020-12-09T16:10:49.535008: step 31, loss 0.867815, acc 0.59375, learning_rate 0.00384628\n",
      "2020-12-09T16:10:50.139778: step 32, loss 0.834057, acc 0.59375, learning_rate 0.00384126\n",
      "2020-12-09T16:10:50.750245: step 33, loss 0.984949, acc 0.46875, learning_rate 0.00383625\n",
      "2020-12-09T16:10:51.384560: step 34, loss 1.12738, acc 0.34375, learning_rate 0.00383124\n",
      "2020-12-09T16:10:52.006966: step 35, loss 1.10991, acc 0.375, learning_rate 0.00382625\n",
      "2020-12-09T16:10:52.590962: step 36, loss 1.05679, acc 0.34375, learning_rate 0.00382125\n",
      "2020-12-09T16:10:53.175494: step 37, loss 0.984936, acc 0.4375, learning_rate 0.00381627\n",
      "2020-12-09T16:10:53.767623: step 38, loss 0.830753, acc 0.59375, learning_rate 0.00381129\n",
      "2020-12-09T16:10:54.364449: step 39, loss 1.04906, acc 0.4375, learning_rate 0.00380632\n",
      "2020-12-09T16:10:54.936039: step 40, loss 0.926894, acc 0.5, learning_rate 0.00380135\n",
      "2020-12-09T16:10:55.553426: step 41, loss 1.14612, acc 0.34375, learning_rate 0.0037964\n",
      "2020-12-09T16:10:56.139260: step 42, loss 0.99176, acc 0.53125, learning_rate 0.00379144\n",
      "2020-12-09T16:10:56.727299: step 43, loss 0.865426, acc 0.625, learning_rate 0.0037865\n",
      "2020-12-09T16:10:57.321307: step 44, loss 1.05051, acc 0.46875, learning_rate 0.00378156\n",
      "2020-12-09T16:10:57.888252: step 45, loss 0.919766, acc 0.59375, learning_rate 0.00377663\n",
      "2020-12-09T16:10:58.470984: step 46, loss 0.850706, acc 0.65625, learning_rate 0.0037717\n",
      "2020-12-09T16:10:59.057083: step 47, loss 0.857152, acc 0.59375, learning_rate 0.00376679\n",
      "2020-12-09T16:10:59.665644: step 48, loss 1.04119, acc 0.4375, learning_rate 0.00376187\n",
      "2020-12-09T16:11:00.255493: step 49, loss 1.03114, acc 0.34375, learning_rate 0.00375697\n",
      "2020-12-09T16:11:00.839644: step 50, loss 1.00654, acc 0.5625, learning_rate 0.00375207\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:11:04.424673: step 50, loss 0.876958, acc 0.561793\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-50\n",
      "\n",
      "2020-12-09T16:11:06.026645: step 51, loss 1.08875, acc 0.40625, learning_rate 0.00374718\n",
      "2020-12-09T16:11:06.637104: step 52, loss 0.767334, acc 0.6875, learning_rate 0.00374229\n",
      "2020-12-09T16:11:07.202100: step 53, loss 0.823917, acc 0.6875, learning_rate 0.00373741\n",
      "2020-12-09T16:11:07.793647: step 54, loss 0.824531, acc 0.625, learning_rate 0.00373254\n",
      "2020-12-09T16:11:08.386075: step 55, loss 0.939034, acc 0.5, learning_rate 0.00372768\n",
      "2020-12-09T16:11:08.952418: step 56, loss 0.833803, acc 0.625, learning_rate 0.00372282\n",
      "2020-12-09T16:11:09.533936: step 57, loss 0.991111, acc 0.53125, learning_rate 0.00371796\n",
      "2020-12-09T16:11:10.140309: step 58, loss 0.722082, acc 0.6875, learning_rate 0.00371312\n",
      "2020-12-09T16:11:10.711706: step 59, loss 0.841175, acc 0.59375, learning_rate 0.00370828\n",
      "2020-12-09T16:11:11.302034: step 60, loss 1.00204, acc 0.53125, learning_rate 0.00370344\n",
      "2020-12-09T16:11:11.880438: step 61, loss 0.735388, acc 0.65625, learning_rate 0.00369862\n",
      "2020-12-09T16:11:12.448292: step 62, loss 0.757966, acc 0.65625, learning_rate 0.0036938\n",
      "2020-12-09T16:11:13.064658: step 63, loss 0.807205, acc 0.75, learning_rate 0.00368898\n",
      "2020-12-09T16:11:13.645515: step 64, loss 0.795142, acc 0.5625, learning_rate 0.00368417\n",
      "2020-12-09T16:11:14.229700: step 65, loss 0.891311, acc 0.53125, learning_rate 0.00367937\n",
      "2020-12-09T16:11:14.807720: step 66, loss 0.835836, acc 0.625, learning_rate 0.00367458\n",
      "2020-12-09T16:11:15.415298: step 67, loss 0.806087, acc 0.625, learning_rate 0.00366979\n",
      "2020-12-09T16:11:16.008400: step 68, loss 0.865682, acc 0.53125, learning_rate 0.00366501\n",
      "2020-12-09T16:11:16.602669: step 69, loss 0.705909, acc 0.78125, learning_rate 0.00366023\n",
      "2020-12-09T16:11:17.185199: step 70, loss 0.869892, acc 0.625, learning_rate 0.00365546\n",
      "2020-12-09T16:11:17.792097: step 71, loss 0.84985, acc 0.6875, learning_rate 0.0036507\n",
      "2020-12-09T16:11:18.387382: step 72, loss 0.877384, acc 0.53125, learning_rate 0.00364594\n",
      "2020-12-09T16:11:18.951373: step 73, loss 0.714448, acc 0.71875, learning_rate 0.00364119\n",
      "2020-12-09T16:11:19.540981: step 74, loss 0.733507, acc 0.6875, learning_rate 0.00363645\n",
      "2020-12-09T16:11:20.135439: step 75, loss 0.926243, acc 0.59375, learning_rate 0.00363171\n",
      "2020-12-09T16:11:20.718931: step 76, loss 0.931357, acc 0.65625, learning_rate 0.00362698\n",
      "2020-12-09T16:11:21.309813: step 77, loss 0.753614, acc 0.65625, learning_rate 0.00362226\n",
      "2020-12-09T16:11:21.903217: step 78, loss 0.785918, acc 0.59375, learning_rate 0.00361754\n",
      "2020-12-09T16:11:22.503766: step 79, loss 0.967603, acc 0.5, learning_rate 0.00361283\n",
      "2020-12-09T16:11:23.089767: step 80, loss 1.06218, acc 0.65625, learning_rate 0.00360812\n",
      "2020-12-09T16:11:23.667891: step 81, loss 0.751524, acc 0.625, learning_rate 0.00360342\n",
      "2020-12-09T16:11:24.240250: step 82, loss 1.17148, acc 0.53125, learning_rate 0.00359873\n",
      "2020-12-09T16:11:24.815792: step 83, loss 0.926773, acc 0.53125, learning_rate 0.00359404\n",
      "2020-12-09T16:11:25.417467: step 84, loss 0.967598, acc 0.5625, learning_rate 0.00358936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:11:26.080397: step 85, loss 1.05463, acc 0.4375, learning_rate 0.00358469\n",
      "2020-12-09T16:11:26.681250: step 86, loss 0.845241, acc 0.59375, learning_rate 0.00358002\n",
      "2020-12-09T16:11:27.263910: step 87, loss 0.795397, acc 0.6875, learning_rate 0.00357536\n",
      "2020-12-09T16:11:27.860362: step 88, loss 0.817473, acc 0.59375, learning_rate 0.0035707\n",
      "2020-12-09T16:11:28.442301: step 89, loss 0.85647, acc 0.5625, learning_rate 0.00356605\n",
      "2020-12-09T16:11:28.999795: step 90, loss 0.664982, acc 0.78125, learning_rate 0.00356141\n",
      "2020-12-09T16:11:29.596955: step 91, loss 0.756699, acc 0.625, learning_rate 0.00355677\n",
      "2020-12-09T16:11:30.184001: step 92, loss 0.74835, acc 0.71875, learning_rate 0.00355214\n",
      "2020-12-09T16:11:30.779378: step 93, loss 1.04438, acc 0.46875, learning_rate 0.00354752\n",
      "2020-12-09T16:11:31.366152: step 94, loss 0.885096, acc 0.625, learning_rate 0.0035429\n",
      "2020-12-09T16:11:31.950335: step 95, loss 0.688864, acc 0.6875, learning_rate 0.00353829\n",
      "2020-12-09T16:11:32.551345: step 96, loss 0.744645, acc 0.75, learning_rate 0.00353368\n",
      "2020-12-09T16:11:33.131361: step 97, loss 0.718949, acc 0.6875, learning_rate 0.00352908\n",
      "2020-12-09T16:11:33.692885: step 98, loss 0.754268, acc 0.6875, learning_rate 0.00352449\n",
      "2020-12-09T16:11:34.296875: step 99, loss 0.589496, acc 0.8125, learning_rate 0.0035199\n",
      "2020-12-09T16:11:34.867335: step 100, loss 0.797091, acc 0.65625, learning_rate 0.00351532\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:11:38.044603: step 100, loss 0.784295, acc 0.644742\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-100\n",
      "\n",
      "2020-12-09T16:11:39.527432: step 101, loss 0.832448, acc 0.625, learning_rate 0.00351075\n",
      "2020-12-09T16:11:40.129275: step 102, loss 0.798962, acc 0.59375, learning_rate 0.00350618\n",
      "2020-12-09T16:11:40.714865: step 103, loss 0.564811, acc 0.6875, learning_rate 0.00350161\n",
      "2020-12-09T16:11:41.294284: step 104, loss 0.760232, acc 0.6875, learning_rate 0.00349706\n",
      "2020-12-09T16:11:41.892277: step 105, loss 1.09885, acc 0.4375, learning_rate 0.00349251\n",
      "2020-12-09T16:11:42.484919: step 106, loss 0.913069, acc 0.59375, learning_rate 0.00348796\n",
      "2020-12-09T16:11:43.047486: step 107, loss 0.808714, acc 0.625, learning_rate 0.00348342\n",
      "2020-12-09T16:11:43.634025: step 108, loss 0.94355, acc 0.53125, learning_rate 0.00347889\n",
      "2020-12-09T16:11:44.215521: step 109, loss 0.635165, acc 0.6875, learning_rate 0.00347437\n",
      "2020-12-09T16:11:44.795259: step 110, loss 0.702087, acc 0.75, learning_rate 0.00346985\n",
      "2020-12-09T16:11:45.380260: step 111, loss 0.634898, acc 0.71875, learning_rate 0.00346533\n",
      "2020-12-09T16:11:45.952802: step 112, loss 0.728698, acc 0.6875, learning_rate 0.00346082\n",
      "2020-12-09T16:11:46.533776: step 113, loss 0.757937, acc 0.71875, learning_rate 0.00345632\n",
      "2020-12-09T16:11:47.103240: step 114, loss 0.841384, acc 0.5625, learning_rate 0.00345183\n",
      "2020-12-09T16:11:47.685507: step 115, loss 0.952955, acc 0.5, learning_rate 0.00344734\n",
      "2020-12-09T16:11:48.252514: step 116, loss 0.908497, acc 0.625, learning_rate 0.00344285\n",
      "2020-12-09T16:11:48.825034: step 117, loss 0.680137, acc 0.6875, learning_rate 0.00343837\n",
      "2020-12-09T16:11:49.411555: step 118, loss 0.865023, acc 0.5, learning_rate 0.0034339\n",
      "2020-12-09T16:11:50.009136: step 119, loss 0.774308, acc 0.5, learning_rate 0.00342944\n",
      "2020-12-09T16:11:50.605174: step 120, loss 1.04328, acc 0.46875, learning_rate 0.00342498\n",
      "2020-12-09T16:11:51.176623: step 121, loss 0.714105, acc 0.75, learning_rate 0.00342052\n",
      "2020-12-09T16:11:51.755056: step 122, loss 1.09402, acc 0.4375, learning_rate 0.00341607\n",
      "2020-12-09T16:11:52.323316: step 123, loss 0.692852, acc 0.6875, learning_rate 0.00341163\n",
      "2020-12-09T16:11:52.913991: step 124, loss 0.69847, acc 0.6875, learning_rate 0.0034072\n",
      "2020-12-09T16:11:53.495230: step 125, loss 0.891061, acc 0.53125, learning_rate 0.00340277\n",
      "2020-12-09T16:11:54.100494: step 126, loss 0.839051, acc 0.625, learning_rate 0.00339834\n",
      "2020-12-09T16:11:54.720380: step 127, loss 0.598525, acc 0.75, learning_rate 0.00339392\n",
      "2020-12-09T16:11:55.295140: step 128, loss 0.73993, acc 0.625, learning_rate 0.00338951\n",
      "2020-12-09T16:11:55.865312: step 129, loss 0.770245, acc 0.65625, learning_rate 0.0033851\n",
      "2020-12-09T16:11:56.457797: step 130, loss 0.843714, acc 0.59375, learning_rate 0.0033807\n",
      "2020-12-09T16:11:57.068295: step 131, loss 0.931105, acc 0.5625, learning_rate 0.00337631\n",
      "2020-12-09T16:11:57.659659: step 132, loss 0.781954, acc 0.625, learning_rate 0.00337192\n",
      "2020-12-09T16:11:58.269764: step 133, loss 0.772363, acc 0.65625, learning_rate 0.00336754\n",
      "2020-12-09T16:11:58.873480: step 134, loss 0.697398, acc 0.65625, learning_rate 0.00336316\n",
      "2020-12-09T16:11:59.450479: step 135, loss 0.65157, acc 0.75, learning_rate 0.00335879\n",
      "2020-12-09T16:12:00.074238: step 136, loss 0.951819, acc 0.53125, learning_rate 0.00335442\n",
      "2020-12-09T16:12:00.673716: step 137, loss 0.573101, acc 0.78125, learning_rate 0.00335006\n",
      "2020-12-09T16:12:01.253774: step 138, loss 0.796014, acc 0.65625, learning_rate 0.00334571\n",
      "2020-12-09T16:12:01.840601: step 139, loss 0.690686, acc 0.65625, learning_rate 0.00334136\n",
      "2020-12-09T16:12:02.416488: step 140, loss 0.72768, acc 0.65625, learning_rate 0.00333702\n",
      "2020-12-09T16:12:02.998398: step 141, loss 0.651141, acc 0.6875, learning_rate 0.00333268\n",
      "2020-12-09T16:12:03.583369: step 142, loss 0.677529, acc 0.65625, learning_rate 0.00332835\n",
      "2020-12-09T16:12:04.190861: step 143, loss 0.75454, acc 0.625, learning_rate 0.00332403\n",
      "2020-12-09T16:12:04.793923: step 144, loss 0.801882, acc 0.65625, learning_rate 0.00331971\n",
      "2020-12-09T16:12:05.356976: step 145, loss 0.771495, acc 0.65625, learning_rate 0.0033154\n",
      "2020-12-09T16:12:05.934072: step 146, loss 0.648916, acc 0.71875, learning_rate 0.00331109\n",
      "2020-12-09T16:12:06.528400: step 147, loss 0.542084, acc 0.8125, learning_rate 0.00330679\n",
      "2020-12-09T16:12:07.116098: step 148, loss 0.7066, acc 0.6875, learning_rate 0.00330249\n",
      "2020-12-09T16:12:07.704595: step 149, loss 0.780009, acc 0.6875, learning_rate 0.0032982\n",
      "2020-12-09T16:12:08.291889: step 150, loss 0.777236, acc 0.59375, learning_rate 0.00329392\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:12:11.555322: step 150, loss 0.713438, acc 0.66946\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-150\n",
      "\n",
      "2020-12-09T16:12:13.022143: step 151, loss 0.646137, acc 0.75, learning_rate 0.00328964\n",
      "2020-12-09T16:12:13.601832: step 152, loss 0.622168, acc 0.75, learning_rate 0.00328537\n",
      "2020-12-09T16:12:14.196090: step 153, loss 1.01337, acc 0.4375, learning_rate 0.0032811\n",
      "2020-12-09T16:12:14.793405: step 154, loss 0.735551, acc 0.65625, learning_rate 0.00327684\n",
      "2020-12-09T16:12:15.364939: step 155, loss 0.743978, acc 0.65625, learning_rate 0.00327258\n",
      "2020-12-09T16:12:15.942029: step 156, loss 0.595617, acc 0.6875, learning_rate 0.00326833\n",
      "2020-12-09T16:12:16.547926: step 157, loss 0.572354, acc 0.75, learning_rate 0.00326409\n",
      "2020-12-09T16:12:17.166464: step 158, loss 0.538448, acc 0.78125, learning_rate 0.00325985\n",
      "2020-12-09T16:12:17.755503: step 159, loss 0.645845, acc 0.75, learning_rate 0.00325562\n",
      "2020-12-09T16:12:18.358170: step 160, loss 0.824457, acc 0.71875, learning_rate 0.00325139\n",
      "2020-12-09T16:12:18.941334: step 161, loss 0.780861, acc 0.71875, learning_rate 0.00324717\n",
      "2020-12-09T16:12:19.516788: step 162, loss 0.879236, acc 0.53125, learning_rate 0.00324295\n",
      "2020-12-09T16:12:20.085819: step 163, loss 0.629439, acc 0.75, learning_rate 0.00323874\n",
      "2020-12-09T16:12:20.664786: step 164, loss 0.884024, acc 0.53125, learning_rate 0.00323454\n",
      "2020-12-09T16:12:21.244779: step 165, loss 0.617182, acc 0.625, learning_rate 0.00323034\n",
      "2020-12-09T16:12:21.819309: step 166, loss 0.625264, acc 0.71875, learning_rate 0.00322615\n",
      "2020-12-09T16:12:22.409424: step 167, loss 0.809499, acc 0.6875, learning_rate 0.00322196\n",
      "2020-12-09T16:12:23.046662: step 168, loss 0.869632, acc 0.59375, learning_rate 0.00321778\n",
      "2020-12-09T16:12:23.639776: step 169, loss 0.602429, acc 0.75, learning_rate 0.0032136\n",
      "2020-12-09T16:12:24.227256: step 170, loss 0.624031, acc 0.71875, learning_rate 0.00320943\n",
      "2020-12-09T16:12:24.857278: step 171, loss 0.70057, acc 0.65625, learning_rate 0.00320527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:12:25.420782: step 172, loss 0.802531, acc 0.6875, learning_rate 0.00320111\n",
      "2020-12-09T16:12:26.018819: step 173, loss 0.566902, acc 0.78125, learning_rate 0.00319695\n",
      "2020-12-09T16:12:26.601780: step 174, loss 0.704352, acc 0.6875, learning_rate 0.0031928\n",
      "2020-12-09T16:12:27.190449: step 175, loss 0.763516, acc 0.75, learning_rate 0.00318866\n",
      "2020-12-09T16:12:27.764460: step 176, loss 0.707481, acc 0.71875, learning_rate 0.00318452\n",
      "2020-12-09T16:12:28.357401: step 177, loss 0.902625, acc 0.5625, learning_rate 0.00318039\n",
      "2020-12-09T16:12:28.953124: step 178, loss 0.753949, acc 0.5625, learning_rate 0.00317626\n",
      "2020-12-09T16:12:29.514588: step 179, loss 0.722815, acc 0.65625, learning_rate 0.00317214\n",
      "2020-12-09T16:12:30.094613: step 180, loss 0.548255, acc 0.71875, learning_rate 0.00316803\n",
      "2020-12-09T16:12:30.667342: step 181, loss 0.584278, acc 0.78125, learning_rate 0.00316392\n",
      "2020-12-09T16:12:31.258755: step 182, loss 0.615858, acc 0.6875, learning_rate 0.00315981\n",
      "2020-12-09T16:12:31.848968: step 183, loss 0.527478, acc 0.78125, learning_rate 0.00315572\n",
      "2020-12-09T16:12:32.438557: step 184, loss 0.752514, acc 0.625, learning_rate 0.00315162\n",
      "2020-12-09T16:12:33.011919: step 185, loss 0.66031, acc 0.6875, learning_rate 0.00314753\n",
      "2020-12-09T16:12:33.579134: step 186, loss 0.773569, acc 0.6875, learning_rate 0.00314345\n",
      "2020-12-09T16:12:34.170816: step 187, loss 0.770376, acc 0.78125, learning_rate 0.00313938\n",
      "2020-12-09T16:12:34.746985: step 188, loss 0.750213, acc 0.65625, learning_rate 0.0031353\n",
      "2020-12-09T16:12:35.327675: step 189, loss 0.730721, acc 0.75, learning_rate 0.00313124\n",
      "2020-12-09T16:12:35.901253: step 190, loss 0.928655, acc 0.625, learning_rate 0.00312718\n",
      "2020-12-09T16:12:36.493253: step 191, loss 0.648428, acc 0.78125, learning_rate 0.00312312\n",
      "2020-12-09T16:12:37.084921: step 192, loss 0.627594, acc 0.75, learning_rate 0.00311907\n",
      "2020-12-09T16:12:37.665057: step 193, loss 0.929577, acc 0.46875, learning_rate 0.00311503\n",
      "2020-12-09T16:12:38.235524: step 194, loss 0.638572, acc 0.6875, learning_rate 0.00311099\n",
      "2020-12-09T16:12:38.820299: step 195, loss 0.534365, acc 0.71875, learning_rate 0.00310696\n",
      "2020-12-09T16:12:39.398638: step 196, loss 0.590439, acc 0.78125, learning_rate 0.00310293\n",
      "2020-12-09T16:12:39.988012: step 197, loss 0.544776, acc 0.75, learning_rate 0.00309891\n",
      "2020-12-09T16:12:40.564424: step 198, loss 0.777262, acc 0.71875, learning_rate 0.00309489\n",
      "2020-12-09T16:12:41.126234: step 199, loss 0.455783, acc 0.84375, learning_rate 0.00309088\n",
      "2020-12-09T16:12:41.707108: step 200, loss 0.709968, acc 0.625, learning_rate 0.00308687\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:12:44.938689: step 200, loss 0.672276, acc 0.695015\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-200\n",
      "\n",
      "2020-12-09T16:12:46.411190: step 201, loss 0.55963, acc 0.71875, learning_rate 0.00308287\n",
      "2020-12-09T16:12:46.984024: step 202, loss 0.643043, acc 0.6875, learning_rate 0.00307887\n",
      "2020-12-09T16:12:47.570217: step 203, loss 0.738812, acc 0.65625, learning_rate 0.00307488\n",
      "2020-12-09T16:12:48.154579: step 204, loss 0.521598, acc 0.75, learning_rate 0.0030709\n",
      "2020-12-09T16:12:48.770726: step 205, loss 0.567603, acc 0.65625, learning_rate 0.00306692\n",
      "2020-12-09T16:12:49.347604: step 206, loss 0.772152, acc 0.65625, learning_rate 0.00306294\n",
      "2020-12-09T16:12:49.922576: step 207, loss 0.73929, acc 0.625, learning_rate 0.00305898\n",
      "2020-12-09T16:12:50.505173: step 208, loss 0.941157, acc 0.65625, learning_rate 0.00305501\n",
      "2020-12-09T16:12:51.079191: step 209, loss 0.609158, acc 0.65625, learning_rate 0.00305105\n",
      "2020-12-09T16:12:51.660191: step 210, loss 0.728561, acc 0.6875, learning_rate 0.0030471\n",
      "2020-12-09T16:12:52.255158: step 211, loss 0.782268, acc 0.65625, learning_rate 0.00304315\n",
      "2020-12-09T16:12:52.844162: step 212, loss 0.707592, acc 0.65625, learning_rate 0.00303921\n",
      "2020-12-09T16:12:53.433659: step 213, loss 0.729854, acc 0.625, learning_rate 0.00303527\n",
      "2020-12-09T16:12:54.004068: step 214, loss 0.590331, acc 0.75, learning_rate 0.00303134\n",
      "2020-12-09T16:12:54.585100: step 215, loss 0.527758, acc 0.875, learning_rate 0.00302741\n",
      "2020-12-09T16:12:55.171705: step 216, loss 0.509324, acc 0.875, learning_rate 0.00302349\n",
      "2020-12-09T16:12:55.743164: step 217, loss 0.686801, acc 0.75, learning_rate 0.00301958\n",
      "2020-12-09T16:12:56.325425: step 218, loss 0.823073, acc 0.59375, learning_rate 0.00301567\n",
      "2020-12-09T16:12:56.891149: step 219, loss 0.570485, acc 0.78125, learning_rate 0.00301176\n",
      "2020-12-09T16:12:57.469052: step 220, loss 0.846882, acc 0.53125, learning_rate 0.00300786\n",
      "2020-12-09T16:12:58.054211: step 221, loss 0.621572, acc 0.75, learning_rate 0.00300396\n",
      "2020-12-09T16:12:58.670453: step 222, loss 0.613427, acc 0.6875, learning_rate 0.00300007\n",
      "2020-12-09T16:12:59.267641: step 223, loss 0.790184, acc 0.6875, learning_rate 0.00299619\n",
      "2020-12-09T16:12:59.857707: step 224, loss 0.618894, acc 0.6875, learning_rate 0.00299231\n",
      "2020-12-09T16:13:00.447699: step 225, loss 0.809991, acc 0.6875, learning_rate 0.00298843\n",
      "2020-12-09T16:13:01.046527: step 226, loss 0.462528, acc 0.75, learning_rate 0.00298457\n",
      "2020-12-09T16:13:01.613489: step 227, loss 0.611199, acc 0.75, learning_rate 0.0029807\n",
      "2020-12-09T16:13:02.195945: step 228, loss 0.721669, acc 0.59375, learning_rate 0.00297684\n",
      "2020-12-09T16:13:02.793206: step 229, loss 0.762822, acc 0.65625, learning_rate 0.00297299\n",
      "2020-12-09T16:13:03.381826: step 230, loss 0.501459, acc 0.84375, learning_rate 0.00296914\n",
      "2020-12-09T16:13:04.003324: step 231, loss 0.71882, acc 0.71875, learning_rate 0.0029653\n",
      "2020-12-09T16:13:04.587298: step 232, loss 0.75426, acc 0.6875, learning_rate 0.00296146\n",
      "2020-12-09T16:13:05.180736: step 233, loss 0.517993, acc 0.71875, learning_rate 0.00295763\n",
      "2020-12-09T16:13:05.769751: step 234, loss 0.746627, acc 0.59375, learning_rate 0.0029538\n",
      "2020-12-09T16:13:06.414340: step 235, loss 0.74713, acc 0.65625, learning_rate 0.00294997\n",
      "2020-12-09T16:13:07.003964: step 236, loss 0.621444, acc 0.6875, learning_rate 0.00294616\n",
      "2020-12-09T16:13:07.614863: step 237, loss 0.511076, acc 0.75, learning_rate 0.00294234\n",
      "2020-12-09T16:13:08.213361: step 238, loss 0.600119, acc 0.75, learning_rate 0.00293854\n",
      "2020-12-09T16:13:08.777384: step 239, loss 0.756576, acc 0.5625, learning_rate 0.00293473\n",
      "2020-12-09T16:13:09.363686: step 240, loss 0.663967, acc 0.78125, learning_rate 0.00293094\n",
      "2020-12-09T16:13:09.935367: step 241, loss 0.556187, acc 0.75, learning_rate 0.00292715\n",
      "2020-12-09T16:13:10.519488: step 242, loss 0.525452, acc 0.75, learning_rate 0.00292336\n",
      "2020-12-09T16:13:11.107617: step 243, loss 0.600625, acc 0.75, learning_rate 0.00291958\n",
      "2020-12-09T16:13:11.685084: step 244, loss 0.618152, acc 0.75, learning_rate 0.0029158\n",
      "2020-12-09T16:13:12.264082: step 245, loss 0.705462, acc 0.625, learning_rate 0.00291203\n",
      "2020-12-09T16:13:12.884465: step 246, loss 0.49143, acc 0.78125, learning_rate 0.00290826\n",
      "2020-12-09T16:13:13.464683: step 247, loss 0.625989, acc 0.65625, learning_rate 0.0029045\n",
      "2020-12-09T16:13:14.041751: step 248, loss 0.728263, acc 0.71875, learning_rate 0.00290074\n",
      "2020-12-09T16:13:14.678468: step 249, loss 0.581385, acc 0.6875, learning_rate 0.00289699\n",
      "2020-12-09T16:13:15.264038: step 250, loss 0.70003, acc 0.65625, learning_rate 0.00289324\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:13:18.616296: step 250, loss 0.64497, acc 0.71638\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-250\n",
      "\n",
      "2020-12-09T16:13:20.046130: step 251, loss 0.844019, acc 0.59375, learning_rate 0.0028895\n",
      "2020-12-09T16:13:20.620927: step 252, loss 0.516845, acc 0.8125, learning_rate 0.00288576\n",
      "2020-12-09T16:13:21.213422: step 253, loss 1.04969, acc 0.625, learning_rate 0.00288203\n",
      "2020-12-09T16:13:21.795391: step 254, loss 0.6367, acc 0.71875, learning_rate 0.00287831\n",
      "2020-12-09T16:13:22.375145: step 255, loss 0.560417, acc 0.65625, learning_rate 0.00287458\n",
      "2020-12-09T16:13:22.965421: step 256, loss 0.711249, acc 0.75, learning_rate 0.00287087\n",
      "2020-12-09T16:13:23.540369: step 257, loss 0.69558, acc 0.59375, learning_rate 0.00286716\n",
      "2020-12-09T16:13:24.110323: step 258, loss 0.985446, acc 0.625, learning_rate 0.00286345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:13:24.703966: step 259, loss 0.66735, acc 0.65625, learning_rate 0.00285975\n",
      "2020-12-09T16:13:25.286967: step 260, loss 0.801868, acc 0.65625, learning_rate 0.00285605\n",
      "2020-12-09T16:13:25.867451: step 261, loss 0.77187, acc 0.71875, learning_rate 0.00285236\n",
      "2020-12-09T16:13:26.445936: step 262, loss 0.647984, acc 0.6875, learning_rate 0.00284867\n",
      "2020-12-09T16:13:27.031204: step 263, loss 0.977967, acc 0.46875, learning_rate 0.00284499\n",
      "2020-12-09T16:13:27.608051: step 264, loss 0.772406, acc 0.59375, learning_rate 0.00284131\n",
      "2020-12-09T16:13:28.183522: step 265, loss 0.724135, acc 0.5625, learning_rate 0.00283764\n",
      "2020-12-09T16:13:28.797542: step 266, loss 0.790715, acc 0.625, learning_rate 0.00283397\n",
      "2020-12-09T16:13:29.382320: step 267, loss 0.7362, acc 0.6875, learning_rate 0.00283031\n",
      "2020-12-09T16:13:29.970324: step 268, loss 0.481774, acc 0.75, learning_rate 0.00282665\n",
      "2020-12-09T16:13:30.550087: step 269, loss 0.66335, acc 0.6875, learning_rate 0.002823\n",
      "2020-12-09T16:13:31.144937: step 270, loss 0.634897, acc 0.78125, learning_rate 0.00281935\n",
      "2020-12-09T16:13:31.728929: step 271, loss 0.757434, acc 0.65625, learning_rate 0.00281571\n",
      "2020-12-09T16:13:32.318848: step 272, loss 0.945835, acc 0.59375, learning_rate 0.00281207\n",
      "2020-12-09T16:13:32.914919: step 273, loss 0.605962, acc 0.78125, learning_rate 0.00280844\n",
      "2020-12-09T16:13:33.511128: step 274, loss 0.644484, acc 0.8125, learning_rate 0.00280481\n",
      "2020-12-09T16:13:34.081580: step 275, loss 0.516303, acc 0.75, learning_rate 0.00280119\n",
      "2020-12-09T16:13:34.664149: step 276, loss 0.803298, acc 0.65625, learning_rate 0.00279757\n",
      "2020-12-09T16:13:35.245659: step 277, loss 0.861834, acc 0.625, learning_rate 0.00279396\n",
      "2020-12-09T16:13:35.836124: step 278, loss 0.966068, acc 0.5625, learning_rate 0.00279035\n",
      "2020-12-09T16:13:36.424910: step 279, loss 0.705162, acc 0.65625, learning_rate 0.00278674\n",
      "2020-12-09T16:13:37.014312: step 280, loss 0.677986, acc 0.71875, learning_rate 0.00278315\n",
      "2020-12-09T16:13:37.610041: step 281, loss 0.690835, acc 0.75, learning_rate 0.00277955\n",
      "2020-12-09T16:13:38.176223: step 282, loss 0.657672, acc 0.65625, learning_rate 0.00277596\n",
      "2020-12-09T16:13:38.755107: step 283, loss 0.620535, acc 0.8125, learning_rate 0.00277238\n",
      "2020-12-09T16:13:39.343230: step 284, loss 0.649476, acc 0.71875, learning_rate 0.0027688\n",
      "2020-12-09T16:13:39.919760: step 285, loss 0.683774, acc 0.71875, learning_rate 0.00276522\n",
      "2020-12-09T16:13:40.507258: step 286, loss 0.879426, acc 0.65625, learning_rate 0.00276165\n",
      "2020-12-09T16:13:41.086758: step 287, loss 0.699678, acc 0.5625, learning_rate 0.00275809\n",
      "2020-12-09T16:13:41.688730: step 288, loss 0.621069, acc 0.6875, learning_rate 0.00275453\n",
      "2020-12-09T16:13:42.248693: step 289, loss 0.606819, acc 0.71875, learning_rate 0.00275097\n",
      "2020-12-09T16:13:42.862370: step 290, loss 0.536739, acc 0.78125, learning_rate 0.00274742\n",
      "2020-12-09T16:13:43.456720: step 291, loss 0.637006, acc 0.65625, learning_rate 0.00274387\n",
      "2020-12-09T16:13:44.013679: step 292, loss 0.778013, acc 0.625, learning_rate 0.00274033\n",
      "2020-12-09T16:13:44.597120: step 293, loss 0.584, acc 0.6875, learning_rate 0.00273679\n",
      "2020-12-09T16:13:45.163754: step 294, loss 0.491591, acc 0.75, learning_rate 0.00273326\n",
      "2020-12-09T16:13:45.760009: step 295, loss 0.708392, acc 0.71875, learning_rate 0.00272973\n",
      "2020-12-09T16:13:46.346520: step 296, loss 0.631667, acc 0.75, learning_rate 0.00272621\n",
      "2020-12-09T16:13:46.949253: step 297, loss 0.582314, acc 0.78125, learning_rate 0.00272269\n",
      "2020-12-09T16:13:47.552648: step 298, loss 0.657715, acc 0.71875, learning_rate 0.00271918\n",
      "2020-12-09T16:13:47.806946: step 299, loss 0.567465, acc 0.769231, learning_rate 0.00271567\n",
      "2020-12-09T16:13:48.379407: step 300, loss 0.590311, acc 0.71875, learning_rate 0.00271217\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:13:51.600164: step 300, loss 0.625148, acc 0.716799\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-300\n",
      "\n",
      "2020-12-09T16:13:53.095244: step 301, loss 0.314647, acc 0.90625, learning_rate 0.00270867\n",
      "2020-12-09T16:13:53.690943: step 302, loss 0.526281, acc 0.75, learning_rate 0.00270517\n",
      "2020-12-09T16:13:54.246991: step 303, loss 0.55276, acc 0.75, learning_rate 0.00270168\n",
      "2020-12-09T16:13:54.828362: step 304, loss 0.687858, acc 0.625, learning_rate 0.0026982\n",
      "2020-12-09T16:13:55.420888: step 305, loss 0.491546, acc 0.75, learning_rate 0.00269472\n",
      "2020-12-09T16:13:56.001420: step 306, loss 0.665053, acc 0.65625, learning_rate 0.00269124\n",
      "2020-12-09T16:13:56.578781: step 307, loss 0.54288, acc 0.6875, learning_rate 0.00268777\n",
      "2020-12-09T16:13:57.189066: step 308, loss 0.357491, acc 0.84375, learning_rate 0.00268431\n",
      "2020-12-09T16:13:57.773996: step 309, loss 0.31253, acc 0.875, learning_rate 0.00268084\n",
      "2020-12-09T16:13:58.349520: step 310, loss 0.606074, acc 0.65625, learning_rate 0.00267739\n",
      "2020-12-09T16:13:58.925552: step 311, loss 0.586447, acc 0.71875, learning_rate 0.00267393\n",
      "2020-12-09T16:13:59.504125: step 312, loss 0.593312, acc 0.71875, learning_rate 0.00267049\n",
      "2020-12-09T16:14:00.105086: step 313, loss 0.686908, acc 0.6875, learning_rate 0.00266704\n",
      "2020-12-09T16:14:00.694598: step 314, loss 0.517878, acc 0.6875, learning_rate 0.0026636\n",
      "2020-12-09T16:14:01.277520: step 315, loss 0.374414, acc 0.8125, learning_rate 0.00266017\n",
      "2020-12-09T16:14:01.857004: step 316, loss 0.551453, acc 0.78125, learning_rate 0.00265674\n",
      "2020-12-09T16:14:02.427506: step 317, loss 0.465457, acc 0.78125, learning_rate 0.00265332\n",
      "2020-12-09T16:14:02.993610: step 318, loss 0.561027, acc 0.78125, learning_rate 0.0026499\n",
      "2020-12-09T16:14:03.637322: step 319, loss 0.693751, acc 0.71875, learning_rate 0.00264648\n",
      "2020-12-09T16:14:04.204816: step 320, loss 0.452954, acc 0.875, learning_rate 0.00264307\n",
      "2020-12-09T16:14:04.782248: step 321, loss 0.466273, acc 0.8125, learning_rate 0.00263966\n",
      "2020-12-09T16:14:05.372150: step 322, loss 0.41293, acc 0.75, learning_rate 0.00263626\n",
      "2020-12-09T16:14:05.955104: step 323, loss 0.449321, acc 0.71875, learning_rate 0.00263286\n",
      "2020-12-09T16:14:06.528285: step 324, loss 0.450818, acc 0.84375, learning_rate 0.00262947\n",
      "2020-12-09T16:14:07.102340: step 325, loss 0.290064, acc 0.90625, learning_rate 0.00262608\n",
      "2020-12-09T16:14:07.686055: step 326, loss 0.542417, acc 0.8125, learning_rate 0.0026227\n",
      "2020-12-09T16:14:08.255391: step 327, loss 0.479903, acc 0.84375, learning_rate 0.00261932\n",
      "2020-12-09T16:14:08.822490: step 328, loss 0.596735, acc 0.84375, learning_rate 0.00261594\n",
      "2020-12-09T16:14:09.398385: step 329, loss 0.510527, acc 0.75, learning_rate 0.00261257\n",
      "2020-12-09T16:14:09.983145: step 330, loss 0.351967, acc 0.84375, learning_rate 0.00260921\n",
      "2020-12-09T16:14:10.601149: step 331, loss 0.4035, acc 0.875, learning_rate 0.00260585\n",
      "2020-12-09T16:14:11.202024: step 332, loss 0.510722, acc 0.6875, learning_rate 0.00260249\n",
      "2020-12-09T16:14:11.805530: step 333, loss 0.346491, acc 0.78125, learning_rate 0.00259914\n",
      "2020-12-09T16:14:12.393529: step 334, loss 0.531542, acc 0.78125, learning_rate 0.00259579\n",
      "2020-12-09T16:14:12.984028: step 335, loss 0.530276, acc 0.6875, learning_rate 0.00259245\n",
      "2020-12-09T16:14:13.582861: step 336, loss 0.478575, acc 0.8125, learning_rate 0.00258911\n",
      "2020-12-09T16:14:14.171364: step 337, loss 0.404296, acc 0.8125, learning_rate 0.00258577\n",
      "2020-12-09T16:14:14.791898: step 338, loss 0.88259, acc 0.65625, learning_rate 0.00258244\n",
      "2020-12-09T16:14:15.354761: step 339, loss 0.584742, acc 0.8125, learning_rate 0.00257912\n",
      "2020-12-09T16:14:15.962382: step 340, loss 0.501381, acc 0.75, learning_rate 0.0025758\n",
      "2020-12-09T16:14:16.544379: step 341, loss 0.502474, acc 0.75, learning_rate 0.00257248\n",
      "2020-12-09T16:14:17.106252: step 342, loss 0.447655, acc 0.78125, learning_rate 0.00256917\n",
      "2020-12-09T16:14:17.694726: step 343, loss 0.428054, acc 0.78125, learning_rate 0.00256586\n",
      "2020-12-09T16:14:18.267216: step 344, loss 0.371128, acc 0.875, learning_rate 0.00256256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:14:18.860457: step 345, loss 0.407239, acc 0.8125, learning_rate 0.00255926\n",
      "2020-12-09T16:14:19.432958: step 346, loss 0.540997, acc 0.75, learning_rate 0.00255596\n",
      "2020-12-09T16:14:20.013471: step 347, loss 0.36816, acc 0.9375, learning_rate 0.00255268\n",
      "2020-12-09T16:14:20.584974: step 348, loss 0.381735, acc 0.78125, learning_rate 0.00254939\n",
      "2020-12-09T16:14:21.178513: step 349, loss 0.455517, acc 0.8125, learning_rate 0.00254611\n",
      "2020-12-09T16:14:21.754854: step 350, loss 0.521646, acc 0.71875, learning_rate 0.00254283\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:14:25.039957: step 350, loss 0.617177, acc 0.720151\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-350\n",
      "\n",
      "2020-12-09T16:14:26.498318: step 351, loss 0.520172, acc 0.71875, learning_rate 0.00253956\n",
      "2020-12-09T16:14:27.071422: step 352, loss 0.477961, acc 0.78125, learning_rate 0.00253629\n",
      "2020-12-09T16:14:27.656452: step 353, loss 0.534409, acc 0.78125, learning_rate 0.00253303\n",
      "2020-12-09T16:14:28.259568: step 354, loss 0.61396, acc 0.78125, learning_rate 0.00252977\n",
      "2020-12-09T16:14:28.843605: step 355, loss 0.460562, acc 0.75, learning_rate 0.00252651\n",
      "2020-12-09T16:14:29.439839: step 356, loss 0.40849, acc 0.8125, learning_rate 0.00252326\n",
      "2020-12-09T16:14:30.028835: step 357, loss 0.472008, acc 0.875, learning_rate 0.00252002\n",
      "2020-12-09T16:14:30.605919: step 358, loss 0.416881, acc 0.75, learning_rate 0.00251678\n",
      "2020-12-09T16:14:31.178706: step 359, loss 0.455809, acc 0.75, learning_rate 0.00251354\n",
      "2020-12-09T16:14:31.764156: step 360, loss 0.560924, acc 0.71875, learning_rate 0.00251031\n",
      "2020-12-09T16:14:32.347118: step 361, loss 0.403671, acc 0.875, learning_rate 0.00250708\n",
      "2020-12-09T16:14:32.928122: step 362, loss 0.651048, acc 0.625, learning_rate 0.00250385\n",
      "2020-12-09T16:14:33.504642: step 363, loss 0.522243, acc 0.78125, learning_rate 0.00250063\n",
      "2020-12-09T16:14:34.079077: step 364, loss 0.342966, acc 0.8125, learning_rate 0.00249742\n",
      "2020-12-09T16:14:34.657497: step 365, loss 0.596474, acc 0.6875, learning_rate 0.0024942\n",
      "2020-12-09T16:14:35.238008: step 366, loss 0.518321, acc 0.78125, learning_rate 0.002491\n",
      "2020-12-09T16:14:35.809222: step 367, loss 0.565225, acc 0.8125, learning_rate 0.00248779\n",
      "2020-12-09T16:14:36.392649: step 368, loss 0.524601, acc 0.75, learning_rate 0.0024846\n",
      "2020-12-09T16:14:36.967578: step 369, loss 0.618119, acc 0.6875, learning_rate 0.0024814\n",
      "2020-12-09T16:14:37.557220: step 370, loss 0.647552, acc 0.75, learning_rate 0.00247821\n",
      "2020-12-09T16:14:38.152090: step 371, loss 0.485111, acc 0.71875, learning_rate 0.00247503\n",
      "2020-12-09T16:14:38.721989: step 372, loss 0.517329, acc 0.8125, learning_rate 0.00247184\n",
      "2020-12-09T16:14:39.287823: step 373, loss 0.392477, acc 0.8125, learning_rate 0.00246867\n",
      "2020-12-09T16:14:39.878720: step 374, loss 0.560307, acc 0.71875, learning_rate 0.00246549\n",
      "2020-12-09T16:14:40.456219: step 375, loss 0.233904, acc 0.90625, learning_rate 0.00246233\n",
      "2020-12-09T16:14:41.018606: step 376, loss 0.485697, acc 0.78125, learning_rate 0.00245916\n",
      "2020-12-09T16:14:41.616644: step 377, loss 0.470187, acc 0.75, learning_rate 0.002456\n",
      "2020-12-09T16:14:42.199908: step 378, loss 0.759231, acc 0.65625, learning_rate 0.00245284\n",
      "2020-12-09T16:14:42.777770: step 379, loss 0.49012, acc 0.8125, learning_rate 0.00244969\n",
      "2020-12-09T16:14:43.353860: step 380, loss 0.48139, acc 0.78125, learning_rate 0.00244655\n",
      "2020-12-09T16:14:43.953048: step 381, loss 0.546807, acc 0.71875, learning_rate 0.0024434\n",
      "2020-12-09T16:14:44.523015: step 382, loss 0.515885, acc 0.78125, learning_rate 0.00244026\n",
      "2020-12-09T16:14:45.126491: step 383, loss 0.499013, acc 0.75, learning_rate 0.00243713\n",
      "2020-12-09T16:14:45.778025: step 384, loss 0.431169, acc 0.8125, learning_rate 0.002434\n",
      "2020-12-09T16:14:46.369025: step 385, loss 0.510032, acc 0.6875, learning_rate 0.00243087\n",
      "2020-12-09T16:14:46.977993: step 386, loss 0.448806, acc 0.78125, learning_rate 0.00242775\n",
      "2020-12-09T16:14:47.564496: step 387, loss 0.571338, acc 0.75, learning_rate 0.00242463\n",
      "2020-12-09T16:14:48.168529: step 388, loss 0.636753, acc 0.71875, learning_rate 0.00242152\n",
      "2020-12-09T16:14:48.772491: step 389, loss 0.466501, acc 0.84375, learning_rate 0.00241841\n",
      "2020-12-09T16:14:49.369491: step 390, loss 0.364163, acc 0.84375, learning_rate 0.0024153\n",
      "2020-12-09T16:14:49.975990: step 391, loss 0.447817, acc 0.875, learning_rate 0.0024122\n",
      "2020-12-09T16:14:50.588497: step 392, loss 0.419292, acc 0.75, learning_rate 0.0024091\n",
      "2020-12-09T16:14:51.189991: step 393, loss 0.679679, acc 0.71875, learning_rate 0.00240601\n",
      "2020-12-09T16:14:51.774495: step 394, loss 0.666798, acc 0.71875, learning_rate 0.00240292\n",
      "2020-12-09T16:14:52.365995: step 395, loss 0.60065, acc 0.71875, learning_rate 0.00239984\n",
      "2020-12-09T16:14:52.982495: step 396, loss 0.695706, acc 0.625, learning_rate 0.00239675\n",
      "2020-12-09T16:14:53.583994: step 397, loss 0.600653, acc 0.6875, learning_rate 0.00239368\n",
      "2020-12-09T16:14:54.170024: step 398, loss 0.584768, acc 0.71875, learning_rate 0.00239061\n",
      "2020-12-09T16:14:54.787994: step 399, loss 0.339843, acc 0.84375, learning_rate 0.00238754\n",
      "2020-12-09T16:14:55.389530: step 400, loss 0.451704, acc 0.8125, learning_rate 0.00238447\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:14:58.693494: step 400, loss 0.614135, acc 0.718894\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-400\n",
      "\n",
      "2020-12-09T16:15:00.220524: step 401, loss 0.607266, acc 0.75, learning_rate 0.00238141\n",
      "2020-12-09T16:15:00.836996: step 402, loss 0.446223, acc 0.84375, learning_rate 0.00237836\n",
      "2020-12-09T16:15:01.431996: step 403, loss 0.505911, acc 0.75, learning_rate 0.0023753\n",
      "2020-12-09T16:15:02.006524: step 404, loss 0.637439, acc 0.6875, learning_rate 0.00237226\n",
      "2020-12-09T16:15:02.615990: step 405, loss 0.665466, acc 0.625, learning_rate 0.00236921\n",
      "2020-12-09T16:15:03.216490: step 406, loss 0.526115, acc 0.8125, learning_rate 0.00236617\n",
      "2020-12-09T16:15:03.817491: step 407, loss 0.438514, acc 0.75, learning_rate 0.00236314\n",
      "2020-12-09T16:15:04.455026: step 408, loss 0.429914, acc 0.90625, learning_rate 0.00236011\n",
      "2020-12-09T16:15:05.061496: step 409, loss 0.413782, acc 0.78125, learning_rate 0.00235708\n",
      "2020-12-09T16:15:05.677350: step 410, loss 0.402769, acc 0.75, learning_rate 0.00235405\n",
      "2020-12-09T16:15:06.302383: step 411, loss 0.449747, acc 0.75, learning_rate 0.00235104\n",
      "2020-12-09T16:15:06.921380: step 412, loss 0.365249, acc 0.875, learning_rate 0.00234802\n",
      "2020-12-09T16:15:07.530349: step 413, loss 0.491851, acc 0.78125, learning_rate 0.00234501\n",
      "2020-12-09T16:15:08.141881: step 414, loss 0.675174, acc 0.71875, learning_rate 0.002342\n",
      "2020-12-09T16:15:08.743849: step 415, loss 0.679534, acc 0.65625, learning_rate 0.002339\n",
      "2020-12-09T16:15:09.341850: step 416, loss 0.652225, acc 0.65625, learning_rate 0.002336\n",
      "2020-12-09T16:15:09.951850: step 417, loss 0.579916, acc 0.75, learning_rate 0.002333\n",
      "2020-12-09T16:15:10.537350: step 418, loss 0.528233, acc 0.6875, learning_rate 0.00233001\n",
      "2020-12-09T16:15:11.142350: step 419, loss 0.472458, acc 0.71875, learning_rate 0.00232702\n",
      "2020-12-09T16:15:11.749878: step 420, loss 0.512638, acc 0.75, learning_rate 0.00232404\n",
      "2020-12-09T16:15:12.353345: step 421, loss 0.36234, acc 0.8125, learning_rate 0.00232106\n",
      "2020-12-09T16:15:12.967847: step 422, loss 0.498403, acc 0.75, learning_rate 0.00231809\n",
      "2020-12-09T16:15:13.587883: step 423, loss 0.613786, acc 0.65625, learning_rate 0.00231512\n",
      "2020-12-09T16:15:14.187851: step 424, loss 0.593256, acc 0.6875, learning_rate 0.00231215\n",
      "2020-12-09T16:15:14.785881: step 425, loss 0.325851, acc 0.90625, learning_rate 0.00230919\n",
      "2020-12-09T16:15:15.393878: step 426, loss 0.480302, acc 0.8125, learning_rate 0.00230623\n",
      "2020-12-09T16:15:15.987880: step 427, loss 0.672883, acc 0.78125, learning_rate 0.00230327\n",
      "2020-12-09T16:15:16.592349: step 428, loss 0.29161, acc 0.90625, learning_rate 0.00230032\n",
      "2020-12-09T16:15:17.225846: step 429, loss 0.57634, acc 0.71875, learning_rate 0.00229737\n",
      "2020-12-09T16:15:17.842845: step 430, loss 0.341185, acc 0.875, learning_rate 0.00229443\n",
      "2020-12-09T16:15:18.467382: step 431, loss 0.338055, acc 0.84375, learning_rate 0.00229149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:15:19.074883: step 432, loss 0.428696, acc 0.71875, learning_rate 0.00228855\n",
      "2020-12-09T16:15:19.667845: step 433, loss 0.430041, acc 0.8125, learning_rate 0.00228562\n",
      "2020-12-09T16:15:20.261930: step 434, loss 0.596902, acc 0.71875, learning_rate 0.00228269\n",
      "2020-12-09T16:15:20.850435: step 435, loss 0.559195, acc 0.78125, learning_rate 0.00227977\n",
      "2020-12-09T16:15:21.433429: step 436, loss 0.244823, acc 0.90625, learning_rate 0.00227685\n",
      "2020-12-09T16:15:22.001386: step 437, loss 0.475399, acc 0.8125, learning_rate 0.00227393\n",
      "2020-12-09T16:15:22.578969: step 438, loss 0.354173, acc 0.78125, learning_rate 0.00227102\n",
      "2020-12-09T16:15:23.160075: step 439, loss 0.574256, acc 0.84375, learning_rate 0.00226811\n",
      "2020-12-09T16:15:23.795362: step 440, loss 0.529342, acc 0.875, learning_rate 0.00226521\n",
      "2020-12-09T16:15:24.392809: step 441, loss 0.306318, acc 0.875, learning_rate 0.00226231\n",
      "2020-12-09T16:15:24.963847: step 442, loss 0.671167, acc 0.59375, learning_rate 0.00225941\n",
      "2020-12-09T16:15:25.555122: step 443, loss 0.434144, acc 0.71875, learning_rate 0.00225652\n",
      "2020-12-09T16:15:26.145918: step 444, loss 0.502324, acc 0.78125, learning_rate 0.00225363\n",
      "2020-12-09T16:15:26.737329: step 445, loss 0.428192, acc 0.8125, learning_rate 0.00225075\n",
      "2020-12-09T16:15:27.313328: step 446, loss 0.44028, acc 0.78125, learning_rate 0.00224786\n",
      "2020-12-09T16:15:27.884821: step 447, loss 0.329999, acc 0.84375, learning_rate 0.00224499\n",
      "2020-12-09T16:15:28.462252: step 448, loss 0.453806, acc 0.78125, learning_rate 0.00224211\n",
      "2020-12-09T16:15:29.030271: step 449, loss 0.663704, acc 0.8125, learning_rate 0.00223924\n",
      "2020-12-09T16:15:29.601066: step 450, loss 0.577392, acc 0.71875, learning_rate 0.00223638\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:15:32.900656: step 450, loss 0.617642, acc 0.726016\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-450\n",
      "\n",
      "2020-12-09T16:15:34.459855: step 451, loss 0.489748, acc 0.8125, learning_rate 0.00223352\n",
      "2020-12-09T16:15:35.014831: step 452, loss 0.574361, acc 0.75, learning_rate 0.00223066\n",
      "2020-12-09T16:15:35.599492: step 453, loss 0.521341, acc 0.78125, learning_rate 0.00222781\n",
      "2020-12-09T16:15:36.209477: step 454, loss 0.666614, acc 0.6875, learning_rate 0.00222496\n",
      "2020-12-09T16:15:36.800477: step 455, loss 0.646725, acc 0.78125, learning_rate 0.00222211\n",
      "2020-12-09T16:15:37.368484: step 456, loss 0.413895, acc 0.71875, learning_rate 0.00221927\n",
      "2020-12-09T16:15:38.017732: step 457, loss 0.480286, acc 0.8125, learning_rate 0.00221643\n",
      "2020-12-09T16:15:38.587320: step 458, loss 0.532378, acc 0.78125, learning_rate 0.00221359\n",
      "2020-12-09T16:15:39.158151: step 459, loss 0.527587, acc 0.75, learning_rate 0.00221076\n",
      "2020-12-09T16:15:39.728400: step 460, loss 0.48279, acc 0.78125, learning_rate 0.00220793\n",
      "2020-12-09T16:15:40.306193: step 461, loss 0.358428, acc 0.84375, learning_rate 0.00220511\n",
      "2020-12-09T16:15:40.899975: step 462, loss 0.403881, acc 0.84375, learning_rate 0.00220229\n",
      "2020-12-09T16:15:41.477443: step 463, loss 0.452734, acc 0.78125, learning_rate 0.00219947\n",
      "2020-12-09T16:15:42.061741: step 464, loss 0.45801, acc 0.78125, learning_rate 0.00219666\n",
      "2020-12-09T16:15:42.629070: step 465, loss 0.539635, acc 0.75, learning_rate 0.00219385\n",
      "2020-12-09T16:15:43.195109: step 466, loss 0.423194, acc 0.8125, learning_rate 0.00219105\n",
      "2020-12-09T16:15:43.768451: step 467, loss 0.455326, acc 0.71875, learning_rate 0.00218825\n",
      "2020-12-09T16:15:44.337903: step 468, loss 0.452549, acc 0.8125, learning_rate 0.00218545\n",
      "2020-12-09T16:15:44.921309: step 469, loss 0.736202, acc 0.78125, learning_rate 0.00218266\n",
      "2020-12-09T16:15:45.505712: step 470, loss 0.347321, acc 0.84375, learning_rate 0.00217987\n",
      "2020-12-09T16:15:46.099070: step 471, loss 0.479936, acc 0.78125, learning_rate 0.00217708\n",
      "2020-12-09T16:15:46.680026: step 472, loss 0.446595, acc 0.78125, learning_rate 0.0021743\n",
      "2020-12-09T16:15:47.247690: step 473, loss 0.666751, acc 0.65625, learning_rate 0.00217152\n",
      "2020-12-09T16:15:47.824670: step 474, loss 0.349601, acc 0.90625, learning_rate 0.00216874\n",
      "2020-12-09T16:15:48.401241: step 475, loss 0.269322, acc 0.875, learning_rate 0.00216597\n",
      "2020-12-09T16:15:48.977241: step 476, loss 0.470241, acc 0.8125, learning_rate 0.00216321\n",
      "2020-12-09T16:15:49.548154: step 477, loss 0.493903, acc 0.78125, learning_rate 0.00216044\n",
      "2020-12-09T16:15:50.114354: step 478, loss 0.587103, acc 0.59375, learning_rate 0.00215768\n",
      "2020-12-09T16:15:50.675593: step 479, loss 0.352726, acc 0.875, learning_rate 0.00215492\n",
      "2020-12-09T16:15:51.254819: step 480, loss 0.638028, acc 0.75, learning_rate 0.00215217\n",
      "2020-12-09T16:15:51.817227: step 481, loss 0.380879, acc 0.78125, learning_rate 0.00214942\n",
      "2020-12-09T16:15:52.389743: step 482, loss 0.437737, acc 0.875, learning_rate 0.00214668\n",
      "2020-12-09T16:15:52.962215: step 483, loss 0.576888, acc 0.75, learning_rate 0.00214394\n",
      "2020-12-09T16:15:53.545046: step 484, loss 0.415973, acc 0.8125, learning_rate 0.0021412\n",
      "2020-12-09T16:15:54.150453: step 485, loss 0.425602, acc 0.8125, learning_rate 0.00213846\n",
      "2020-12-09T16:15:54.726379: step 486, loss 0.409074, acc 0.84375, learning_rate 0.00213573\n",
      "2020-12-09T16:15:55.307112: step 487, loss 0.376922, acc 0.75, learning_rate 0.00213301\n",
      "2020-12-09T16:15:55.876955: step 488, loss 0.583508, acc 0.71875, learning_rate 0.00213028\n",
      "2020-12-09T16:15:56.460951: step 489, loss 0.673911, acc 0.71875, learning_rate 0.00212756\n",
      "2020-12-09T16:15:57.042954: step 490, loss 0.550976, acc 0.8125, learning_rate 0.00212485\n",
      "2020-12-09T16:15:57.613915: step 491, loss 0.532146, acc 0.75, learning_rate 0.00212213\n",
      "2020-12-09T16:15:58.201769: step 492, loss 0.336056, acc 0.875, learning_rate 0.00211943\n",
      "2020-12-09T16:15:58.803146: step 493, loss 0.521753, acc 0.6875, learning_rate 0.00211672\n",
      "2020-12-09T16:15:59.383109: step 494, loss 0.581038, acc 0.8125, learning_rate 0.00211402\n",
      "2020-12-09T16:15:59.991566: step 495, loss 0.63725, acc 0.71875, learning_rate 0.00211132\n",
      "2020-12-09T16:16:00.581416: step 496, loss 0.42462, acc 0.84375, learning_rate 0.00210863\n",
      "2020-12-09T16:16:01.147387: step 497, loss 0.647805, acc 0.71875, learning_rate 0.00210594\n",
      "2020-12-09T16:16:01.731923: step 498, loss 0.342668, acc 0.875, learning_rate 0.00210325\n",
      "2020-12-09T16:16:02.319737: step 499, loss 0.52867, acc 0.65625, learning_rate 0.00210057\n",
      "2020-12-09T16:16:02.910848: step 500, loss 0.537137, acc 0.78125, learning_rate 0.00209789\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:16:06.145045: step 500, loss 0.617414, acc 0.717218\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-500\n",
      "\n",
      "2020-12-09T16:16:07.658803: step 501, loss 0.640311, acc 0.71875, learning_rate 0.00209521\n",
      "2020-12-09T16:16:08.244997: step 502, loss 0.376599, acc 0.78125, learning_rate 0.00209254\n",
      "2020-12-09T16:16:08.837301: step 503, loss 0.507667, acc 0.8125, learning_rate 0.00208987\n",
      "2020-12-09T16:16:09.410869: step 504, loss 0.493263, acc 0.75, learning_rate 0.0020872\n",
      "2020-12-09T16:16:10.006246: step 505, loss 0.508563, acc 0.8125, learning_rate 0.00208454\n",
      "2020-12-09T16:16:10.601434: step 506, loss 0.433558, acc 0.8125, learning_rate 0.00208188\n",
      "2020-12-09T16:16:11.186935: step 507, loss 0.582309, acc 0.78125, learning_rate 0.00207923\n",
      "2020-12-09T16:16:11.778974: step 508, loss 0.425224, acc 0.75, learning_rate 0.00207658\n",
      "2020-12-09T16:16:12.361983: step 509, loss 0.534654, acc 0.75, learning_rate 0.00207393\n",
      "2020-12-09T16:16:12.948477: step 510, loss 0.455721, acc 0.84375, learning_rate 0.00207128\n",
      "2020-12-09T16:16:13.515996: step 511, loss 0.356073, acc 0.84375, learning_rate 0.00206864\n",
      "2020-12-09T16:16:14.121942: step 512, loss 0.620137, acc 0.65625, learning_rate 0.00206601\n",
      "2020-12-09T16:16:14.721068: step 513, loss 0.471907, acc 0.6875, learning_rate 0.00206337\n",
      "2020-12-09T16:16:15.272572: step 514, loss 0.630235, acc 0.59375, learning_rate 0.00206074\n",
      "2020-12-09T16:16:15.857574: step 515, loss 0.776437, acc 0.78125, learning_rate 0.00205812\n",
      "2020-12-09T16:16:16.434873: step 516, loss 0.311347, acc 0.875, learning_rate 0.00205549\n",
      "2020-12-09T16:16:17.002154: step 517, loss 0.582273, acc 0.78125, learning_rate 0.00205287\n",
      "2020-12-09T16:16:17.573695: step 518, loss 0.508111, acc 0.71875, learning_rate 0.00205026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:16:18.182850: step 519, loss 0.489697, acc 0.75, learning_rate 0.00204765\n",
      "2020-12-09T16:16:18.790141: step 520, loss 0.471524, acc 0.75, learning_rate 0.00204504\n",
      "2020-12-09T16:16:19.361155: step 521, loss 0.474914, acc 0.75, learning_rate 0.00204243\n",
      "2020-12-09T16:16:19.951143: step 522, loss 0.60764, acc 0.78125, learning_rate 0.00203983\n",
      "2020-12-09T16:16:20.583823: step 523, loss 0.368012, acc 0.8125, learning_rate 0.00203723\n",
      "2020-12-09T16:16:21.152616: step 524, loss 0.353818, acc 0.84375, learning_rate 0.00203464\n",
      "2020-12-09T16:16:21.720580: step 525, loss 0.375217, acc 0.8125, learning_rate 0.00203204\n",
      "2020-12-09T16:16:22.308957: step 526, loss 0.795382, acc 0.65625, learning_rate 0.00202946\n",
      "2020-12-09T16:16:22.876949: step 527, loss 0.540304, acc 0.78125, learning_rate 0.00202687\n",
      "2020-12-09T16:16:23.457369: step 528, loss 0.686757, acc 0.625, learning_rate 0.00202429\n",
      "2020-12-09T16:16:24.024817: step 529, loss 0.504952, acc 0.71875, learning_rate 0.00202171\n",
      "2020-12-09T16:16:24.608538: step 530, loss 0.361813, acc 0.84375, learning_rate 0.00201914\n",
      "2020-12-09T16:16:25.184830: step 531, loss 0.516163, acc 0.6875, learning_rate 0.00201657\n",
      "2020-12-09T16:16:25.761031: step 532, loss 0.658249, acc 0.71875, learning_rate 0.002014\n",
      "2020-12-09T16:16:26.353515: step 533, loss 0.241328, acc 0.875, learning_rate 0.00201144\n",
      "2020-12-09T16:16:26.943419: step 534, loss 0.378285, acc 0.875, learning_rate 0.00200888\n",
      "2020-12-09T16:16:27.554946: step 535, loss 0.622346, acc 0.71875, learning_rate 0.00200632\n",
      "2020-12-09T16:16:28.151857: step 536, loss 0.39034, acc 0.8125, learning_rate 0.00200376\n",
      "2020-12-09T16:16:28.750703: step 537, loss 0.439859, acc 0.8125, learning_rate 0.00200121\n",
      "2020-12-09T16:16:29.338703: step 538, loss 0.664338, acc 0.75, learning_rate 0.00199867\n",
      "2020-12-09T16:16:29.929206: step 539, loss 0.493647, acc 0.8125, learning_rate 0.00199612\n",
      "2020-12-09T16:16:30.499730: step 540, loss 0.509672, acc 0.78125, learning_rate 0.00199358\n",
      "2020-12-09T16:16:31.102886: step 541, loss 0.663783, acc 0.6875, learning_rate 0.00199105\n",
      "2020-12-09T16:16:31.701242: step 542, loss 0.484848, acc 0.8125, learning_rate 0.00198851\n",
      "2020-12-09T16:16:32.300743: step 543, loss 0.512968, acc 0.78125, learning_rate 0.00198598\n",
      "2020-12-09T16:16:32.880667: step 544, loss 0.557369, acc 0.78125, learning_rate 0.00198346\n",
      "2020-12-09T16:16:33.450628: step 545, loss 0.548674, acc 0.75, learning_rate 0.00198094\n",
      "2020-12-09T16:16:34.041985: step 546, loss 0.413567, acc 0.9375, learning_rate 0.00197842\n",
      "2020-12-09T16:16:34.633825: step 547, loss 0.552262, acc 0.78125, learning_rate 0.0019759\n",
      "2020-12-09T16:16:35.219843: step 548, loss 0.360546, acc 0.8125, learning_rate 0.00197339\n",
      "2020-12-09T16:16:35.800736: step 549, loss 0.373523, acc 0.8125, learning_rate 0.00197088\n",
      "2020-12-09T16:16:36.387758: step 550, loss 0.413227, acc 0.8125, learning_rate 0.00196837\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:16:39.548416: step 550, loss 0.589406, acc 0.739841\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-550\n",
      "\n",
      "2020-12-09T16:16:41.022745: step 551, loss 0.38609, acc 0.84375, learning_rate 0.00196587\n",
      "2020-12-09T16:16:41.594214: step 552, loss 0.438432, acc 0.84375, learning_rate 0.00196337\n",
      "2020-12-09T16:16:42.173657: step 553, loss 0.546461, acc 0.75, learning_rate 0.00196087\n",
      "2020-12-09T16:16:42.755739: step 554, loss 0.349508, acc 0.875, learning_rate 0.00195838\n",
      "2020-12-09T16:16:43.330460: step 555, loss 0.671077, acc 0.71875, learning_rate 0.00195589\n",
      "2020-12-09T16:16:43.916674: step 556, loss 0.561042, acc 0.8125, learning_rate 0.0019534\n",
      "2020-12-09T16:16:44.525652: step 557, loss 0.513855, acc 0.75, learning_rate 0.00195092\n",
      "2020-12-09T16:16:45.127167: step 558, loss 0.72499, acc 0.71875, learning_rate 0.00194844\n",
      "2020-12-09T16:16:45.703665: step 559, loss 0.608862, acc 0.71875, learning_rate 0.00194597\n",
      "2020-12-09T16:16:46.278036: step 560, loss 0.426525, acc 0.78125, learning_rate 0.00194349\n",
      "2020-12-09T16:16:46.840169: step 561, loss 0.468212, acc 0.84375, learning_rate 0.00194102\n",
      "2020-12-09T16:16:47.418926: step 562, loss 0.849415, acc 0.75, learning_rate 0.00193856\n",
      "2020-12-09T16:16:48.008739: step 563, loss 0.489145, acc 0.71875, learning_rate 0.0019361\n",
      "2020-12-09T16:16:48.579014: step 564, loss 0.528647, acc 0.78125, learning_rate 0.00193364\n",
      "2020-12-09T16:16:49.172240: step 565, loss 0.337974, acc 0.875, learning_rate 0.00193118\n",
      "2020-12-09T16:16:49.737987: step 566, loss 0.453933, acc 0.8125, learning_rate 0.00192873\n",
      "2020-12-09T16:16:50.317257: step 567, loss 0.558152, acc 0.8125, learning_rate 0.00192628\n",
      "2020-12-09T16:16:50.912513: step 568, loss 0.451854, acc 0.78125, learning_rate 0.00192383\n",
      "2020-12-09T16:16:51.485482: step 569, loss 0.439512, acc 0.65625, learning_rate 0.00192139\n",
      "2020-12-09T16:16:52.069467: step 570, loss 0.446502, acc 0.8125, learning_rate 0.00191895\n",
      "2020-12-09T16:16:52.668222: step 571, loss 0.552734, acc 0.6875, learning_rate 0.00191651\n",
      "2020-12-09T16:16:53.264273: step 572, loss 0.496531, acc 0.75, learning_rate 0.00191408\n",
      "2020-12-09T16:16:53.829618: step 573, loss 0.587055, acc 0.65625, learning_rate 0.00191165\n",
      "2020-12-09T16:16:54.432279: step 574, loss 0.527629, acc 0.78125, learning_rate 0.00190922\n",
      "2020-12-09T16:16:55.040531: step 575, loss 0.698653, acc 0.71875, learning_rate 0.0019068\n",
      "2020-12-09T16:16:55.613599: step 576, loss 0.43014, acc 0.78125, learning_rate 0.00190438\n",
      "2020-12-09T16:16:56.204481: step 577, loss 0.522604, acc 0.8125, learning_rate 0.00190196\n",
      "2020-12-09T16:16:56.810722: step 578, loss 0.356499, acc 0.84375, learning_rate 0.00189955\n",
      "2020-12-09T16:16:57.400184: step 579, loss 0.411794, acc 0.75, learning_rate 0.00189714\n",
      "2020-12-09T16:16:57.964593: step 580, loss 0.491635, acc 0.84375, learning_rate 0.00189473\n",
      "2020-12-09T16:16:58.544822: step 581, loss 0.426567, acc 0.78125, learning_rate 0.00189232\n",
      "2020-12-09T16:16:59.126869: step 582, loss 0.514489, acc 0.8125, learning_rate 0.00188992\n",
      "2020-12-09T16:16:59.698944: step 583, loss 0.451457, acc 0.75, learning_rate 0.00188753\n",
      "2020-12-09T16:17:00.286395: step 584, loss 0.46476, acc 0.75, learning_rate 0.00188513\n",
      "2020-12-09T16:17:00.849536: step 585, loss 0.506263, acc 0.75, learning_rate 0.00188274\n",
      "2020-12-09T16:17:01.425028: step 586, loss 0.561505, acc 0.75, learning_rate 0.00188035\n",
      "2020-12-09T16:17:01.990033: step 587, loss 0.459081, acc 0.8125, learning_rate 0.00187797\n",
      "2020-12-09T16:17:02.572030: step 588, loss 0.633831, acc 0.71875, learning_rate 0.00187558\n",
      "2020-12-09T16:17:03.186623: step 589, loss 0.353276, acc 0.875, learning_rate 0.00187321\n",
      "2020-12-09T16:17:03.767614: step 590, loss 0.371563, acc 0.84375, learning_rate 0.00187083\n",
      "2020-12-09T16:17:04.367622: step 591, loss 0.408842, acc 0.875, learning_rate 0.00186846\n",
      "2020-12-09T16:17:04.960082: step 592, loss 0.362927, acc 0.8125, learning_rate 0.00186609\n",
      "2020-12-09T16:17:05.557082: step 593, loss 0.54144, acc 0.75, learning_rate 0.00186372\n",
      "2020-12-09T16:17:06.154044: step 594, loss 0.513079, acc 0.71875, learning_rate 0.00186136\n",
      "2020-12-09T16:17:06.733099: step 595, loss 0.505539, acc 0.75, learning_rate 0.001859\n",
      "2020-12-09T16:17:07.322854: step 596, loss 0.388509, acc 0.78125, learning_rate 0.00185665\n",
      "2020-12-09T16:17:07.902649: step 597, loss 0.281617, acc 0.90625, learning_rate 0.00185429\n",
      "2020-12-09T16:17:08.161687: step 598, loss 0.369543, acc 1, learning_rate 0.00185194\n",
      "2020-12-09T16:17:08.729977: step 599, loss 0.419298, acc 0.84375, learning_rate 0.0018496\n",
      "2020-12-09T16:17:09.313544: step 600, loss 0.384404, acc 0.8125, learning_rate 0.00184725\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:17:12.604272: step 600, loss 0.595642, acc 0.730205\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-600\n",
      "\n",
      "2020-12-09T16:17:14.050279: step 601, loss 0.450211, acc 0.78125, learning_rate 0.00184491\n",
      "2020-12-09T16:17:14.632836: step 602, loss 0.432912, acc 0.78125, learning_rate 0.00184257\n",
      "2020-12-09T16:17:15.231910: step 603, loss 0.246466, acc 0.90625, learning_rate 0.00184024\n",
      "2020-12-09T16:17:15.798905: step 604, loss 0.263901, acc 0.875, learning_rate 0.00183791\n",
      "2020-12-09T16:17:16.381411: step 605, loss 0.411307, acc 0.78125, learning_rate 0.00183558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:17:16.976320: step 606, loss 0.172661, acc 0.90625, learning_rate 0.00183326\n",
      "2020-12-09T16:17:17.602401: step 607, loss 0.190564, acc 0.90625, learning_rate 0.00183093\n",
      "2020-12-09T16:17:18.179955: step 608, loss 0.14769, acc 0.96875, learning_rate 0.00182862\n",
      "2020-12-09T16:17:18.767041: step 609, loss 0.260686, acc 0.84375, learning_rate 0.0018263\n",
      "2020-12-09T16:17:19.345079: step 610, loss 0.321518, acc 0.8125, learning_rate 0.00182399\n",
      "2020-12-09T16:17:19.906936: step 611, loss 0.454015, acc 0.8125, learning_rate 0.00182168\n",
      "2020-12-09T16:17:20.486627: step 612, loss 0.527094, acc 0.75, learning_rate 0.00181937\n",
      "2020-12-09T16:17:21.059721: step 613, loss 0.479332, acc 0.78125, learning_rate 0.00181707\n",
      "2020-12-09T16:17:21.632722: step 614, loss 0.322704, acc 0.8125, learning_rate 0.00181477\n",
      "2020-12-09T16:17:22.218756: step 615, loss 0.358094, acc 0.8125, learning_rate 0.00181247\n",
      "2020-12-09T16:17:22.812330: step 616, loss 0.579144, acc 0.71875, learning_rate 0.00181018\n",
      "2020-12-09T16:17:23.403211: step 617, loss 0.522192, acc 0.75, learning_rate 0.00180789\n",
      "2020-12-09T16:17:23.977712: step 618, loss 0.266792, acc 0.84375, learning_rate 0.0018056\n",
      "2020-12-09T16:17:24.552197: step 619, loss 0.32861, acc 0.9375, learning_rate 0.00180331\n",
      "2020-12-09T16:17:25.124491: step 620, loss 0.324492, acc 0.84375, learning_rate 0.00180103\n",
      "2020-12-09T16:17:25.718958: step 621, loss 0.66534, acc 0.78125, learning_rate 0.00179875\n",
      "2020-12-09T16:17:26.292065: step 622, loss 0.369474, acc 0.84375, learning_rate 0.00179648\n",
      "2020-12-09T16:17:26.881510: step 623, loss 0.39694, acc 0.78125, learning_rate 0.00179421\n",
      "2020-12-09T16:17:27.486803: step 624, loss 0.288388, acc 0.9375, learning_rate 0.00179194\n",
      "2020-12-09T16:17:28.067689: step 625, loss 0.429019, acc 0.78125, learning_rate 0.00178967\n",
      "2020-12-09T16:17:28.639773: step 626, loss 0.331027, acc 0.84375, learning_rate 0.00178741\n",
      "2020-12-09T16:17:29.215058: step 627, loss 0.277254, acc 0.90625, learning_rate 0.00178515\n",
      "2020-12-09T16:17:29.790483: step 628, loss 0.202088, acc 0.9375, learning_rate 0.00178289\n",
      "2020-12-09T16:17:30.366447: step 629, loss 0.439965, acc 0.8125, learning_rate 0.00178063\n",
      "2020-12-09T16:17:30.952632: step 630, loss 0.30272, acc 0.875, learning_rate 0.00177838\n",
      "2020-12-09T16:17:31.521594: step 631, loss 0.351654, acc 0.84375, learning_rate 0.00177613\n",
      "2020-12-09T16:17:32.112532: step 632, loss 0.347381, acc 0.875, learning_rate 0.00177389\n",
      "2020-12-09T16:17:32.702984: step 633, loss 0.428945, acc 0.8125, learning_rate 0.00177165\n",
      "2020-12-09T16:17:33.265397: step 634, loss 0.227707, acc 0.9375, learning_rate 0.00176941\n",
      "2020-12-09T16:17:33.837366: step 635, loss 0.180082, acc 0.90625, learning_rate 0.00176717\n",
      "2020-12-09T16:17:34.404318: step 636, loss 0.390486, acc 0.8125, learning_rate 0.00176494\n",
      "2020-12-09T16:17:34.980158: step 637, loss 0.274439, acc 0.875, learning_rate 0.00176271\n",
      "2020-12-09T16:17:35.567710: step 638, loss 0.327551, acc 0.875, learning_rate 0.00176048\n",
      "2020-12-09T16:17:36.177096: step 639, loss 0.172898, acc 0.9375, learning_rate 0.00175826\n",
      "2020-12-09T16:17:36.780592: step 640, loss 0.317316, acc 0.78125, learning_rate 0.00175603\n",
      "2020-12-09T16:17:37.362790: step 641, loss 0.302059, acc 0.8125, learning_rate 0.00175382\n",
      "2020-12-09T16:17:37.968312: step 642, loss 0.22213, acc 0.9375, learning_rate 0.0017516\n",
      "2020-12-09T16:17:38.556342: step 643, loss 0.238489, acc 0.875, learning_rate 0.00174939\n",
      "2020-12-09T16:17:39.141996: step 644, loss 0.57533, acc 0.75, learning_rate 0.00174718\n",
      "2020-12-09T16:17:39.749682: step 645, loss 0.336848, acc 0.875, learning_rate 0.00174497\n",
      "2020-12-09T16:17:40.321872: step 646, loss 0.444583, acc 0.875, learning_rate 0.00174277\n",
      "2020-12-09T16:17:40.938775: step 647, loss 0.335041, acc 0.90625, learning_rate 0.00174057\n",
      "2020-12-09T16:17:41.546870: step 648, loss 0.290461, acc 0.84375, learning_rate 0.00173837\n",
      "2020-12-09T16:17:42.127525: step 649, loss 0.226603, acc 0.9375, learning_rate 0.00173618\n",
      "2020-12-09T16:17:42.697534: step 650, loss 0.277996, acc 0.9375, learning_rate 0.00173398\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:17:45.920162: step 650, loss 0.624809, acc 0.743192\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-650\n",
      "\n",
      "2020-12-09T16:17:47.355835: step 651, loss 0.282643, acc 0.90625, learning_rate 0.0017318\n",
      "2020-12-09T16:17:47.939045: step 652, loss 0.583748, acc 0.78125, learning_rate 0.00172961\n",
      "2020-12-09T16:17:48.531803: step 653, loss 0.322315, acc 0.90625, learning_rate 0.00172743\n",
      "2020-12-09T16:17:49.129108: step 654, loss 0.215796, acc 0.96875, learning_rate 0.00172525\n",
      "2020-12-09T16:17:49.704280: step 655, loss 0.213786, acc 0.90625, learning_rate 0.00172307\n",
      "2020-12-09T16:17:50.292525: step 656, loss 0.3256, acc 0.875, learning_rate 0.0017209\n",
      "2020-12-09T16:17:50.857868: step 657, loss 0.302473, acc 0.8125, learning_rate 0.00171872\n",
      "2020-12-09T16:17:51.444949: step 658, loss 0.476581, acc 0.78125, learning_rate 0.00171656\n",
      "2020-12-09T16:17:52.012450: step 659, loss 0.380322, acc 0.8125, learning_rate 0.00171439\n",
      "2020-12-09T16:17:52.578871: step 660, loss 0.237887, acc 0.875, learning_rate 0.00171223\n",
      "2020-12-09T16:17:53.150326: step 661, loss 0.406418, acc 0.875, learning_rate 0.00171007\n",
      "2020-12-09T16:17:53.743322: step 662, loss 0.242868, acc 0.90625, learning_rate 0.00170791\n",
      "2020-12-09T16:17:54.316571: step 663, loss 0.33483, acc 0.875, learning_rate 0.00170576\n",
      "2020-12-09T16:17:54.887247: step 664, loss 0.747503, acc 0.75, learning_rate 0.00170361\n",
      "2020-12-09T16:17:55.471674: step 665, loss 0.339453, acc 0.875, learning_rate 0.00170146\n",
      "2020-12-09T16:17:56.045635: step 666, loss 0.501108, acc 0.8125, learning_rate 0.00169931\n",
      "2020-12-09T16:17:56.626287: step 667, loss 0.115541, acc 0.96875, learning_rate 0.00169717\n",
      "2020-12-09T16:17:57.209520: step 668, loss 0.194632, acc 0.9375, learning_rate 0.00169503\n",
      "2020-12-09T16:17:57.813642: step 669, loss 0.307639, acc 0.875, learning_rate 0.00169289\n",
      "2020-12-09T16:17:58.391175: step 670, loss 0.356024, acc 0.8125, learning_rate 0.00169076\n",
      "2020-12-09T16:17:58.986061: step 671, loss 0.398145, acc 0.78125, learning_rate 0.00168863\n",
      "2020-12-09T16:17:59.554480: step 672, loss 0.163466, acc 0.9375, learning_rate 0.0016865\n",
      "2020-12-09T16:18:00.131469: step 673, loss 0.259712, acc 0.90625, learning_rate 0.00168438\n",
      "2020-12-09T16:18:00.727417: step 674, loss 0.158624, acc 0.96875, learning_rate 0.00168225\n",
      "2020-12-09T16:18:01.330163: step 675, loss 0.430473, acc 0.875, learning_rate 0.00168013\n",
      "2020-12-09T16:18:01.922724: step 676, loss 0.296886, acc 0.84375, learning_rate 0.00167802\n",
      "2020-12-09T16:18:02.481191: step 677, loss 0.267651, acc 0.9375, learning_rate 0.0016759\n",
      "2020-12-09T16:18:03.085534: step 678, loss 0.252727, acc 0.875, learning_rate 0.00167379\n",
      "2020-12-09T16:18:03.649970: step 679, loss 0.426233, acc 0.78125, learning_rate 0.00167169\n",
      "2020-12-09T16:18:04.225470: step 680, loss 0.342527, acc 0.84375, learning_rate 0.00166958\n",
      "2020-12-09T16:18:04.812507: step 681, loss 0.350242, acc 0.84375, learning_rate 0.00166748\n",
      "2020-12-09T16:18:05.400076: step 682, loss 0.423644, acc 0.78125, learning_rate 0.00166538\n",
      "2020-12-09T16:18:05.982711: step 683, loss 0.242775, acc 0.9375, learning_rate 0.00166328\n",
      "2020-12-09T16:18:06.549685: step 684, loss 0.22502, acc 0.9375, learning_rate 0.00166119\n",
      "2020-12-09T16:18:07.186578: step 685, loss 0.190548, acc 0.9375, learning_rate 0.0016591\n",
      "2020-12-09T16:18:07.782849: step 686, loss 0.431068, acc 0.8125, learning_rate 0.00165701\n",
      "2020-12-09T16:18:08.343352: step 687, loss 0.321286, acc 0.90625, learning_rate 0.00165492\n",
      "2020-12-09T16:18:08.939495: step 688, loss 0.189672, acc 0.9375, learning_rate 0.00165284\n",
      "2020-12-09T16:18:09.561323: step 689, loss 0.433769, acc 0.84375, learning_rate 0.00165076\n",
      "2020-12-09T16:18:10.150159: step 690, loss 0.346031, acc 0.875, learning_rate 0.00164868\n",
      "2020-12-09T16:18:10.728063: step 691, loss 0.491448, acc 0.8125, learning_rate 0.00164661\n",
      "2020-12-09T16:18:11.326244: step 692, loss 0.248869, acc 0.90625, learning_rate 0.00164453\n",
      "2020-12-09T16:18:11.917233: step 693, loss 0.360702, acc 0.84375, learning_rate 0.00164247\n",
      "2020-12-09T16:18:12.493204: step 694, loss 0.256664, acc 0.875, learning_rate 0.0016404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:18:13.098786: step 695, loss 0.352978, acc 0.84375, learning_rate 0.00163834\n",
      "2020-12-09T16:18:13.683148: step 696, loss 0.308662, acc 0.90625, learning_rate 0.00163628\n",
      "2020-12-09T16:18:14.262179: step 697, loss 0.166241, acc 1, learning_rate 0.00163422\n",
      "2020-12-09T16:18:14.862839: step 698, loss 0.278184, acc 0.875, learning_rate 0.00163216\n",
      "2020-12-09T16:18:15.412578: step 699, loss 0.360907, acc 0.8125, learning_rate 0.00163011\n",
      "2020-12-09T16:18:15.987449: step 700, loss 0.264961, acc 0.875, learning_rate 0.00162806\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:18:19.279029: step 700, loss 0.649804, acc 0.734395\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-700\n",
      "\n",
      "2020-12-09T16:18:20.723729: step 701, loss 0.467141, acc 0.84375, learning_rate 0.00162601\n",
      "2020-12-09T16:18:21.313268: step 702, loss 0.378404, acc 0.75, learning_rate 0.00162397\n",
      "2020-12-09T16:18:21.909540: step 703, loss 0.339232, acc 0.84375, learning_rate 0.00162193\n",
      "2020-12-09T16:18:22.478461: step 704, loss 0.311071, acc 0.90625, learning_rate 0.00161989\n",
      "2020-12-09T16:18:23.041938: step 705, loss 0.508269, acc 0.8125, learning_rate 0.00161785\n",
      "2020-12-09T16:18:23.621581: step 706, loss 0.431943, acc 0.78125, learning_rate 0.00161582\n",
      "2020-12-09T16:18:24.178658: step 707, loss 0.350709, acc 0.875, learning_rate 0.00161379\n",
      "2020-12-09T16:18:24.763628: step 708, loss 0.477539, acc 0.78125, learning_rate 0.00161176\n",
      "2020-12-09T16:18:25.368266: step 709, loss 0.295168, acc 0.90625, learning_rate 0.00160974\n",
      "2020-12-09T16:18:25.947214: step 710, loss 0.326643, acc 0.84375, learning_rate 0.00160771\n",
      "2020-12-09T16:18:26.523777: step 711, loss 0.237136, acc 0.875, learning_rate 0.00160569\n",
      "2020-12-09T16:18:27.099463: step 712, loss 0.258239, acc 0.90625, learning_rate 0.00160368\n",
      "2020-12-09T16:18:27.677721: step 713, loss 0.255049, acc 0.90625, learning_rate 0.00160166\n",
      "2020-12-09T16:18:28.266724: step 714, loss 0.306919, acc 0.875, learning_rate 0.00159965\n",
      "2020-12-09T16:18:28.855728: step 715, loss 0.375997, acc 0.8125, learning_rate 0.00159764\n",
      "2020-12-09T16:18:29.434323: step 716, loss 0.169895, acc 0.90625, learning_rate 0.00159564\n",
      "2020-12-09T16:18:30.019686: step 717, loss 0.138758, acc 0.9375, learning_rate 0.00159363\n",
      "2020-12-09T16:18:30.595291: step 718, loss 0.371708, acc 0.84375, learning_rate 0.00159163\n",
      "2020-12-09T16:18:31.157377: step 719, loss 0.324992, acc 0.90625, learning_rate 0.00158963\n",
      "2020-12-09T16:18:31.711071: step 720, loss 0.295706, acc 0.84375, learning_rate 0.00158764\n",
      "2020-12-09T16:18:32.298631: step 721, loss 0.27282, acc 0.84375, learning_rate 0.00158565\n",
      "2020-12-09T16:18:32.879257: step 722, loss 0.550306, acc 0.8125, learning_rate 0.00158366\n",
      "2020-12-09T16:18:33.455293: step 723, loss 0.354869, acc 0.84375, learning_rate 0.00158167\n",
      "2020-12-09T16:18:34.056547: step 724, loss 0.440539, acc 0.84375, learning_rate 0.00157968\n",
      "2020-12-09T16:18:34.628794: step 725, loss 0.648186, acc 0.75, learning_rate 0.0015777\n",
      "2020-12-09T16:18:35.203530: step 726, loss 0.344325, acc 0.84375, learning_rate 0.00157572\n",
      "2020-12-09T16:18:35.829482: step 727, loss 0.345229, acc 0.875, learning_rate 0.00157374\n",
      "2020-12-09T16:18:36.402986: step 728, loss 0.287408, acc 0.84375, learning_rate 0.00157177\n",
      "2020-12-09T16:18:36.972986: step 729, loss 0.387603, acc 0.8125, learning_rate 0.0015698\n",
      "2020-12-09T16:18:37.553833: step 730, loss 0.31447, acc 0.8125, learning_rate 0.00156783\n",
      "2020-12-09T16:18:38.127887: step 731, loss 0.240473, acc 0.90625, learning_rate 0.00156586\n",
      "2020-12-09T16:18:38.691307: step 732, loss 0.451681, acc 0.8125, learning_rate 0.0015639\n",
      "2020-12-09T16:18:39.302311: step 733, loss 0.344062, acc 0.84375, learning_rate 0.00156194\n",
      "2020-12-09T16:18:39.867088: step 734, loss 0.406211, acc 0.84375, learning_rate 0.00155998\n",
      "2020-12-09T16:18:40.435048: step 735, loss 0.209836, acc 0.9375, learning_rate 0.00155803\n",
      "2020-12-09T16:18:40.995189: step 736, loss 0.451614, acc 0.75, learning_rate 0.00155607\n",
      "2020-12-09T16:18:41.557054: step 737, loss 0.153749, acc 0.96875, learning_rate 0.00155412\n",
      "2020-12-09T16:18:42.134051: step 738, loss 0.0884026, acc 0.96875, learning_rate 0.00155217\n",
      "2020-12-09T16:18:42.703111: step 739, loss 0.280074, acc 0.875, learning_rate 0.00155023\n",
      "2020-12-09T16:18:43.299574: step 740, loss 0.299051, acc 0.9375, learning_rate 0.00154829\n",
      "2020-12-09T16:18:43.869109: step 741, loss 0.365907, acc 0.84375, learning_rate 0.00154635\n",
      "2020-12-09T16:18:44.454572: step 742, loss 0.284552, acc 0.90625, learning_rate 0.00154441\n",
      "2020-12-09T16:18:45.034683: step 743, loss 0.312078, acc 0.84375, learning_rate 0.00154247\n",
      "2020-12-09T16:18:45.612109: step 744, loss 0.428393, acc 0.8125, learning_rate 0.00154054\n",
      "2020-12-09T16:18:46.219084: step 745, loss 0.200137, acc 0.9375, learning_rate 0.00153861\n",
      "2020-12-09T16:18:46.791583: step 746, loss 0.397634, acc 0.875, learning_rate 0.00153668\n",
      "2020-12-09T16:18:47.391641: step 747, loss 0.306269, acc 0.84375, learning_rate 0.00153476\n",
      "2020-12-09T16:18:47.979469: step 748, loss 0.374338, acc 0.8125, learning_rate 0.00153284\n",
      "2020-12-09T16:18:48.555279: step 749, loss 0.396076, acc 0.84375, learning_rate 0.00153092\n",
      "2020-12-09T16:18:49.134857: step 750, loss 0.166878, acc 0.9375, learning_rate 0.001529\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:18:52.447693: step 750, loss 0.651383, acc 0.731881\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-750\n",
      "\n",
      "2020-12-09T16:18:54.034215: step 751, loss 0.283443, acc 0.8125, learning_rate 0.00152709\n",
      "2020-12-09T16:18:54.604221: step 752, loss 0.341033, acc 0.90625, learning_rate 0.00152518\n",
      "2020-12-09T16:18:55.184114: step 753, loss 0.243978, acc 0.90625, learning_rate 0.00152327\n",
      "2020-12-09T16:18:55.763144: step 754, loss 0.309133, acc 0.84375, learning_rate 0.00152136\n",
      "2020-12-09T16:18:56.354468: step 755, loss 0.337728, acc 0.90625, learning_rate 0.00151946\n",
      "2020-12-09T16:18:56.940465: step 756, loss 0.569799, acc 0.84375, learning_rate 0.00151755\n",
      "2020-12-09T16:18:57.521695: step 757, loss 0.309876, acc 0.8125, learning_rate 0.00151566\n",
      "2020-12-09T16:18:58.111607: step 758, loss 0.301406, acc 0.875, learning_rate 0.00151376\n",
      "2020-12-09T16:18:58.673107: step 759, loss 0.397516, acc 0.875, learning_rate 0.00151187\n",
      "2020-12-09T16:18:59.258370: step 760, loss 0.232198, acc 0.9375, learning_rate 0.00150997\n",
      "2020-12-09T16:18:59.844803: step 761, loss 0.371097, acc 0.84375, learning_rate 0.00150809\n",
      "2020-12-09T16:19:00.431059: step 762, loss 0.410195, acc 0.8125, learning_rate 0.0015062\n",
      "2020-12-09T16:19:01.007060: step 763, loss 0.377611, acc 0.84375, learning_rate 0.00150432\n",
      "2020-12-09T16:19:01.606827: step 764, loss 0.564583, acc 0.84375, learning_rate 0.00150243\n",
      "2020-12-09T16:19:02.236282: step 765, loss 0.314382, acc 0.875, learning_rate 0.00150056\n",
      "2020-12-09T16:19:02.809875: step 766, loss 0.360282, acc 0.875, learning_rate 0.00149868\n",
      "2020-12-09T16:19:03.388173: step 767, loss 0.301443, acc 0.875, learning_rate 0.00149681\n",
      "2020-12-09T16:19:03.978029: step 768, loss 0.291074, acc 0.84375, learning_rate 0.00149494\n",
      "2020-12-09T16:19:04.542404: step 769, loss 0.316269, acc 0.875, learning_rate 0.00149307\n",
      "2020-12-09T16:19:05.130718: step 770, loss 0.263924, acc 0.90625, learning_rate 0.0014912\n",
      "2020-12-09T16:19:05.717061: step 771, loss 0.257042, acc 0.84375, learning_rate 0.00148934\n",
      "2020-12-09T16:19:06.333646: step 772, loss 0.306044, acc 0.875, learning_rate 0.00148748\n",
      "2020-12-09T16:19:06.907203: step 773, loss 0.452504, acc 0.84375, learning_rate 0.00148562\n",
      "2020-12-09T16:19:07.491497: step 774, loss 0.246022, acc 0.84375, learning_rate 0.00148376\n",
      "2020-12-09T16:19:08.081372: step 775, loss 0.143002, acc 0.96875, learning_rate 0.00148191\n",
      "2020-12-09T16:19:08.662373: step 776, loss 0.206927, acc 0.96875, learning_rate 0.00148006\n",
      "2020-12-09T16:19:09.235019: step 777, loss 0.287727, acc 0.90625, learning_rate 0.00147821\n",
      "2020-12-09T16:19:09.832594: step 778, loss 0.239575, acc 0.9375, learning_rate 0.00147636\n",
      "2020-12-09T16:19:10.419620: step 779, loss 0.196288, acc 0.9375, learning_rate 0.00147452\n",
      "2020-12-09T16:19:10.991521: step 780, loss 0.35187, acc 0.90625, learning_rate 0.00147268\n",
      "2020-12-09T16:19:11.589693: step 781, loss 0.722974, acc 0.75, learning_rate 0.00147084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:19:12.155493: step 782, loss 0.464414, acc 0.75, learning_rate 0.001469\n",
      "2020-12-09T16:19:12.739003: step 783, loss 0.236186, acc 0.875, learning_rate 0.00146717\n",
      "2020-12-09T16:19:13.318029: step 784, loss 0.494115, acc 0.8125, learning_rate 0.00146534\n",
      "2020-12-09T16:19:13.901991: step 785, loss 0.294645, acc 0.84375, learning_rate 0.00146351\n",
      "2020-12-09T16:19:14.501834: step 786, loss 0.203778, acc 0.9375, learning_rate 0.00146168\n",
      "2020-12-09T16:19:15.068835: step 787, loss 0.370912, acc 0.78125, learning_rate 0.00145986\n",
      "2020-12-09T16:19:15.668993: step 788, loss 0.263718, acc 0.875, learning_rate 0.00145804\n",
      "2020-12-09T16:19:16.242998: step 789, loss 0.310317, acc 0.90625, learning_rate 0.00145622\n",
      "2020-12-09T16:19:16.820521: step 790, loss 0.435211, acc 0.8125, learning_rate 0.0014544\n",
      "2020-12-09T16:19:17.403564: step 791, loss 0.371092, acc 0.84375, learning_rate 0.00145258\n",
      "2020-12-09T16:19:17.964712: step 792, loss 0.420111, acc 0.8125, learning_rate 0.00145077\n",
      "2020-12-09T16:19:18.538188: step 793, loss 0.257666, acc 0.90625, learning_rate 0.00144896\n",
      "2020-12-09T16:19:19.114344: step 794, loss 0.311375, acc 0.875, learning_rate 0.00144716\n",
      "2020-12-09T16:19:19.706517: step 795, loss 0.28574, acc 0.90625, learning_rate 0.00144535\n",
      "2020-12-09T16:19:20.284345: step 796, loss 0.382361, acc 0.875, learning_rate 0.00144355\n",
      "2020-12-09T16:19:20.858811: step 797, loss 0.374026, acc 0.875, learning_rate 0.00144175\n",
      "2020-12-09T16:19:21.431841: step 798, loss 0.251089, acc 0.875, learning_rate 0.00143995\n",
      "2020-12-09T16:19:22.034348: step 799, loss 0.463933, acc 0.75, learning_rate 0.00143816\n",
      "2020-12-09T16:19:22.609822: step 800, loss 0.159769, acc 0.96875, learning_rate 0.00143637\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:19:25.931460: step 800, loss 0.65331, acc 0.742354\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-800\n",
      "\n",
      "2020-12-09T16:19:27.391241: step 801, loss 0.851254, acc 0.6875, learning_rate 0.00143458\n",
      "2020-12-09T16:19:27.963337: step 802, loss 0.503287, acc 0.875, learning_rate 0.00143279\n",
      "2020-12-09T16:19:28.554836: step 803, loss 0.193923, acc 0.9375, learning_rate 0.001431\n",
      "2020-12-09T16:19:29.129835: step 804, loss 0.328341, acc 0.8125, learning_rate 0.00142922\n",
      "2020-12-09T16:19:29.716571: step 805, loss 0.326578, acc 0.84375, learning_rate 0.00142744\n",
      "2020-12-09T16:19:30.292916: step 806, loss 0.439823, acc 0.8125, learning_rate 0.00142566\n",
      "2020-12-09T16:19:30.867964: step 807, loss 0.206862, acc 0.9375, learning_rate 0.00142388\n",
      "2020-12-09T16:19:31.439962: step 808, loss 0.207389, acc 0.875, learning_rate 0.00142211\n",
      "2020-12-09T16:19:32.004104: step 809, loss 0.361112, acc 0.875, learning_rate 0.00142034\n",
      "2020-12-09T16:19:32.578101: step 810, loss 0.392478, acc 0.84375, learning_rate 0.00141857\n",
      "2020-12-09T16:19:33.161228: step 811, loss 0.429753, acc 0.84375, learning_rate 0.00141681\n",
      "2020-12-09T16:19:33.759041: step 812, loss 0.29995, acc 0.875, learning_rate 0.00141504\n",
      "2020-12-09T16:19:34.370967: step 813, loss 0.265447, acc 0.875, learning_rate 0.00141328\n",
      "2020-12-09T16:19:34.940529: step 814, loss 0.20775, acc 0.90625, learning_rate 0.00141152\n",
      "2020-12-09T16:19:35.514997: step 815, loss 0.271262, acc 0.84375, learning_rate 0.00140976\n",
      "2020-12-09T16:19:36.085628: step 816, loss 0.543036, acc 0.8125, learning_rate 0.00140801\n",
      "2020-12-09T16:19:36.660758: step 817, loss 0.198597, acc 0.90625, learning_rate 0.00140626\n",
      "2020-12-09T16:19:37.252709: step 818, loss 0.20812, acc 0.96875, learning_rate 0.00140451\n",
      "2020-12-09T16:19:37.852244: step 819, loss 0.267575, acc 0.90625, learning_rate 0.00140276\n",
      "2020-12-09T16:19:38.491126: step 820, loss 0.230041, acc 0.90625, learning_rate 0.00140101\n",
      "2020-12-09T16:19:39.062625: step 821, loss 0.160741, acc 0.9375, learning_rate 0.00139927\n",
      "2020-12-09T16:19:39.643383: step 822, loss 0.403193, acc 0.875, learning_rate 0.00139753\n",
      "2020-12-09T16:19:40.248745: step 823, loss 0.364317, acc 0.875, learning_rate 0.00139579\n",
      "2020-12-09T16:19:40.824402: step 824, loss 0.309763, acc 0.8125, learning_rate 0.00139406\n",
      "2020-12-09T16:19:41.399368: step 825, loss 0.0945367, acc 0.96875, learning_rate 0.00139232\n",
      "2020-12-09T16:19:41.960369: step 826, loss 0.299592, acc 0.84375, learning_rate 0.00139059\n",
      "2020-12-09T16:19:42.546624: step 827, loss 0.260981, acc 0.96875, learning_rate 0.00138886\n",
      "2020-12-09T16:19:43.102257: step 828, loss 0.386741, acc 0.875, learning_rate 0.00138714\n",
      "2020-12-09T16:19:43.673860: step 829, loss 0.20362, acc 0.875, learning_rate 0.00138541\n",
      "2020-12-09T16:19:44.257895: step 830, loss 0.309982, acc 0.90625, learning_rate 0.00138369\n",
      "2020-12-09T16:19:44.844664: step 831, loss 0.29413, acc 0.8125, learning_rate 0.00138197\n",
      "2020-12-09T16:19:45.430847: step 832, loss 0.240533, acc 0.84375, learning_rate 0.00138025\n",
      "2020-12-09T16:19:46.011154: step 833, loss 0.284157, acc 0.84375, learning_rate 0.00137854\n",
      "2020-12-09T16:19:46.615720: step 834, loss 0.342223, acc 0.875, learning_rate 0.00137683\n",
      "2020-12-09T16:19:47.195245: step 835, loss 0.415258, acc 0.8125, learning_rate 0.00137512\n",
      "2020-12-09T16:19:47.779298: step 836, loss 0.22403, acc 0.90625, learning_rate 0.00137341\n",
      "2020-12-09T16:19:48.366768: step 837, loss 0.247295, acc 0.875, learning_rate 0.0013717\n",
      "2020-12-09T16:19:48.944265: step 838, loss 0.140788, acc 1, learning_rate 0.00137\n",
      "2020-12-09T16:19:49.525879: step 839, loss 0.23237, acc 0.9375, learning_rate 0.0013683\n",
      "2020-12-09T16:19:50.103343: step 840, loss 0.365461, acc 0.84375, learning_rate 0.0013666\n",
      "2020-12-09T16:19:50.683348: step 841, loss 0.27021, acc 0.90625, learning_rate 0.0013649\n",
      "2020-12-09T16:19:51.276083: step 842, loss 0.270805, acc 0.84375, learning_rate 0.00136321\n",
      "2020-12-09T16:19:51.892326: step 843, loss 0.370349, acc 0.84375, learning_rate 0.00136152\n",
      "2020-12-09T16:19:52.493116: step 844, loss 0.167776, acc 0.96875, learning_rate 0.00135983\n",
      "2020-12-09T16:19:53.048616: step 845, loss 0.195549, acc 0.84375, learning_rate 0.00135814\n",
      "2020-12-09T16:19:53.636780: step 846, loss 0.306706, acc 0.84375, learning_rate 0.00135645\n",
      "2020-12-09T16:19:54.226181: step 847, loss 0.291689, acc 0.875, learning_rate 0.00135477\n",
      "2020-12-09T16:19:54.816216: step 848, loss 0.253329, acc 0.9375, learning_rate 0.00135309\n",
      "2020-12-09T16:19:55.396136: step 849, loss 0.304056, acc 0.875, learning_rate 0.00135141\n",
      "2020-12-09T16:19:56.016221: step 850, loss 0.375414, acc 0.8125, learning_rate 0.00134973\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:19:59.214070: step 850, loss 0.695001, acc 0.72434\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-850\n",
      "\n",
      "2020-12-09T16:20:00.662069: step 851, loss 0.613826, acc 0.78125, learning_rate 0.00134806\n",
      "2020-12-09T16:20:01.236605: step 852, loss 0.456383, acc 0.71875, learning_rate 0.00134639\n",
      "2020-12-09T16:20:01.815107: step 853, loss 0.179278, acc 0.90625, learning_rate 0.00134472\n",
      "2020-12-09T16:20:02.422392: step 854, loss 0.309376, acc 0.90625, learning_rate 0.00134305\n",
      "2020-12-09T16:20:03.018250: step 855, loss 0.24674, acc 0.875, learning_rate 0.00134139\n",
      "2020-12-09T16:20:03.589901: step 856, loss 0.522677, acc 0.71875, learning_rate 0.00133972\n",
      "2020-12-09T16:20:04.164334: step 857, loss 0.358029, acc 0.8125, learning_rate 0.00133806\n",
      "2020-12-09T16:20:04.750832: step 858, loss 0.32477, acc 0.90625, learning_rate 0.0013364\n",
      "2020-12-09T16:20:05.324294: step 859, loss 0.311254, acc 0.8125, learning_rate 0.00133475\n",
      "2020-12-09T16:20:05.899976: step 860, loss 0.330894, acc 0.90625, learning_rate 0.00133309\n",
      "2020-12-09T16:20:06.486719: step 861, loss 0.201543, acc 0.9375, learning_rate 0.00133144\n",
      "2020-12-09T16:20:07.061751: step 862, loss 0.471414, acc 0.875, learning_rate 0.00132979\n",
      "2020-12-09T16:20:07.632673: step 863, loss 0.260876, acc 0.84375, learning_rate 0.00132814\n",
      "2020-12-09T16:20:08.208093: step 864, loss 0.487832, acc 0.84375, learning_rate 0.0013265\n",
      "2020-12-09T16:20:08.818721: step 865, loss 0.266213, acc 0.875, learning_rate 0.00132486\n",
      "2020-12-09T16:20:09.396968: step 866, loss 0.156623, acc 0.9375, learning_rate 0.00132322\n",
      "2020-12-09T16:20:09.966305: step 867, loss 0.282021, acc 0.90625, learning_rate 0.00132158\n",
      "2020-12-09T16:20:10.612015: step 868, loss 0.292849, acc 0.84375, learning_rate 0.00131994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:20:11.178150: step 869, loss 0.363975, acc 0.84375, learning_rate 0.00131831\n",
      "2020-12-09T16:20:11.732541: step 870, loss 0.252336, acc 0.875, learning_rate 0.00131667\n",
      "2020-12-09T16:20:12.308306: step 871, loss 0.257027, acc 0.84375, learning_rate 0.00131505\n",
      "2020-12-09T16:20:12.875570: step 872, loss 0.278562, acc 0.8125, learning_rate 0.00131342\n",
      "2020-12-09T16:20:13.456429: step 873, loss 0.494878, acc 0.8125, learning_rate 0.00131179\n",
      "2020-12-09T16:20:14.035529: step 874, loss 0.28177, acc 0.90625, learning_rate 0.00131017\n",
      "2020-12-09T16:20:14.628569: step 875, loss 0.36801, acc 0.9375, learning_rate 0.00130855\n",
      "2020-12-09T16:20:15.192527: step 876, loss 0.411957, acc 0.84375, learning_rate 0.00130693\n",
      "2020-12-09T16:20:15.762618: step 877, loss 0.175709, acc 0.9375, learning_rate 0.00130531\n",
      "2020-12-09T16:20:16.362117: step 878, loss 0.101551, acc 0.96875, learning_rate 0.0013037\n",
      "2020-12-09T16:20:16.946677: step 879, loss 0.396859, acc 0.90625, learning_rate 0.00130208\n",
      "2020-12-09T16:20:17.528677: step 880, loss 0.287292, acc 0.875, learning_rate 0.00130047\n",
      "2020-12-09T16:20:18.110678: step 881, loss 0.343782, acc 0.84375, learning_rate 0.00129887\n",
      "2020-12-09T16:20:18.693291: step 882, loss 0.297715, acc 0.84375, learning_rate 0.00129726\n",
      "2020-12-09T16:20:19.266282: step 883, loss 0.372695, acc 0.875, learning_rate 0.00129566\n",
      "2020-12-09T16:20:19.834294: step 884, loss 0.325302, acc 0.875, learning_rate 0.00129406\n",
      "2020-12-09T16:20:20.412007: step 885, loss 0.195412, acc 0.9375, learning_rate 0.00129246\n",
      "2020-12-09T16:20:20.999098: step 886, loss 0.474688, acc 0.84375, learning_rate 0.00129086\n",
      "2020-12-09T16:20:21.579233: step 887, loss 0.357252, acc 0.84375, learning_rate 0.00128926\n",
      "2020-12-09T16:20:22.167997: step 888, loss 0.479782, acc 0.84375, learning_rate 0.00128767\n",
      "2020-12-09T16:20:22.761717: step 889, loss 0.245962, acc 0.875, learning_rate 0.00128608\n",
      "2020-12-09T16:20:23.336252: step 890, loss 0.170202, acc 0.90625, learning_rate 0.00128449\n",
      "2020-12-09T16:20:23.951319: step 891, loss 0.509094, acc 0.8125, learning_rate 0.0012829\n",
      "2020-12-09T16:20:24.533930: step 892, loss 0.318216, acc 0.8125, learning_rate 0.00128132\n",
      "2020-12-09T16:20:25.138395: step 893, loss 0.454971, acc 0.8125, learning_rate 0.00127974\n",
      "2020-12-09T16:20:25.713300: step 894, loss 0.34733, acc 0.8125, learning_rate 0.00127816\n",
      "2020-12-09T16:20:26.290755: step 895, loss 0.462234, acc 0.78125, learning_rate 0.00127658\n",
      "2020-12-09T16:20:26.872107: step 896, loss 0.443723, acc 0.78125, learning_rate 0.001275\n",
      "2020-12-09T16:20:27.254605: step 897, loss 0.218332, acc 0.923077, learning_rate 0.00127343\n",
      "2020-12-09T16:20:27.797321: step 898, loss 0.267072, acc 0.90625, learning_rate 0.00127186\n",
      "2020-12-09T16:20:28.359194: step 899, loss 0.284207, acc 0.90625, learning_rate 0.00127029\n",
      "2020-12-09T16:20:28.914439: step 900, loss 0.416741, acc 0.78125, learning_rate 0.00126872\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:20:32.028411: step 900, loss 0.683154, acc 0.727692\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-900\n",
      "\n",
      "2020-12-09T16:20:33.452444: step 901, loss 0.251971, acc 0.96875, learning_rate 0.00126715\n",
      "2020-12-09T16:20:34.002382: step 902, loss 0.333661, acc 0.875, learning_rate 0.00126559\n",
      "2020-12-09T16:20:34.559910: step 903, loss 0.185101, acc 0.9375, learning_rate 0.00126403\n",
      "2020-12-09T16:20:35.128946: step 904, loss 0.230051, acc 0.9375, learning_rate 0.00126247\n",
      "2020-12-09T16:20:35.671556: step 905, loss 0.264574, acc 0.875, learning_rate 0.00126091\n",
      "2020-12-09T16:20:36.233586: step 906, loss 0.336039, acc 0.84375, learning_rate 0.00125936\n",
      "2020-12-09T16:20:36.804163: step 907, loss 0.333443, acc 0.875, learning_rate 0.0012578\n",
      "2020-12-09T16:20:37.360663: step 908, loss 0.228223, acc 0.9375, learning_rate 0.00125625\n",
      "2020-12-09T16:20:37.897242: step 909, loss 0.365135, acc 0.84375, learning_rate 0.0012547\n",
      "2020-12-09T16:20:38.472828: step 910, loss 0.134245, acc 1, learning_rate 0.00125316\n",
      "2020-12-09T16:20:39.066351: step 911, loss 0.140343, acc 0.96875, learning_rate 0.00125161\n",
      "2020-12-09T16:20:39.620389: step 912, loss 0.312461, acc 0.84375, learning_rate 0.00125007\n",
      "2020-12-09T16:20:40.166632: step 913, loss 0.128656, acc 0.96875, learning_rate 0.00124853\n",
      "2020-12-09T16:20:40.696573: step 914, loss 0.22855, acc 0.9375, learning_rate 0.00124699\n",
      "2020-12-09T16:20:41.247193: step 915, loss 0.466872, acc 0.90625, learning_rate 0.00124545\n",
      "2020-12-09T16:20:41.783727: step 916, loss 0.280081, acc 0.90625, learning_rate 0.00124392\n",
      "2020-12-09T16:20:42.363534: step 917, loss 0.24356, acc 0.9375, learning_rate 0.00124239\n",
      "2020-12-09T16:20:42.933533: step 918, loss 0.182616, acc 0.9375, learning_rate 0.00124086\n",
      "2020-12-09T16:20:43.475543: step 919, loss 0.262088, acc 0.875, learning_rate 0.00123933\n",
      "2020-12-09T16:20:44.026755: step 920, loss 0.16972, acc 0.96875, learning_rate 0.0012378\n",
      "2020-12-09T16:20:44.579955: step 921, loss 0.185117, acc 0.9375, learning_rate 0.00123628\n",
      "2020-12-09T16:20:45.123986: step 922, loss 0.256405, acc 0.875, learning_rate 0.00123476\n",
      "2020-12-09T16:20:45.665023: step 923, loss 0.0998278, acc 0.96875, learning_rate 0.00123324\n",
      "2020-12-09T16:20:46.214410: step 924, loss 0.287533, acc 0.875, learning_rate 0.00123172\n",
      "2020-12-09T16:20:46.791068: step 925, loss 0.328338, acc 0.875, learning_rate 0.0012302\n",
      "2020-12-09T16:20:47.327707: step 926, loss 0.231221, acc 0.90625, learning_rate 0.00122869\n",
      "2020-12-09T16:20:47.886206: step 927, loss 0.117469, acc 1, learning_rate 0.00122718\n",
      "2020-12-09T16:20:48.456363: step 928, loss 0.189952, acc 0.90625, learning_rate 0.00122567\n",
      "2020-12-09T16:20:49.023247: step 929, loss 0.165217, acc 0.9375, learning_rate 0.00122416\n",
      "2020-12-09T16:20:49.567779: step 930, loss 0.0929801, acc 1, learning_rate 0.00122265\n",
      "2020-12-09T16:20:50.138279: step 931, loss 0.227465, acc 0.90625, learning_rate 0.00122115\n",
      "2020-12-09T16:20:50.694269: step 932, loss 0.196138, acc 0.90625, learning_rate 0.00121965\n",
      "2020-12-09T16:20:51.238233: step 933, loss 0.213083, acc 0.9375, learning_rate 0.00121815\n",
      "2020-12-09T16:20:51.785975: step 934, loss 0.169881, acc 0.9375, learning_rate 0.00121665\n",
      "2020-12-09T16:20:52.327062: step 935, loss 0.159752, acc 0.90625, learning_rate 0.00121515\n",
      "2020-12-09T16:20:52.897823: step 936, loss 0.279535, acc 0.90625, learning_rate 0.00121366\n",
      "2020-12-09T16:20:53.437346: step 937, loss 0.229913, acc 0.90625, learning_rate 0.00121217\n",
      "2020-12-09T16:20:54.003937: step 938, loss 0.178546, acc 0.90625, learning_rate 0.00121068\n",
      "2020-12-09T16:20:54.576713: step 939, loss 0.401625, acc 0.90625, learning_rate 0.00120919\n",
      "2020-12-09T16:20:55.139545: step 940, loss 0.224424, acc 0.90625, learning_rate 0.0012077\n",
      "2020-12-09T16:20:55.667081: step 941, loss 0.357255, acc 0.90625, learning_rate 0.00120622\n",
      "2020-12-09T16:20:56.216513: step 942, loss 0.212837, acc 0.9375, learning_rate 0.00120474\n",
      "2020-12-09T16:20:56.781488: step 943, loss 0.307419, acc 0.875, learning_rate 0.00120326\n",
      "2020-12-09T16:20:57.347334: step 944, loss 0.24168, acc 0.90625, learning_rate 0.00120178\n",
      "2020-12-09T16:20:57.874373: step 945, loss 0.184326, acc 0.9375, learning_rate 0.00120031\n",
      "2020-12-09T16:20:58.484214: step 946, loss 0.163136, acc 0.9375, learning_rate 0.00119883\n",
      "2020-12-09T16:20:59.031817: step 947, loss 0.142973, acc 0.96875, learning_rate 0.00119736\n",
      "2020-12-09T16:20:59.572781: step 948, loss 0.222915, acc 0.90625, learning_rate 0.00119589\n",
      "2020-12-09T16:21:00.141789: step 949, loss 0.257041, acc 0.90625, learning_rate 0.00119442\n",
      "2020-12-09T16:21:00.701790: step 950, loss 0.204863, acc 0.96875, learning_rate 0.00119296\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:21:03.944662: step 950, loss 0.687577, acc 0.725597\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-950\n",
      "\n",
      "2020-12-09T16:21:05.487730: step 951, loss 0.282084, acc 0.875, learning_rate 0.00119149\n",
      "2020-12-09T16:21:06.041029: step 952, loss 0.109642, acc 0.9375, learning_rate 0.00119003\n",
      "2020-12-09T16:21:06.608041: step 953, loss 0.475514, acc 0.84375, learning_rate 0.00118857\n",
      "2020-12-09T16:21:07.143539: step 954, loss 0.155411, acc 0.96875, learning_rate 0.00118711\n",
      "2020-12-09T16:21:07.677041: step 955, loss 0.10003, acc 0.96875, learning_rate 0.00118565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:21:08.233702: step 956, loss 0.189168, acc 0.9375, learning_rate 0.0011842\n",
      "2020-12-09T16:21:08.822196: step 957, loss 0.449392, acc 0.875, learning_rate 0.00118275\n",
      "2020-12-09T16:21:09.373121: step 958, loss 0.165301, acc 0.90625, learning_rate 0.0011813\n",
      "2020-12-09T16:21:09.916491: step 959, loss 0.401545, acc 0.84375, learning_rate 0.00117985\n",
      "2020-12-09T16:21:10.466136: step 960, loss 0.0514201, acc 1, learning_rate 0.0011784\n",
      "2020-12-09T16:21:11.037975: step 961, loss 0.206169, acc 0.9375, learning_rate 0.00117696\n",
      "2020-12-09T16:21:11.590472: step 962, loss 0.211565, acc 0.875, learning_rate 0.00117552\n",
      "2020-12-09T16:21:12.155006: step 963, loss 0.213179, acc 0.9375, learning_rate 0.00117407\n",
      "2020-12-09T16:21:12.717530: step 964, loss 0.111491, acc 0.96875, learning_rate 0.00117264\n",
      "2020-12-09T16:21:13.295050: step 965, loss 0.187174, acc 0.96875, learning_rate 0.0011712\n",
      "2020-12-09T16:21:13.848560: step 966, loss 0.107654, acc 0.96875, learning_rate 0.00116976\n",
      "2020-12-09T16:21:14.407103: step 967, loss 0.306584, acc 0.90625, learning_rate 0.00116833\n",
      "2020-12-09T16:21:14.955590: step 968, loss 0.339356, acc 0.8125, learning_rate 0.0011669\n",
      "2020-12-09T16:21:15.512059: step 969, loss 0.17669, acc 0.90625, learning_rate 0.00116547\n",
      "2020-12-09T16:21:16.063848: step 970, loss 0.186687, acc 0.9375, learning_rate 0.00116404\n",
      "2020-12-09T16:21:16.628886: step 971, loss 0.300732, acc 0.84375, learning_rate 0.00116262\n",
      "2020-12-09T16:21:17.179022: step 972, loss 0.255483, acc 0.84375, learning_rate 0.00116119\n",
      "2020-12-09T16:21:17.728518: step 973, loss 0.213565, acc 0.90625, learning_rate 0.00115977\n",
      "2020-12-09T16:21:18.275521: step 974, loss 0.239621, acc 0.9375, learning_rate 0.00115835\n",
      "2020-12-09T16:21:18.834026: step 975, loss 0.425911, acc 0.84375, learning_rate 0.00115694\n",
      "2020-12-09T16:21:19.380363: step 976, loss 0.16542, acc 0.9375, learning_rate 0.00115552\n",
      "2020-12-09T16:21:19.933824: step 977, loss 0.328023, acc 0.875, learning_rate 0.00115411\n",
      "2020-12-09T16:21:20.467857: step 978, loss 0.299941, acc 0.84375, learning_rate 0.00115269\n",
      "2020-12-09T16:21:21.022058: step 979, loss 0.202598, acc 0.9375, learning_rate 0.00115128\n",
      "2020-12-09T16:21:21.570524: step 980, loss 0.32061, acc 0.78125, learning_rate 0.00114988\n",
      "2020-12-09T16:21:22.115059: step 981, loss 0.242707, acc 0.875, learning_rate 0.00114847\n",
      "2020-12-09T16:21:22.702072: step 982, loss 0.283407, acc 0.875, learning_rate 0.00114706\n",
      "2020-12-09T16:21:23.263610: step 983, loss 0.155893, acc 0.90625, learning_rate 0.00114566\n",
      "2020-12-09T16:21:23.825012: step 984, loss 0.348743, acc 0.84375, learning_rate 0.00114426\n",
      "2020-12-09T16:21:24.377757: step 985, loss 0.232297, acc 0.9375, learning_rate 0.00114286\n",
      "2020-12-09T16:21:24.911564: step 986, loss 0.11743, acc 0.9375, learning_rate 0.00114147\n",
      "2020-12-09T16:21:25.457029: step 987, loss 0.213923, acc 0.96875, learning_rate 0.00114007\n",
      "2020-12-09T16:21:25.999651: step 988, loss 0.348014, acc 0.8125, learning_rate 0.00113868\n",
      "2020-12-09T16:21:26.540151: step 989, loss 0.347162, acc 0.8125, learning_rate 0.00113729\n",
      "2020-12-09T16:21:27.105219: step 990, loss 0.25287, acc 0.90625, learning_rate 0.0011359\n",
      "2020-12-09T16:21:27.658590: step 991, loss 0.350374, acc 0.84375, learning_rate 0.00113451\n",
      "2020-12-09T16:21:28.206593: step 992, loss 0.202217, acc 0.90625, learning_rate 0.00113312\n",
      "2020-12-09T16:21:28.791641: step 993, loss 0.146118, acc 0.9375, learning_rate 0.00113174\n",
      "2020-12-09T16:21:29.344978: step 994, loss 0.240005, acc 0.90625, learning_rate 0.00113036\n",
      "2020-12-09T16:21:29.881476: step 995, loss 0.24869, acc 0.84375, learning_rate 0.00112898\n",
      "2020-12-09T16:21:30.441255: step 996, loss 0.211264, acc 0.90625, learning_rate 0.0011276\n",
      "2020-12-09T16:21:30.979975: step 997, loss 0.215817, acc 0.9375, learning_rate 0.00112622\n",
      "2020-12-09T16:21:31.533741: step 998, loss 0.342889, acc 0.84375, learning_rate 0.00112485\n",
      "2020-12-09T16:21:32.081595: step 999, loss 0.376213, acc 0.8125, learning_rate 0.00112347\n",
      "2020-12-09T16:21:32.623552: step 1000, loss 0.374259, acc 0.90625, learning_rate 0.0011221\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:21:35.765525: step 1000, loss 0.706005, acc 0.731462\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1000\n",
      "\n",
      "2020-12-09T16:21:37.210513: step 1001, loss 0.252045, acc 0.90625, learning_rate 0.00112073\n",
      "2020-12-09T16:21:37.763828: step 1002, loss 0.157027, acc 0.9375, learning_rate 0.00111937\n",
      "2020-12-09T16:21:38.312799: step 1003, loss 0.29703, acc 0.90625, learning_rate 0.001118\n",
      "2020-12-09T16:21:38.885193: step 1004, loss 0.0834961, acc 1, learning_rate 0.00111664\n",
      "2020-12-09T16:21:39.451120: step 1005, loss 0.156609, acc 0.9375, learning_rate 0.00111528\n",
      "2020-12-09T16:21:39.985587: step 1006, loss 0.280127, acc 0.875, learning_rate 0.00111392\n",
      "2020-12-09T16:21:40.547122: step 1007, loss 0.297859, acc 0.84375, learning_rate 0.00111256\n",
      "2020-12-09T16:21:41.096590: step 1008, loss 0.404711, acc 0.78125, learning_rate 0.0011112\n",
      "2020-12-09T16:21:41.665287: step 1009, loss 0.255194, acc 0.9375, learning_rate 0.00110985\n",
      "2020-12-09T16:21:42.215512: step 1010, loss 0.0910387, acc 0.96875, learning_rate 0.00110849\n",
      "2020-12-09T16:21:42.772041: step 1011, loss 0.219009, acc 0.90625, learning_rate 0.00110714\n",
      "2020-12-09T16:21:43.348489: step 1012, loss 0.390827, acc 0.8125, learning_rate 0.00110579\n",
      "2020-12-09T16:21:43.893549: step 1013, loss 0.249798, acc 0.84375, learning_rate 0.00110445\n",
      "2020-12-09T16:21:44.452047: step 1014, loss 0.159677, acc 0.9375, learning_rate 0.0011031\n",
      "2020-12-09T16:21:45.036559: step 1015, loss 0.20578, acc 0.90625, learning_rate 0.00110176\n",
      "2020-12-09T16:21:45.579518: step 1016, loss 0.239199, acc 0.9375, learning_rate 0.00110042\n",
      "2020-12-09T16:21:46.128483: step 1017, loss 0.293125, acc 0.84375, learning_rate 0.00109908\n",
      "2020-12-09T16:21:46.675979: step 1018, loss 0.289393, acc 0.875, learning_rate 0.00109774\n",
      "2020-12-09T16:21:47.218531: step 1019, loss 0.153442, acc 0.96875, learning_rate 0.0010964\n",
      "2020-12-09T16:21:47.761494: step 1020, loss 0.114485, acc 0.96875, learning_rate 0.00109507\n",
      "2020-12-09T16:21:48.307736: step 1021, loss 0.435379, acc 0.875, learning_rate 0.00109373\n",
      "2020-12-09T16:21:48.868333: step 1022, loss 0.213726, acc 0.90625, learning_rate 0.0010924\n",
      "2020-12-09T16:21:49.424246: step 1023, loss 0.351747, acc 0.9375, learning_rate 0.00109107\n",
      "2020-12-09T16:21:49.975211: step 1024, loss 0.2779, acc 0.875, learning_rate 0.00108974\n",
      "2020-12-09T16:21:50.518245: step 1025, loss 0.258948, acc 0.90625, learning_rate 0.00108842\n",
      "2020-12-09T16:21:51.097071: step 1026, loss 0.191657, acc 0.90625, learning_rate 0.00108709\n",
      "2020-12-09T16:21:51.680771: step 1027, loss 0.300058, acc 0.84375, learning_rate 0.00108577\n",
      "2020-12-09T16:21:52.229422: step 1028, loss 0.21088, acc 0.9375, learning_rate 0.00108445\n",
      "2020-12-09T16:21:52.758628: step 1029, loss 0.273839, acc 0.90625, learning_rate 0.00108313\n",
      "2020-12-09T16:21:53.325612: step 1030, loss 0.659102, acc 0.71875, learning_rate 0.00108182\n",
      "2020-12-09T16:21:53.864712: step 1031, loss 0.208035, acc 0.90625, learning_rate 0.0010805\n",
      "2020-12-09T16:21:54.411714: step 1032, loss 0.279132, acc 0.8125, learning_rate 0.00107919\n",
      "2020-12-09T16:21:54.977600: step 1033, loss 0.265034, acc 0.84375, learning_rate 0.00107788\n",
      "2020-12-09T16:21:55.517557: step 1034, loss 0.0607674, acc 1, learning_rate 0.00107657\n",
      "2020-12-09T16:21:56.067565: step 1035, loss 0.227671, acc 0.9375, learning_rate 0.00107526\n",
      "2020-12-09T16:21:56.616599: step 1036, loss 0.244458, acc 0.9375, learning_rate 0.00107395\n",
      "2020-12-09T16:21:57.155634: step 1037, loss 0.108921, acc 0.9375, learning_rate 0.00107265\n",
      "2020-12-09T16:21:57.708149: step 1038, loss 0.185827, acc 0.90625, learning_rate 0.00107134\n",
      "2020-12-09T16:21:58.253923: step 1039, loss 0.132075, acc 0.9375, learning_rate 0.00107004\n",
      "2020-12-09T16:21:58.794870: step 1040, loss 0.206123, acc 0.9375, learning_rate 0.00106874\n",
      "2020-12-09T16:21:59.344950: step 1041, loss 0.305347, acc 0.9375, learning_rate 0.00106745\n",
      "2020-12-09T16:21:59.920401: step 1042, loss 0.514615, acc 0.78125, learning_rate 0.00106615\n",
      "2020-12-09T16:22:00.488744: step 1043, loss 0.328906, acc 0.875, learning_rate 0.00106486\n",
      "2020-12-09T16:22:01.050219: step 1044, loss 0.142016, acc 0.96875, learning_rate 0.00106356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:22:01.609174: step 1045, loss 0.110065, acc 0.9375, learning_rate 0.00106227\n",
      "2020-12-09T16:22:02.132668: step 1046, loss 0.184939, acc 0.90625, learning_rate 0.00106098\n",
      "2020-12-09T16:22:02.678672: step 1047, loss 0.103696, acc 0.96875, learning_rate 0.0010597\n",
      "2020-12-09T16:22:03.231122: step 1048, loss 0.222735, acc 0.9375, learning_rate 0.00105841\n",
      "2020-12-09T16:22:03.805573: step 1049, loss 0.132471, acc 0.9375, learning_rate 0.00105713\n",
      "2020-12-09T16:22:04.362058: step 1050, loss 0.388009, acc 0.875, learning_rate 0.00105584\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:22:07.624631: step 1050, loss 0.715925, acc 0.739841\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1050\n",
      "\n",
      "2020-12-09T16:22:09.098996: step 1051, loss 0.279957, acc 0.875, learning_rate 0.00105456\n",
      "2020-12-09T16:22:09.650167: step 1052, loss 0.307388, acc 0.84375, learning_rate 0.00105329\n",
      "2020-12-09T16:22:10.183168: step 1053, loss 0.426149, acc 0.84375, learning_rate 0.00105201\n",
      "2020-12-09T16:22:10.748201: step 1054, loss 0.328147, acc 0.84375, learning_rate 0.00105073\n",
      "2020-12-09T16:22:11.316211: step 1055, loss 0.30264, acc 0.90625, learning_rate 0.00104946\n",
      "2020-12-09T16:22:11.880741: step 1056, loss 0.368284, acc 0.78125, learning_rate 0.00104819\n",
      "2020-12-09T16:22:12.479208: step 1057, loss 0.153218, acc 0.90625, learning_rate 0.00104692\n",
      "2020-12-09T16:22:13.086106: step 1058, loss 0.307382, acc 0.90625, learning_rate 0.00104565\n",
      "2020-12-09T16:22:13.647321: step 1059, loss 0.190083, acc 0.90625, learning_rate 0.00104438\n",
      "2020-12-09T16:22:14.225822: step 1060, loss 0.107132, acc 0.96875, learning_rate 0.00104312\n",
      "2020-12-09T16:22:14.806854: step 1061, loss 0.239064, acc 0.90625, learning_rate 0.00104185\n",
      "2020-12-09T16:22:15.407820: step 1062, loss 0.153453, acc 0.96875, learning_rate 0.00104059\n",
      "2020-12-09T16:22:15.962368: step 1063, loss 0.149207, acc 0.9375, learning_rate 0.00103933\n",
      "2020-12-09T16:22:16.516379: step 1064, loss 0.243561, acc 0.9375, learning_rate 0.00103807\n",
      "2020-12-09T16:22:17.088879: step 1065, loss 0.200177, acc 0.90625, learning_rate 0.00103682\n",
      "2020-12-09T16:22:17.643723: step 1066, loss 0.206656, acc 0.90625, learning_rate 0.00103556\n",
      "2020-12-09T16:22:18.181680: step 1067, loss 0.132382, acc 0.9375, learning_rate 0.00103431\n",
      "2020-12-09T16:22:18.742590: step 1068, loss 0.262307, acc 0.875, learning_rate 0.00103306\n",
      "2020-12-09T16:22:19.316628: step 1069, loss 0.0978879, acc 0.96875, learning_rate 0.00103181\n",
      "2020-12-09T16:22:19.885390: step 1070, loss 0.34035, acc 0.875, learning_rate 0.00103056\n",
      "2020-12-09T16:22:20.431216: step 1071, loss 0.137912, acc 0.96875, learning_rate 0.00102931\n",
      "2020-12-09T16:22:20.981515: step 1072, loss 0.123658, acc 0.9375, learning_rate 0.00102807\n",
      "2020-12-09T16:22:21.537128: step 1073, loss 0.107764, acc 0.9375, learning_rate 0.00102682\n",
      "2020-12-09T16:22:22.083656: step 1074, loss 0.316689, acc 0.8125, learning_rate 0.00102558\n",
      "2020-12-09T16:22:22.651189: step 1075, loss 0.306979, acc 0.84375, learning_rate 0.00102434\n",
      "2020-12-09T16:22:23.263584: step 1076, loss 0.293948, acc 0.84375, learning_rate 0.00102311\n",
      "2020-12-09T16:22:23.827514: step 1077, loss 0.131382, acc 0.96875, learning_rate 0.00102187\n",
      "2020-12-09T16:22:24.383260: step 1078, loss 0.204686, acc 0.875, learning_rate 0.00102063\n",
      "2020-12-09T16:22:24.941798: step 1079, loss 0.185873, acc 0.9375, learning_rate 0.0010194\n",
      "2020-12-09T16:22:25.498864: step 1080, loss 0.17577, acc 0.90625, learning_rate 0.00101817\n",
      "2020-12-09T16:22:26.058969: step 1081, loss 0.145979, acc 0.90625, learning_rate 0.00101694\n",
      "2020-12-09T16:22:26.623094: step 1082, loss 0.132427, acc 0.90625, learning_rate 0.00101571\n",
      "2020-12-09T16:22:27.191104: step 1083, loss 0.429289, acc 0.84375, learning_rate 0.00101448\n",
      "2020-12-09T16:22:27.735767: step 1084, loss 0.183835, acc 0.9375, learning_rate 0.00101326\n",
      "2020-12-09T16:22:28.279577: step 1085, loss 0.205852, acc 0.9375, learning_rate 0.00101204\n",
      "2020-12-09T16:22:28.820534: step 1086, loss 0.0769589, acc 1, learning_rate 0.00101081\n",
      "2020-12-09T16:22:29.355694: step 1087, loss 0.290642, acc 0.84375, learning_rate 0.00100959\n",
      "2020-12-09T16:22:29.913629: step 1088, loss 0.139447, acc 0.96875, learning_rate 0.00100838\n",
      "2020-12-09T16:22:30.462028: step 1089, loss 0.220834, acc 0.90625, learning_rate 0.00100716\n",
      "2020-12-09T16:22:31.013061: step 1090, loss 0.151787, acc 0.96875, learning_rate 0.00100594\n",
      "2020-12-09T16:22:31.577187: step 1091, loss 0.169562, acc 0.90625, learning_rate 0.00100473\n",
      "2020-12-09T16:22:32.133920: step 1092, loss 0.136808, acc 0.90625, learning_rate 0.00100352\n",
      "2020-12-09T16:22:32.681270: step 1093, loss 0.187618, acc 0.90625, learning_rate 0.00100231\n",
      "2020-12-09T16:22:33.259011: step 1094, loss 0.0814227, acc 1, learning_rate 0.0010011\n",
      "2020-12-09T16:22:33.835585: step 1095, loss 0.262427, acc 0.90625, learning_rate 0.000999892\n",
      "2020-12-09T16:22:34.399068: step 1096, loss 0.174129, acc 0.9375, learning_rate 0.000998686\n",
      "2020-12-09T16:22:34.960718: step 1097, loss 0.111298, acc 0.96875, learning_rate 0.000997483\n",
      "2020-12-09T16:22:35.531525: step 1098, loss 0.276817, acc 0.875, learning_rate 0.00099628\n",
      "2020-12-09T16:22:36.104228: step 1099, loss 0.1816, acc 0.9375, learning_rate 0.00099508\n",
      "2020-12-09T16:22:36.652408: step 1100, loss 0.278506, acc 0.9375, learning_rate 0.000993881\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:22:39.951758: step 1100, loss 0.796184, acc 0.721827\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1100\n",
      "\n",
      "2020-12-09T16:22:41.417566: step 1101, loss 0.236042, acc 0.9375, learning_rate 0.000992683\n",
      "2020-12-09T16:22:41.959592: step 1102, loss 0.358796, acc 0.78125, learning_rate 0.000991488\n",
      "2020-12-09T16:22:42.514058: step 1103, loss 0.308736, acc 0.78125, learning_rate 0.000990293\n",
      "2020-12-09T16:22:43.068058: step 1104, loss 0.174426, acc 0.90625, learning_rate 0.000989101\n",
      "2020-12-09T16:22:43.615788: step 1105, loss 0.154334, acc 0.9375, learning_rate 0.00098791\n",
      "2020-12-09T16:22:44.173379: step 1106, loss 0.128466, acc 0.96875, learning_rate 0.00098672\n",
      "2020-12-09T16:22:44.725343: step 1107, loss 0.13673, acc 0.90625, learning_rate 0.000985532\n",
      "2020-12-09T16:22:45.290520: step 1108, loss 0.173099, acc 0.9375, learning_rate 0.000984346\n",
      "2020-12-09T16:22:45.835341: step 1109, loss 0.250552, acc 0.90625, learning_rate 0.000983162\n",
      "2020-12-09T16:22:46.379231: step 1110, loss 0.060377, acc 0.96875, learning_rate 0.000981979\n",
      "2020-12-09T16:22:46.942738: step 1111, loss 0.249282, acc 0.875, learning_rate 0.000980797\n",
      "2020-12-09T16:22:47.505292: step 1112, loss 0.109268, acc 0.96875, learning_rate 0.000979617\n",
      "2020-12-09T16:22:48.039008: step 1113, loss 0.164542, acc 0.96875, learning_rate 0.000978439\n",
      "2020-12-09T16:22:48.582914: step 1114, loss 0.169459, acc 0.96875, learning_rate 0.000977262\n",
      "2020-12-09T16:22:49.154148: step 1115, loss 0.225396, acc 0.9375, learning_rate 0.000976087\n",
      "2020-12-09T16:22:49.683147: step 1116, loss 0.174948, acc 0.90625, learning_rate 0.000974914\n",
      "2020-12-09T16:22:50.220649: step 1117, loss 0.305044, acc 0.90625, learning_rate 0.000973742\n",
      "2020-12-09T16:22:50.767091: step 1118, loss 0.156525, acc 0.90625, learning_rate 0.000972571\n",
      "2020-12-09T16:22:51.338478: step 1119, loss 0.342554, acc 0.90625, learning_rate 0.000971402\n",
      "2020-12-09T16:22:51.891731: step 1120, loss 0.46861, acc 0.8125, learning_rate 0.000970235\n",
      "2020-12-09T16:22:52.443765: step 1121, loss 0.0954687, acc 0.96875, learning_rate 0.000969069\n",
      "2020-12-09T16:22:52.989571: step 1122, loss 0.357704, acc 0.90625, learning_rate 0.000967905\n",
      "2020-12-09T16:22:53.544608: step 1123, loss 0.218909, acc 0.875, learning_rate 0.000966742\n",
      "2020-12-09T16:22:54.098537: step 1124, loss 0.141526, acc 0.96875, learning_rate 0.000965581\n",
      "2020-12-09T16:22:54.641007: step 1125, loss 0.206414, acc 0.84375, learning_rate 0.000964422\n",
      "2020-12-09T16:22:55.198755: step 1126, loss 0.170016, acc 0.9375, learning_rate 0.000963264\n",
      "2020-12-09T16:22:55.749088: step 1127, loss 0.178204, acc 0.9375, learning_rate 0.000962108\n",
      "2020-12-09T16:22:56.308607: step 1128, loss 0.166457, acc 0.9375, learning_rate 0.000960953\n",
      "2020-12-09T16:22:56.855472: step 1129, loss 0.121353, acc 0.9375, learning_rate 0.000959799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:22:57.412613: step 1130, loss 0.287748, acc 0.84375, learning_rate 0.000958648\n",
      "2020-12-09T16:22:57.948720: step 1131, loss 0.190873, acc 0.9375, learning_rate 0.000957497\n",
      "2020-12-09T16:22:58.509932: step 1132, loss 0.226708, acc 0.90625, learning_rate 0.000956349\n",
      "2020-12-09T16:22:59.041963: step 1133, loss 0.201686, acc 0.90625, learning_rate 0.000955202\n",
      "2020-12-09T16:22:59.612160: step 1134, loss 0.220529, acc 0.84375, learning_rate 0.000954056\n",
      "2020-12-09T16:23:00.198464: step 1135, loss 0.14537, acc 0.90625, learning_rate 0.000952912\n",
      "2020-12-09T16:23:00.746587: step 1136, loss 0.0970187, acc 0.96875, learning_rate 0.00095177\n",
      "2020-12-09T16:23:01.295498: step 1137, loss 0.214391, acc 0.9375, learning_rate 0.000950629\n",
      "2020-12-09T16:23:01.870605: step 1138, loss 0.188769, acc 0.90625, learning_rate 0.000949489\n",
      "2020-12-09T16:23:02.408059: step 1139, loss 0.369865, acc 0.84375, learning_rate 0.000948351\n",
      "2020-12-09T16:23:02.960526: step 1140, loss 0.0922957, acc 1, learning_rate 0.000947215\n",
      "2020-12-09T16:23:03.529560: step 1141, loss 0.0979647, acc 0.96875, learning_rate 0.00094608\n",
      "2020-12-09T16:23:04.116935: step 1142, loss 0.0685187, acc 0.96875, learning_rate 0.000944946\n",
      "2020-12-09T16:23:04.667885: step 1143, loss 0.185461, acc 0.9375, learning_rate 0.000943815\n",
      "2020-12-09T16:23:05.249388: step 1144, loss 0.222014, acc 0.9375, learning_rate 0.000942684\n",
      "2020-12-09T16:23:05.802920: step 1145, loss 0.232937, acc 0.9375, learning_rate 0.000941555\n",
      "2020-12-09T16:23:06.369355: step 1146, loss 0.223119, acc 0.90625, learning_rate 0.000940428\n",
      "2020-12-09T16:23:06.911269: step 1147, loss 0.242623, acc 0.90625, learning_rate 0.000939302\n",
      "2020-12-09T16:23:07.489761: step 1148, loss 0.133038, acc 0.90625, learning_rate 0.000938178\n",
      "2020-12-09T16:23:08.029599: step 1149, loss 0.241731, acc 0.90625, learning_rate 0.000937055\n",
      "2020-12-09T16:23:08.591823: step 1150, loss 0.105739, acc 0.9375, learning_rate 0.000935934\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:23:11.764595: step 1150, loss 0.798864, acc 0.731043\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1150\n",
      "\n",
      "2020-12-09T16:23:13.204448: step 1151, loss 0.158883, acc 0.96875, learning_rate 0.000934814\n",
      "2020-12-09T16:23:13.746444: step 1152, loss 0.198673, acc 0.875, learning_rate 0.000933696\n",
      "2020-12-09T16:23:14.315022: step 1153, loss 0.306076, acc 0.90625, learning_rate 0.000932579\n",
      "2020-12-09T16:23:14.860961: step 1154, loss 0.413975, acc 0.71875, learning_rate 0.000931464\n",
      "2020-12-09T16:23:15.400808: step 1155, loss 0.269143, acc 0.84375, learning_rate 0.00093035\n",
      "2020-12-09T16:23:15.962089: step 1156, loss 0.254768, acc 0.9375, learning_rate 0.000929238\n",
      "2020-12-09T16:23:16.511682: step 1157, loss 0.371047, acc 0.875, learning_rate 0.000928127\n",
      "2020-12-09T16:23:17.063175: step 1158, loss 0.174985, acc 0.96875, learning_rate 0.000927018\n",
      "2020-12-09T16:23:17.613813: step 1159, loss 0.211732, acc 0.9375, learning_rate 0.00092591\n",
      "2020-12-09T16:23:18.159996: step 1160, loss 0.255241, acc 0.84375, learning_rate 0.000924803\n",
      "2020-12-09T16:23:18.704997: step 1161, loss 0.090324, acc 0.96875, learning_rate 0.000923699\n",
      "2020-12-09T16:23:19.251867: step 1162, loss 0.158221, acc 0.9375, learning_rate 0.000922595\n",
      "2020-12-09T16:23:19.794789: step 1163, loss 0.334204, acc 0.90625, learning_rate 0.000921493\n",
      "2020-12-09T16:23:20.371787: step 1164, loss 0.0871071, acc 0.96875, learning_rate 0.000920393\n",
      "2020-12-09T16:23:20.960786: step 1165, loss 0.214258, acc 0.96875, learning_rate 0.000919294\n",
      "2020-12-09T16:23:21.522695: step 1166, loss 0.106746, acc 0.96875, learning_rate 0.000918196\n",
      "2020-12-09T16:23:22.103232: step 1167, loss 0.556445, acc 0.875, learning_rate 0.0009171\n",
      "2020-12-09T16:23:22.653230: step 1168, loss 0.150528, acc 0.9375, learning_rate 0.000916006\n",
      "2020-12-09T16:23:23.254203: step 1169, loss 0.194297, acc 0.875, learning_rate 0.000914913\n",
      "2020-12-09T16:23:23.794094: step 1170, loss 0.107656, acc 0.9375, learning_rate 0.000913821\n",
      "2020-12-09T16:23:24.373853: step 1171, loss 0.321778, acc 0.90625, learning_rate 0.000912731\n",
      "2020-12-09T16:23:24.944035: step 1172, loss 0.133449, acc 0.96875, learning_rate 0.000911642\n",
      "2020-12-09T16:23:25.495238: step 1173, loss 0.284088, acc 0.875, learning_rate 0.000910555\n",
      "2020-12-09T16:23:26.060225: step 1174, loss 0.304958, acc 0.875, learning_rate 0.000909469\n",
      "2020-12-09T16:23:26.623804: step 1175, loss 0.161171, acc 0.90625, learning_rate 0.000908385\n",
      "2020-12-09T16:23:27.185304: step 1176, loss 0.349292, acc 0.8125, learning_rate 0.000907302\n",
      "2020-12-09T16:23:27.751023: step 1177, loss 0.63889, acc 0.84375, learning_rate 0.000906221\n",
      "2020-12-09T16:23:28.302496: step 1178, loss 0.242997, acc 0.9375, learning_rate 0.000905141\n",
      "2020-12-09T16:23:28.832436: step 1179, loss 0.210032, acc 0.90625, learning_rate 0.000904062\n",
      "2020-12-09T16:23:29.386436: step 1180, loss 0.201223, acc 0.9375, learning_rate 0.000902985\n",
      "2020-12-09T16:23:29.930874: step 1181, loss 0.21115, acc 0.9375, learning_rate 0.000901909\n",
      "2020-12-09T16:23:30.478324: step 1182, loss 0.28246, acc 0.90625, learning_rate 0.000900835\n",
      "2020-12-09T16:23:31.039825: step 1183, loss 0.43395, acc 0.84375, learning_rate 0.000899762\n",
      "2020-12-09T16:23:31.590777: step 1184, loss 0.112056, acc 0.96875, learning_rate 0.000898691\n",
      "2020-12-09T16:23:32.126636: step 1185, loss 0.0919549, acc 0.96875, learning_rate 0.000897621\n",
      "2020-12-09T16:23:32.688697: step 1186, loss 0.143681, acc 0.90625, learning_rate 0.000896553\n",
      "2020-12-09T16:23:33.238100: step 1187, loss 0.196992, acc 0.84375, learning_rate 0.000895486\n",
      "2020-12-09T16:23:33.788922: step 1188, loss 0.291861, acc 0.875, learning_rate 0.00089442\n",
      "2020-12-09T16:23:34.348010: step 1189, loss 0.185891, acc 0.875, learning_rate 0.000893356\n",
      "2020-12-09T16:23:34.884008: step 1190, loss 0.398759, acc 0.8125, learning_rate 0.000892293\n",
      "2020-12-09T16:23:35.434141: step 1191, loss 0.20884, acc 0.90625, learning_rate 0.000891232\n",
      "2020-12-09T16:23:36.016562: step 1192, loss 0.107666, acc 0.9375, learning_rate 0.000890172\n",
      "2020-12-09T16:23:36.580582: step 1193, loss 0.164896, acc 0.90625, learning_rate 0.000889113\n",
      "2020-12-09T16:23:37.115679: step 1194, loss 0.144895, acc 0.96875, learning_rate 0.000888056\n",
      "2020-12-09T16:23:37.680018: step 1195, loss 0.229638, acc 0.90625, learning_rate 0.000887001\n",
      "2020-12-09T16:23:37.896557: step 1196, loss 0.923947, acc 0.769231, learning_rate 0.000885946\n",
      "2020-12-09T16:23:38.448055: step 1197, loss 0.253254, acc 0.90625, learning_rate 0.000884894\n",
      "2020-12-09T16:23:38.988015: step 1198, loss 0.183381, acc 0.90625, learning_rate 0.000883842\n",
      "2020-12-09T16:23:39.546051: step 1199, loss 0.117194, acc 0.96875, learning_rate 0.000882792\n",
      "2020-12-09T16:23:40.095296: step 1200, loss 0.17118, acc 0.9375, learning_rate 0.000881744\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:23:43.337026: step 1200, loss 0.792309, acc 0.721827\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1200\n",
      "\n",
      "2020-12-09T16:23:44.759565: step 1201, loss 0.236656, acc 0.875, learning_rate 0.000880696\n",
      "2020-12-09T16:23:45.303051: step 1202, loss 0.0805843, acc 1, learning_rate 0.000879651\n",
      "2020-12-09T16:23:45.845514: step 1203, loss 0.128305, acc 0.96875, learning_rate 0.000878606\n",
      "2020-12-09T16:23:46.402558: step 1204, loss 0.351015, acc 0.84375, learning_rate 0.000877563\n",
      "2020-12-09T16:23:46.948033: step 1205, loss 0.170365, acc 0.9375, learning_rate 0.000876522\n",
      "2020-12-09T16:23:47.511491: step 1206, loss 0.173465, acc 0.96875, learning_rate 0.000875482\n",
      "2020-12-09T16:23:48.053703: step 1207, loss 0.254769, acc 0.84375, learning_rate 0.000874443\n",
      "2020-12-09T16:23:48.610354: step 1208, loss 0.384475, acc 0.84375, learning_rate 0.000873405\n",
      "2020-12-09T16:23:49.153916: step 1209, loss 0.459665, acc 0.84375, learning_rate 0.000872369\n",
      "2020-12-09T16:23:49.687857: step 1210, loss 0.136706, acc 0.9375, learning_rate 0.000871335\n",
      "2020-12-09T16:23:50.242358: step 1211, loss 0.260782, acc 0.84375, learning_rate 0.000870301\n",
      "2020-12-09T16:23:50.802744: step 1212, loss 0.296546, acc 0.9375, learning_rate 0.00086927\n",
      "2020-12-09T16:23:51.354381: step 1213, loss 0.381379, acc 0.875, learning_rate 0.000868239\n",
      "2020-12-09T16:23:51.899873: step 1214, loss 0.482361, acc 0.8125, learning_rate 0.00086721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:23:52.448536: step 1215, loss 0.215212, acc 0.90625, learning_rate 0.000866182\n",
      "2020-12-09T16:23:52.978026: step 1216, loss 0.197111, acc 0.9375, learning_rate 0.000865156\n",
      "2020-12-09T16:23:53.543516: step 1217, loss 0.22348, acc 0.90625, learning_rate 0.000864131\n",
      "2020-12-09T16:23:54.106616: step 1218, loss 0.0983737, acc 1, learning_rate 0.000863107\n",
      "2020-12-09T16:23:54.668892: step 1219, loss 0.167021, acc 0.9375, learning_rate 0.000862085\n",
      "2020-12-09T16:23:55.216767: step 1220, loss 0.144939, acc 0.96875, learning_rate 0.000861064\n",
      "2020-12-09T16:23:55.758111: step 1221, loss 0.232388, acc 0.90625, learning_rate 0.000860045\n",
      "2020-12-09T16:23:56.314307: step 1222, loss 0.266082, acc 0.875, learning_rate 0.000859027\n",
      "2020-12-09T16:23:56.865773: step 1223, loss 0.172312, acc 0.9375, learning_rate 0.00085801\n",
      "2020-12-09T16:23:57.417532: step 1224, loss 0.104565, acc 0.9375, learning_rate 0.000856994\n",
      "2020-12-09T16:23:57.968056: step 1225, loss 0.222575, acc 0.9375, learning_rate 0.00085598\n",
      "2020-12-09T16:23:58.511928: step 1226, loss 0.183075, acc 0.9375, learning_rate 0.000854968\n",
      "2020-12-09T16:23:59.050004: step 1227, loss 0.226852, acc 0.84375, learning_rate 0.000853956\n",
      "2020-12-09T16:23:59.609069: step 1228, loss 0.236893, acc 0.875, learning_rate 0.000852946\n",
      "2020-12-09T16:24:00.196873: step 1229, loss 0.204322, acc 0.90625, learning_rate 0.000851938\n",
      "2020-12-09T16:24:00.774900: step 1230, loss 0.279585, acc 0.8125, learning_rate 0.000850931\n",
      "2020-12-09T16:24:01.324199: step 1231, loss 0.238691, acc 0.84375, learning_rate 0.000849925\n",
      "2020-12-09T16:24:01.902827: step 1232, loss 0.143112, acc 0.9375, learning_rate 0.00084892\n",
      "2020-12-09T16:24:02.451280: step 1233, loss 0.153288, acc 0.96875, learning_rate 0.000847917\n",
      "2020-12-09T16:24:02.993313: step 1234, loss 0.364861, acc 0.84375, learning_rate 0.000846915\n",
      "2020-12-09T16:24:03.545539: step 1235, loss 0.142544, acc 0.90625, learning_rate 0.000845914\n",
      "2020-12-09T16:24:04.111185: step 1236, loss 0.115338, acc 0.96875, learning_rate 0.000844915\n",
      "2020-12-09T16:24:04.652575: step 1237, loss 0.12751, acc 0.96875, learning_rate 0.000843917\n",
      "2020-12-09T16:24:05.186278: step 1238, loss 0.128775, acc 0.96875, learning_rate 0.000842921\n",
      "2020-12-09T16:24:05.744692: step 1239, loss 0.14329, acc 0.9375, learning_rate 0.000841926\n",
      "2020-12-09T16:24:06.298941: step 1240, loss 0.211384, acc 0.90625, learning_rate 0.000840932\n",
      "2020-12-09T16:24:06.869966: step 1241, loss 0.223374, acc 0.90625, learning_rate 0.000839939\n",
      "2020-12-09T16:24:07.415528: step 1242, loss 0.235096, acc 0.875, learning_rate 0.000838948\n",
      "2020-12-09T16:24:07.991473: step 1243, loss 0.189145, acc 0.9375, learning_rate 0.000837958\n",
      "2020-12-09T16:24:08.552272: step 1244, loss 0.0834918, acc 1, learning_rate 0.00083697\n",
      "2020-12-09T16:24:09.089742: step 1245, loss 0.234528, acc 0.90625, learning_rate 0.000835983\n",
      "2020-12-09T16:24:09.668266: step 1246, loss 0.163393, acc 0.9375, learning_rate 0.000834997\n",
      "2020-12-09T16:24:10.231129: step 1247, loss 0.159756, acc 0.9375, learning_rate 0.000834012\n",
      "2020-12-09T16:24:10.797407: step 1248, loss 0.106142, acc 0.96875, learning_rate 0.000833029\n",
      "2020-12-09T16:24:11.330407: step 1249, loss 0.196317, acc 0.9375, learning_rate 0.000832047\n",
      "2020-12-09T16:24:11.880953: step 1250, loss 0.282396, acc 0.84375, learning_rate 0.000831066\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:24:15.181498: step 1250, loss 0.848707, acc 0.725597\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1250\n",
      "\n",
      "2020-12-09T16:24:16.605568: step 1251, loss 0.186553, acc 0.9375, learning_rate 0.000830087\n",
      "2020-12-09T16:24:17.156849: step 1252, loss 0.23094, acc 0.90625, learning_rate 0.000829109\n",
      "2020-12-09T16:24:17.722802: step 1253, loss 0.238682, acc 0.90625, learning_rate 0.000828132\n",
      "2020-12-09T16:24:18.274466: step 1254, loss 0.114671, acc 0.96875, learning_rate 0.000827157\n",
      "2020-12-09T16:24:18.838506: step 1255, loss 0.300403, acc 0.90625, learning_rate 0.000826183\n",
      "2020-12-09T16:24:19.386718: step 1256, loss 0.0556566, acc 0.96875, learning_rate 0.00082521\n",
      "2020-12-09T16:24:19.925716: step 1257, loss 0.144056, acc 0.9375, learning_rate 0.000824239\n",
      "2020-12-09T16:24:20.506250: step 1258, loss 0.442725, acc 0.8125, learning_rate 0.000823269\n",
      "2020-12-09T16:24:21.060739: step 1259, loss 0.261751, acc 0.875, learning_rate 0.0008223\n",
      "2020-12-09T16:24:21.623978: step 1260, loss 0.231446, acc 0.875, learning_rate 0.000821332\n",
      "2020-12-09T16:24:22.183811: step 1261, loss 0.228342, acc 0.875, learning_rate 0.000820366\n",
      "2020-12-09T16:24:22.732323: step 1262, loss 0.161034, acc 0.875, learning_rate 0.000819401\n",
      "2020-12-09T16:24:23.269366: step 1263, loss 0.0782755, acc 1, learning_rate 0.000818437\n",
      "2020-12-09T16:24:23.821375: step 1264, loss 0.330853, acc 0.84375, learning_rate 0.000817475\n",
      "2020-12-09T16:24:24.375739: step 1265, loss 0.29721, acc 0.90625, learning_rate 0.000816514\n",
      "2020-12-09T16:24:24.926521: step 1266, loss 0.0710743, acc 1, learning_rate 0.000815554\n",
      "2020-12-09T16:24:25.478828: step 1267, loss 0.235208, acc 0.875, learning_rate 0.000814595\n",
      "2020-12-09T16:24:26.046311: step 1268, loss 0.395506, acc 0.875, learning_rate 0.000813638\n",
      "2020-12-09T16:24:26.586296: step 1269, loss 0.257001, acc 0.875, learning_rate 0.000812682\n",
      "2020-12-09T16:24:27.126293: step 1270, loss 0.209542, acc 0.9375, learning_rate 0.000811727\n",
      "2020-12-09T16:24:27.682125: step 1271, loss 0.361388, acc 0.875, learning_rate 0.000810774\n",
      "2020-12-09T16:24:28.227737: step 1272, loss 0.27768, acc 0.9375, learning_rate 0.000809822\n",
      "2020-12-09T16:24:28.781203: step 1273, loss 0.330544, acc 0.8125, learning_rate 0.000808871\n",
      "2020-12-09T16:24:29.354707: step 1274, loss 0.307212, acc 0.875, learning_rate 0.000807922\n",
      "2020-12-09T16:24:29.918118: step 1275, loss 0.322794, acc 0.90625, learning_rate 0.000806973\n",
      "2020-12-09T16:24:30.491654: step 1276, loss 0.257785, acc 0.90625, learning_rate 0.000806026\n",
      "2020-12-09T16:24:31.058784: step 1277, loss 0.150189, acc 0.9375, learning_rate 0.00080508\n",
      "2020-12-09T16:24:31.630784: step 1278, loss 0.290414, acc 0.875, learning_rate 0.000804136\n",
      "2020-12-09T16:24:32.213319: step 1279, loss 0.262957, acc 0.8125, learning_rate 0.000803193\n",
      "2020-12-09T16:24:32.775667: step 1280, loss 0.179155, acc 0.90625, learning_rate 0.000802251\n",
      "2020-12-09T16:24:33.331201: step 1281, loss 0.1933, acc 0.875, learning_rate 0.00080131\n",
      "2020-12-09T16:24:33.904174: step 1282, loss 0.120528, acc 0.96875, learning_rate 0.000800371\n",
      "2020-12-09T16:24:34.474209: step 1283, loss 0.137949, acc 0.90625, learning_rate 0.000799432\n",
      "2020-12-09T16:24:35.036673: step 1284, loss 0.475725, acc 0.8125, learning_rate 0.000798495\n",
      "2020-12-09T16:24:35.591710: step 1285, loss 0.0413923, acc 1, learning_rate 0.00079756\n",
      "2020-12-09T16:24:36.168651: step 1286, loss 0.297388, acc 0.84375, learning_rate 0.000796625\n",
      "2020-12-09T16:24:36.726532: step 1287, loss 0.328744, acc 0.84375, learning_rate 0.000795692\n",
      "2020-12-09T16:24:37.264636: step 1288, loss 0.30292, acc 0.8125, learning_rate 0.00079476\n",
      "2020-12-09T16:24:37.823907: step 1289, loss 0.260378, acc 0.90625, learning_rate 0.00079383\n",
      "2020-12-09T16:24:38.380405: step 1290, loss 0.227025, acc 0.90625, learning_rate 0.0007929\n",
      "2020-12-09T16:24:38.921232: step 1291, loss 0.249853, acc 0.90625, learning_rate 0.000791972\n",
      "2020-12-09T16:24:39.467788: step 1292, loss 0.21186, acc 0.8125, learning_rate 0.000791045\n",
      "2020-12-09T16:24:40.014788: step 1293, loss 0.147531, acc 0.9375, learning_rate 0.000790119\n",
      "2020-12-09T16:24:40.574888: step 1294, loss 0.228806, acc 0.9375, learning_rate 0.000789195\n",
      "2020-12-09T16:24:41.139784: step 1295, loss 0.166179, acc 0.96875, learning_rate 0.000788272\n",
      "2020-12-09T16:24:41.697284: step 1296, loss 0.245385, acc 0.875, learning_rate 0.00078735\n",
      "2020-12-09T16:24:42.255145: step 1297, loss 0.239681, acc 0.8125, learning_rate 0.000786429\n",
      "2020-12-09T16:24:42.815224: step 1298, loss 0.38768, acc 0.90625, learning_rate 0.000785509\n",
      "2020-12-09T16:24:43.339187: step 1299, loss 0.126959, acc 0.96875, learning_rate 0.000784591\n",
      "2020-12-09T16:24:43.877686: step 1300, loss 0.191238, acc 0.9375, learning_rate 0.000783674\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:24:47.061861: step 1300, loss 0.844705, acc 0.714286\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1300\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:24:48.555362: step 1301, loss 0.109531, acc 0.96875, learning_rate 0.000782758\n",
      "2020-12-09T16:24:49.098933: step 1302, loss 0.242656, acc 0.84375, learning_rate 0.000781844\n",
      "2020-12-09T16:24:49.637847: step 1303, loss 0.297556, acc 0.90625, learning_rate 0.00078093\n",
      "2020-12-09T16:24:50.199883: step 1304, loss 0.187403, acc 0.90625, learning_rate 0.000780018\n",
      "2020-12-09T16:24:50.772315: step 1305, loss 0.136192, acc 0.9375, learning_rate 0.000779107\n",
      "2020-12-09T16:24:51.312815: step 1306, loss 0.126296, acc 0.9375, learning_rate 0.000778198\n",
      "2020-12-09T16:24:51.875729: step 1307, loss 0.230795, acc 0.90625, learning_rate 0.000777289\n",
      "2020-12-09T16:24:52.441857: step 1308, loss 0.231996, acc 0.90625, learning_rate 0.000776382\n",
      "2020-12-09T16:24:52.976786: step 1309, loss 0.151901, acc 0.96875, learning_rate 0.000775476\n",
      "2020-12-09T16:24:53.540752: step 1310, loss 0.0930828, acc 0.96875, learning_rate 0.000774571\n",
      "2020-12-09T16:24:54.100072: step 1311, loss 0.287803, acc 0.875, learning_rate 0.000773667\n",
      "2020-12-09T16:24:54.661267: step 1312, loss 0.142238, acc 0.875, learning_rate 0.000772765\n",
      "2020-12-09T16:24:55.230679: step 1313, loss 0.103819, acc 0.96875, learning_rate 0.000771864\n",
      "2020-12-09T16:24:55.784980: step 1314, loss 0.199937, acc 0.90625, learning_rate 0.000770964\n",
      "2020-12-09T16:24:56.331855: step 1315, loss 0.161848, acc 0.96875, learning_rate 0.000770065\n",
      "2020-12-09T16:24:56.882870: step 1316, loss 0.22718, acc 0.9375, learning_rate 0.000769167\n",
      "2020-12-09T16:24:57.410003: step 1317, loss 0.204997, acc 0.9375, learning_rate 0.000768271\n",
      "2020-12-09T16:24:57.964110: step 1318, loss 0.0355676, acc 1, learning_rate 0.000767376\n",
      "2020-12-09T16:24:58.522790: step 1319, loss 0.117169, acc 1, learning_rate 0.000766482\n",
      "2020-12-09T16:24:59.096326: step 1320, loss 0.218963, acc 0.9375, learning_rate 0.000765589\n",
      "2020-12-09T16:24:59.641853: step 1321, loss 0.128724, acc 0.9375, learning_rate 0.000764697\n",
      "2020-12-09T16:25:00.191693: step 1322, loss 0.146067, acc 0.90625, learning_rate 0.000763807\n",
      "2020-12-09T16:25:00.800518: step 1323, loss 0.3061, acc 0.875, learning_rate 0.000762918\n",
      "2020-12-09T16:25:01.350517: step 1324, loss 0.260297, acc 0.875, learning_rate 0.00076203\n",
      "2020-12-09T16:25:01.918049: step 1325, loss 0.287081, acc 0.84375, learning_rate 0.000761143\n",
      "2020-12-09T16:25:02.483159: step 1326, loss 0.14411, acc 0.9375, learning_rate 0.000760257\n",
      "2020-12-09T16:25:03.056694: step 1327, loss 0.171566, acc 0.9375, learning_rate 0.000759373\n",
      "2020-12-09T16:25:03.593689: step 1328, loss 0.27725, acc 0.9375, learning_rate 0.00075849\n",
      "2020-12-09T16:25:04.165145: step 1329, loss 0.218691, acc 0.90625, learning_rate 0.000757608\n",
      "2020-12-09T16:25:04.717970: step 1330, loss 0.166416, acc 0.90625, learning_rate 0.000756727\n",
      "2020-12-09T16:25:05.295367: step 1331, loss 0.0918209, acc 1, learning_rate 0.000755847\n",
      "2020-12-09T16:25:05.854883: step 1332, loss 0.263661, acc 0.875, learning_rate 0.000754968\n",
      "2020-12-09T16:25:06.436700: step 1333, loss 0.37045, acc 0.875, learning_rate 0.000754091\n",
      "2020-12-09T16:25:06.998888: step 1334, loss 0.277267, acc 0.90625, learning_rate 0.000753215\n",
      "2020-12-09T16:25:07.536924: step 1335, loss 0.419072, acc 0.71875, learning_rate 0.00075234\n",
      "2020-12-09T16:25:08.104923: step 1336, loss 0.16364, acc 0.9375, learning_rate 0.000751466\n",
      "2020-12-09T16:25:08.648386: step 1337, loss 0.212332, acc 0.90625, learning_rate 0.000750593\n",
      "2020-12-09T16:25:09.208506: step 1338, loss 0.44905, acc 0.90625, learning_rate 0.000749722\n",
      "2020-12-09T16:25:09.758971: step 1339, loss 0.231286, acc 0.9375, learning_rate 0.000748851\n",
      "2020-12-09T16:25:10.302723: step 1340, loss 0.0917046, acc 0.9375, learning_rate 0.000747982\n",
      "2020-12-09T16:25:10.838764: step 1341, loss 0.211896, acc 0.90625, learning_rate 0.000747114\n",
      "2020-12-09T16:25:11.390225: step 1342, loss 0.325059, acc 0.84375, learning_rate 0.000746247\n",
      "2020-12-09T16:25:11.952183: step 1343, loss 0.17645, acc 0.9375, learning_rate 0.000745382\n",
      "2020-12-09T16:25:12.495219: step 1344, loss 0.169257, acc 0.90625, learning_rate 0.000744517\n",
      "2020-12-09T16:25:13.051854: step 1345, loss 0.158518, acc 0.90625, learning_rate 0.000743654\n",
      "2020-12-09T16:25:13.585329: step 1346, loss 0.207849, acc 0.875, learning_rate 0.000742792\n",
      "2020-12-09T16:25:14.151263: step 1347, loss 0.15805, acc 0.9375, learning_rate 0.000741931\n",
      "2020-12-09T16:25:14.694431: step 1348, loss 0.217449, acc 0.875, learning_rate 0.000741071\n",
      "2020-12-09T16:25:15.275750: step 1349, loss 0.339947, acc 0.84375, learning_rate 0.000740212\n",
      "2020-12-09T16:25:15.819215: step 1350, loss 0.148122, acc 0.96875, learning_rate 0.000739354\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:25:18.964681: step 1350, loss 0.880788, acc 0.71261\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1350\n",
      "\n",
      "2020-12-09T16:25:20.442550: step 1351, loss 0.0515439, acc 0.96875, learning_rate 0.000738498\n",
      "2020-12-09T16:25:21.004196: step 1352, loss 0.100463, acc 0.9375, learning_rate 0.000737643\n",
      "2020-12-09T16:25:21.549767: step 1353, loss 0.263342, acc 0.84375, learning_rate 0.000736788\n",
      "2020-12-09T16:25:22.098267: step 1354, loss 0.15355, acc 0.9375, learning_rate 0.000735935\n",
      "2020-12-09T16:25:22.673596: step 1355, loss 0.200992, acc 0.90625, learning_rate 0.000735083\n",
      "2020-12-09T16:25:23.241756: step 1356, loss 0.119236, acc 1, learning_rate 0.000734233\n",
      "2020-12-09T16:25:23.773257: step 1357, loss 0.177849, acc 0.90625, learning_rate 0.000733383\n",
      "2020-12-09T16:25:24.322310: step 1358, loss 0.342476, acc 0.84375, learning_rate 0.000732535\n",
      "2020-12-09T16:25:24.900870: step 1359, loss 0.0645785, acc 0.96875, learning_rate 0.000731687\n",
      "2020-12-09T16:25:25.439868: step 1360, loss 0.231244, acc 0.84375, learning_rate 0.000730841\n",
      "2020-12-09T16:25:25.976501: step 1361, loss 0.118124, acc 0.9375, learning_rate 0.000729996\n",
      "2020-12-09T16:25:26.520654: step 1362, loss 0.180118, acc 0.90625, learning_rate 0.000729152\n",
      "2020-12-09T16:25:27.052676: step 1363, loss 0.17541, acc 0.90625, learning_rate 0.000728309\n",
      "2020-12-09T16:25:27.601209: step 1364, loss 0.269385, acc 0.90625, learning_rate 0.000727468\n",
      "2020-12-09T16:25:28.153207: step 1365, loss 0.0927008, acc 1, learning_rate 0.000726627\n",
      "2020-12-09T16:25:28.753623: step 1366, loss 0.146747, acc 0.96875, learning_rate 0.000725788\n",
      "2020-12-09T16:25:29.309127: step 1367, loss 0.154397, acc 0.96875, learning_rate 0.00072495\n",
      "2020-12-09T16:25:29.867674: step 1368, loss 0.0709433, acc 1, learning_rate 0.000724112\n",
      "2020-12-09T16:25:30.412446: step 1369, loss 0.0950547, acc 1, learning_rate 0.000723276\n",
      "2020-12-09T16:25:30.958444: step 1370, loss 0.250549, acc 0.9375, learning_rate 0.000722441\n",
      "2020-12-09T16:25:31.501809: step 1371, loss 0.360431, acc 0.84375, learning_rate 0.000721608\n",
      "2020-12-09T16:25:32.052428: step 1372, loss 0.158342, acc 0.875, learning_rate 0.000720775\n",
      "2020-12-09T16:25:32.604007: step 1373, loss 0.178374, acc 0.90625, learning_rate 0.000719943\n",
      "2020-12-09T16:25:33.177218: step 1374, loss 0.372547, acc 0.90625, learning_rate 0.000719113\n",
      "2020-12-09T16:25:33.734694: step 1375, loss 0.113198, acc 0.96875, learning_rate 0.000718284\n",
      "2020-12-09T16:25:34.285194: step 1376, loss 0.229984, acc 0.9375, learning_rate 0.000717455\n",
      "2020-12-09T16:25:34.838602: step 1377, loss 0.128311, acc 0.9375, learning_rate 0.000716628\n",
      "2020-12-09T16:25:35.385567: step 1378, loss 0.629005, acc 0.75, learning_rate 0.000715802\n",
      "2020-12-09T16:25:35.958506: step 1379, loss 0.232269, acc 0.9375, learning_rate 0.000714977\n",
      "2020-12-09T16:25:36.543714: step 1380, loss 0.286706, acc 0.875, learning_rate 0.000714154\n",
      "2020-12-09T16:25:37.113888: step 1381, loss 0.16514, acc 0.90625, learning_rate 0.000713331\n",
      "2020-12-09T16:25:37.706387: step 1382, loss 0.205548, acc 0.9375, learning_rate 0.000712509\n",
      "2020-12-09T16:25:38.288422: step 1383, loss 0.210755, acc 0.875, learning_rate 0.000711689\n",
      "2020-12-09T16:25:38.839925: step 1384, loss 0.118315, acc 0.96875, learning_rate 0.000710869\n",
      "2020-12-09T16:25:39.394950: step 1385, loss 0.164855, acc 0.9375, learning_rate 0.000710051\n",
      "2020-12-09T16:25:39.939951: step 1386, loss 0.238817, acc 0.9375, learning_rate 0.000709234\n",
      "2020-12-09T16:25:40.495185: step 1387, loss 0.411266, acc 0.875, learning_rate 0.000708418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:25:41.041262: step 1388, loss 0.143564, acc 0.96875, learning_rate 0.000707603\n",
      "2020-12-09T16:25:41.591147: step 1389, loss 0.053457, acc 0.96875, learning_rate 0.000706789\n",
      "2020-12-09T16:25:42.134843: step 1390, loss 0.190683, acc 0.875, learning_rate 0.000705976\n",
      "2020-12-09T16:25:42.700758: step 1391, loss 0.497028, acc 0.875, learning_rate 0.000705164\n",
      "2020-12-09T16:25:43.255356: step 1392, loss 0.222928, acc 0.9375, learning_rate 0.000704354\n",
      "2020-12-09T16:25:43.808587: step 1393, loss 0.136338, acc 0.96875, learning_rate 0.000703544\n",
      "2020-12-09T16:25:44.360088: step 1394, loss 0.321965, acc 0.90625, learning_rate 0.000702736\n",
      "2020-12-09T16:25:44.898056: step 1395, loss 0.226393, acc 0.9375, learning_rate 0.000701928\n",
      "2020-12-09T16:25:45.449587: step 1396, loss 0.190697, acc 0.9375, learning_rate 0.000701122\n",
      "2020-12-09T16:25:45.987444: step 1397, loss 0.292954, acc 0.875, learning_rate 0.000700317\n",
      "2020-12-09T16:25:46.543480: step 1398, loss 0.243821, acc 0.875, learning_rate 0.000699513\n",
      "2020-12-09T16:25:47.080785: step 1399, loss 0.145303, acc 0.9375, learning_rate 0.000698709\n",
      "2020-12-09T16:25:47.632890: step 1400, loss 0.257939, acc 0.90625, learning_rate 0.000697907\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:25:50.892460: step 1400, loss 0.892928, acc 0.722664\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1400\n",
      "\n",
      "2020-12-09T16:25:52.464493: step 1401, loss 0.194889, acc 0.84375, learning_rate 0.000697107\n",
      "2020-12-09T16:25:53.020599: step 1402, loss 0.312012, acc 0.90625, learning_rate 0.000696307\n",
      "2020-12-09T16:25:53.570925: step 1403, loss 0.102393, acc 0.9375, learning_rate 0.000695508\n",
      "2020-12-09T16:25:54.110425: step 1404, loss 0.152016, acc 0.96875, learning_rate 0.00069471\n",
      "2020-12-09T16:25:54.669013: step 1405, loss 0.0940115, acc 1, learning_rate 0.000693914\n",
      "2020-12-09T16:25:55.214976: step 1406, loss 0.09224, acc 1, learning_rate 0.000693118\n",
      "2020-12-09T16:25:55.787481: step 1407, loss 0.309831, acc 0.875, learning_rate 0.000692323\n",
      "2020-12-09T16:25:56.343793: step 1408, loss 0.335094, acc 0.875, learning_rate 0.00069153\n",
      "2020-12-09T16:25:56.922680: step 1409, loss 0.279367, acc 0.84375, learning_rate 0.000690738\n",
      "2020-12-09T16:25:57.491611: step 1410, loss 0.249553, acc 0.875, learning_rate 0.000689946\n",
      "2020-12-09T16:25:58.054142: step 1411, loss 0.159671, acc 0.90625, learning_rate 0.000689156\n",
      "2020-12-09T16:25:58.600772: step 1412, loss 0.359309, acc 0.90625, learning_rate 0.000688367\n",
      "2020-12-09T16:25:59.159997: step 1413, loss 0.325031, acc 0.875, learning_rate 0.000687579\n",
      "2020-12-09T16:25:59.719473: step 1414, loss 0.124944, acc 0.96875, learning_rate 0.000686792\n",
      "2020-12-09T16:26:00.255550: step 1415, loss 0.0877497, acc 0.96875, learning_rate 0.000686005\n",
      "2020-12-09T16:26:00.803399: step 1416, loss 0.200555, acc 0.9375, learning_rate 0.000685221\n",
      "2020-12-09T16:26:01.392707: step 1417, loss 0.0905236, acc 1, learning_rate 0.000684437\n",
      "2020-12-09T16:26:01.942746: step 1418, loss 0.487825, acc 0.84375, learning_rate 0.000683654\n",
      "2020-12-09T16:26:02.497745: step 1419, loss 0.148231, acc 0.9375, learning_rate 0.000682872\n",
      "2020-12-09T16:26:03.057403: step 1420, loss 0.182862, acc 0.9375, learning_rate 0.000682091\n",
      "2020-12-09T16:26:03.642417: step 1421, loss 0.211363, acc 0.875, learning_rate 0.000681311\n",
      "2020-12-09T16:26:04.188141: step 1422, loss 0.228688, acc 0.875, learning_rate 0.000680533\n",
      "2020-12-09T16:26:04.730362: step 1423, loss 0.345748, acc 0.8125, learning_rate 0.000679755\n",
      "2020-12-09T16:26:05.285796: step 1424, loss 0.187326, acc 0.96875, learning_rate 0.000678978\n",
      "2020-12-09T16:26:05.844192: step 1425, loss 0.10648, acc 0.96875, learning_rate 0.000678203\n",
      "2020-12-09T16:26:06.386680: step 1426, loss 0.158393, acc 0.96875, learning_rate 0.000677428\n",
      "2020-12-09T16:26:06.973338: step 1427, loss 0.168205, acc 0.90625, learning_rate 0.000676655\n",
      "2020-12-09T16:26:07.506525: step 1428, loss 0.294854, acc 0.9375, learning_rate 0.000675882\n",
      "2020-12-09T16:26:08.059493: step 1429, loss 0.39349, acc 0.84375, learning_rate 0.000675111\n",
      "2020-12-09T16:26:08.611597: step 1430, loss 0.235731, acc 0.9375, learning_rate 0.00067434\n",
      "2020-12-09T16:26:09.177594: step 1431, loss 0.110632, acc 0.9375, learning_rate 0.000673571\n",
      "2020-12-09T16:26:09.716446: step 1432, loss 0.256608, acc 0.90625, learning_rate 0.000672803\n",
      "2020-12-09T16:26:10.256970: step 1433, loss 0.264673, acc 0.90625, learning_rate 0.000672035\n",
      "2020-12-09T16:26:10.796495: step 1434, loss 0.0916246, acc 0.96875, learning_rate 0.000671269\n",
      "2020-12-09T16:26:11.341992: step 1435, loss 0.0949092, acc 0.96875, learning_rate 0.000670504\n",
      "2020-12-09T16:26:11.898725: step 1436, loss 0.137416, acc 0.90625, learning_rate 0.00066974\n",
      "2020-12-09T16:26:12.454330: step 1437, loss 0.111493, acc 1, learning_rate 0.000668977\n",
      "2020-12-09T16:26:13.046507: step 1438, loss 0.138054, acc 1, learning_rate 0.000668214\n",
      "2020-12-09T16:26:13.584711: step 1439, loss 0.416019, acc 0.875, learning_rate 0.000667453\n",
      "2020-12-09T16:26:14.126122: step 1440, loss 0.130978, acc 0.9375, learning_rate 0.000666693\n",
      "2020-12-09T16:26:14.677018: step 1441, loss 0.207345, acc 0.9375, learning_rate 0.000665934\n",
      "2020-12-09T16:26:15.207484: step 1442, loss 0.206881, acc 0.9375, learning_rate 0.000665176\n",
      "2020-12-09T16:26:15.759548: step 1443, loss 0.129852, acc 0.9375, learning_rate 0.000664419\n",
      "2020-12-09T16:26:16.308695: step 1444, loss 0.202029, acc 0.90625, learning_rate 0.000663663\n",
      "2020-12-09T16:26:16.863553: step 1445, loss 0.240492, acc 0.90625, learning_rate 0.000662908\n",
      "2020-12-09T16:26:17.417424: step 1446, loss 0.185741, acc 0.9375, learning_rate 0.000662154\n",
      "2020-12-09T16:26:17.967320: step 1447, loss 0.10878, acc 0.90625, learning_rate 0.000661401\n",
      "2020-12-09T16:26:18.523820: step 1448, loss 0.379248, acc 0.84375, learning_rate 0.000660649\n",
      "2020-12-09T16:26:19.075364: step 1449, loss 0.147717, acc 0.9375, learning_rate 0.000659897\n",
      "2020-12-09T16:26:19.638221: step 1450, loss 0.127228, acc 0.90625, learning_rate 0.000659147\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:26:22.827720: step 1450, loss 0.850283, acc 0.727273\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1450\n",
      "\n",
      "2020-12-09T16:26:24.252750: step 1451, loss 0.0563297, acc 0.96875, learning_rate 0.000658398\n",
      "2020-12-09T16:26:24.821250: step 1452, loss 0.207491, acc 0.875, learning_rate 0.00065765\n",
      "2020-12-09T16:26:25.373464: step 1453, loss 0.140379, acc 0.96875, learning_rate 0.000656903\n",
      "2020-12-09T16:26:25.932947: step 1454, loss 0.210418, acc 0.875, learning_rate 0.000656157\n",
      "2020-12-09T16:26:26.479460: step 1455, loss 0.452551, acc 0.875, learning_rate 0.000655412\n",
      "2020-12-09T16:26:27.029379: step 1456, loss 0.168311, acc 0.9375, learning_rate 0.000654668\n",
      "2020-12-09T16:26:27.588481: step 1457, loss 0.314937, acc 0.9375, learning_rate 0.000653925\n",
      "2020-12-09T16:26:28.150979: step 1458, loss 0.140027, acc 0.9375, learning_rate 0.000653183\n",
      "2020-12-09T16:26:28.708448: step 1459, loss 0.279862, acc 0.9375, learning_rate 0.000652442\n",
      "2020-12-09T16:26:29.248981: step 1460, loss 0.079288, acc 1, learning_rate 0.000651702\n",
      "2020-12-09T16:26:29.815300: step 1461, loss 0.283314, acc 0.84375, learning_rate 0.000650963\n",
      "2020-12-09T16:26:30.352429: step 1462, loss 0.105677, acc 0.9375, learning_rate 0.000650225\n",
      "2020-12-09T16:26:30.942900: step 1463, loss 0.177674, acc 0.90625, learning_rate 0.000649488\n",
      "2020-12-09T16:26:31.499654: step 1464, loss 0.203755, acc 0.875, learning_rate 0.000648752\n",
      "2020-12-09T16:26:32.045850: step 1465, loss 0.245725, acc 0.875, learning_rate 0.000648017\n",
      "2020-12-09T16:26:32.617340: step 1466, loss 0.0926327, acc 0.96875, learning_rate 0.000647283\n",
      "2020-12-09T16:26:33.207181: step 1467, loss 0.098434, acc 0.9375, learning_rate 0.00064655\n",
      "2020-12-09T16:26:33.778688: step 1468, loss 0.0923636, acc 0.96875, learning_rate 0.000645818\n",
      "2020-12-09T16:26:34.327714: step 1469, loss 0.228541, acc 0.96875, learning_rate 0.000645087\n",
      "2020-12-09T16:26:34.883018: step 1470, loss 0.370971, acc 0.84375, learning_rate 0.000644356\n",
      "2020-12-09T16:26:35.425608: step 1471, loss 0.474981, acc 0.875, learning_rate 0.000643627\n",
      "2020-12-09T16:26:35.984657: step 1472, loss 0.227886, acc 0.90625, learning_rate 0.000642899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:26:36.530618: step 1473, loss 0.0940781, acc 0.96875, learning_rate 0.000642172\n",
      "2020-12-09T16:26:37.086638: step 1474, loss 0.091528, acc 0.96875, learning_rate 0.000641445\n",
      "2020-12-09T16:26:37.636892: step 1475, loss 0.2701, acc 0.875, learning_rate 0.00064072\n",
      "2020-12-09T16:26:38.190268: step 1476, loss 0.380841, acc 0.84375, learning_rate 0.000639996\n",
      "2020-12-09T16:26:38.747807: step 1477, loss 0.25219, acc 0.9375, learning_rate 0.000639272\n",
      "2020-12-09T16:26:39.357014: step 1478, loss 0.225591, acc 0.875, learning_rate 0.00063855\n",
      "2020-12-09T16:26:39.909386: step 1479, loss 0.148733, acc 0.96875, learning_rate 0.000637829\n",
      "2020-12-09T16:26:40.458394: step 1480, loss 0.115666, acc 0.96875, learning_rate 0.000637108\n",
      "2020-12-09T16:26:41.006098: step 1481, loss 0.25117, acc 0.875, learning_rate 0.000636389\n",
      "2020-12-09T16:26:41.574182: step 1482, loss 0.338307, acc 0.90625, learning_rate 0.00063567\n",
      "2020-12-09T16:26:42.139192: step 1483, loss 0.148501, acc 0.90625, learning_rate 0.000634953\n",
      "2020-12-09T16:26:42.727318: step 1484, loss 0.221284, acc 0.90625, learning_rate 0.000634236\n",
      "2020-12-09T16:26:43.302342: step 1485, loss 0.673174, acc 0.90625, learning_rate 0.00063352\n",
      "2020-12-09T16:26:43.862810: step 1486, loss 0.187215, acc 0.9375, learning_rate 0.000632806\n",
      "2020-12-09T16:26:44.425310: step 1487, loss 0.239063, acc 0.8125, learning_rate 0.000632092\n",
      "2020-12-09T16:26:44.995342: step 1488, loss 0.217826, acc 0.96875, learning_rate 0.000631379\n",
      "2020-12-09T16:26:45.545811: step 1489, loss 0.391071, acc 0.8125, learning_rate 0.000630667\n",
      "2020-12-09T16:26:46.106152: step 1490, loss 0.199139, acc 0.9375, learning_rate 0.000629957\n",
      "2020-12-09T16:26:46.677972: step 1491, loss 0.18861, acc 0.90625, learning_rate 0.000629247\n",
      "2020-12-09T16:26:47.240813: step 1492, loss 0.205216, acc 0.90625, learning_rate 0.000628538\n",
      "2020-12-09T16:26:47.810382: step 1493, loss 0.0990148, acc 0.96875, learning_rate 0.00062783\n",
      "2020-12-09T16:26:48.348847: step 1494, loss 0.207551, acc 0.90625, learning_rate 0.000627123\n",
      "2020-12-09T16:26:48.568351: step 1495, loss 0.0804989, acc 1, learning_rate 0.000626417\n",
      "2020-12-09T16:26:49.126480: step 1496, loss 0.115226, acc 0.96875, learning_rate 0.000625711\n",
      "2020-12-09T16:26:49.674355: step 1497, loss 0.342295, acc 0.90625, learning_rate 0.000625007\n",
      "2020-12-09T16:26:50.252937: step 1498, loss 0.42243, acc 0.8125, learning_rate 0.000624304\n",
      "2020-12-09T16:26:50.799436: step 1499, loss 0.265375, acc 0.90625, learning_rate 0.000623602\n",
      "2020-12-09T16:26:51.402471: step 1500, loss 0.126168, acc 0.9375, learning_rate 0.0006229\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:26:54.647375: step 1500, loss 0.880295, acc 0.717637\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1500\n",
      "\n",
      "2020-12-09T16:26:56.135349: step 1501, loss 0.167523, acc 0.90625, learning_rate 0.0006222\n",
      "2020-12-09T16:26:56.674842: step 1502, loss 0.104034, acc 0.96875, learning_rate 0.0006215\n",
      "2020-12-09T16:26:57.219165: step 1503, loss 0.18232, acc 0.9375, learning_rate 0.000620802\n",
      "2020-12-09T16:26:57.760456: step 1504, loss 0.340071, acc 0.90625, learning_rate 0.000620104\n",
      "2020-12-09T16:26:58.318458: step 1505, loss 0.202131, acc 0.9375, learning_rate 0.000619407\n",
      "2020-12-09T16:26:58.866422: step 1506, loss 0.455997, acc 0.65625, learning_rate 0.000618711\n",
      "2020-12-09T16:26:59.451818: step 1507, loss 0.235594, acc 0.875, learning_rate 0.000618017\n",
      "2020-12-09T16:27:00.005807: step 1508, loss 0.227066, acc 0.875, learning_rate 0.000617323\n",
      "2020-12-09T16:27:00.537837: step 1509, loss 0.134223, acc 0.96875, learning_rate 0.00061663\n",
      "2020-12-09T16:27:01.103973: step 1510, loss 0.155874, acc 0.90625, learning_rate 0.000615938\n",
      "2020-12-09T16:27:01.632950: step 1511, loss 0.155952, acc 0.90625, learning_rate 0.000615247\n",
      "2020-12-09T16:27:02.273510: step 1512, loss 0.268034, acc 0.90625, learning_rate 0.000614556\n",
      "2020-12-09T16:27:02.820446: step 1513, loss 0.0999014, acc 0.96875, learning_rate 0.000613867\n",
      "2020-12-09T16:27:03.363188: step 1514, loss 0.139496, acc 0.9375, learning_rate 0.000613179\n",
      "2020-12-09T16:27:03.926658: step 1515, loss 0.181351, acc 0.90625, learning_rate 0.000612491\n",
      "2020-12-09T16:27:04.500098: step 1516, loss 0.145592, acc 0.9375, learning_rate 0.000611805\n",
      "2020-12-09T16:27:05.060098: step 1517, loss 0.117221, acc 0.9375, learning_rate 0.000611119\n",
      "2020-12-09T16:27:05.607597: step 1518, loss 0.208451, acc 0.90625, learning_rate 0.000610435\n",
      "2020-12-09T16:27:06.164103: step 1519, loss 0.12031, acc 0.96875, learning_rate 0.000609751\n",
      "2020-12-09T16:27:06.706630: step 1520, loss 0.188242, acc 0.90625, learning_rate 0.000609068\n",
      "2020-12-09T16:27:07.264856: step 1521, loss 0.23581, acc 0.84375, learning_rate 0.000608386\n",
      "2020-12-09T16:27:07.846168: step 1522, loss 0.167114, acc 0.90625, learning_rate 0.000607705\n",
      "2020-12-09T16:27:08.396699: step 1523, loss 0.122208, acc 0.96875, learning_rate 0.000607025\n",
      "2020-12-09T16:27:08.941272: step 1524, loss 0.126414, acc 0.96875, learning_rate 0.000606346\n",
      "2020-12-09T16:27:09.513924: step 1525, loss 0.0799621, acc 1, learning_rate 0.000605667\n",
      "2020-12-09T16:27:10.056495: step 1526, loss 0.143115, acc 0.90625, learning_rate 0.00060499\n",
      "2020-12-09T16:27:10.610026: step 1527, loss 0.182691, acc 0.90625, learning_rate 0.000604314\n",
      "2020-12-09T16:27:11.162410: step 1528, loss 0.207737, acc 0.9375, learning_rate 0.000603638\n",
      "2020-12-09T16:27:11.744788: step 1529, loss 0.054863, acc 1, learning_rate 0.000602963\n",
      "2020-12-09T16:27:12.329142: step 1530, loss 0.115781, acc 0.9375, learning_rate 0.00060229\n",
      "2020-12-09T16:27:12.885513: step 1531, loss 0.42189, acc 0.84375, learning_rate 0.000601617\n",
      "2020-12-09T16:27:13.440931: step 1532, loss 0.0525752, acc 1, learning_rate 0.000600945\n",
      "2020-12-09T16:27:14.006540: step 1533, loss 0.271978, acc 0.90625, learning_rate 0.000600274\n",
      "2020-12-09T16:27:14.556524: step 1534, loss 0.198178, acc 0.9375, learning_rate 0.000599604\n",
      "2020-12-09T16:27:15.117447: step 1535, loss 0.222217, acc 0.90625, learning_rate 0.000598934\n",
      "2020-12-09T16:27:15.674466: step 1536, loss 0.354232, acc 0.875, learning_rate 0.000598266\n",
      "2020-12-09T16:27:16.227859: step 1537, loss 0.0700102, acc 1, learning_rate 0.000597599\n",
      "2020-12-09T16:27:16.780323: step 1538, loss 0.0587611, acc 0.96875, learning_rate 0.000596932\n",
      "2020-12-09T16:27:17.332938: step 1539, loss 0.253622, acc 0.875, learning_rate 0.000596266\n",
      "2020-12-09T16:27:17.863977: step 1540, loss 0.129023, acc 0.90625, learning_rate 0.000595602\n",
      "2020-12-09T16:27:18.401953: step 1541, loss 0.240307, acc 0.875, learning_rate 0.000594938\n",
      "2020-12-09T16:27:18.948186: step 1542, loss 0.235265, acc 0.90625, learning_rate 0.000594275\n",
      "2020-12-09T16:27:19.505070: step 1543, loss 0.121832, acc 0.9375, learning_rate 0.000593613\n",
      "2020-12-09T16:27:20.039533: step 1544, loss 0.0853961, acc 1, learning_rate 0.000592951\n",
      "2020-12-09T16:27:20.583247: step 1545, loss 0.311983, acc 0.9375, learning_rate 0.000592291\n",
      "2020-12-09T16:27:21.134954: step 1546, loss 0.243268, acc 0.90625, learning_rate 0.000591632\n",
      "2020-12-09T16:27:21.721654: step 1547, loss 0.168547, acc 0.96875, learning_rate 0.000590973\n",
      "2020-12-09T16:27:22.277830: step 1548, loss 0.0693542, acc 0.96875, learning_rate 0.000590315\n",
      "2020-12-09T16:27:22.835827: step 1549, loss 0.200852, acc 0.90625, learning_rate 0.000589659\n",
      "2020-12-09T16:27:23.388787: step 1550, loss 0.500681, acc 0.84375, learning_rate 0.000589003\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:27:26.729488: step 1550, loss 0.888137, acc 0.717637\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1550\n",
      "\n",
      "2020-12-09T16:27:28.196064: step 1551, loss 0.240304, acc 0.90625, learning_rate 0.000588348\n",
      "2020-12-09T16:27:28.744029: step 1552, loss 0.20521, acc 0.90625, learning_rate 0.000587693\n",
      "2020-12-09T16:27:29.298491: step 1553, loss 0.270511, acc 0.875, learning_rate 0.00058704\n",
      "2020-12-09T16:27:29.844515: step 1554, loss 0.275118, acc 0.875, learning_rate 0.000586388\n",
      "2020-12-09T16:27:30.415314: step 1555, loss 0.14258, acc 0.9375, learning_rate 0.000585736\n",
      "2020-12-09T16:27:30.974200: step 1556, loss 0.0817306, acc 0.96875, learning_rate 0.000585085\n",
      "2020-12-09T16:27:31.521567: step 1557, loss 0.209453, acc 0.875, learning_rate 0.000584436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:27:32.124608: step 1558, loss 0.243764, acc 0.90625, learning_rate 0.000583787\n",
      "2020-12-09T16:27:32.677252: step 1559, loss 0.297661, acc 0.9375, learning_rate 0.000583139\n",
      "2020-12-09T16:27:33.234370: step 1560, loss 0.158655, acc 0.96875, learning_rate 0.000582491\n",
      "2020-12-09T16:27:33.785101: step 1561, loss 0.216257, acc 0.9375, learning_rate 0.000581845\n",
      "2020-12-09T16:27:34.323116: step 1562, loss 0.174613, acc 0.90625, learning_rate 0.0005812\n",
      "2020-12-09T16:27:34.863212: step 1563, loss 0.211295, acc 0.9375, learning_rate 0.000580555\n",
      "2020-12-09T16:27:35.427709: step 1564, loss 0.241581, acc 0.96875, learning_rate 0.000579911\n",
      "2020-12-09T16:27:35.994151: step 1565, loss 0.127068, acc 0.9375, learning_rate 0.000579269\n",
      "2020-12-09T16:27:36.563921: step 1566, loss 0.154226, acc 0.96875, learning_rate 0.000578626\n",
      "2020-12-09T16:27:37.116381: step 1567, loss 0.177156, acc 0.875, learning_rate 0.000577985\n",
      "2020-12-09T16:27:37.666840: step 1568, loss 0.105671, acc 0.96875, learning_rate 0.000577345\n",
      "2020-12-09T16:27:38.224835: step 1569, loss 0.205024, acc 0.90625, learning_rate 0.000576706\n",
      "2020-12-09T16:27:38.764565: step 1570, loss 0.189509, acc 0.9375, learning_rate 0.000576067\n",
      "2020-12-09T16:27:39.307138: step 1571, loss 0.126646, acc 0.9375, learning_rate 0.000575429\n",
      "2020-12-09T16:27:39.875622: step 1572, loss 0.165631, acc 0.9375, learning_rate 0.000574792\n",
      "2020-12-09T16:27:40.425965: step 1573, loss 0.194662, acc 0.90625, learning_rate 0.000574156\n",
      "2020-12-09T16:27:40.973930: step 1574, loss 0.229085, acc 0.90625, learning_rate 0.000573521\n",
      "2020-12-09T16:27:41.529462: step 1575, loss 0.285789, acc 0.875, learning_rate 0.000572887\n",
      "2020-12-09T16:27:42.080713: step 1576, loss 0.128138, acc 0.9375, learning_rate 0.000572254\n",
      "2020-12-09T16:27:42.639830: step 1577, loss 0.0748048, acc 1, learning_rate 0.000571621\n",
      "2020-12-09T16:27:43.183457: step 1578, loss 0.154096, acc 0.9375, learning_rate 0.000570989\n",
      "2020-12-09T16:27:43.753409: step 1579, loss 0.140892, acc 0.9375, learning_rate 0.000570358\n",
      "2020-12-09T16:27:44.301951: step 1580, loss 0.0737613, acc 1, learning_rate 0.000569728\n",
      "2020-12-09T16:27:44.859478: step 1581, loss 0.0726855, acc 0.96875, learning_rate 0.000569099\n",
      "2020-12-09T16:27:45.433476: step 1582, loss 0.12482, acc 0.96875, learning_rate 0.000568471\n",
      "2020-12-09T16:27:46.003253: step 1583, loss 0.0989583, acc 0.9375, learning_rate 0.000567843\n",
      "2020-12-09T16:27:46.546219: step 1584, loss 0.469162, acc 0.8125, learning_rate 0.000567216\n",
      "2020-12-09T16:27:47.091751: step 1585, loss 0.262082, acc 0.875, learning_rate 0.00056659\n",
      "2020-12-09T16:27:47.641695: step 1586, loss 0.0886393, acc 1, learning_rate 0.000565965\n",
      "2020-12-09T16:27:48.223994: step 1587, loss 0.0999516, acc 0.96875, learning_rate 0.000565341\n",
      "2020-12-09T16:27:48.796588: step 1588, loss 0.364003, acc 0.8125, learning_rate 0.000564718\n",
      "2020-12-09T16:27:49.377575: step 1589, loss 0.265041, acc 0.90625, learning_rate 0.000564095\n",
      "2020-12-09T16:27:49.957010: step 1590, loss 0.144808, acc 0.9375, learning_rate 0.000563474\n",
      "2020-12-09T16:27:50.530118: step 1591, loss 0.100099, acc 0.9375, learning_rate 0.000562853\n",
      "2020-12-09T16:27:51.093621: step 1592, loss 0.162549, acc 0.9375, learning_rate 0.000562233\n",
      "2020-12-09T16:27:51.680645: step 1593, loss 0.203489, acc 0.90625, learning_rate 0.000561614\n",
      "2020-12-09T16:27:52.266293: step 1594, loss 0.353857, acc 0.8125, learning_rate 0.000560995\n",
      "2020-12-09T16:27:52.817649: step 1595, loss 0.258157, acc 0.875, learning_rate 0.000560378\n",
      "2020-12-09T16:27:53.372115: step 1596, loss 0.289245, acc 0.8125, learning_rate 0.000559761\n",
      "2020-12-09T16:27:53.977168: step 1597, loss 0.427104, acc 0.8125, learning_rate 0.000559145\n",
      "2020-12-09T16:27:54.534416: step 1598, loss 0.356563, acc 0.875, learning_rate 0.00055853\n",
      "2020-12-09T16:27:55.083877: step 1599, loss 0.189201, acc 0.9375, learning_rate 0.000557916\n",
      "2020-12-09T16:27:55.640027: step 1600, loss 0.255374, acc 0.90625, learning_rate 0.000557302\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:27:58.038978: step 1600, loss 0.898314, acc 0.720989\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1600\n",
      "\n",
      "2020-12-09T16:27:59.491333: step 1601, loss 0.346741, acc 0.84375, learning_rate 0.00055669\n",
      "2020-12-09T16:28:00.029797: step 1602, loss 0.110108, acc 0.96875, learning_rate 0.000556078\n",
      "2020-12-09T16:28:00.580532: step 1603, loss 0.0897569, acc 0.96875, learning_rate 0.000555467\n",
      "2020-12-09T16:28:01.113735: step 1604, loss 0.0727058, acc 1, learning_rate 0.000554857\n",
      "2020-12-09T16:28:01.673771: step 1605, loss 0.132386, acc 0.9375, learning_rate 0.000554248\n",
      "2020-12-09T16:28:02.216027: step 1606, loss 0.259375, acc 0.875, learning_rate 0.000553639\n",
      "2020-12-09T16:28:02.754296: step 1607, loss 0.326883, acc 0.84375, learning_rate 0.000553032\n",
      "2020-12-09T16:28:03.301629: step 1608, loss 0.110158, acc 0.9375, learning_rate 0.000552425\n",
      "2020-12-09T16:28:03.852162: step 1609, loss 0.207909, acc 0.9375, learning_rate 0.000551819\n",
      "2020-12-09T16:28:04.413695: step 1610, loss 0.308064, acc 0.875, learning_rate 0.000551213\n",
      "2020-12-09T16:28:04.965233: step 1611, loss 0.198064, acc 0.9375, learning_rate 0.000550609\n",
      "2020-12-09T16:28:05.530266: step 1612, loss 0.2919, acc 0.9375, learning_rate 0.000550005\n",
      "2020-12-09T16:28:06.094259: step 1613, loss 0.257203, acc 0.9375, learning_rate 0.000549403\n",
      "2020-12-09T16:28:06.648197: step 1614, loss 0.10111, acc 0.96875, learning_rate 0.000548801\n",
      "2020-12-09T16:28:07.192627: step 1615, loss 0.527303, acc 0.9375, learning_rate 0.000548199\n",
      "2020-12-09T16:28:07.737835: step 1616, loss 0.192135, acc 0.9375, learning_rate 0.000547599\n",
      "2020-12-09T16:28:08.276368: step 1617, loss 0.0744447, acc 1, learning_rate 0.000546999\n",
      "2020-12-09T16:28:08.842318: step 1618, loss 0.203788, acc 0.90625, learning_rate 0.000546401\n",
      "2020-12-09T16:28:09.398158: step 1619, loss 0.300205, acc 0.875, learning_rate 0.000545803\n",
      "2020-12-09T16:28:09.939879: step 1620, loss 0.172224, acc 0.90625, learning_rate 0.000545206\n",
      "2020-12-09T16:28:10.512219: step 1621, loss 0.383596, acc 0.875, learning_rate 0.000544609\n",
      "2020-12-09T16:28:11.063096: step 1622, loss 0.157619, acc 0.96875, learning_rate 0.000544014\n",
      "2020-12-09T16:28:11.631132: step 1623, loss 0.106608, acc 0.96875, learning_rate 0.000543419\n",
      "2020-12-09T16:28:12.176874: step 1624, loss 0.192768, acc 0.875, learning_rate 0.000542825\n",
      "2020-12-09T16:28:12.721205: step 1625, loss 0.233526, acc 0.90625, learning_rate 0.000542232\n",
      "2020-12-09T16:28:13.258799: step 1626, loss 0.112846, acc 0.96875, learning_rate 0.000541639\n",
      "2020-12-09T16:28:13.840160: step 1627, loss 0.0920878, acc 0.96875, learning_rate 0.000541048\n",
      "2020-12-09T16:28:14.393651: step 1628, loss 0.18969, acc 0.875, learning_rate 0.000540457\n",
      "2020-12-09T16:28:14.957171: step 1629, loss 0.0902989, acc 1, learning_rate 0.000539867\n",
      "2020-12-09T16:28:15.510764: step 1630, loss 0.185346, acc 0.90625, learning_rate 0.000539278\n",
      "2020-12-09T16:28:16.114263: step 1631, loss 0.164827, acc 0.9375, learning_rate 0.000538689\n",
      "2020-12-09T16:28:16.641834: step 1632, loss 0.24178, acc 0.90625, learning_rate 0.000538101\n",
      "2020-12-09T16:28:17.186801: step 1633, loss 0.159064, acc 0.9375, learning_rate 0.000537515\n",
      "2020-12-09T16:28:17.743801: step 1634, loss 0.140079, acc 0.9375, learning_rate 0.000536929\n",
      "2020-12-09T16:28:18.319258: step 1635, loss 0.144944, acc 0.90625, learning_rate 0.000536343\n",
      "2020-12-09T16:28:18.895562: step 1636, loss 0.285612, acc 0.90625, learning_rate 0.000535759\n",
      "2020-12-09T16:28:19.450976: step 1637, loss 0.229695, acc 0.9375, learning_rate 0.000535175\n",
      "2020-12-09T16:28:20.000972: step 1638, loss 0.188971, acc 0.9375, learning_rate 0.000534592\n",
      "2020-12-09T16:28:20.552097: step 1639, loss 0.255417, acc 0.84375, learning_rate 0.00053401\n",
      "2020-12-09T16:28:21.127415: step 1640, loss 0.159016, acc 0.96875, learning_rate 0.000533429\n",
      "2020-12-09T16:28:21.671414: step 1641, loss 0.0253912, acc 1, learning_rate 0.000532848\n",
      "2020-12-09T16:28:22.240957: step 1642, loss 0.191861, acc 0.875, learning_rate 0.000532268\n",
      "2020-12-09T16:28:22.784418: step 1643, loss 0.0724172, acc 1, learning_rate 0.000531689\n",
      "2020-12-09T16:28:23.315034: step 1644, loss 0.283563, acc 0.875, learning_rate 0.000531111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:28:23.871534: step 1645, loss 0.163086, acc 0.90625, learning_rate 0.000530533\n",
      "2020-12-09T16:28:24.420454: step 1646, loss 0.50818, acc 0.84375, learning_rate 0.000529957\n",
      "2020-12-09T16:28:24.972092: step 1647, loss 0.1894, acc 0.9375, learning_rate 0.000529381\n",
      "2020-12-09T16:28:25.518523: step 1648, loss 0.146144, acc 0.9375, learning_rate 0.000528805\n",
      "2020-12-09T16:28:26.078956: step 1649, loss 0.26134, acc 0.90625, learning_rate 0.000528231\n",
      "2020-12-09T16:28:26.633805: step 1650, loss 0.198374, acc 0.9375, learning_rate 0.000527657\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:28:29.094517: step 1650, loss 0.89383, acc 0.721827\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1650\n",
      "\n",
      "2020-12-09T16:28:30.544928: step 1651, loss 0.287302, acc 0.875, learning_rate 0.000527085\n",
      "2020-12-09T16:28:31.093263: step 1652, loss 0.200667, acc 0.875, learning_rate 0.000526512\n",
      "2020-12-09T16:28:31.630277: step 1653, loss 0.297436, acc 0.875, learning_rate 0.000525941\n",
      "2020-12-09T16:28:32.170590: step 1654, loss 0.300188, acc 0.9375, learning_rate 0.00052537\n",
      "2020-12-09T16:28:32.736565: step 1655, loss 0.118606, acc 0.96875, learning_rate 0.000524801\n",
      "2020-12-09T16:28:33.270565: step 1656, loss 0.0714276, acc 1, learning_rate 0.000524232\n",
      "2020-12-09T16:28:33.836027: step 1657, loss 0.274493, acc 0.875, learning_rate 0.000523663\n",
      "2020-12-09T16:28:34.471234: step 1658, loss 0.196603, acc 0.90625, learning_rate 0.000523096\n",
      "2020-12-09T16:28:35.028884: step 1659, loss 0.266448, acc 0.9375, learning_rate 0.000522529\n",
      "2020-12-09T16:28:35.568822: step 1660, loss 0.236601, acc 0.90625, learning_rate 0.000521963\n",
      "2020-12-09T16:28:36.124579: step 1661, loss 0.189681, acc 0.90625, learning_rate 0.000521398\n",
      "2020-12-09T16:28:36.674379: step 1662, loss 0.310203, acc 0.90625, learning_rate 0.000520833\n",
      "2020-12-09T16:28:37.218152: step 1663, loss 0.17475, acc 0.9375, learning_rate 0.00052027\n",
      "2020-12-09T16:28:37.774374: step 1664, loss 0.235522, acc 0.90625, learning_rate 0.000519707\n",
      "2020-12-09T16:28:38.348461: step 1665, loss 0.201294, acc 0.875, learning_rate 0.000519144\n",
      "2020-12-09T16:28:38.907506: step 1666, loss 0.482443, acc 0.71875, learning_rate 0.000518583\n",
      "2020-12-09T16:28:39.447973: step 1667, loss 0.257491, acc 0.875, learning_rate 0.000518022\n",
      "2020-12-09T16:28:40.000470: step 1668, loss 0.217397, acc 0.9375, learning_rate 0.000517462\n",
      "2020-12-09T16:28:40.559867: step 1669, loss 0.146838, acc 0.9375, learning_rate 0.000516903\n",
      "2020-12-09T16:28:41.108020: step 1670, loss 0.459165, acc 0.84375, learning_rate 0.000516345\n",
      "2020-12-09T16:28:41.650552: step 1671, loss 0.229612, acc 0.90625, learning_rate 0.000515787\n",
      "2020-12-09T16:28:42.201095: step 1672, loss 0.0736005, acc 1, learning_rate 0.00051523\n",
      "2020-12-09T16:28:42.762561: step 1673, loss 0.38862, acc 0.875, learning_rate 0.000514674\n",
      "2020-12-09T16:28:43.313563: step 1674, loss 0.115526, acc 0.96875, learning_rate 0.000514118\n",
      "2020-12-09T16:28:43.870563: step 1675, loss 0.219347, acc 0.90625, learning_rate 0.000513563\n",
      "2020-12-09T16:28:44.421064: step 1676, loss 0.291817, acc 0.875, learning_rate 0.000513009\n",
      "2020-12-09T16:28:44.974542: step 1677, loss 0.0554145, acc 1, learning_rate 0.000512456\n",
      "2020-12-09T16:28:45.513508: step 1678, loss 0.160222, acc 0.9375, learning_rate 0.000511904\n",
      "2020-12-09T16:28:46.082629: step 1679, loss 0.11499, acc 0.96875, learning_rate 0.000511352\n",
      "2020-12-09T16:28:46.646452: step 1680, loss 0.116607, acc 0.96875, learning_rate 0.000510801\n",
      "2020-12-09T16:28:47.179109: step 1681, loss 0.21149, acc 0.9375, learning_rate 0.000510251\n",
      "2020-12-09T16:28:47.742661: step 1682, loss 0.251186, acc 0.8125, learning_rate 0.000509701\n",
      "2020-12-09T16:28:48.297159: step 1683, loss 0.200275, acc 0.9375, learning_rate 0.000509152\n",
      "2020-12-09T16:28:48.836346: step 1684, loss 0.188595, acc 0.90625, learning_rate 0.000508604\n",
      "2020-12-09T16:28:49.387389: step 1685, loss 0.0733777, acc 0.96875, learning_rate 0.000508057\n",
      "2020-12-09T16:28:49.957213: step 1686, loss 0.227842, acc 0.90625, learning_rate 0.00050751\n",
      "2020-12-09T16:28:50.524059: step 1687, loss 0.343604, acc 0.9375, learning_rate 0.000506964\n",
      "2020-12-09T16:28:51.100879: step 1688, loss 0.144362, acc 0.9375, learning_rate 0.000506419\n",
      "2020-12-09T16:28:51.635837: step 1689, loss 0.156526, acc 0.875, learning_rate 0.000505875\n",
      "2020-12-09T16:28:52.184529: step 1690, loss 0.114062, acc 0.96875, learning_rate 0.000505331\n",
      "2020-12-09T16:28:52.734486: step 1691, loss 0.0803999, acc 0.96875, learning_rate 0.000504788\n",
      "2020-12-09T16:28:53.305485: step 1692, loss 0.135936, acc 0.96875, learning_rate 0.000504246\n",
      "2020-12-09T16:28:53.854830: step 1693, loss 0.152742, acc 0.90625, learning_rate 0.000503704\n",
      "2020-12-09T16:28:54.428381: step 1694, loss 0.181619, acc 0.90625, learning_rate 0.000503164\n",
      "2020-12-09T16:28:55.009384: step 1695, loss 0.125125, acc 0.9375, learning_rate 0.000502624\n",
      "2020-12-09T16:28:55.570880: step 1696, loss 0.0506568, acc 1, learning_rate 0.000502084\n",
      "2020-12-09T16:28:56.158413: step 1697, loss 0.17795, acc 0.90625, learning_rate 0.000501546\n",
      "2020-12-09T16:28:56.710240: step 1698, loss 0.372493, acc 0.90625, learning_rate 0.000501008\n",
      "2020-12-09T16:28:57.275502: step 1699, loss 0.199657, acc 0.90625, learning_rate 0.00050047\n",
      "2020-12-09T16:28:57.830536: step 1700, loss 0.247815, acc 0.90625, learning_rate 0.000499934\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:29:01.113539: step 1700, loss 0.896549, acc 0.72057\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1700\n",
      "\n",
      "2020-12-09T16:29:02.667905: step 1701, loss 0.517937, acc 0.84375, learning_rate 0.000499398\n",
      "2020-12-09T16:29:03.213390: step 1702, loss 0.14139, acc 0.96875, learning_rate 0.000498863\n",
      "2020-12-09T16:29:03.749854: step 1703, loss 0.227897, acc 0.875, learning_rate 0.000498329\n",
      "2020-12-09T16:29:04.354937: step 1704, loss 0.132761, acc 0.90625, learning_rate 0.000497795\n",
      "2020-12-09T16:29:04.896951: step 1705, loss 0.148229, acc 0.90625, learning_rate 0.000497263\n",
      "2020-12-09T16:29:05.464021: step 1706, loss 0.266835, acc 0.84375, learning_rate 0.00049673\n",
      "2020-12-09T16:29:06.016058: step 1707, loss 0.186653, acc 0.9375, learning_rate 0.000496199\n",
      "2020-12-09T16:29:06.591867: step 1708, loss 0.375057, acc 0.84375, learning_rate 0.000495668\n",
      "2020-12-09T16:29:07.164747: step 1709, loss 0.140588, acc 0.96875, learning_rate 0.000495138\n",
      "2020-12-09T16:29:07.718710: step 1710, loss 0.206277, acc 0.90625, learning_rate 0.000494609\n",
      "2020-12-09T16:29:08.259143: step 1711, loss 0.260201, acc 0.9375, learning_rate 0.00049408\n",
      "2020-12-09T16:29:08.840571: step 1712, loss 0.0756725, acc 1, learning_rate 0.000493552\n",
      "2020-12-09T16:29:09.370052: step 1713, loss 0.144733, acc 0.9375, learning_rate 0.000493025\n",
      "2020-12-09T16:29:09.909084: step 1714, loss 0.394265, acc 0.90625, learning_rate 0.000492499\n",
      "2020-12-09T16:29:10.449551: step 1715, loss 0.187289, acc 0.9375, learning_rate 0.000491973\n",
      "2020-12-09T16:29:11.002484: step 1716, loss 0.0832618, acc 0.96875, learning_rate 0.000491448\n",
      "2020-12-09T16:29:11.563782: step 1717, loss 0.164222, acc 0.90625, learning_rate 0.000490924\n",
      "2020-12-09T16:29:12.123317: step 1718, loss 0.497839, acc 0.9375, learning_rate 0.0004904\n",
      "2020-12-09T16:29:12.664289: step 1719, loss 0.214158, acc 0.875, learning_rate 0.000489877\n",
      "2020-12-09T16:29:13.225867: step 1720, loss 0.244692, acc 0.875, learning_rate 0.000489355\n",
      "2020-12-09T16:29:13.758829: step 1721, loss 0.290359, acc 0.9375, learning_rate 0.000488833\n",
      "2020-12-09T16:29:14.315194: step 1722, loss 0.238768, acc 0.84375, learning_rate 0.000488312\n",
      "2020-12-09T16:29:14.855768: step 1723, loss 0.142518, acc 0.9375, learning_rate 0.000487792\n",
      "2020-12-09T16:29:15.388304: step 1724, loss 0.338282, acc 0.90625, learning_rate 0.000487273\n",
      "2020-12-09T16:29:15.951443: step 1725, loss 0.11944, acc 0.9375, learning_rate 0.000486754\n",
      "2020-12-09T16:29:16.494809: step 1726, loss 0.092982, acc 0.9375, learning_rate 0.000486236\n",
      "2020-12-09T16:29:17.094132: step 1727, loss 0.0954245, acc 0.96875, learning_rate 0.000485718\n",
      "2020-12-09T16:29:17.664921: step 1728, loss 0.294142, acc 0.84375, learning_rate 0.000485202\n",
      "2020-12-09T16:29:18.228886: step 1729, loss 0.188273, acc 0.875, learning_rate 0.000484686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:29:18.784085: step 1730, loss 0.357969, acc 0.875, learning_rate 0.00048417\n",
      "2020-12-09T16:29:19.346693: step 1731, loss 0.111289, acc 0.96875, learning_rate 0.000483656\n",
      "2020-12-09T16:29:19.893660: step 1732, loss 0.305895, acc 0.875, learning_rate 0.000483142\n",
      "2020-12-09T16:29:20.452311: step 1733, loss 0.0958707, acc 0.96875, learning_rate 0.000482629\n",
      "2020-12-09T16:29:21.016509: step 1734, loss 0.206651, acc 0.90625, learning_rate 0.000482116\n",
      "2020-12-09T16:29:21.586937: step 1735, loss 0.133509, acc 0.9375, learning_rate 0.000481604\n",
      "2020-12-09T16:29:22.147019: step 1736, loss 0.322301, acc 0.78125, learning_rate 0.000481093\n",
      "2020-12-09T16:29:22.706451: step 1737, loss 0.41987, acc 0.84375, learning_rate 0.000480582\n",
      "2020-12-09T16:29:23.276722: step 1738, loss 0.186607, acc 0.96875, learning_rate 0.000480073\n",
      "2020-12-09T16:29:23.819759: step 1739, loss 0.16602, acc 0.90625, learning_rate 0.000479564\n",
      "2020-12-09T16:29:24.366123: step 1740, loss 0.139117, acc 0.9375, learning_rate 0.000479055\n",
      "2020-12-09T16:29:24.917216: step 1741, loss 0.249899, acc 0.9375, learning_rate 0.000478547\n",
      "2020-12-09T16:29:25.483061: step 1742, loss 0.297197, acc 0.8125, learning_rate 0.00047804\n",
      "2020-12-09T16:29:26.025057: step 1743, loss 0.393096, acc 0.875, learning_rate 0.000477534\n",
      "2020-12-09T16:29:26.578670: step 1744, loss 0.204079, acc 0.90625, learning_rate 0.000477028\n",
      "2020-12-09T16:29:27.124308: step 1745, loss 0.159773, acc 0.9375, learning_rate 0.000476523\n",
      "2020-12-09T16:29:27.679225: step 1746, loss 0.158706, acc 0.90625, learning_rate 0.000476019\n",
      "2020-12-09T16:29:28.237984: step 1747, loss 0.281384, acc 0.90625, learning_rate 0.000475515\n",
      "2020-12-09T16:29:28.801534: step 1748, loss 0.0678422, acc 1, learning_rate 0.000475012\n",
      "2020-12-09T16:29:29.336882: step 1749, loss 0.0932192, acc 0.96875, learning_rate 0.00047451\n",
      "2020-12-09T16:29:29.878907: step 1750, loss 0.122348, acc 0.9375, learning_rate 0.000474008\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:29:32.990380: step 1750, loss 0.904518, acc 0.720989\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1750\n",
      "\n",
      "2020-12-09T16:29:34.446972: step 1751, loss 0.303035, acc 0.84375, learning_rate 0.000473507\n",
      "2020-12-09T16:29:34.999963: step 1752, loss 0.115285, acc 0.96875, learning_rate 0.000473007\n",
      "2020-12-09T16:29:35.553421: step 1753, loss 0.191051, acc 0.90625, learning_rate 0.000472507\n",
      "2020-12-09T16:29:36.108751: step 1754, loss 0.160722, acc 0.90625, learning_rate 0.000472008\n",
      "2020-12-09T16:29:36.650931: step 1755, loss 0.120802, acc 1, learning_rate 0.00047151\n",
      "2020-12-09T16:29:37.251487: step 1756, loss 0.0969329, acc 0.96875, learning_rate 0.000471012\n",
      "2020-12-09T16:29:37.818814: step 1757, loss 0.235671, acc 0.9375, learning_rate 0.000470515\n",
      "2020-12-09T16:29:38.371282: step 1758, loss 0.204279, acc 0.90625, learning_rate 0.000470019\n",
      "2020-12-09T16:29:38.922978: step 1759, loss 0.176722, acc 0.9375, learning_rate 0.000469523\n",
      "2020-12-09T16:29:39.495087: step 1760, loss 0.261218, acc 0.9375, learning_rate 0.000469028\n",
      "2020-12-09T16:29:40.045585: step 1761, loss 0.104222, acc 0.9375, learning_rate 0.000468534\n",
      "2020-12-09T16:29:40.623134: step 1762, loss 0.239695, acc 0.84375, learning_rate 0.00046804\n",
      "2020-12-09T16:29:41.175185: step 1763, loss 0.25536, acc 0.875, learning_rate 0.000467547\n",
      "2020-12-09T16:29:41.735858: step 1764, loss 0.332432, acc 0.875, learning_rate 0.000467055\n",
      "2020-12-09T16:29:42.269359: step 1765, loss 0.167649, acc 0.90625, learning_rate 0.000466563\n",
      "2020-12-09T16:29:42.827844: step 1766, loss 0.144021, acc 0.96875, learning_rate 0.000466072\n",
      "2020-12-09T16:29:43.383380: step 1767, loss 0.181903, acc 0.90625, learning_rate 0.000465581\n",
      "2020-12-09T16:29:43.928843: step 1768, loss 0.241882, acc 0.875, learning_rate 0.000465092\n",
      "2020-12-09T16:29:44.491161: step 1769, loss 0.263908, acc 0.875, learning_rate 0.000464603\n",
      "2020-12-09T16:29:45.060842: step 1770, loss 0.226844, acc 0.90625, learning_rate 0.000464114\n",
      "2020-12-09T16:29:45.599067: step 1771, loss 0.31725, acc 0.9375, learning_rate 0.000463627\n",
      "2020-12-09T16:29:46.142245: step 1772, loss 0.125548, acc 0.96875, learning_rate 0.000463139\n",
      "2020-12-09T16:29:46.691746: step 1773, loss 0.157822, acc 0.96875, learning_rate 0.000462653\n",
      "2020-12-09T16:29:47.245675: step 1774, loss 0.435355, acc 0.84375, learning_rate 0.000462167\n",
      "2020-12-09T16:29:47.807201: step 1775, loss 0.210355, acc 0.90625, learning_rate 0.000461682\n",
      "2020-12-09T16:29:48.354231: step 1776, loss 0.242362, acc 0.90625, learning_rate 0.000461198\n",
      "2020-12-09T16:29:48.904336: step 1777, loss 0.133051, acc 0.96875, learning_rate 0.000460714\n",
      "2020-12-09T16:29:49.457142: step 1778, loss 0.171357, acc 0.90625, learning_rate 0.000460231\n",
      "2020-12-09T16:29:50.003608: step 1779, loss 0.174033, acc 0.9375, learning_rate 0.000459748\n",
      "2020-12-09T16:29:50.546904: step 1780, loss 0.165516, acc 0.9375, learning_rate 0.000459266\n",
      "2020-12-09T16:29:51.114954: step 1781, loss 0.0396496, acc 1, learning_rate 0.000458785\n",
      "2020-12-09T16:29:51.656347: step 1782, loss 0.109397, acc 0.90625, learning_rate 0.000458304\n",
      "2020-12-09T16:29:52.188811: step 1783, loss 0.152468, acc 0.9375, learning_rate 0.000457824\n",
      "2020-12-09T16:29:52.749847: step 1784, loss 0.103318, acc 0.96875, learning_rate 0.000457345\n",
      "2020-12-09T16:29:53.315250: step 1785, loss 0.155074, acc 0.90625, learning_rate 0.000456866\n",
      "2020-12-09T16:29:53.881800: step 1786, loss 0.1182, acc 0.96875, learning_rate 0.000456388\n",
      "2020-12-09T16:29:54.421445: step 1787, loss 0.157095, acc 0.90625, learning_rate 0.000455911\n",
      "2020-12-09T16:29:54.986710: step 1788, loss 0.218863, acc 0.90625, learning_rate 0.000455434\n",
      "2020-12-09T16:29:55.552878: step 1789, loss 0.274958, acc 0.90625, learning_rate 0.000454958\n",
      "2020-12-09T16:29:56.112318: step 1790, loss 0.245943, acc 0.9375, learning_rate 0.000454482\n",
      "2020-12-09T16:29:56.669549: step 1791, loss 0.161387, acc 0.9375, learning_rate 0.000454008\n",
      "2020-12-09T16:29:57.221436: step 1792, loss 0.14894, acc 0.90625, learning_rate 0.000453533\n",
      "2020-12-09T16:29:57.769361: step 1793, loss 0.379782, acc 0.875, learning_rate 0.00045306\n",
      "2020-12-09T16:29:57.981981: step 1794, loss 0.317245, acc 0.846154, learning_rate 0.000452587\n",
      "2020-12-09T16:29:58.556686: step 1795, loss 0.137303, acc 0.90625, learning_rate 0.000452115\n",
      "2020-12-09T16:29:59.135240: step 1796, loss 0.14127, acc 0.9375, learning_rate 0.000451643\n",
      "2020-12-09T16:29:59.706699: step 1797, loss 0.0816842, acc 0.96875, learning_rate 0.000451172\n",
      "2020-12-09T16:30:00.286237: step 1798, loss 0.153833, acc 0.9375, learning_rate 0.000450701\n",
      "2020-12-09T16:30:00.863697: step 1799, loss 0.348956, acc 0.9375, learning_rate 0.000450232\n",
      "2020-12-09T16:30:01.452198: step 1800, loss 0.0767046, acc 0.96875, learning_rate 0.000449762\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:30:04.619162: step 1800, loss 0.936665, acc 0.719732\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1800\n",
      "\n",
      "2020-12-09T16:30:06.084048: step 1801, loss 0.273941, acc 0.875, learning_rate 0.000449294\n",
      "2020-12-09T16:30:06.650001: step 1802, loss 0.188805, acc 0.90625, learning_rate 0.000448826\n",
      "2020-12-09T16:30:07.229099: step 1803, loss 0.253268, acc 0.90625, learning_rate 0.000448359\n",
      "2020-12-09T16:30:07.778932: step 1804, loss 0.108848, acc 0.96875, learning_rate 0.000447892\n",
      "2020-12-09T16:30:08.329150: step 1805, loss 0.0863147, acc 0.96875, learning_rate 0.000447426\n",
      "2020-12-09T16:30:08.887648: step 1806, loss 0.136676, acc 0.96875, learning_rate 0.000446961\n",
      "2020-12-09T16:30:09.429089: step 1807, loss 0.170073, acc 0.875, learning_rate 0.000446496\n",
      "2020-12-09T16:30:09.987157: step 1808, loss 0.0590032, acc 1, learning_rate 0.000446032\n",
      "2020-12-09T16:30:10.555225: step 1809, loss 0.0707013, acc 1, learning_rate 0.000445568\n",
      "2020-12-09T16:30:11.160758: step 1810, loss 0.205655, acc 0.875, learning_rate 0.000445105\n",
      "2020-12-09T16:30:11.698255: step 1811, loss 0.307596, acc 0.90625, learning_rate 0.000444643\n",
      "2020-12-09T16:30:12.236717: step 1812, loss 0.236031, acc 0.90625, learning_rate 0.000444181\n",
      "2020-12-09T16:30:12.776085: step 1813, loss 0.0888032, acc 1, learning_rate 0.00044372\n",
      "2020-12-09T16:30:13.331697: step 1814, loss 0.183068, acc 0.90625, learning_rate 0.00044326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:30:13.888635: step 1815, loss 0.101985, acc 0.9375, learning_rate 0.0004428\n",
      "2020-12-09T16:30:14.425305: step 1816, loss 0.251937, acc 0.90625, learning_rate 0.000442341\n",
      "2020-12-09T16:30:14.979449: step 1817, loss 0.0769411, acc 1, learning_rate 0.000441882\n",
      "2020-12-09T16:30:15.534951: step 1818, loss 0.211665, acc 0.90625, learning_rate 0.000441424\n",
      "2020-12-09T16:30:16.127441: step 1819, loss 0.206454, acc 0.9375, learning_rate 0.000440967\n",
      "2020-12-09T16:30:16.676641: step 1820, loss 0.173491, acc 0.90625, learning_rate 0.00044051\n",
      "2020-12-09T16:30:17.229112: step 1821, loss 0.128887, acc 0.9375, learning_rate 0.000440054\n",
      "2020-12-09T16:30:17.771574: step 1822, loss 0.145691, acc 0.90625, learning_rate 0.000439599\n",
      "2020-12-09T16:30:18.304457: step 1823, loss 0.141188, acc 0.9375, learning_rate 0.000439144\n",
      "2020-12-09T16:30:18.846155: step 1824, loss 0.136192, acc 0.9375, learning_rate 0.000438689\n",
      "2020-12-09T16:30:19.397582: step 1825, loss 0.119315, acc 0.9375, learning_rate 0.000438236\n",
      "2020-12-09T16:30:19.947043: step 1826, loss 0.189478, acc 0.96875, learning_rate 0.000437783\n",
      "2020-12-09T16:30:20.502576: step 1827, loss 0.45385, acc 0.8125, learning_rate 0.00043733\n",
      "2020-12-09T16:30:21.058720: step 1828, loss 0.257539, acc 0.9375, learning_rate 0.000436878\n",
      "2020-12-09T16:30:21.619402: step 1829, loss 0.265733, acc 0.875, learning_rate 0.000436427\n",
      "2020-12-09T16:30:22.190034: step 1830, loss 0.109918, acc 1, learning_rate 0.000435976\n",
      "2020-12-09T16:30:22.739987: step 1831, loss 0.199149, acc 0.9375, learning_rate 0.000435526\n",
      "2020-12-09T16:30:23.275590: step 1832, loss 0.283995, acc 0.84375, learning_rate 0.000435077\n",
      "2020-12-09T16:30:23.836517: step 1833, loss 0.432758, acc 0.8125, learning_rate 0.000434628\n",
      "2020-12-09T16:30:24.389045: step 1834, loss 0.117784, acc 0.96875, learning_rate 0.00043418\n",
      "2020-12-09T16:30:24.943549: step 1835, loss 0.17448, acc 0.90625, learning_rate 0.000433732\n",
      "2020-12-09T16:30:25.486044: step 1836, loss 0.0775566, acc 0.96875, learning_rate 0.000433285\n",
      "2020-12-09T16:30:26.055119: step 1837, loss 0.124716, acc 0.96875, learning_rate 0.000432838\n",
      "2020-12-09T16:30:26.614116: step 1838, loss 0.594201, acc 0.875, learning_rate 0.000432393\n",
      "2020-12-09T16:30:27.186902: step 1839, loss 0.460575, acc 0.875, learning_rate 0.000431947\n",
      "2020-12-09T16:30:27.745167: step 1840, loss 0.406872, acc 0.84375, learning_rate 0.000431503\n",
      "2020-12-09T16:30:28.305037: step 1841, loss 0.106698, acc 0.96875, learning_rate 0.000431059\n",
      "2020-12-09T16:30:28.861909: step 1842, loss 0.371778, acc 0.8125, learning_rate 0.000430615\n",
      "2020-12-09T16:30:29.402996: step 1843, loss 0.333201, acc 0.84375, learning_rate 0.000430172\n",
      "2020-12-09T16:30:29.978542: step 1844, loss 0.156307, acc 0.96875, learning_rate 0.00042973\n",
      "2020-12-09T16:30:30.525039: step 1845, loss 0.242422, acc 0.875, learning_rate 0.000429288\n",
      "2020-12-09T16:30:31.098402: step 1846, loss 0.315706, acc 0.84375, learning_rate 0.000428847\n",
      "2020-12-09T16:30:31.643923: step 1847, loss 0.185112, acc 0.90625, learning_rate 0.000428407\n",
      "2020-12-09T16:30:32.210359: step 1848, loss 0.143655, acc 0.90625, learning_rate 0.000427967\n",
      "2020-12-09T16:30:32.752879: step 1849, loss 0.287439, acc 0.875, learning_rate 0.000427527\n",
      "2020-12-09T16:30:33.307917: step 1850, loss 0.0600666, acc 0.96875, learning_rate 0.000427089\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:30:36.551715: step 1850, loss 0.955775, acc 0.710934\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1850\n",
      "\n",
      "2020-12-09T16:30:38.014385: step 1851, loss 0.137301, acc 0.9375, learning_rate 0.000426651\n",
      "2020-12-09T16:30:38.542137: step 1852, loss 0.180992, acc 0.9375, learning_rate 0.000426213\n",
      "2020-12-09T16:30:39.097670: step 1853, loss 0.0943573, acc 1, learning_rate 0.000425776\n",
      "2020-12-09T16:30:39.651883: step 1854, loss 0.256657, acc 0.875, learning_rate 0.00042534\n",
      "2020-12-09T16:30:40.214218: step 1855, loss 0.223911, acc 0.90625, learning_rate 0.000424904\n",
      "2020-12-09T16:30:40.757096: step 1856, loss 0.156665, acc 0.96875, learning_rate 0.000424469\n",
      "2020-12-09T16:30:41.314415: step 1857, loss 0.114223, acc 0.9375, learning_rate 0.000424034\n",
      "2020-12-09T16:30:41.861475: step 1858, loss 0.222482, acc 0.90625, learning_rate 0.0004236\n",
      "2020-12-09T16:30:42.410319: step 1859, loss 0.13997, acc 0.96875, learning_rate 0.000423166\n",
      "2020-12-09T16:30:42.969047: step 1860, loss 0.135673, acc 1, learning_rate 0.000422734\n",
      "2020-12-09T16:30:43.526813: step 1861, loss 0.156132, acc 0.90625, learning_rate 0.000422301\n",
      "2020-12-09T16:30:44.088258: step 1862, loss 0.134265, acc 0.90625, learning_rate 0.000421869\n",
      "2020-12-09T16:30:44.625077: step 1863, loss 0.209846, acc 0.90625, learning_rate 0.000421438\n",
      "2020-12-09T16:30:45.171041: step 1864, loss 0.166814, acc 0.90625, learning_rate 0.000421008\n",
      "2020-12-09T16:30:45.716737: step 1865, loss 0.265667, acc 0.84375, learning_rate 0.000420578\n",
      "2020-12-09T16:30:46.280682: step 1866, loss 0.142738, acc 0.96875, learning_rate 0.000420148\n",
      "2020-12-09T16:30:46.823823: step 1867, loss 0.234341, acc 0.90625, learning_rate 0.000419719\n",
      "2020-12-09T16:30:47.384065: step 1868, loss 0.182333, acc 0.875, learning_rate 0.000419291\n",
      "2020-12-09T16:30:47.948939: step 1869, loss 0.237275, acc 0.8125, learning_rate 0.000418863\n",
      "2020-12-09T16:30:48.486436: step 1870, loss 0.256088, acc 0.96875, learning_rate 0.000418436\n",
      "2020-12-09T16:30:49.046971: step 1871, loss 0.234669, acc 0.875, learning_rate 0.00041801\n",
      "2020-12-09T16:30:49.601218: step 1872, loss 0.106241, acc 0.96875, learning_rate 0.000417584\n",
      "2020-12-09T16:30:50.165770: step 1873, loss 0.20954, acc 0.9375, learning_rate 0.000417158\n",
      "2020-12-09T16:30:50.704243: step 1874, loss 0.0591379, acc 1, learning_rate 0.000416733\n",
      "2020-12-09T16:30:51.262210: step 1875, loss 0.134885, acc 0.9375, learning_rate 0.000416309\n",
      "2020-12-09T16:30:51.837174: step 1876, loss 0.0572554, acc 1, learning_rate 0.000415885\n",
      "2020-12-09T16:30:52.401910: step 1877, loss 0.229999, acc 0.90625, learning_rate 0.000415462\n",
      "2020-12-09T16:30:52.933602: step 1878, loss 0.150573, acc 0.90625, learning_rate 0.00041504\n",
      "2020-12-09T16:30:53.515509: step 1879, loss 0.257913, acc 0.875, learning_rate 0.000414618\n",
      "2020-12-09T16:30:54.072248: step 1880, loss 0.0681056, acc 1, learning_rate 0.000414196\n",
      "2020-12-09T16:30:54.629325: step 1881, loss 0.0994417, acc 0.96875, learning_rate 0.000413775\n",
      "2020-12-09T16:30:55.179803: step 1882, loss 0.0923927, acc 0.9375, learning_rate 0.000413355\n",
      "2020-12-09T16:30:55.738455: step 1883, loss 0.249155, acc 0.875, learning_rate 0.000412935\n",
      "2020-12-09T16:30:56.285637: step 1884, loss 0.690803, acc 0.75, learning_rate 0.000412516\n",
      "2020-12-09T16:30:56.832834: step 1885, loss 0.392877, acc 0.84375, learning_rate 0.000412097\n",
      "2020-12-09T16:30:57.393812: step 1886, loss 0.257901, acc 0.90625, learning_rate 0.000411679\n",
      "2020-12-09T16:30:57.941419: step 1887, loss 0.114626, acc 0.9375, learning_rate 0.000411262\n",
      "2020-12-09T16:30:58.494832: step 1888, loss 0.218284, acc 0.90625, learning_rate 0.000410845\n",
      "2020-12-09T16:30:59.040457: step 1889, loss 0.176816, acc 0.90625, learning_rate 0.000410429\n",
      "2020-12-09T16:30:59.580439: step 1890, loss 0.13572, acc 0.96875, learning_rate 0.000410013\n",
      "2020-12-09T16:31:00.137398: step 1891, loss 0.150374, acc 0.9375, learning_rate 0.000409597\n",
      "2020-12-09T16:31:00.674903: step 1892, loss 0.0966875, acc 0.96875, learning_rate 0.000409183\n",
      "2020-12-09T16:31:01.237764: step 1893, loss 0.106702, acc 0.96875, learning_rate 0.000408769\n",
      "2020-12-09T16:31:01.806684: step 1894, loss 0.359332, acc 0.90625, learning_rate 0.000408355\n",
      "2020-12-09T16:31:02.365604: step 1895, loss 0.260213, acc 0.875, learning_rate 0.000407942\n",
      "2020-12-09T16:31:02.922678: step 1896, loss 0.247324, acc 0.90625, learning_rate 0.000407529\n",
      "2020-12-09T16:31:03.454929: step 1897, loss 0.172467, acc 0.96875, learning_rate 0.000407117\n",
      "2020-12-09T16:31:04.038894: step 1898, loss 0.240113, acc 0.875, learning_rate 0.000406706\n",
      "2020-12-09T16:31:04.576764: step 1899, loss 0.109771, acc 0.96875, learning_rate 0.000406295\n",
      "2020-12-09T16:31:05.140764: step 1900, loss 0.209772, acc 0.90625, learning_rate 0.000405885\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:31:08.566165: step 1900, loss 0.954753, acc 0.714286\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1900\n",
      "\n",
      "2020-12-09T16:31:10.023316: step 1901, loss 0.198665, acc 0.90625, learning_rate 0.000405475\n",
      "2020-12-09T16:31:10.581407: step 1902, loss 0.231707, acc 0.9375, learning_rate 0.000405066\n",
      "2020-12-09T16:31:11.156373: step 1903, loss 0.184888, acc 0.96875, learning_rate 0.000404657\n",
      "2020-12-09T16:31:11.725761: step 1904, loss 0.343832, acc 0.90625, learning_rate 0.000404249\n",
      "2020-12-09T16:31:12.299410: step 1905, loss 0.246991, acc 0.875, learning_rate 0.000403842\n",
      "2020-12-09T16:31:12.835906: step 1906, loss 0.266609, acc 0.84375, learning_rate 0.000403435\n",
      "2020-12-09T16:31:13.431966: step 1907, loss 0.10375, acc 1, learning_rate 0.000403028\n",
      "2020-12-09T16:31:13.965445: step 1908, loss 0.159791, acc 0.9375, learning_rate 0.000402622\n",
      "2020-12-09T16:31:14.508076: step 1909, loss 0.074047, acc 1, learning_rate 0.000402217\n",
      "2020-12-09T16:31:15.069663: step 1910, loss 0.176767, acc 0.90625, learning_rate 0.000401812\n",
      "2020-12-09T16:31:15.618085: step 1911, loss 0.159369, acc 0.9375, learning_rate 0.000401408\n",
      "2020-12-09T16:31:16.155544: step 1912, loss 0.151439, acc 0.96875, learning_rate 0.000401004\n",
      "2020-12-09T16:31:16.704079: step 1913, loss 0.102325, acc 0.9375, learning_rate 0.000400601\n",
      "2020-12-09T16:31:17.269080: step 1914, loss 0.140306, acc 0.9375, learning_rate 0.000400198\n",
      "2020-12-09T16:31:17.806020: step 1915, loss 0.085044, acc 0.96875, learning_rate 0.000399796\n",
      "2020-12-09T16:31:18.357327: step 1916, loss 0.105495, acc 0.9375, learning_rate 0.000399394\n",
      "2020-12-09T16:31:18.894592: step 1917, loss 0.180866, acc 0.875, learning_rate 0.000398993\n",
      "2020-12-09T16:31:19.449091: step 1918, loss 0.126063, acc 0.96875, learning_rate 0.000398593\n",
      "2020-12-09T16:31:20.012453: step 1919, loss 0.191062, acc 0.9375, learning_rate 0.000398193\n",
      "2020-12-09T16:31:20.568600: step 1920, loss 0.0914234, acc 0.9375, learning_rate 0.000397793\n",
      "2020-12-09T16:31:21.112102: step 1921, loss 0.140714, acc 0.9375, learning_rate 0.000397394\n",
      "2020-12-09T16:31:21.683925: step 1922, loss 0.198929, acc 0.9375, learning_rate 0.000396996\n",
      "2020-12-09T16:31:22.237470: step 1923, loss 0.184676, acc 0.90625, learning_rate 0.000396598\n",
      "2020-12-09T16:31:22.783469: step 1924, loss 0.108775, acc 0.96875, learning_rate 0.000396201\n",
      "2020-12-09T16:31:23.324468: step 1925, loss 0.0705895, acc 1, learning_rate 0.000395804\n",
      "2020-12-09T16:31:23.858005: step 1926, loss 0.293528, acc 0.84375, learning_rate 0.000395408\n",
      "2020-12-09T16:31:24.402061: step 1927, loss 0.0665195, acc 1, learning_rate 0.000395012\n",
      "2020-12-09T16:31:24.940618: step 1928, loss 0.35887, acc 0.78125, learning_rate 0.000394617\n",
      "2020-12-09T16:31:25.495166: step 1929, loss 0.142964, acc 0.9375, learning_rate 0.000394222\n",
      "2020-12-09T16:31:26.108292: step 1930, loss 0.181239, acc 0.9375, learning_rate 0.000393828\n",
      "2020-12-09T16:31:26.650278: step 1931, loss 0.200187, acc 0.875, learning_rate 0.000393435\n",
      "2020-12-09T16:31:27.198778: step 1932, loss 0.059958, acc 1, learning_rate 0.000393041\n",
      "2020-12-09T16:31:27.777814: step 1933, loss 0.0842298, acc 1, learning_rate 0.000392649\n",
      "2020-12-09T16:31:28.342002: step 1934, loss 0.380054, acc 0.8125, learning_rate 0.000392257\n",
      "2020-12-09T16:31:28.882501: step 1935, loss 0.138304, acc 0.9375, learning_rate 0.000391865\n",
      "2020-12-09T16:31:29.434732: step 1936, loss 0.199813, acc 0.875, learning_rate 0.000391474\n",
      "2020-12-09T16:31:30.002519: step 1937, loss 0.194622, acc 0.9375, learning_rate 0.000391084\n",
      "2020-12-09T16:31:30.553851: step 1938, loss 0.217509, acc 0.9375, learning_rate 0.000390694\n",
      "2020-12-09T16:31:31.108014: step 1939, loss 0.145222, acc 0.90625, learning_rate 0.000390305\n",
      "2020-12-09T16:31:31.678563: step 1940, loss 0.216854, acc 0.9375, learning_rate 0.000389916\n",
      "2020-12-09T16:31:32.219049: step 1941, loss 0.432587, acc 0.8125, learning_rate 0.000389527\n",
      "2020-12-09T16:31:32.761443: step 1942, loss 0.176753, acc 0.875, learning_rate 0.00038914\n",
      "2020-12-09T16:31:33.305476: step 1943, loss 0.129657, acc 0.96875, learning_rate 0.000388752\n",
      "2020-12-09T16:31:33.865560: step 1944, loss 0.114642, acc 0.9375, learning_rate 0.000388365\n",
      "2020-12-09T16:31:34.408828: step 1945, loss 0.16692, acc 0.90625, learning_rate 0.000387979\n",
      "2020-12-09T16:31:34.945330: step 1946, loss 0.217199, acc 0.90625, learning_rate 0.000387593\n",
      "2020-12-09T16:31:35.515393: step 1947, loss 0.484634, acc 0.90625, learning_rate 0.000387208\n",
      "2020-12-09T16:31:36.083928: step 1948, loss 0.120425, acc 0.9375, learning_rate 0.000386823\n",
      "2020-12-09T16:31:36.651896: step 1949, loss 0.0682511, acc 1, learning_rate 0.000386439\n",
      "2020-12-09T16:31:37.221725: step 1950, loss 0.272909, acc 0.8125, learning_rate 0.000386056\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:31:40.465568: step 1950, loss 0.925608, acc 0.722664\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-1950\n",
      "\n",
      "2020-12-09T16:31:41.908035: step 1951, loss 0.196574, acc 0.875, learning_rate 0.000385672\n",
      "2020-12-09T16:31:42.476363: step 1952, loss 0.163891, acc 0.9375, learning_rate 0.00038529\n",
      "2020-12-09T16:31:43.017388: step 1953, loss 0.147254, acc 0.9375, learning_rate 0.000384908\n",
      "2020-12-09T16:31:43.572330: step 1954, loss 0.106408, acc 0.96875, learning_rate 0.000384526\n",
      "2020-12-09T16:31:44.110333: step 1955, loss 0.21098, acc 0.90625, learning_rate 0.000384145\n",
      "2020-12-09T16:31:44.670016: step 1956, loss 0.241972, acc 0.875, learning_rate 0.000383764\n",
      "2020-12-09T16:31:45.226018: step 1957, loss 0.212792, acc 0.90625, learning_rate 0.000383384\n",
      "2020-12-09T16:31:45.763746: step 1958, loss 0.315181, acc 0.84375, learning_rate 0.000383004\n",
      "2020-12-09T16:31:46.330826: step 1959, loss 0.0602221, acc 1, learning_rate 0.000382625\n",
      "2020-12-09T16:31:46.892775: step 1960, loss 0.0999155, acc 0.9375, learning_rate 0.000382247\n",
      "2020-12-09T16:31:47.455546: step 1961, loss 0.263348, acc 0.875, learning_rate 0.000381869\n",
      "2020-12-09T16:31:48.025942: step 1962, loss 0.208573, acc 0.90625, learning_rate 0.000381491\n",
      "2020-12-09T16:31:48.597936: step 1963, loss 0.215061, acc 0.90625, learning_rate 0.000381114\n",
      "2020-12-09T16:31:49.137007: step 1964, loss 0.367389, acc 0.9375, learning_rate 0.000380737\n",
      "2020-12-09T16:31:49.694503: step 1965, loss 0.204888, acc 0.875, learning_rate 0.000380361\n",
      "2020-12-09T16:31:50.237317: step 1966, loss 0.0830591, acc 0.96875, learning_rate 0.000379986\n",
      "2020-12-09T16:31:50.813676: step 1967, loss 0.349226, acc 0.8125, learning_rate 0.000379611\n",
      "2020-12-09T16:31:51.368059: step 1968, loss 0.262798, acc 0.9375, learning_rate 0.000379236\n",
      "2020-12-09T16:31:51.926632: step 1969, loss 0.123748, acc 0.96875, learning_rate 0.000378862\n",
      "2020-12-09T16:31:52.465080: step 1970, loss 0.153212, acc 0.90625, learning_rate 0.000378489\n",
      "2020-12-09T16:31:53.014036: step 1971, loss 0.0493355, acc 0.96875, learning_rate 0.000378115\n",
      "2020-12-09T16:31:53.567929: step 1972, loss 0.0257322, acc 1, learning_rate 0.000377743\n",
      "2020-12-09T16:31:54.112819: step 1973, loss 0.193833, acc 0.90625, learning_rate 0.000377371\n",
      "2020-12-09T16:31:54.668083: step 1974, loss 0.166484, acc 0.90625, learning_rate 0.000376999\n",
      "2020-12-09T16:31:55.217840: step 1975, loss 0.363127, acc 0.90625, learning_rate 0.000376628\n",
      "2020-12-09T16:31:55.780271: step 1976, loss 0.186748, acc 0.96875, learning_rate 0.000376258\n",
      "2020-12-09T16:31:56.350930: step 1977, loss 0.0951779, acc 0.9375, learning_rate 0.000375888\n",
      "2020-12-09T16:31:56.920471: step 1978, loss 0.082668, acc 0.96875, learning_rate 0.000375518\n",
      "2020-12-09T16:31:57.478470: step 1979, loss 0.212154, acc 0.875, learning_rate 0.000375149\n",
      "2020-12-09T16:31:58.040933: step 1980, loss 0.311049, acc 0.84375, learning_rate 0.00037478\n",
      "2020-12-09T16:31:58.592889: step 1981, loss 0.270617, acc 0.78125, learning_rate 0.000374412\n",
      "2020-12-09T16:31:59.132860: step 1982, loss 0.201209, acc 0.90625, learning_rate 0.000374045\n",
      "2020-12-09T16:31:59.687372: step 1983, loss 0.272279, acc 0.90625, learning_rate 0.000373678\n",
      "2020-12-09T16:32:00.253305: step 1984, loss 0.270776, acc 0.90625, learning_rate 0.000373311\n",
      "2020-12-09T16:32:00.811503: step 1985, loss 0.0708372, acc 0.96875, learning_rate 0.000372945\n",
      "2020-12-09T16:32:01.354116: step 1986, loss 0.230392, acc 0.9375, learning_rate 0.000372579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:32:01.898673: step 1987, loss 0.0647515, acc 0.96875, learning_rate 0.000372214\n",
      "2020-12-09T16:32:02.442011: step 1988, loss 0.124292, acc 0.9375, learning_rate 0.00037185\n",
      "2020-12-09T16:32:03.028534: step 1989, loss 0.210216, acc 0.90625, learning_rate 0.000371485\n",
      "2020-12-09T16:32:03.582686: step 1990, loss 0.28039, acc 0.90625, learning_rate 0.000371122\n",
      "2020-12-09T16:32:04.147188: step 1991, loss 0.128847, acc 0.9375, learning_rate 0.000370759\n",
      "2020-12-09T16:32:04.698232: step 1992, loss 0.391805, acc 0.875, learning_rate 0.000370396\n",
      "2020-12-09T16:32:05.238198: step 1993, loss 0.143515, acc 0.96875, learning_rate 0.000370034\n",
      "2020-12-09T16:32:05.785678: step 1994, loss 0.256357, acc 0.875, learning_rate 0.000369672\n",
      "2020-12-09T16:32:06.365764: step 1995, loss 0.0619082, acc 1, learning_rate 0.000369311\n",
      "2020-12-09T16:32:06.915883: step 1996, loss 0.118108, acc 1, learning_rate 0.00036895\n",
      "2020-12-09T16:32:07.457370: step 1997, loss 0.200504, acc 0.90625, learning_rate 0.00036859\n",
      "2020-12-09T16:32:08.010407: step 1998, loss 0.0862382, acc 1, learning_rate 0.00036823\n",
      "2020-12-09T16:32:08.590319: step 1999, loss 0.411675, acc 0.875, learning_rate 0.000367871\n",
      "2020-12-09T16:32:09.134804: step 2000, loss 0.134879, acc 0.9375, learning_rate 0.000367512\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:32:12.331840: step 2000, loss 0.939652, acc 0.718475\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2000\n",
      "\n",
      "2020-12-09T16:32:13.777289: step 2001, loss 0.2102, acc 0.875, learning_rate 0.000367153\n",
      "2020-12-09T16:32:14.352590: step 2002, loss 0.11173, acc 0.96875, learning_rate 0.000366795\n",
      "2020-12-09T16:32:14.889087: step 2003, loss 0.147881, acc 0.9375, learning_rate 0.000366438\n",
      "2020-12-09T16:32:15.437053: step 2004, loss 0.14035, acc 0.96875, learning_rate 0.000366081\n",
      "2020-12-09T16:32:16.032115: step 2005, loss 0.259131, acc 0.90625, learning_rate 0.000365725\n",
      "2020-12-09T16:32:16.580919: step 2006, loss 0.732961, acc 0.65625, learning_rate 0.000365369\n",
      "2020-12-09T16:32:17.151909: step 2007, loss 0.160236, acc 0.90625, learning_rate 0.000365013\n",
      "2020-12-09T16:32:17.722017: step 2008, loss 0.273724, acc 0.90625, learning_rate 0.000364658\n",
      "2020-12-09T16:32:18.281155: step 2009, loss 0.20017, acc 0.90625, learning_rate 0.000364304\n",
      "2020-12-09T16:32:18.831004: step 2010, loss 0.235154, acc 0.90625, learning_rate 0.00036395\n",
      "2020-12-09T16:32:19.373500: step 2011, loss 0.0596215, acc 0.96875, learning_rate 0.000363596\n",
      "2020-12-09T16:32:19.948149: step 2012, loss 0.249476, acc 0.96875, learning_rate 0.000363243\n",
      "2020-12-09T16:32:20.504694: step 2013, loss 0.352835, acc 0.875, learning_rate 0.00036289\n",
      "2020-12-09T16:32:21.077048: step 2014, loss 0.0711214, acc 1, learning_rate 0.000362538\n",
      "2020-12-09T16:32:21.636809: step 2015, loss 0.0760553, acc 0.96875, learning_rate 0.000362187\n",
      "2020-12-09T16:32:22.195810: step 2016, loss 0.168821, acc 0.96875, learning_rate 0.000361835\n",
      "2020-12-09T16:32:22.760809: step 2017, loss 0.407558, acc 0.84375, learning_rate 0.000361485\n",
      "2020-12-09T16:32:23.308817: step 2018, loss 0.0902403, acc 0.96875, learning_rate 0.000361134\n",
      "2020-12-09T16:32:23.852309: step 2019, loss 0.125878, acc 0.9375, learning_rate 0.000360785\n",
      "2020-12-09T16:32:24.405108: step 2020, loss 0.111222, acc 0.90625, learning_rate 0.000360435\n",
      "2020-12-09T16:32:24.963520: step 2021, loss 0.137381, acc 0.90625, learning_rate 0.000360086\n",
      "2020-12-09T16:32:25.507485: step 2022, loss 0.171559, acc 0.9375, learning_rate 0.000359738\n",
      "2020-12-09T16:32:26.052520: step 2023, loss 0.27585, acc 0.84375, learning_rate 0.00035939\n",
      "2020-12-09T16:32:26.596052: step 2024, loss 0.167813, acc 0.9375, learning_rate 0.000359043\n",
      "2020-12-09T16:32:27.139605: step 2025, loss 0.113384, acc 0.9375, learning_rate 0.000358696\n",
      "2020-12-09T16:32:27.693071: step 2026, loss 0.214603, acc 0.9375, learning_rate 0.000358349\n",
      "2020-12-09T16:32:28.268065: step 2027, loss 0.102222, acc 0.96875, learning_rate 0.000358003\n",
      "2020-12-09T16:32:28.833776: step 2028, loss 0.0729472, acc 1, learning_rate 0.000357657\n",
      "2020-12-09T16:32:29.372310: step 2029, loss 0.150483, acc 0.9375, learning_rate 0.000357312\n",
      "2020-12-09T16:32:29.922345: step 2030, loss 0.233896, acc 0.90625, learning_rate 0.000356968\n",
      "2020-12-09T16:32:30.479190: step 2031, loss 0.129479, acc 0.96875, learning_rate 0.000356623\n",
      "2020-12-09T16:32:31.056905: step 2032, loss 0.223107, acc 0.90625, learning_rate 0.00035628\n",
      "2020-12-09T16:32:31.627498: step 2033, loss 0.151696, acc 0.90625, learning_rate 0.000355936\n",
      "2020-12-09T16:32:32.264499: step 2034, loss 0.137146, acc 0.90625, learning_rate 0.000355593\n",
      "2020-12-09T16:32:32.900999: step 2035, loss 0.238782, acc 0.96875, learning_rate 0.000355251\n",
      "2020-12-09T16:32:33.535998: step 2036, loss 0.155141, acc 0.9375, learning_rate 0.000354909\n",
      "2020-12-09T16:32:34.174000: step 2037, loss 0.282441, acc 0.90625, learning_rate 0.000354568\n",
      "2020-12-09T16:32:34.784501: step 2038, loss 0.260142, acc 0.8125, learning_rate 0.000354227\n",
      "2020-12-09T16:32:35.393502: step 2039, loss 0.309916, acc 0.9375, learning_rate 0.000353886\n",
      "2020-12-09T16:32:36.019033: step 2040, loss 0.255335, acc 0.875, learning_rate 0.000353546\n",
      "2020-12-09T16:32:36.737000: step 2041, loss 0.244881, acc 0.875, learning_rate 0.000353206\n",
      "2020-12-09T16:32:37.669000: step 2042, loss 0.200173, acc 0.90625, learning_rate 0.000352867\n",
      "2020-12-09T16:32:38.470499: step 2043, loss 0.205241, acc 0.9375, learning_rate 0.000352528\n",
      "2020-12-09T16:32:39.117455: step 2044, loss 0.161547, acc 0.9375, learning_rate 0.00035219\n",
      "2020-12-09T16:32:39.757436: step 2045, loss 0.303332, acc 0.9375, learning_rate 0.000351852\n",
      "2020-12-09T16:32:40.678939: step 2046, loss 0.178357, acc 0.875, learning_rate 0.000351515\n",
      "2020-12-09T16:32:41.629437: step 2047, loss 0.13343, acc 0.9375, learning_rate 0.000351178\n",
      "2020-12-09T16:32:42.560437: step 2048, loss 0.358586, acc 0.90625, learning_rate 0.000350842\n",
      "2020-12-09T16:32:43.388657: step 2049, loss 0.182174, acc 0.9375, learning_rate 0.000350506\n",
      "2020-12-09T16:32:43.967008: step 2050, loss 0.0810691, acc 0.96875, learning_rate 0.00035017\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:32:47.624922: step 2050, loss 0.937287, acc 0.718056\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2050\n",
      "\n",
      "2020-12-09T16:32:49.197795: step 2051, loss 0.159949, acc 0.9375, learning_rate 0.000349835\n",
      "2020-12-09T16:32:49.762080: step 2052, loss 0.252031, acc 0.875, learning_rate 0.0003495\n",
      "2020-12-09T16:32:50.303439: step 2053, loss 0.126102, acc 0.9375, learning_rate 0.000349166\n",
      "2020-12-09T16:32:50.880960: step 2054, loss 0.240011, acc 0.875, learning_rate 0.000348832\n",
      "2020-12-09T16:32:51.426426: step 2055, loss 0.181025, acc 0.9375, learning_rate 0.000348499\n",
      "2020-12-09T16:32:51.976423: step 2056, loss 0.194218, acc 0.9375, learning_rate 0.000348166\n",
      "2020-12-09T16:32:52.575960: step 2057, loss 0.302756, acc 0.875, learning_rate 0.000347834\n",
      "2020-12-09T16:32:53.137815: step 2058, loss 0.309512, acc 0.90625, learning_rate 0.000347502\n",
      "2020-12-09T16:32:53.684352: step 2059, loss 0.209504, acc 0.9375, learning_rate 0.00034717\n",
      "2020-12-09T16:32:54.234377: step 2060, loss 0.205508, acc 0.90625, learning_rate 0.000346839\n",
      "2020-12-09T16:32:54.779379: step 2061, loss 0.296992, acc 0.8125, learning_rate 0.000346508\n",
      "2020-12-09T16:32:55.342130: step 2062, loss 0.137109, acc 0.9375, learning_rate 0.000346178\n",
      "2020-12-09T16:32:55.897241: step 2063, loss 0.296759, acc 0.84375, learning_rate 0.000345848\n",
      "2020-12-09T16:32:56.442041: step 2064, loss 0.274342, acc 0.84375, learning_rate 0.000345519\n",
      "2020-12-09T16:32:56.993555: step 2065, loss 0.0690816, acc 1, learning_rate 0.00034519\n",
      "2020-12-09T16:32:57.543520: step 2066, loss 0.235636, acc 0.90625, learning_rate 0.000344862\n",
      "2020-12-09T16:32:58.105538: step 2067, loss 0.160945, acc 0.9375, learning_rate 0.000344534\n",
      "2020-12-09T16:32:58.663986: step 2068, loss 0.228785, acc 0.90625, learning_rate 0.000344206\n",
      "2020-12-09T16:32:59.207985: step 2069, loss 0.381517, acc 0.84375, learning_rate 0.000343879\n",
      "2020-12-09T16:32:59.739985: step 2070, loss 0.190937, acc 0.90625, learning_rate 0.000343552\n",
      "2020-12-09T16:33:00.310177: step 2071, loss 0.211251, acc 0.9375, learning_rate 0.000343226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:33:00.846320: step 2072, loss 0.171714, acc 0.9375, learning_rate 0.0003429\n",
      "2020-12-09T16:33:01.416319: step 2073, loss 0.147971, acc 0.9375, learning_rate 0.000342575\n",
      "2020-12-09T16:33:01.948720: step 2074, loss 0.0874833, acc 0.9375, learning_rate 0.00034225\n",
      "2020-12-09T16:33:02.509039: step 2075, loss 0.134546, acc 0.96875, learning_rate 0.000341925\n",
      "2020-12-09T16:33:03.086506: step 2076, loss 0.150566, acc 0.9375, learning_rate 0.000341601\n",
      "2020-12-09T16:33:03.628426: step 2077, loss 0.146893, acc 0.9375, learning_rate 0.000341278\n",
      "2020-12-09T16:33:04.260581: step 2078, loss 0.233102, acc 0.875, learning_rate 0.000340954\n",
      "2020-12-09T16:33:04.819377: step 2079, loss 0.169271, acc 0.90625, learning_rate 0.000340632\n",
      "2020-12-09T16:33:05.434219: step 2080, loss 0.265168, acc 0.875, learning_rate 0.000340309\n",
      "2020-12-09T16:33:05.977747: step 2081, loss 0.136581, acc 0.9375, learning_rate 0.000339987\n",
      "2020-12-09T16:33:06.665909: step 2082, loss 0.207345, acc 0.90625, learning_rate 0.000339666\n",
      "2020-12-09T16:33:07.234968: step 2083, loss 0.225621, acc 0.84375, learning_rate 0.000339345\n",
      "2020-12-09T16:33:07.761785: step 2084, loss 0.0756691, acc 1, learning_rate 0.000339024\n",
      "2020-12-09T16:33:08.328703: step 2085, loss 0.159787, acc 0.90625, learning_rate 0.000338704\n",
      "2020-12-09T16:33:08.885912: step 2086, loss 0.210153, acc 0.90625, learning_rate 0.000338384\n",
      "2020-12-09T16:33:09.472500: step 2087, loss 0.299495, acc 0.875, learning_rate 0.000338065\n",
      "2020-12-09T16:33:10.008810: step 2088, loss 0.155512, acc 0.9375, learning_rate 0.000337746\n",
      "2020-12-09T16:33:10.585295: step 2089, loss 0.116811, acc 0.90625, learning_rate 0.000337428\n",
      "2020-12-09T16:33:11.141369: step 2090, loss 0.270247, acc 0.90625, learning_rate 0.00033711\n",
      "2020-12-09T16:33:11.691325: step 2091, loss 0.282895, acc 0.90625, learning_rate 0.000336792\n",
      "2020-12-09T16:33:12.247168: step 2092, loss 0.298986, acc 0.875, learning_rate 0.000336475\n",
      "2020-12-09T16:33:12.467038: step 2093, loss 0.246182, acc 0.846154, learning_rate 0.000336158\n",
      "2020-12-09T16:33:13.054188: step 2094, loss 0.156446, acc 0.90625, learning_rate 0.000335842\n",
      "2020-12-09T16:33:13.612692: step 2095, loss 0.164992, acc 0.9375, learning_rate 0.000335526\n",
      "2020-12-09T16:33:14.162690: step 2096, loss 0.0914897, acc 0.9375, learning_rate 0.00033521\n",
      "2020-12-09T16:33:14.724161: step 2097, loss 0.0705367, acc 1, learning_rate 0.000334895\n",
      "2020-12-09T16:33:15.279287: step 2098, loss 0.0972255, acc 0.9375, learning_rate 0.00033458\n",
      "2020-12-09T16:33:15.833752: step 2099, loss 0.0904878, acc 0.96875, learning_rate 0.000334266\n",
      "2020-12-09T16:33:16.401752: step 2100, loss 0.193216, acc 0.9375, learning_rate 0.000333952\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:33:19.777577: step 2100, loss 0.946882, acc 0.715961\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2100\n",
      "\n",
      "2020-12-09T16:33:21.243210: step 2101, loss 0.114489, acc 0.96875, learning_rate 0.000333639\n",
      "2020-12-09T16:33:21.789248: step 2102, loss 0.181319, acc 0.96875, learning_rate 0.000333326\n",
      "2020-12-09T16:33:22.330211: step 2103, loss 0.150648, acc 0.90625, learning_rate 0.000333014\n",
      "2020-12-09T16:33:22.881765: step 2104, loss 0.243785, acc 0.90625, learning_rate 0.000332701\n",
      "2020-12-09T16:33:23.443365: step 2105, loss 0.0822594, acc 0.96875, learning_rate 0.00033239\n",
      "2020-12-09T16:33:24.029276: step 2106, loss 0.315811, acc 0.875, learning_rate 0.000332078\n",
      "2020-12-09T16:33:24.619778: step 2107, loss 0.151134, acc 0.9375, learning_rate 0.000331767\n",
      "2020-12-09T16:33:25.208631: step 2108, loss 0.140605, acc 0.9375, learning_rate 0.000331457\n",
      "2020-12-09T16:33:25.765869: step 2109, loss 0.0410991, acc 1, learning_rate 0.000331147\n",
      "2020-12-09T16:33:26.347448: step 2110, loss 0.155571, acc 0.9375, learning_rate 0.000330837\n",
      "2020-12-09T16:33:26.916379: step 2111, loss 0.244528, acc 0.9375, learning_rate 0.000330528\n",
      "2020-12-09T16:33:27.483100: step 2112, loss 0.274407, acc 0.90625, learning_rate 0.000330219\n",
      "2020-12-09T16:33:28.047390: step 2113, loss 0.349473, acc 0.84375, learning_rate 0.000329911\n",
      "2020-12-09T16:33:28.594444: step 2114, loss 0.0753759, acc 1, learning_rate 0.000329603\n",
      "2020-12-09T16:33:29.173909: step 2115, loss 0.11719, acc 0.96875, learning_rate 0.000329295\n",
      "2020-12-09T16:33:29.713499: step 2116, loss 0.164219, acc 0.90625, learning_rate 0.000328988\n",
      "2020-12-09T16:33:30.279168: step 2117, loss 0.223352, acc 0.90625, learning_rate 0.000328681\n",
      "2020-12-09T16:33:30.860021: step 2118, loss 0.123331, acc 0.96875, learning_rate 0.000328375\n",
      "2020-12-09T16:33:31.419304: step 2119, loss 0.121317, acc 0.96875, learning_rate 0.000328069\n",
      "2020-12-09T16:33:31.958844: step 2120, loss 0.229477, acc 0.90625, learning_rate 0.000327764\n",
      "2020-12-09T16:33:32.522288: step 2121, loss 0.144423, acc 0.96875, learning_rate 0.000327459\n",
      "2020-12-09T16:33:33.100023: step 2122, loss 0.0814734, acc 0.96875, learning_rate 0.000327154\n",
      "2020-12-09T16:33:33.657020: step 2123, loss 0.28735, acc 0.875, learning_rate 0.00032685\n",
      "2020-12-09T16:33:34.211761: step 2124, loss 0.143931, acc 0.9375, learning_rate 0.000326546\n",
      "2020-12-09T16:33:34.798256: step 2125, loss 0.121799, acc 0.96875, learning_rate 0.000326242\n",
      "2020-12-09T16:33:35.355926: step 2126, loss 0.146042, acc 0.9375, learning_rate 0.000325939\n",
      "2020-12-09T16:33:35.908894: step 2127, loss 0.236227, acc 0.875, learning_rate 0.000325637\n",
      "2020-12-09T16:33:36.458768: step 2128, loss 0.113598, acc 0.96875, learning_rate 0.000325334\n",
      "2020-12-09T16:33:37.017721: step 2129, loss 0.161873, acc 0.90625, learning_rate 0.000325032\n",
      "2020-12-09T16:33:37.607228: step 2130, loss 0.21111, acc 0.90625, learning_rate 0.000324731\n",
      "2020-12-09T16:33:38.157956: step 2131, loss 0.208312, acc 0.90625, learning_rate 0.00032443\n",
      "2020-12-09T16:33:38.718472: step 2132, loss 0.0817308, acc 0.96875, learning_rate 0.000324129\n",
      "2020-12-09T16:33:39.280265: step 2133, loss 0.157824, acc 0.9375, learning_rate 0.000323829\n",
      "2020-12-09T16:33:39.836767: step 2134, loss 0.358595, acc 0.84375, learning_rate 0.000323529\n",
      "2020-12-09T16:33:40.399306: step 2135, loss 0.224788, acc 0.90625, learning_rate 0.00032323\n",
      "2020-12-09T16:33:40.980346: step 2136, loss 0.11101, acc 0.96875, learning_rate 0.000322931\n",
      "2020-12-09T16:33:41.543448: step 2137, loss 0.151814, acc 0.90625, learning_rate 0.000322632\n",
      "2020-12-09T16:33:42.091467: step 2138, loss 0.253721, acc 0.875, learning_rate 0.000322334\n",
      "2020-12-09T16:33:42.657593: step 2139, loss 0.225214, acc 0.90625, learning_rate 0.000322036\n",
      "2020-12-09T16:33:43.209697: step 2140, loss 0.176438, acc 0.90625, learning_rate 0.000321739\n",
      "2020-12-09T16:33:43.762537: step 2141, loss 0.283832, acc 0.84375, learning_rate 0.000321442\n",
      "2020-12-09T16:33:44.317500: step 2142, loss 0.193269, acc 0.875, learning_rate 0.000321145\n",
      "2020-12-09T16:33:44.881000: step 2143, loss 0.440775, acc 0.90625, learning_rate 0.000320849\n",
      "2020-12-09T16:33:45.427085: step 2144, loss 0.205071, acc 0.9375, learning_rate 0.000320553\n",
      "2020-12-09T16:33:45.980053: step 2145, loss 0.0856983, acc 0.96875, learning_rate 0.000320258\n",
      "2020-12-09T16:33:46.533044: step 2146, loss 0.192897, acc 0.875, learning_rate 0.000319962\n",
      "2020-12-09T16:33:47.105582: step 2147, loss 0.108715, acc 0.96875, learning_rate 0.000319668\n",
      "2020-12-09T16:33:47.674061: step 2148, loss 0.203075, acc 0.9375, learning_rate 0.000319374\n",
      "2020-12-09T16:33:48.217062: step 2149, loss 0.0886672, acc 0.96875, learning_rate 0.00031908\n",
      "2020-12-09T16:33:48.775032: step 2150, loss 0.344023, acc 0.9375, learning_rate 0.000318786\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:33:52.046765: step 2150, loss 0.956758, acc 0.720989\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2150\n",
      "\n",
      "2020-12-09T16:33:53.512160: step 2151, loss 0.228343, acc 0.90625, learning_rate 0.000318493\n",
      "2020-12-09T16:33:54.064374: step 2152, loss 0.374362, acc 0.90625, learning_rate 0.0003182\n",
      "2020-12-09T16:33:54.612338: step 2153, loss 0.194213, acc 0.90625, learning_rate 0.000317908\n",
      "2020-12-09T16:33:55.159768: step 2154, loss 0.205442, acc 0.90625, learning_rate 0.000317616\n",
      "2020-12-09T16:33:55.705210: step 2155, loss 0.0710958, acc 1, learning_rate 0.000317325\n",
      "2020-12-09T16:33:56.256214: step 2156, loss 0.128069, acc 0.9375, learning_rate 0.000317034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:33:56.819246: step 2157, loss 0.267739, acc 0.90625, learning_rate 0.000316743\n",
      "2020-12-09T16:33:57.372580: step 2158, loss 0.120132, acc 0.96875, learning_rate 0.000316453\n",
      "2020-12-09T16:33:57.918058: step 2159, loss 0.214109, acc 0.90625, learning_rate 0.000316163\n",
      "2020-12-09T16:33:58.471033: step 2160, loss 0.130832, acc 0.96875, learning_rate 0.000315873\n",
      "2020-12-09T16:33:59.029568: step 2161, loss 0.468531, acc 0.8125, learning_rate 0.000315584\n",
      "2020-12-09T16:33:59.560033: step 2162, loss 0.105709, acc 0.96875, learning_rate 0.000315295\n",
      "2020-12-09T16:34:00.109571: step 2163, loss 0.174744, acc 0.875, learning_rate 0.000315007\n",
      "2020-12-09T16:34:00.663023: step 2164, loss 0.0701673, acc 0.96875, learning_rate 0.000314719\n",
      "2020-12-09T16:34:01.216100: step 2165, loss 0.254754, acc 0.84375, learning_rate 0.000314431\n",
      "2020-12-09T16:34:01.762683: step 2166, loss 0.203909, acc 0.875, learning_rate 0.000314144\n",
      "2020-12-09T16:34:02.312182: step 2167, loss 0.459824, acc 0.84375, learning_rate 0.000313857\n",
      "2020-12-09T16:34:02.863114: step 2168, loss 0.233513, acc 0.90625, learning_rate 0.00031357\n",
      "2020-12-09T16:34:03.408102: step 2169, loss 0.530247, acc 0.84375, learning_rate 0.000313284\n",
      "2020-12-09T16:34:03.966760: step 2170, loss 0.118712, acc 0.90625, learning_rate 0.000312999\n",
      "2020-12-09T16:34:04.508607: step 2171, loss 0.156242, acc 0.90625, learning_rate 0.000312713\n",
      "2020-12-09T16:34:05.064858: step 2172, loss 0.121313, acc 0.96875, learning_rate 0.000312428\n",
      "2020-12-09T16:34:05.623601: step 2173, loss 0.168281, acc 0.96875, learning_rate 0.000312144\n",
      "2020-12-09T16:34:06.174124: step 2174, loss 0.305567, acc 0.90625, learning_rate 0.00031186\n",
      "2020-12-09T16:34:06.724576: step 2175, loss 0.0962456, acc 1, learning_rate 0.000311576\n",
      "2020-12-09T16:34:07.273457: step 2176, loss 0.289859, acc 0.875, learning_rate 0.000311292\n",
      "2020-12-09T16:34:07.826072: step 2177, loss 0.10198, acc 0.96875, learning_rate 0.000311009\n",
      "2020-12-09T16:34:08.381345: step 2178, loss 0.0549109, acc 1, learning_rate 0.000310727\n",
      "2020-12-09T16:34:08.951997: step 2179, loss 0.34855, acc 0.8125, learning_rate 0.000310444\n",
      "2020-12-09T16:34:09.533382: step 2180, loss 0.103556, acc 0.96875, learning_rate 0.000310163\n",
      "2020-12-09T16:34:10.094040: step 2181, loss 0.347893, acc 0.90625, learning_rate 0.000309881\n",
      "2020-12-09T16:34:10.662423: step 2182, loss 0.200728, acc 0.90625, learning_rate 0.0003096\n",
      "2020-12-09T16:34:11.220116: step 2183, loss 0.145439, acc 0.9375, learning_rate 0.000309319\n",
      "2020-12-09T16:34:11.766434: step 2184, loss 0.0649054, acc 0.96875, learning_rate 0.000309039\n",
      "2020-12-09T16:34:12.316342: step 2185, loss 0.156545, acc 0.90625, learning_rate 0.000308759\n",
      "2020-12-09T16:34:12.868410: step 2186, loss 0.234432, acc 0.90625, learning_rate 0.000308479\n",
      "2020-12-09T16:34:13.421565: step 2187, loss 0.245162, acc 0.875, learning_rate 0.0003082\n",
      "2020-12-09T16:34:13.968805: step 2188, loss 0.235241, acc 0.8125, learning_rate 0.000307921\n",
      "2020-12-09T16:34:14.529572: step 2189, loss 0.0585671, acc 1, learning_rate 0.000307642\n",
      "2020-12-09T16:34:15.071530: step 2190, loss 0.223847, acc 0.90625, learning_rate 0.000307364\n",
      "2020-12-09T16:34:15.627043: step 2191, loss 0.126233, acc 1, learning_rate 0.000307086\n",
      "2020-12-09T16:34:16.179439: step 2192, loss 0.155803, acc 0.90625, learning_rate 0.000306809\n",
      "2020-12-09T16:34:16.733433: step 2193, loss 0.268713, acc 0.84375, learning_rate 0.000306532\n",
      "2020-12-09T16:34:17.299167: step 2194, loss 0.203574, acc 0.9375, learning_rate 0.000306255\n",
      "2020-12-09T16:34:17.839553: step 2195, loss 0.0884913, acc 0.96875, learning_rate 0.000305979\n",
      "2020-12-09T16:34:18.378608: step 2196, loss 0.164619, acc 0.90625, learning_rate 0.000305703\n",
      "2020-12-09T16:34:18.940696: step 2197, loss 0.177035, acc 0.90625, learning_rate 0.000305428\n",
      "2020-12-09T16:34:19.501149: step 2198, loss 0.310781, acc 0.78125, learning_rate 0.000305152\n",
      "2020-12-09T16:34:20.073281: step 2199, loss 0.180315, acc 0.90625, learning_rate 0.000304878\n",
      "2020-12-09T16:34:20.622783: step 2200, loss 0.159619, acc 0.9375, learning_rate 0.000304603\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:34:23.835738: step 2200, loss 0.944426, acc 0.720989\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2200\n",
      "\n",
      "2020-12-09T16:34:25.338738: step 2201, loss 0.215064, acc 0.875, learning_rate 0.000304329\n",
      "2020-12-09T16:34:25.900891: step 2202, loss 0.0438144, acc 1, learning_rate 0.000304055\n",
      "2020-12-09T16:34:26.444393: step 2203, loss 0.0790067, acc 1, learning_rate 0.000303782\n",
      "2020-12-09T16:34:27.010049: step 2204, loss 0.25514, acc 0.84375, learning_rate 0.000303509\n",
      "2020-12-09T16:34:27.553693: step 2205, loss 0.230653, acc 0.875, learning_rate 0.000303236\n",
      "2020-12-09T16:34:28.110760: step 2206, loss 0.137667, acc 0.875, learning_rate 0.000302964\n",
      "2020-12-09T16:34:28.671797: step 2207, loss 0.234766, acc 0.9375, learning_rate 0.000302692\n",
      "2020-12-09T16:34:29.228028: step 2208, loss 0.297925, acc 0.9375, learning_rate 0.000302421\n",
      "2020-12-09T16:34:29.795963: step 2209, loss 0.687634, acc 0.8125, learning_rate 0.00030215\n",
      "2020-12-09T16:34:30.349466: step 2210, loss 0.113045, acc 0.96875, learning_rate 0.000301879\n",
      "2020-12-09T16:34:30.888602: step 2211, loss 0.186799, acc 0.90625, learning_rate 0.000301608\n",
      "2020-12-09T16:34:31.453602: step 2212, loss 0.271611, acc 0.875, learning_rate 0.000301338\n",
      "2020-12-09T16:34:32.005783: step 2213, loss 0.175086, acc 0.90625, learning_rate 0.000301069\n",
      "2020-12-09T16:34:32.598790: step 2214, loss 0.162211, acc 0.90625, learning_rate 0.000300799\n",
      "2020-12-09T16:34:33.170711: step 2215, loss 0.0726921, acc 1, learning_rate 0.00030053\n",
      "2020-12-09T16:34:33.734710: step 2216, loss 0.0122013, acc 1, learning_rate 0.000300262\n",
      "2020-12-09T16:34:34.329139: step 2217, loss 0.157688, acc 0.90625, learning_rate 0.000299993\n",
      "2020-12-09T16:34:34.910244: step 2218, loss 0.278205, acc 0.9375, learning_rate 0.000299726\n",
      "2020-12-09T16:34:35.485064: step 2219, loss 0.261094, acc 0.84375, learning_rate 0.000299458\n",
      "2020-12-09T16:34:36.055656: step 2220, loss 0.271422, acc 0.84375, learning_rate 0.000299191\n",
      "2020-12-09T16:34:36.632041: step 2221, loss 0.157333, acc 0.9375, learning_rate 0.000298924\n",
      "2020-12-09T16:34:37.208018: step 2222, loss 0.361268, acc 0.90625, learning_rate 0.000298658\n",
      "2020-12-09T16:34:37.783078: step 2223, loss 0.306164, acc 0.875, learning_rate 0.000298391\n",
      "2020-12-09T16:34:38.334045: step 2224, loss 0.762747, acc 0.875, learning_rate 0.000298126\n",
      "2020-12-09T16:34:38.885670: step 2225, loss 0.0977097, acc 0.96875, learning_rate 0.00029786\n",
      "2020-12-09T16:34:39.458485: step 2226, loss 0.450349, acc 0.8125, learning_rate 0.000297595\n",
      "2020-12-09T16:34:40.023894: step 2227, loss 0.239031, acc 0.90625, learning_rate 0.000297331\n",
      "2020-12-09T16:34:40.575897: step 2228, loss 0.201921, acc 0.96875, learning_rate 0.000297066\n",
      "2020-12-09T16:34:41.122394: step 2229, loss 0.115261, acc 0.96875, learning_rate 0.000296802\n",
      "2020-12-09T16:34:41.682214: step 2230, loss 0.230087, acc 0.875, learning_rate 0.000296539\n",
      "2020-12-09T16:34:42.224356: step 2231, loss 0.185108, acc 0.9375, learning_rate 0.000296275\n",
      "2020-12-09T16:34:42.773400: step 2232, loss 0.154925, acc 0.9375, learning_rate 0.000296012\n",
      "2020-12-09T16:34:43.313524: step 2233, loss 0.133484, acc 0.96875, learning_rate 0.00029575\n",
      "2020-12-09T16:34:43.887194: step 2234, loss 0.0932692, acc 0.96875, learning_rate 0.000295488\n",
      "2020-12-09T16:34:44.429191: step 2235, loss 0.241963, acc 0.96875, learning_rate 0.000295226\n",
      "2020-12-09T16:34:45.008058: step 2236, loss 0.164694, acc 0.90625, learning_rate 0.000294964\n",
      "2020-12-09T16:34:45.559428: step 2237, loss 0.200253, acc 0.96875, learning_rate 0.000294703\n",
      "2020-12-09T16:34:46.113933: step 2238, loss 0.231789, acc 0.9375, learning_rate 0.000294442\n",
      "2020-12-09T16:34:46.666080: step 2239, loss 0.213289, acc 0.90625, learning_rate 0.000294182\n",
      "2020-12-09T16:34:47.219058: step 2240, loss 0.256268, acc 0.90625, learning_rate 0.000293922\n",
      "2020-12-09T16:34:47.770835: step 2241, loss 0.259086, acc 0.84375, learning_rate 0.000293662\n",
      "2020-12-09T16:34:48.337631: step 2242, loss 0.268426, acc 0.90625, learning_rate 0.000293402\n",
      "2020-12-09T16:34:48.916356: step 2243, loss 0.183864, acc 0.96875, learning_rate 0.000293143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:34:49.491601: step 2244, loss 0.155311, acc 0.90625, learning_rate 0.000292885\n",
      "2020-12-09T16:34:50.064285: step 2245, loss 0.119554, acc 0.96875, learning_rate 0.000292626\n",
      "2020-12-09T16:34:50.615783: step 2246, loss 0.103413, acc 0.96875, learning_rate 0.000292368\n",
      "2020-12-09T16:34:51.183219: step 2247, loss 0.3281, acc 0.875, learning_rate 0.000292111\n",
      "2020-12-09T16:34:51.754682: step 2248, loss 0.119837, acc 1, learning_rate 0.000291853\n",
      "2020-12-09T16:34:52.288257: step 2249, loss 0.299447, acc 0.84375, learning_rate 0.000291596\n",
      "2020-12-09T16:34:52.860582: step 2250, loss 0.114524, acc 0.9375, learning_rate 0.00029134\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:34:56.244204: step 2250, loss 0.951239, acc 0.714286\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2250\n",
      "\n",
      "2020-12-09T16:34:57.690554: step 2251, loss 0.0595106, acc 1, learning_rate 0.000291083\n",
      "2020-12-09T16:34:58.240923: step 2252, loss 0.435836, acc 0.84375, learning_rate 0.000290827\n",
      "2020-12-09T16:34:58.793783: step 2253, loss 0.120746, acc 0.96875, learning_rate 0.000290572\n",
      "2020-12-09T16:34:59.356764: step 2254, loss 0.0912322, acc 0.96875, learning_rate 0.000290316\n",
      "2020-12-09T16:34:59.904249: step 2255, loss 0.260339, acc 0.84375, learning_rate 0.000290061\n",
      "2020-12-09T16:35:00.489426: step 2256, loss 0.144315, acc 0.9375, learning_rate 0.000289807\n",
      "2020-12-09T16:35:01.042271: step 2257, loss 0.218109, acc 0.875, learning_rate 0.000289553\n",
      "2020-12-09T16:35:01.613838: step 2258, loss 0.282631, acc 0.84375, learning_rate 0.000289299\n",
      "2020-12-09T16:35:02.167675: step 2259, loss 0.199968, acc 0.96875, learning_rate 0.000289045\n",
      "2020-12-09T16:35:02.720176: step 2260, loss 0.181143, acc 0.9375, learning_rate 0.000288792\n",
      "2020-12-09T16:35:03.265702: step 2261, loss 0.221853, acc 0.84375, learning_rate 0.000288539\n",
      "2020-12-09T16:35:03.825740: step 2262, loss 0.194237, acc 0.9375, learning_rate 0.000288286\n",
      "2020-12-09T16:35:04.403500: step 2263, loss 0.140435, acc 0.9375, learning_rate 0.000288034\n",
      "2020-12-09T16:35:04.959665: step 2264, loss 0.146178, acc 0.96875, learning_rate 0.000287782\n",
      "2020-12-09T16:35:05.509587: step 2265, loss 0.179633, acc 0.90625, learning_rate 0.000287531\n",
      "2020-12-09T16:35:06.070474: step 2266, loss 0.0684372, acc 0.96875, learning_rate 0.00028728\n",
      "2020-12-09T16:35:06.633471: step 2267, loss 0.0847759, acc 0.96875, learning_rate 0.000287029\n",
      "2020-12-09T16:35:07.186736: step 2268, loss 0.249568, acc 0.84375, learning_rate 0.000286778\n",
      "2020-12-09T16:35:07.754457: step 2269, loss 0.16601, acc 0.96875, learning_rate 0.000286528\n",
      "2020-12-09T16:35:08.305931: step 2270, loss 0.163016, acc 0.90625, learning_rate 0.000286278\n",
      "2020-12-09T16:35:08.847906: step 2271, loss 0.0636204, acc 1, learning_rate 0.000286029\n",
      "2020-12-09T16:35:09.399562: step 2272, loss 0.269886, acc 0.90625, learning_rate 0.000285779\n",
      "2020-12-09T16:35:09.932295: step 2273, loss 0.174574, acc 0.875, learning_rate 0.00028553\n",
      "2020-12-09T16:35:10.473808: step 2274, loss 0.0897464, acc 0.96875, learning_rate 0.000285282\n",
      "2020-12-09T16:35:11.021701: step 2275, loss 0.306179, acc 0.84375, learning_rate 0.000285034\n",
      "2020-12-09T16:35:11.616269: step 2276, loss 0.146147, acc 0.90625, learning_rate 0.000284786\n",
      "2020-12-09T16:35:12.167153: step 2277, loss 0.137997, acc 0.9375, learning_rate 0.000284538\n",
      "2020-12-09T16:35:12.733035: step 2278, loss 0.323587, acc 0.84375, learning_rate 0.000284291\n",
      "2020-12-09T16:35:13.296038: step 2279, loss 0.244211, acc 0.8125, learning_rate 0.000284044\n",
      "2020-12-09T16:35:13.870588: step 2280, loss 0.173605, acc 0.9375, learning_rate 0.000283798\n",
      "2020-12-09T16:35:14.424621: step 2281, loss 0.180245, acc 0.90625, learning_rate 0.000283552\n",
      "2020-12-09T16:35:14.981724: step 2282, loss 0.256761, acc 0.90625, learning_rate 0.000283306\n",
      "2020-12-09T16:35:15.540354: step 2283, loss 0.193251, acc 0.9375, learning_rate 0.00028306\n",
      "2020-12-09T16:35:16.112524: step 2284, loss 0.161024, acc 0.90625, learning_rate 0.000282815\n",
      "2020-12-09T16:35:16.665403: step 2285, loss 0.161201, acc 0.90625, learning_rate 0.00028257\n",
      "2020-12-09T16:35:17.209896: step 2286, loss 0.245813, acc 0.90625, learning_rate 0.000282325\n",
      "2020-12-09T16:35:17.778179: step 2287, loss 0.0905059, acc 0.96875, learning_rate 0.000282081\n",
      "2020-12-09T16:35:18.336649: step 2288, loss 0.33217, acc 0.875, learning_rate 0.000281837\n",
      "2020-12-09T16:35:18.890647: step 2289, loss 0.243044, acc 0.84375, learning_rate 0.000281594\n",
      "2020-12-09T16:35:19.441609: step 2290, loss 0.0988678, acc 0.96875, learning_rate 0.00028135\n",
      "2020-12-09T16:35:19.984115: step 2291, loss 0.256246, acc 0.90625, learning_rate 0.000281108\n",
      "2020-12-09T16:35:20.542062: step 2292, loss 0.209564, acc 0.9375, learning_rate 0.000280865\n",
      "2020-12-09T16:35:21.101800: step 2293, loss 0.0814493, acc 1, learning_rate 0.000280623\n",
      "2020-12-09T16:35:21.664935: step 2294, loss 0.209697, acc 0.9375, learning_rate 0.000280381\n",
      "2020-12-09T16:35:22.225669: step 2295, loss 0.197381, acc 0.875, learning_rate 0.000280139\n",
      "2020-12-09T16:35:22.789319: step 2296, loss 0.256667, acc 0.9375, learning_rate 0.000279898\n",
      "2020-12-09T16:35:23.357340: step 2297, loss 0.193265, acc 0.9375, learning_rate 0.000279657\n",
      "2020-12-09T16:35:23.921153: step 2298, loss 0.0920738, acc 0.96875, learning_rate 0.000279416\n",
      "2020-12-09T16:35:24.459136: step 2299, loss 0.127445, acc 0.9375, learning_rate 0.000279176\n",
      "2020-12-09T16:35:25.010635: step 2300, loss 0.100009, acc 1, learning_rate 0.000278936\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:35:28.327191: step 2300, loss 0.977164, acc 0.715542\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2300\n",
      "\n",
      "2020-12-09T16:35:29.753914: step 2301, loss 0.192349, acc 0.90625, learning_rate 0.000278696\n",
      "2020-12-09T16:35:30.301448: step 2302, loss 0.0651586, acc 0.96875, learning_rate 0.000278457\n",
      "2020-12-09T16:35:30.861520: step 2303, loss 0.176229, acc 0.875, learning_rate 0.000278218\n",
      "2020-12-09T16:35:31.432735: step 2304, loss 0.116848, acc 0.9375, learning_rate 0.000277979\n",
      "2020-12-09T16:35:31.986235: step 2305, loss 0.166752, acc 0.90625, learning_rate 0.000277741\n",
      "2020-12-09T16:35:32.544735: step 2306, loss 0.446115, acc 0.875, learning_rate 0.000277502\n",
      "2020-12-09T16:35:33.083201: step 2307, loss 0.225252, acc 0.875, learning_rate 0.000277265\n",
      "2020-12-09T16:35:33.638738: step 2308, loss 0.117538, acc 0.9375, learning_rate 0.000277027\n",
      "2020-12-09T16:35:34.201891: step 2309, loss 0.109092, acc 0.96875, learning_rate 0.00027679\n",
      "2020-12-09T16:35:34.804869: step 2310, loss 0.163034, acc 0.9375, learning_rate 0.000276553\n",
      "2020-12-09T16:35:35.351871: step 2311, loss 0.703006, acc 0.90625, learning_rate 0.000276317\n",
      "2020-12-09T16:35:35.906782: step 2312, loss 0.207653, acc 0.90625, learning_rate 0.000276081\n",
      "2020-12-09T16:35:36.461403: step 2313, loss 0.153549, acc 0.9375, learning_rate 0.000275845\n",
      "2020-12-09T16:35:37.011466: step 2314, loss 0.301225, acc 0.84375, learning_rate 0.000275609\n",
      "2020-12-09T16:35:37.582467: step 2315, loss 0.209992, acc 0.9375, learning_rate 0.000275374\n",
      "2020-12-09T16:35:38.141081: step 2316, loss 0.144052, acc 0.96875, learning_rate 0.000275139\n",
      "2020-12-09T16:35:38.701197: step 2317, loss 0.176942, acc 0.9375, learning_rate 0.000274904\n",
      "2020-12-09T16:35:39.249697: step 2318, loss 0.201907, acc 0.90625, learning_rate 0.00027467\n",
      "2020-12-09T16:35:39.807997: step 2319, loss 0.0288531, acc 1, learning_rate 0.000274436\n",
      "2020-12-09T16:35:40.355461: step 2320, loss 0.412578, acc 0.84375, learning_rate 0.000274202\n",
      "2020-12-09T16:35:40.916324: step 2321, loss 0.548399, acc 0.84375, learning_rate 0.000273969\n",
      "2020-12-09T16:35:41.495824: step 2322, loss 0.135525, acc 0.96875, learning_rate 0.000273736\n",
      "2020-12-09T16:35:42.071323: step 2323, loss 0.0600806, acc 1, learning_rate 0.000273503\n",
      "2020-12-09T16:35:42.646191: step 2324, loss 0.120618, acc 0.96875, learning_rate 0.000273271\n",
      "2020-12-09T16:35:43.214153: step 2325, loss 0.115933, acc 0.9375, learning_rate 0.000273039\n",
      "2020-12-09T16:35:43.800156: step 2326, loss 0.224271, acc 0.90625, learning_rate 0.000272807\n",
      "2020-12-09T16:35:44.379155: step 2327, loss 0.125379, acc 0.96875, learning_rate 0.000272575\n",
      "2020-12-09T16:35:44.939539: step 2328, loss 0.10015, acc 0.96875, learning_rate 0.000272344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:35:45.519006: step 2329, loss 0.190124, acc 0.90625, learning_rate 0.000272113\n",
      "2020-12-09T16:35:46.107152: step 2330, loss 0.149695, acc 0.9375, learning_rate 0.000271883\n",
      "2020-12-09T16:35:46.660630: step 2331, loss 0.118087, acc 0.9375, learning_rate 0.000271653\n",
      "2020-12-09T16:35:47.192361: step 2332, loss 0.125742, acc 0.9375, learning_rate 0.000271423\n",
      "2020-12-09T16:35:47.758491: step 2333, loss 0.215034, acc 0.875, learning_rate 0.000271193\n",
      "2020-12-09T16:35:48.336925: step 2334, loss 0.03322, acc 1, learning_rate 0.000270964\n",
      "2020-12-09T16:35:48.900755: step 2335, loss 0.273852, acc 0.90625, learning_rate 0.000270735\n",
      "2020-12-09T16:35:49.461088: step 2336, loss 0.187031, acc 0.875, learning_rate 0.000270506\n",
      "2020-12-09T16:35:50.022101: step 2337, loss 0.273153, acc 0.9375, learning_rate 0.000270278\n",
      "2020-12-09T16:35:50.569223: step 2338, loss 0.113706, acc 0.96875, learning_rate 0.00027005\n",
      "2020-12-09T16:35:51.112009: step 2339, loss 0.124574, acc 0.96875, learning_rate 0.000269822\n",
      "2020-12-09T16:35:51.662092: step 2340, loss 0.182026, acc 0.9375, learning_rate 0.000269594\n",
      "2020-12-09T16:35:52.221470: step 2341, loss 0.198617, acc 0.90625, learning_rate 0.000269367\n",
      "2020-12-09T16:35:52.770649: step 2342, loss 0.0957758, acc 0.9375, learning_rate 0.00026914\n",
      "2020-12-09T16:35:53.315148: step 2343, loss 0.35358, acc 0.84375, learning_rate 0.000268914\n",
      "2020-12-09T16:35:53.876593: step 2344, loss 0.333377, acc 0.875, learning_rate 0.000268687\n",
      "2020-12-09T16:35:54.448305: step 2345, loss 0.0717986, acc 0.96875, learning_rate 0.000268461\n",
      "2020-12-09T16:35:54.976339: step 2346, loss 0.0940458, acc 0.9375, learning_rate 0.000268236\n",
      "2020-12-09T16:35:55.522811: step 2347, loss 0.240975, acc 0.875, learning_rate 0.00026801\n",
      "2020-12-09T16:35:56.092570: step 2348, loss 0.0864464, acc 0.96875, learning_rate 0.000267785\n",
      "2020-12-09T16:35:56.688879: step 2349, loss 0.116379, acc 0.9375, learning_rate 0.000267561\n",
      "2020-12-09T16:35:57.238915: step 2350, loss 0.198469, acc 0.9375, learning_rate 0.000267336\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:36:00.571397: step 2350, loss 0.973194, acc 0.712191\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2350\n",
      "\n",
      "2020-12-09T16:36:02.165264: step 2351, loss 0.124246, acc 0.96875, learning_rate 0.000267112\n",
      "2020-12-09T16:36:02.738812: step 2352, loss 0.119768, acc 0.96875, learning_rate 0.000266888\n",
      "2020-12-09T16:36:03.283275: step 2353, loss 0.19419, acc 0.9375, learning_rate 0.000266665\n",
      "2020-12-09T16:36:03.830050: step 2354, loss 0.211012, acc 0.90625, learning_rate 0.000266441\n",
      "2020-12-09T16:36:04.369677: step 2355, loss 0.0945709, acc 1, learning_rate 0.000266218\n",
      "2020-12-09T16:36:04.914154: step 2356, loss 0.215422, acc 0.90625, learning_rate 0.000265996\n",
      "2020-12-09T16:36:05.472812: step 2357, loss 0.0872914, acc 0.96875, learning_rate 0.000265773\n",
      "2020-12-09T16:36:06.034447: step 2358, loss 0.246685, acc 0.84375, learning_rate 0.000265551\n",
      "2020-12-09T16:36:06.585084: step 2359, loss 0.150385, acc 0.90625, learning_rate 0.000265329\n",
      "2020-12-09T16:36:07.126281: step 2360, loss 0.0447207, acc 0.96875, learning_rate 0.000265108\n",
      "2020-12-09T16:36:07.679785: step 2361, loss 0.181019, acc 0.90625, learning_rate 0.000264887\n",
      "2020-12-09T16:36:08.281143: step 2362, loss 0.206925, acc 0.84375, learning_rate 0.000264666\n",
      "2020-12-09T16:36:08.842182: step 2363, loss 0.107168, acc 0.96875, learning_rate 0.000264445\n",
      "2020-12-09T16:36:09.392972: step 2364, loss 0.389495, acc 0.8125, learning_rate 0.000264225\n",
      "2020-12-09T16:36:09.969014: step 2365, loss 0.138904, acc 0.9375, learning_rate 0.000264005\n",
      "2020-12-09T16:36:10.524848: step 2366, loss 0.180667, acc 0.90625, learning_rate 0.000263785\n",
      "2020-12-09T16:36:11.087677: step 2367, loss 0.0552168, acc 1, learning_rate 0.000263566\n",
      "2020-12-09T16:36:11.644566: step 2368, loss 0.201473, acc 0.9375, learning_rate 0.000263347\n",
      "2020-12-09T16:36:12.203449: step 2369, loss 0.0427676, acc 1, learning_rate 0.000263128\n",
      "2020-12-09T16:36:12.760658: step 2370, loss 0.190611, acc 0.90625, learning_rate 0.00026291\n",
      "2020-12-09T16:36:13.307600: step 2371, loss 0.287701, acc 0.84375, learning_rate 0.000262691\n",
      "2020-12-09T16:36:13.882082: step 2372, loss 0.279296, acc 0.90625, learning_rate 0.000262473\n",
      "2020-12-09T16:36:14.441832: step 2373, loss 0.101921, acc 0.96875, learning_rate 0.000262256\n",
      "2020-12-09T16:36:15.013289: step 2374, loss 0.162063, acc 0.90625, learning_rate 0.000262038\n",
      "2020-12-09T16:36:15.551284: step 2375, loss 0.140058, acc 0.9375, learning_rate 0.000261821\n",
      "2020-12-09T16:36:16.108005: step 2376, loss 0.126626, acc 0.96875, learning_rate 0.000261605\n",
      "2020-12-09T16:36:16.663470: step 2377, loss 0.101446, acc 0.96875, learning_rate 0.000261388\n",
      "2020-12-09T16:36:17.224123: step 2378, loss 0.176143, acc 0.875, learning_rate 0.000261172\n",
      "2020-12-09T16:36:17.776465: step 2379, loss 0.149453, acc 0.9375, learning_rate 0.000260956\n",
      "2020-12-09T16:36:18.365817: step 2380, loss 0.0381526, acc 1, learning_rate 0.00026074\n",
      "2020-12-09T16:36:18.918384: step 2381, loss 0.215523, acc 0.90625, learning_rate 0.000260525\n",
      "2020-12-09T16:36:19.457350: step 2382, loss 0.252997, acc 0.90625, learning_rate 0.00026031\n",
      "2020-12-09T16:36:20.027884: step 2383, loss 0.160513, acc 0.9375, learning_rate 0.000260095\n",
      "2020-12-09T16:36:20.580206: step 2384, loss 0.28795, acc 0.84375, learning_rate 0.000259881\n",
      "2020-12-09T16:36:21.129064: step 2385, loss 0.223462, acc 0.9375, learning_rate 0.000259667\n",
      "2020-12-09T16:36:21.671564: step 2386, loss 0.181383, acc 0.875, learning_rate 0.000259453\n",
      "2020-12-09T16:36:22.242942: step 2387, loss 0.0581794, acc 0.96875, learning_rate 0.000259239\n",
      "2020-12-09T16:36:22.786434: step 2388, loss 0.107042, acc 0.9375, learning_rate 0.000259026\n",
      "2020-12-09T16:36:23.348451: step 2389, loss 0.0861469, acc 0.96875, learning_rate 0.000258813\n",
      "2020-12-09T16:36:23.904486: step 2390, loss 0.334427, acc 0.84375, learning_rate 0.0002586\n",
      "2020-12-09T16:36:24.484262: step 2391, loss 0.123024, acc 0.9375, learning_rate 0.000258388\n",
      "2020-12-09T16:36:24.700776: step 2392, loss 0.107243, acc 1, learning_rate 0.000258175\n",
      "2020-12-09T16:36:25.266803: step 2393, loss 0.136929, acc 0.9375, learning_rate 0.000257964\n",
      "2020-12-09T16:36:25.829169: step 2394, loss 0.282668, acc 0.875, learning_rate 0.000257752\n",
      "2020-12-09T16:36:26.423484: step 2395, loss 0.267555, acc 0.84375, learning_rate 0.000257541\n",
      "2020-12-09T16:36:27.003249: step 2396, loss 0.249008, acc 0.9375, learning_rate 0.00025733\n",
      "2020-12-09T16:36:27.534212: step 2397, loss 0.156582, acc 0.9375, learning_rate 0.000257119\n",
      "2020-12-09T16:36:28.104639: step 2398, loss 0.121278, acc 0.9375, learning_rate 0.000256908\n",
      "2020-12-09T16:36:28.655140: step 2399, loss 0.223841, acc 0.875, learning_rate 0.000256698\n",
      "2020-12-09T16:36:29.211035: step 2400, loss 0.215135, acc 0.9375, learning_rate 0.000256488\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:36:32.400713: step 2400, loss 0.970521, acc 0.717218\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2400\n",
      "\n",
      "2020-12-09T16:36:33.873957: step 2401, loss 0.134112, acc 0.9375, learning_rate 0.000256279\n",
      "2020-12-09T16:36:34.440163: step 2402, loss 0.139126, acc 0.9375, learning_rate 0.000256069\n",
      "2020-12-09T16:36:34.994583: step 2403, loss 0.143171, acc 0.9375, learning_rate 0.00025586\n",
      "2020-12-09T16:36:35.534979: step 2404, loss 0.193745, acc 0.9375, learning_rate 0.000255652\n",
      "2020-12-09T16:36:36.082444: step 2405, loss 0.369176, acc 0.84375, learning_rate 0.000255443\n",
      "2020-12-09T16:36:36.655555: step 2406, loss 0.0707332, acc 0.96875, learning_rate 0.000255235\n",
      "2020-12-09T16:36:37.215424: step 2407, loss 0.116861, acc 0.96875, learning_rate 0.000255027\n",
      "2020-12-09T16:36:37.775044: step 2408, loss 0.145454, acc 0.96875, learning_rate 0.000254819\n",
      "2020-12-09T16:36:38.337982: step 2409, loss 0.105118, acc 0.9375, learning_rate 0.000254612\n",
      "2020-12-09T16:36:38.917326: step 2410, loss 0.269924, acc 0.9375, learning_rate 0.000254405\n",
      "2020-12-09T16:36:39.478469: step 2411, loss 0.166913, acc 0.90625, learning_rate 0.000254198\n",
      "2020-12-09T16:36:40.025082: step 2412, loss 0.0696333, acc 1, learning_rate 0.000253991\n",
      "2020-12-09T16:36:40.579469: step 2413, loss 0.281832, acc 0.90625, learning_rate 0.000253785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:36:41.178634: step 2414, loss 0.116736, acc 0.96875, learning_rate 0.000253579\n",
      "2020-12-09T16:36:41.724168: step 2415, loss 0.198648, acc 0.90625, learning_rate 0.000253373\n",
      "2020-12-09T16:36:42.281166: step 2416, loss 0.251069, acc 0.8125, learning_rate 0.000253168\n",
      "2020-12-09T16:36:42.831765: step 2417, loss 0.224514, acc 0.9375, learning_rate 0.000252963\n",
      "2020-12-09T16:36:43.384994: step 2418, loss 0.234227, acc 0.875, learning_rate 0.000252758\n",
      "2020-12-09T16:36:43.940954: step 2419, loss 0.147901, acc 0.9375, learning_rate 0.000252553\n",
      "2020-12-09T16:36:44.482989: step 2420, loss 0.226143, acc 0.90625, learning_rate 0.000252349\n",
      "2020-12-09T16:36:45.028643: step 2421, loss 0.217084, acc 0.875, learning_rate 0.000252145\n",
      "2020-12-09T16:36:45.592534: step 2422, loss 0.245613, acc 0.84375, learning_rate 0.000251941\n",
      "2020-12-09T16:36:46.157822: step 2423, loss 0.380616, acc 0.875, learning_rate 0.000251737\n",
      "2020-12-09T16:36:46.723172: step 2424, loss 0.193939, acc 0.9375, learning_rate 0.000251534\n",
      "2020-12-09T16:36:47.400168: step 2425, loss 0.0802057, acc 0.96875, learning_rate 0.000251331\n",
      "2020-12-09T16:36:48.020667: step 2426, loss 0.204234, acc 0.9375, learning_rate 0.000251128\n",
      "2020-12-09T16:36:48.603206: step 2427, loss 0.090279, acc 0.96875, learning_rate 0.000250926\n",
      "2020-12-09T16:36:49.156703: step 2428, loss 0.36039, acc 0.84375, learning_rate 0.000250724\n",
      "2020-12-09T16:36:49.705169: step 2429, loss 0.572022, acc 0.875, learning_rate 0.000250522\n",
      "2020-12-09T16:36:50.279982: step 2430, loss 0.0974944, acc 0.96875, learning_rate 0.00025032\n",
      "2020-12-09T16:36:50.832514: step 2431, loss 0.123612, acc 0.9375, learning_rate 0.000250119\n",
      "2020-12-09T16:36:51.392344: step 2432, loss 0.100884, acc 0.96875, learning_rate 0.000249918\n",
      "2020-12-09T16:36:51.977156: step 2433, loss 0.260312, acc 0.90625, learning_rate 0.000249717\n",
      "2020-12-09T16:36:52.548795: step 2434, loss 0.115602, acc 0.96875, learning_rate 0.000249516\n",
      "2020-12-09T16:36:53.131296: step 2435, loss 0.0351953, acc 1, learning_rate 0.000249316\n",
      "2020-12-09T16:36:53.709795: step 2436, loss 0.169541, acc 0.90625, learning_rate 0.000249116\n",
      "2020-12-09T16:36:54.318339: step 2437, loss 0.0724302, acc 0.96875, learning_rate 0.000248916\n",
      "2020-12-09T16:36:54.891796: step 2438, loss 0.165291, acc 0.96875, learning_rate 0.000248717\n",
      "2020-12-09T16:36:55.468296: step 2439, loss 0.263349, acc 0.875, learning_rate 0.000248518\n",
      "2020-12-09T16:36:56.054795: step 2440, loss 0.179386, acc 0.90625, learning_rate 0.000248319\n",
      "2020-12-09T16:36:56.620206: step 2441, loss 0.0867513, acc 0.96875, learning_rate 0.00024812\n",
      "2020-12-09T16:36:57.168844: step 2442, loss 0.218319, acc 0.9375, learning_rate 0.000247922\n",
      "2020-12-09T16:36:57.711349: step 2443, loss 0.353878, acc 0.8125, learning_rate 0.000247723\n",
      "2020-12-09T16:36:58.281375: step 2444, loss 0.080509, acc 1, learning_rate 0.000247526\n",
      "2020-12-09T16:36:58.859361: step 2445, loss 0.142664, acc 0.9375, learning_rate 0.000247328\n",
      "2020-12-09T16:36:59.395399: step 2446, loss 0.182464, acc 0.875, learning_rate 0.000247131\n",
      "2020-12-09T16:36:59.937896: step 2447, loss 0.203258, acc 0.875, learning_rate 0.000246934\n",
      "2020-12-09T16:37:00.492526: step 2448, loss 0.319795, acc 0.90625, learning_rate 0.000246737\n",
      "2020-12-09T16:37:01.051803: step 2449, loss 0.0981123, acc 0.96875, learning_rate 0.00024654\n",
      "2020-12-09T16:37:01.612336: step 2450, loss 0.112664, acc 0.96875, learning_rate 0.000246344\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:37:04.881012: step 2450, loss 0.992381, acc 0.70884\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2450\n",
      "\n",
      "2020-12-09T16:37:06.352574: step 2451, loss 0.191006, acc 0.90625, learning_rate 0.000246148\n",
      "2020-12-09T16:37:06.927441: step 2452, loss 0.264487, acc 0.90625, learning_rate 0.000245952\n",
      "2020-12-09T16:37:07.498762: step 2453, loss 0.139739, acc 0.9375, learning_rate 0.000245756\n",
      "2020-12-09T16:37:08.049094: step 2454, loss 0.127744, acc 0.96875, learning_rate 0.000245561\n",
      "2020-12-09T16:37:08.610576: step 2455, loss 0.289267, acc 0.90625, learning_rate 0.000245366\n",
      "2020-12-09T16:37:09.168425: step 2456, loss 0.168999, acc 0.90625, learning_rate 0.000245172\n",
      "2020-12-09T16:37:09.719282: step 2457, loss 0.220599, acc 0.84375, learning_rate 0.000244977\n",
      "2020-12-09T16:37:10.281784: step 2458, loss 0.275589, acc 0.90625, learning_rate 0.000244783\n",
      "2020-12-09T16:37:10.847948: step 2459, loss 0.0305826, acc 1, learning_rate 0.000244589\n",
      "2020-12-09T16:37:11.399212: step 2460, loss 0.108452, acc 0.9375, learning_rate 0.000244395\n",
      "2020-12-09T16:37:11.949175: step 2461, loss 0.306754, acc 0.8125, learning_rate 0.000244202\n",
      "2020-12-09T16:37:12.533209: step 2462, loss 0.253868, acc 0.90625, learning_rate 0.000244009\n",
      "2020-12-09T16:37:13.109164: step 2463, loss 0.113901, acc 0.96875, learning_rate 0.000243816\n",
      "2020-12-09T16:37:13.689436: step 2464, loss 0.234808, acc 0.90625, learning_rate 0.000243623\n",
      "2020-12-09T16:37:14.232784: step 2465, loss 0.108107, acc 0.96875, learning_rate 0.000243431\n",
      "2020-12-09T16:37:14.778941: step 2466, loss 0.105715, acc 0.96875, learning_rate 0.000243239\n",
      "2020-12-09T16:37:15.335150: step 2467, loss 0.316972, acc 0.90625, learning_rate 0.000243047\n",
      "2020-12-09T16:37:15.881402: step 2468, loss 0.116502, acc 0.90625, learning_rate 0.000242855\n",
      "2020-12-09T16:37:16.434176: step 2469, loss 0.163008, acc 0.9375, learning_rate 0.000242664\n",
      "2020-12-09T16:37:16.981199: step 2470, loss 0.215811, acc 0.9375, learning_rate 0.000242473\n",
      "2020-12-09T16:37:17.550411: step 2471, loss 0.192281, acc 0.90625, learning_rate 0.000242282\n",
      "2020-12-09T16:37:18.097411: step 2472, loss 0.0863634, acc 0.9375, learning_rate 0.000242091\n",
      "2020-12-09T16:37:18.659854: step 2473, loss 0.158306, acc 0.9375, learning_rate 0.000241901\n",
      "2020-12-09T16:37:19.217178: step 2474, loss 0.190134, acc 0.9375, learning_rate 0.000241711\n",
      "2020-12-09T16:37:19.788255: step 2475, loss 0.191387, acc 0.96875, learning_rate 0.000241521\n",
      "2020-12-09T16:37:20.360983: step 2476, loss 0.104407, acc 0.96875, learning_rate 0.000241331\n",
      "2020-12-09T16:37:20.941720: step 2477, loss 0.109793, acc 0.96875, learning_rate 0.000241142\n",
      "2020-12-09T16:37:21.515764: step 2478, loss 0.0416241, acc 1, learning_rate 0.000240953\n",
      "2020-12-09T16:37:22.086729: step 2479, loss 0.137379, acc 0.9375, learning_rate 0.000240764\n",
      "2020-12-09T16:37:22.645075: step 2480, loss 0.209396, acc 0.875, learning_rate 0.000240576\n",
      "2020-12-09T16:37:23.195334: step 2481, loss 0.203985, acc 0.90625, learning_rate 0.000240387\n",
      "2020-12-09T16:37:23.759328: step 2482, loss 0.0899777, acc 0.96875, learning_rate 0.000240199\n",
      "2020-12-09T16:37:24.323859: step 2483, loss 0.0807327, acc 0.96875, learning_rate 0.000240011\n",
      "2020-12-09T16:37:24.902963: step 2484, loss 0.238306, acc 0.84375, learning_rate 0.000239824\n",
      "2020-12-09T16:37:25.455557: step 2485, loss 0.226233, acc 0.875, learning_rate 0.000239637\n",
      "2020-12-09T16:37:26.010095: step 2486, loss 0.141692, acc 0.9375, learning_rate 0.000239449\n",
      "2020-12-09T16:37:26.569461: step 2487, loss 0.0396041, acc 0.96875, learning_rate 0.000239263\n",
      "2020-12-09T16:37:27.144394: step 2488, loss 0.313166, acc 0.84375, learning_rate 0.000239076\n",
      "2020-12-09T16:37:27.710989: step 2489, loss 0.494229, acc 0.90625, learning_rate 0.00023889\n",
      "2020-12-09T16:37:28.256556: step 2490, loss 0.245962, acc 0.875, learning_rate 0.000238704\n",
      "2020-12-09T16:37:28.816180: step 2491, loss 0.293976, acc 0.875, learning_rate 0.000238518\n",
      "2020-12-09T16:37:29.365729: step 2492, loss 0.0886981, acc 0.9375, learning_rate 0.000238332\n",
      "2020-12-09T16:37:29.953460: step 2493, loss 0.164646, acc 0.9375, learning_rate 0.000238147\n",
      "2020-12-09T16:37:30.524621: step 2494, loss 0.281753, acc 0.84375, learning_rate 0.000237962\n",
      "2020-12-09T16:37:31.090194: step 2495, loss 0.160385, acc 0.96875, learning_rate 0.000237777\n",
      "2020-12-09T16:37:31.647305: step 2496, loss 0.0921034, acc 0.96875, learning_rate 0.000237593\n",
      "2020-12-09T16:37:32.192511: step 2497, loss 0.0714695, acc 0.9375, learning_rate 0.000237408\n",
      "2020-12-09T16:37:32.755117: step 2498, loss 0.277018, acc 0.9375, learning_rate 0.000237224\n",
      "2020-12-09T16:37:33.315261: step 2499, loss 0.171921, acc 0.96875, learning_rate 0.00023704\n",
      "2020-12-09T16:37:33.883428: step 2500, loss 0.262396, acc 0.875, learning_rate 0.000236857\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:37:37.189829: step 2500, loss 0.981712, acc 0.71261\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2500\n",
      "\n",
      "2020-12-09T16:37:38.636172: step 2501, loss 0.0579325, acc 1, learning_rate 0.000236674\n",
      "2020-12-09T16:37:39.196109: step 2502, loss 0.111767, acc 0.96875, learning_rate 0.000236491\n",
      "2020-12-09T16:37:39.753849: step 2503, loss 0.293693, acc 0.90625, learning_rate 0.000236308\n",
      "2020-12-09T16:37:40.281376: step 2504, loss 0.269345, acc 0.90625, learning_rate 0.000236125\n",
      "2020-12-09T16:37:40.841615: step 2505, loss 0.0926766, acc 1, learning_rate 0.000235943\n",
      "2020-12-09T16:37:41.410438: step 2506, loss 0.194787, acc 0.90625, learning_rate 0.000235761\n",
      "2020-12-09T16:37:41.986419: step 2507, loss 0.0461531, acc 1, learning_rate 0.000235579\n",
      "2020-12-09T16:37:42.535857: step 2508, loss 0.0831904, acc 0.96875, learning_rate 0.000235397\n",
      "2020-12-09T16:37:43.158361: step 2509, loss 0.125421, acc 0.96875, learning_rate 0.000235216\n",
      "2020-12-09T16:37:43.721501: step 2510, loss 0.425027, acc 0.96875, learning_rate 0.000235035\n",
      "2020-12-09T16:37:44.255037: step 2511, loss 0.218409, acc 0.875, learning_rate 0.000234854\n",
      "2020-12-09T16:37:44.804024: step 2512, loss 0.190911, acc 0.9375, learning_rate 0.000234673\n",
      "2020-12-09T16:37:45.377864: step 2513, loss 0.0746507, acc 0.96875, learning_rate 0.000234493\n",
      "2020-12-09T16:37:45.934960: step 2514, loss 0.290481, acc 0.90625, learning_rate 0.000234313\n",
      "2020-12-09T16:37:46.475636: step 2515, loss 0.210728, acc 0.90625, learning_rate 0.000234133\n",
      "2020-12-09T16:37:47.016195: step 2516, loss 0.0857324, acc 0.96875, learning_rate 0.000233953\n",
      "2020-12-09T16:37:47.598916: step 2517, loss 0.0789897, acc 0.96875, learning_rate 0.000233774\n",
      "2020-12-09T16:37:48.152353: step 2518, loss 0.0524736, acc 1, learning_rate 0.000233594\n",
      "2020-12-09T16:37:48.701090: step 2519, loss 0.127974, acc 0.9375, learning_rate 0.000233415\n",
      "2020-12-09T16:37:49.252626: step 2520, loss 0.112154, acc 0.96875, learning_rate 0.000233237\n",
      "2020-12-09T16:37:49.815672: step 2521, loss 0.0809906, acc 0.96875, learning_rate 0.000233058\n",
      "2020-12-09T16:37:50.362655: step 2522, loss 0.11148, acc 0.9375, learning_rate 0.00023288\n",
      "2020-12-09T16:37:50.931389: step 2523, loss 0.1436, acc 0.96875, learning_rate 0.000232702\n",
      "2020-12-09T16:37:51.495358: step 2524, loss 0.176595, acc 0.9375, learning_rate 0.000232524\n",
      "2020-12-09T16:37:52.040389: step 2525, loss 0.0889585, acc 0.96875, learning_rate 0.000232347\n",
      "2020-12-09T16:37:52.589061: step 2526, loss 0.16118, acc 0.96875, learning_rate 0.000232169\n",
      "2020-12-09T16:37:53.156194: step 2527, loss 0.25569, acc 0.84375, learning_rate 0.000231992\n",
      "2020-12-09T16:37:53.724677: step 2528, loss 0.545071, acc 0.9375, learning_rate 0.000231816\n",
      "2020-12-09T16:37:54.270176: step 2529, loss 0.0932455, acc 0.96875, learning_rate 0.000231639\n",
      "2020-12-09T16:37:54.822174: step 2530, loss 0.0917831, acc 0.96875, learning_rate 0.000231463\n",
      "2020-12-09T16:37:55.362589: step 2531, loss 0.107866, acc 0.96875, learning_rate 0.000231286\n",
      "2020-12-09T16:37:55.911543: step 2532, loss 0.13392, acc 0.96875, learning_rate 0.000231111\n",
      "2020-12-09T16:37:56.454542: step 2533, loss 0.133596, acc 0.90625, learning_rate 0.000230935\n",
      "2020-12-09T16:37:57.008058: step 2534, loss 0.204404, acc 0.9375, learning_rate 0.00023076\n",
      "2020-12-09T16:37:57.559395: step 2535, loss 0.19094, acc 0.9375, learning_rate 0.000230584\n",
      "2020-12-09T16:37:58.136882: step 2536, loss 0.181473, acc 0.96875, learning_rate 0.00023041\n",
      "2020-12-09T16:37:58.688313: step 2537, loss 0.362121, acc 0.875, learning_rate 0.000230235\n",
      "2020-12-09T16:37:59.230808: step 2538, loss 0.360356, acc 0.90625, learning_rate 0.00023006\n",
      "2020-12-09T16:37:59.782234: step 2539, loss 0.154039, acc 0.90625, learning_rate 0.000229886\n",
      "2020-12-09T16:38:00.319787: step 2540, loss 0.117016, acc 0.90625, learning_rate 0.000229712\n",
      "2020-12-09T16:38:00.891749: step 2541, loss 0.0618793, acc 0.96875, learning_rate 0.000229538\n",
      "2020-12-09T16:38:01.470669: step 2542, loss 0.142504, acc 0.96875, learning_rate 0.000229365\n",
      "2020-12-09T16:38:02.030336: step 2543, loss 0.183798, acc 0.9375, learning_rate 0.000229192\n",
      "2020-12-09T16:38:02.625205: step 2544, loss 0.207345, acc 0.90625, learning_rate 0.000229019\n",
      "2020-12-09T16:38:03.216701: step 2545, loss 0.198784, acc 0.90625, learning_rate 0.000228846\n",
      "2020-12-09T16:38:03.837000: step 2546, loss 0.189007, acc 0.9375, learning_rate 0.000228673\n",
      "2020-12-09T16:38:04.421000: step 2547, loss 0.157987, acc 0.96875, learning_rate 0.000228501\n",
      "2020-12-09T16:38:04.997801: step 2548, loss 0.224295, acc 0.90625, learning_rate 0.000228329\n",
      "2020-12-09T16:38:05.571264: step 2549, loss 0.156819, acc 0.9375, learning_rate 0.000228157\n",
      "2020-12-09T16:38:06.142426: step 2550, loss 0.171584, acc 0.96875, learning_rate 0.000227985\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:38:09.468500: step 2550, loss 0.973966, acc 0.720989\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2550\n",
      "\n",
      "2020-12-09T16:38:10.954131: step 2551, loss 0.299099, acc 0.9375, learning_rate 0.000227814\n",
      "2020-12-09T16:38:11.505924: step 2552, loss 0.0609647, acc 1, learning_rate 0.000227642\n",
      "2020-12-09T16:38:12.066276: step 2553, loss 0.137939, acc 0.96875, learning_rate 0.000227471\n",
      "2020-12-09T16:38:12.628605: step 2554, loss 0.076614, acc 0.96875, learning_rate 0.000227301\n",
      "2020-12-09T16:38:13.171145: step 2555, loss 0.0781076, acc 0.96875, learning_rate 0.00022713\n",
      "2020-12-09T16:38:13.716464: step 2556, loss 0.180325, acc 0.9375, learning_rate 0.00022696\n",
      "2020-12-09T16:38:14.269505: step 2557, loss 0.174869, acc 0.9375, learning_rate 0.00022679\n",
      "2020-12-09T16:38:14.828506: step 2558, loss 0.2512, acc 0.875, learning_rate 0.00022662\n",
      "2020-12-09T16:38:15.400316: step 2559, loss 0.244132, acc 0.875, learning_rate 0.00022645\n",
      "2020-12-09T16:38:15.945712: step 2560, loss 0.118635, acc 0.96875, learning_rate 0.000226281\n",
      "2020-12-09T16:38:16.489073: step 2561, loss 0.351553, acc 0.90625, learning_rate 0.000226112\n",
      "2020-12-09T16:38:17.044608: step 2562, loss 0.2714, acc 0.875, learning_rate 0.000225943\n",
      "2020-12-09T16:38:17.588166: step 2563, loss 0.0591964, acc 1, learning_rate 0.000225774\n",
      "2020-12-09T16:38:18.143173: step 2564, loss 0.255528, acc 0.875, learning_rate 0.000225606\n",
      "2020-12-09T16:38:18.688400: step 2565, loss 0.179944, acc 0.9375, learning_rate 0.000225437\n",
      "2020-12-09T16:38:19.294529: step 2566, loss 0.0331074, acc 1, learning_rate 0.000225269\n",
      "2020-12-09T16:38:19.858530: step 2567, loss 0.112891, acc 0.96875, learning_rate 0.000225102\n",
      "2020-12-09T16:38:20.400005: step 2568, loss 0.169842, acc 0.9375, learning_rate 0.000224934\n",
      "2020-12-09T16:38:20.968398: step 2569, loss 0.178328, acc 0.90625, learning_rate 0.000224767\n",
      "2020-12-09T16:38:21.532752: step 2570, loss 0.160259, acc 0.96875, learning_rate 0.000224599\n",
      "2020-12-09T16:38:22.101112: step 2571, loss 0.150826, acc 0.90625, learning_rate 0.000224433\n",
      "2020-12-09T16:38:22.644573: step 2572, loss 0.201032, acc 0.90625, learning_rate 0.000224266\n",
      "2020-12-09T16:38:23.202085: step 2573, loss 0.0492162, acc 1, learning_rate 0.000224099\n",
      "2020-12-09T16:38:23.786443: step 2574, loss 0.320398, acc 0.90625, learning_rate 0.000223933\n",
      "2020-12-09T16:38:24.350509: step 2575, loss 0.131352, acc 0.90625, learning_rate 0.000223767\n",
      "2020-12-09T16:38:24.903591: step 2576, loss 0.0578344, acc 0.96875, learning_rate 0.000223601\n",
      "2020-12-09T16:38:25.490387: step 2577, loss 0.218929, acc 0.9375, learning_rate 0.000223436\n",
      "2020-12-09T16:38:26.069937: step 2578, loss 0.319989, acc 0.90625, learning_rate 0.00022327\n",
      "2020-12-09T16:38:26.615691: step 2579, loss 0.0832183, acc 1, learning_rate 0.000223105\n",
      "2020-12-09T16:38:27.161789: step 2580, loss 0.11142, acc 0.90625, learning_rate 0.00022294\n",
      "2020-12-09T16:38:27.732296: step 2581, loss 0.117661, acc 0.90625, learning_rate 0.000222776\n",
      "2020-12-09T16:38:28.295134: step 2582, loss 0.0890261, acc 0.9375, learning_rate 0.000222611\n",
      "2020-12-09T16:38:28.851138: step 2583, loss 0.105922, acc 0.9375, learning_rate 0.000222447\n",
      "2020-12-09T16:38:29.410930: step 2584, loss 0.0880007, acc 1, learning_rate 0.000222283\n",
      "2020-12-09T16:38:29.997342: step 2585, loss 0.270144, acc 0.875, learning_rate 0.000222119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:38:30.548910: step 2586, loss 0.0741015, acc 0.96875, learning_rate 0.000221956\n",
      "2020-12-09T16:38:31.128910: step 2587, loss 0.0868055, acc 1, learning_rate 0.000221792\n",
      "2020-12-09T16:38:31.690640: step 2588, loss 0.150261, acc 0.96875, learning_rate 0.000221629\n",
      "2020-12-09T16:38:32.242215: step 2589, loss 0.116668, acc 0.9375, learning_rate 0.000221466\n",
      "2020-12-09T16:38:32.806344: step 2590, loss 0.326354, acc 0.90625, learning_rate 0.000221303\n",
      "2020-12-09T16:38:33.385787: step 2591, loss 0.237806, acc 0.90625, learning_rate 0.000221141\n",
      "2020-12-09T16:38:33.938286: step 2592, loss 0.0942015, acc 0.96875, learning_rate 0.000220979\n",
      "2020-12-09T16:38:34.480287: step 2593, loss 0.150904, acc 0.9375, learning_rate 0.000220817\n",
      "2020-12-09T16:38:35.042315: step 2594, loss 0.358031, acc 0.875, learning_rate 0.000220655\n",
      "2020-12-09T16:38:35.605419: step 2595, loss 0.182794, acc 0.9375, learning_rate 0.000220493\n",
      "2020-12-09T16:38:36.177173: step 2596, loss 0.142983, acc 0.96875, learning_rate 0.000220332\n",
      "2020-12-09T16:38:36.722695: step 2597, loss 0.181697, acc 0.90625, learning_rate 0.000220171\n",
      "2020-12-09T16:38:37.283071: step 2598, loss 0.219917, acc 0.90625, learning_rate 0.00022001\n",
      "2020-12-09T16:38:37.819248: step 2599, loss 0.072815, acc 0.96875, learning_rate 0.000219849\n",
      "2020-12-09T16:38:38.389329: step 2600, loss 0.202222, acc 0.90625, learning_rate 0.000219688\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:38:41.601829: step 2600, loss 0.999264, acc 0.713029\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2600\n",
      "\n",
      "2020-12-09T16:38:43.173859: step 2601, loss 0.162278, acc 0.96875, learning_rate 0.000219528\n",
      "2020-12-09T16:38:43.728826: step 2602, loss 0.0673889, acc 0.96875, learning_rate 0.000219368\n",
      "2020-12-09T16:38:44.293857: step 2603, loss 0.106615, acc 0.96875, learning_rate 0.000219208\n",
      "2020-12-09T16:38:44.832392: step 2604, loss 0.11242, acc 0.9375, learning_rate 0.000219048\n",
      "2020-12-09T16:38:45.385930: step 2605, loss 0.225561, acc 0.90625, learning_rate 0.000218889\n",
      "2020-12-09T16:38:45.942514: step 2606, loss 0.106401, acc 0.90625, learning_rate 0.00021873\n",
      "2020-12-09T16:38:46.502079: step 2607, loss 0.165566, acc 0.875, learning_rate 0.00021857\n",
      "2020-12-09T16:38:47.062615: step 2608, loss 0.170202, acc 0.9375, learning_rate 0.000218412\n",
      "2020-12-09T16:38:47.608515: step 2609, loss 0.142907, acc 0.9375, learning_rate 0.000218253\n",
      "2020-12-09T16:38:48.168457: step 2610, loss 0.260781, acc 0.90625, learning_rate 0.000218095\n",
      "2020-12-09T16:38:48.706884: step 2611, loss 0.227286, acc 0.96875, learning_rate 0.000217936\n",
      "2020-12-09T16:38:49.251418: step 2612, loss 0.151669, acc 0.9375, learning_rate 0.000217778\n",
      "2020-12-09T16:38:49.809595: step 2613, loss 0.280321, acc 0.90625, learning_rate 0.000217621\n",
      "2020-12-09T16:38:50.370595: step 2614, loss 0.12733, acc 0.9375, learning_rate 0.000217463\n",
      "2020-12-09T16:38:50.938613: step 2615, loss 0.206983, acc 0.90625, learning_rate 0.000217306\n",
      "2020-12-09T16:38:51.503101: step 2616, loss 0.217099, acc 0.875, learning_rate 0.000217149\n",
      "2020-12-09T16:38:52.048331: step 2617, loss 0.232788, acc 0.9375, learning_rate 0.000216992\n",
      "2020-12-09T16:38:52.614364: step 2618, loss 0.217019, acc 0.9375, learning_rate 0.000216835\n",
      "2020-12-09T16:38:53.158255: step 2619, loss 0.168278, acc 0.9375, learning_rate 0.000216678\n",
      "2020-12-09T16:38:53.710758: step 2620, loss 0.20882, acc 0.90625, learning_rate 0.000216522\n",
      "2020-12-09T16:38:54.254299: step 2621, loss 0.249272, acc 0.78125, learning_rate 0.000216366\n",
      "2020-12-09T16:38:54.799614: step 2622, loss 0.0956032, acc 0.9375, learning_rate 0.00021621\n",
      "2020-12-09T16:38:55.354144: step 2623, loss 0.341872, acc 0.78125, learning_rate 0.000216055\n",
      "2020-12-09T16:38:55.923018: step 2624, loss 0.130267, acc 0.96875, learning_rate 0.000215899\n",
      "2020-12-09T16:38:56.504648: step 2625, loss 0.0695109, acc 0.96875, learning_rate 0.000215744\n",
      "2020-12-09T16:38:57.048611: step 2626, loss 0.262761, acc 0.84375, learning_rate 0.000215589\n",
      "2020-12-09T16:38:57.629501: step 2627, loss 0.206964, acc 0.90625, learning_rate 0.000215434\n",
      "2020-12-09T16:38:58.199861: step 2628, loss 0.177861, acc 0.90625, learning_rate 0.000215279\n",
      "2020-12-09T16:38:58.736107: step 2629, loss 0.157968, acc 0.9375, learning_rate 0.000215125\n",
      "2020-12-09T16:38:59.289607: step 2630, loss 0.226615, acc 0.90625, learning_rate 0.000214971\n",
      "2020-12-09T16:38:59.866889: step 2631, loss 0.137684, acc 0.96875, learning_rate 0.000214817\n",
      "2020-12-09T16:39:00.416588: step 2632, loss 0.43578, acc 0.90625, learning_rate 0.000214663\n",
      "2020-12-09T16:39:00.984107: step 2633, loss 0.12153, acc 0.96875, learning_rate 0.000214509\n",
      "2020-12-09T16:39:01.545970: step 2634, loss 0.350836, acc 0.84375, learning_rate 0.000214356\n",
      "2020-12-09T16:39:02.112180: step 2635, loss 0.250099, acc 0.84375, learning_rate 0.000214203\n",
      "2020-12-09T16:39:02.656642: step 2636, loss 0.199732, acc 0.90625, learning_rate 0.00021405\n",
      "2020-12-09T16:39:03.214059: step 2637, loss 0.233825, acc 0.84375, learning_rate 0.000213897\n",
      "2020-12-09T16:39:03.773665: step 2638, loss 0.13676, acc 0.9375, learning_rate 0.000213744\n",
      "2020-12-09T16:39:04.377694: step 2639, loss 0.259227, acc 0.875, learning_rate 0.000213592\n",
      "2020-12-09T16:39:04.937297: step 2640, loss 0.0887268, acc 0.9375, learning_rate 0.00021344\n",
      "2020-12-09T16:39:05.492834: step 2641, loss 0.131554, acc 0.9375, learning_rate 0.000213288\n",
      "2020-12-09T16:39:06.105379: step 2642, loss 0.191704, acc 0.875, learning_rate 0.000213136\n",
      "2020-12-09T16:39:06.683111: step 2643, loss 0.492688, acc 0.78125, learning_rate 0.000212985\n",
      "2020-12-09T16:39:07.262578: step 2644, loss 0.131102, acc 0.90625, learning_rate 0.000212833\n",
      "2020-12-09T16:39:07.867876: step 2645, loss 0.293194, acc 0.84375, learning_rate 0.000212682\n",
      "2020-12-09T16:39:08.457785: step 2646, loss 0.313546, acc 0.8125, learning_rate 0.000212531\n",
      "2020-12-09T16:39:09.064319: step 2647, loss 0.245095, acc 0.90625, learning_rate 0.00021238\n",
      "2020-12-09T16:39:09.652776: step 2648, loss 0.210578, acc 0.90625, learning_rate 0.00021223\n",
      "2020-12-09T16:39:10.222779: step 2649, loss 0.161149, acc 0.875, learning_rate 0.000212079\n",
      "2020-12-09T16:39:10.785981: step 2650, loss 0.159036, acc 0.90625, learning_rate 0.000211929\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:39:13.233984: step 2650, loss 1.02027, acc 0.708002\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2650\n",
      "\n",
      "2020-12-09T16:39:14.648239: step 2651, loss 0.121994, acc 0.96875, learning_rate 0.000211779\n",
      "2020-12-09T16:39:15.204651: step 2652, loss 0.160753, acc 0.90625, learning_rate 0.00021163\n",
      "2020-12-09T16:39:15.803874: step 2653, loss 0.250847, acc 0.84375, learning_rate 0.00021148\n",
      "2020-12-09T16:39:16.401706: step 2654, loss 0.345431, acc 0.90625, learning_rate 0.000211331\n",
      "2020-12-09T16:39:16.945709: step 2655, loss 0.23019, acc 0.90625, learning_rate 0.000211182\n",
      "2020-12-09T16:39:17.525943: step 2656, loss 0.182299, acc 0.9375, learning_rate 0.000211033\n",
      "2020-12-09T16:39:18.125517: step 2657, loss 0.143069, acc 0.9375, learning_rate 0.000210884\n",
      "2020-12-09T16:39:18.677850: step 2658, loss 0.0955837, acc 0.96875, learning_rate 0.000210735\n",
      "2020-12-09T16:39:19.222316: step 2659, loss 0.301786, acc 0.90625, learning_rate 0.000210587\n",
      "2020-12-09T16:39:19.790818: step 2660, loss 0.0734301, acc 0.96875, learning_rate 0.000210439\n",
      "2020-12-09T16:39:20.356461: step 2661, loss 0.222408, acc 0.875, learning_rate 0.000210291\n",
      "2020-12-09T16:39:20.897455: step 2662, loss 0.168842, acc 0.96875, learning_rate 0.000210143\n",
      "2020-12-09T16:39:21.450695: step 2663, loss 0.484195, acc 0.78125, learning_rate 0.000209996\n",
      "2020-12-09T16:39:22.031762: step 2664, loss 0.0978123, acc 0.96875, learning_rate 0.000209848\n",
      "2020-12-09T16:39:22.600645: step 2665, loss 0.136278, acc 0.96875, learning_rate 0.000209701\n",
      "2020-12-09T16:39:23.148676: step 2666, loss 0.343386, acc 0.875, learning_rate 0.000209554\n",
      "2020-12-09T16:39:23.704981: step 2667, loss 0.326847, acc 0.84375, learning_rate 0.000209408\n",
      "2020-12-09T16:39:24.253015: step 2668, loss 0.185263, acc 0.90625, learning_rate 0.000209261\n",
      "2020-12-09T16:39:24.827978: step 2669, loss 0.186411, acc 0.90625, learning_rate 0.000209115\n",
      "2020-12-09T16:39:25.372938: step 2670, loss 0.204853, acc 0.90625, learning_rate 0.000208968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:39:25.936311: step 2671, loss 0.0729228, acc 1, learning_rate 0.000208823\n",
      "2020-12-09T16:39:26.480506: step 2672, loss 0.290698, acc 0.8125, learning_rate 0.000208677\n",
      "2020-12-09T16:39:27.022002: step 2673, loss 0.298058, acc 0.875, learning_rate 0.000208531\n",
      "2020-12-09T16:39:27.588973: step 2674, loss 0.244854, acc 0.9375, learning_rate 0.000208386\n",
      "2020-12-09T16:39:28.149379: step 2675, loss 0.0722625, acc 1, learning_rate 0.000208241\n",
      "2020-12-09T16:39:28.692814: step 2676, loss 0.0896786, acc 0.96875, learning_rate 0.000208096\n",
      "2020-12-09T16:39:29.237459: step 2677, loss 0.156008, acc 0.9375, learning_rate 0.000207951\n",
      "2020-12-09T16:39:29.789908: step 2678, loss 0.120143, acc 0.90625, learning_rate 0.000207806\n",
      "2020-12-09T16:39:30.343240: step 2679, loss 0.182498, acc 0.90625, learning_rate 0.000207662\n",
      "2020-12-09T16:39:30.907174: step 2680, loss 0.233804, acc 0.9375, learning_rate 0.000207518\n",
      "2020-12-09T16:39:31.474169: step 2681, loss 0.175274, acc 0.90625, learning_rate 0.000207374\n",
      "2020-12-09T16:39:32.041169: step 2682, loss 0.224214, acc 0.9375, learning_rate 0.00020723\n",
      "2020-12-09T16:39:32.576867: step 2683, loss 0.122288, acc 0.9375, learning_rate 0.000207086\n",
      "2020-12-09T16:39:33.120899: step 2684, loss 0.31338, acc 0.90625, learning_rate 0.000206943\n",
      "2020-12-09T16:39:33.679538: step 2685, loss 0.207683, acc 0.875, learning_rate 0.000206799\n",
      "2020-12-09T16:39:34.241538: step 2686, loss 0.385221, acc 0.90625, learning_rate 0.000206656\n",
      "2020-12-09T16:39:34.805266: step 2687, loss 0.169357, acc 0.96875, learning_rate 0.000206513\n",
      "2020-12-09T16:39:35.343266: step 2688, loss 0.162641, acc 0.90625, learning_rate 0.000206371\n",
      "2020-12-09T16:39:35.904763: step 2689, loss 0.24078, acc 0.875, learning_rate 0.000206228\n",
      "2020-12-09T16:39:36.443487: step 2690, loss 0.274757, acc 0.90625, learning_rate 0.000206086\n",
      "2020-12-09T16:39:36.653827: step 2691, loss 0.30601, acc 0.846154, learning_rate 0.000205944\n",
      "2020-12-09T16:39:37.221540: step 2692, loss 0.243978, acc 0.96875, learning_rate 0.000205802\n",
      "2020-12-09T16:39:37.778725: step 2693, loss 0.271073, acc 0.875, learning_rate 0.00020566\n",
      "2020-12-09T16:39:38.345092: step 2694, loss 0.124192, acc 0.9375, learning_rate 0.000205519\n",
      "2020-12-09T16:39:38.896130: step 2695, loss 0.187346, acc 0.90625, learning_rate 0.000205377\n",
      "2020-12-09T16:39:39.450896: step 2696, loss 0.0835001, acc 0.9375, learning_rate 0.000205236\n",
      "2020-12-09T16:39:40.017310: step 2697, loss 0.102136, acc 0.90625, learning_rate 0.000205095\n",
      "2020-12-09T16:39:40.560372: step 2698, loss 0.282855, acc 0.875, learning_rate 0.000204954\n",
      "2020-12-09T16:39:41.104839: step 2699, loss 0.244111, acc 0.90625, learning_rate 0.000204814\n",
      "2020-12-09T16:39:41.662983: step 2700, loss 0.116151, acc 0.9375, learning_rate 0.000204673\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:39:44.029487: step 2700, loss 1.00938, acc 0.70884\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2700\n",
      "\n",
      "2020-12-09T16:39:45.501999: step 2701, loss 0.139723, acc 0.9375, learning_rate 0.000204533\n",
      "2020-12-09T16:39:46.070504: step 2702, loss 0.13416, acc 0.96875, learning_rate 0.000204393\n",
      "2020-12-09T16:39:46.643874: step 2703, loss 0.213619, acc 0.90625, learning_rate 0.000204253\n",
      "2020-12-09T16:39:47.179874: step 2704, loss 0.165322, acc 0.90625, learning_rate 0.000204114\n",
      "2020-12-09T16:39:47.732871: step 2705, loss 0.264566, acc 0.90625, learning_rate 0.000203974\n",
      "2020-12-09T16:39:48.289877: step 2706, loss 0.0882365, acc 0.96875, learning_rate 0.000203835\n",
      "2020-12-09T16:39:48.848526: step 2707, loss 0.268681, acc 0.9375, learning_rate 0.000203696\n",
      "2020-12-09T16:39:49.399452: step 2708, loss 0.259975, acc 0.90625, learning_rate 0.000203557\n",
      "2020-12-09T16:39:49.952640: step 2709, loss 0.163077, acc 0.875, learning_rate 0.000203418\n",
      "2020-12-09T16:39:50.522999: step 2710, loss 0.140669, acc 0.90625, learning_rate 0.00020328\n",
      "2020-12-09T16:39:51.074521: step 2711, loss 0.154016, acc 0.96875, learning_rate 0.000203141\n",
      "2020-12-09T16:39:51.634592: step 2712, loss 0.0981004, acc 0.96875, learning_rate 0.000203003\n",
      "2020-12-09T16:39:52.186271: step 2713, loss 0.151071, acc 0.96875, learning_rate 0.000202865\n",
      "2020-12-09T16:39:52.755495: step 2714, loss 0.149231, acc 0.9375, learning_rate 0.000202727\n",
      "2020-12-09T16:39:53.300458: step 2715, loss 0.125944, acc 0.90625, learning_rate 0.00020259\n",
      "2020-12-09T16:39:53.866992: step 2716, loss 0.0389672, acc 1, learning_rate 0.000202452\n",
      "2020-12-09T16:39:54.402996: step 2717, loss 0.0633757, acc 0.96875, learning_rate 0.000202315\n",
      "2020-12-09T16:39:54.981459: step 2718, loss 0.161859, acc 0.9375, learning_rate 0.000202178\n",
      "2020-12-09T16:39:55.546413: step 2719, loss 0.197609, acc 0.9375, learning_rate 0.000202041\n",
      "2020-12-09T16:39:56.149465: step 2720, loss 0.076414, acc 0.96875, learning_rate 0.000201904\n",
      "2020-12-09T16:39:56.705493: step 2721, loss 0.331756, acc 0.875, learning_rate 0.000201768\n",
      "2020-12-09T16:39:57.237761: step 2722, loss 0.0628895, acc 1, learning_rate 0.000201632\n",
      "2020-12-09T16:39:57.803879: step 2723, loss 0.146965, acc 0.90625, learning_rate 0.000201496\n",
      "2020-12-09T16:39:58.375692: step 2724, loss 0.26352, acc 0.96875, learning_rate 0.00020136\n",
      "2020-12-09T16:39:58.942190: step 2725, loss 0.130589, acc 0.96875, learning_rate 0.000201224\n",
      "2020-12-09T16:39:59.497151: step 2726, loss 0.121411, acc 0.96875, learning_rate 0.000201088\n",
      "2020-12-09T16:40:00.058688: step 2727, loss 0.214269, acc 0.9375, learning_rate 0.000200953\n",
      "2020-12-09T16:40:00.615392: step 2728, loss 0.154475, acc 0.9375, learning_rate 0.000200818\n",
      "2020-12-09T16:40:01.169040: step 2729, loss 0.421857, acc 0.90625, learning_rate 0.000200682\n",
      "2020-12-09T16:40:01.723891: step 2730, loss 0.333626, acc 0.84375, learning_rate 0.000200548\n",
      "2020-12-09T16:40:02.295414: step 2731, loss 0.215206, acc 0.9375, learning_rate 0.000200413\n",
      "2020-12-09T16:40:02.834843: step 2732, loss 0.120992, acc 0.9375, learning_rate 0.000200278\n",
      "2020-12-09T16:40:03.384351: step 2733, loss 0.155446, acc 0.9375, learning_rate 0.000200144\n",
      "2020-12-09T16:40:03.940839: step 2734, loss 0.190978, acc 0.90625, learning_rate 0.00020001\n",
      "2020-12-09T16:40:04.486192: step 2735, loss 0.219156, acc 0.875, learning_rate 0.000199876\n",
      "2020-12-09T16:40:05.049257: step 2736, loss 0.148793, acc 0.9375, learning_rate 0.000199742\n",
      "2020-12-09T16:40:05.595735: step 2737, loss 0.162038, acc 0.90625, learning_rate 0.000199609\n",
      "2020-12-09T16:40:06.173283: step 2738, loss 0.155041, acc 0.96875, learning_rate 0.000199475\n",
      "2020-12-09T16:40:06.741039: step 2739, loss 0.255714, acc 0.9375, learning_rate 0.000199342\n",
      "2020-12-09T16:40:07.285002: step 2740, loss 0.184336, acc 0.90625, learning_rate 0.000199209\n",
      "2020-12-09T16:40:07.853788: step 2741, loss 0.158215, acc 0.9375, learning_rate 0.000199076\n",
      "2020-12-09T16:40:08.414206: step 2742, loss 0.0704975, acc 1, learning_rate 0.000198943\n",
      "2020-12-09T16:40:08.950100: step 2743, loss 0.121227, acc 0.875, learning_rate 0.000198811\n",
      "2020-12-09T16:40:09.489705: step 2744, loss 0.056056, acc 0.96875, learning_rate 0.000198678\n",
      "2020-12-09T16:40:10.050242: step 2745, loss 0.51752, acc 0.875, learning_rate 0.000198546\n",
      "2020-12-09T16:40:10.615234: step 2746, loss 0.101764, acc 0.96875, learning_rate 0.000198414\n",
      "2020-12-09T16:40:11.177724: step 2747, loss 0.162522, acc 0.9375, learning_rate 0.000198282\n",
      "2020-12-09T16:40:11.733717: step 2748, loss 0.280549, acc 0.875, learning_rate 0.000198151\n",
      "2020-12-09T16:40:12.329428: step 2749, loss 0.213461, acc 0.9375, learning_rate 0.000198019\n",
      "2020-12-09T16:40:12.920703: step 2750, loss 0.118665, acc 1, learning_rate 0.000197888\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:40:16.199171: step 2750, loss 0.987956, acc 0.715124\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2750\n",
      "\n",
      "2020-12-09T16:40:17.712295: step 2751, loss 0.109626, acc 0.9375, learning_rate 0.000197757\n",
      "2020-12-09T16:40:18.263878: step 2752, loss 0.15216, acc 0.9375, learning_rate 0.000197626\n",
      "2020-12-09T16:40:18.812982: step 2753, loss 0.198888, acc 0.96875, learning_rate 0.000197495\n",
      "2020-12-09T16:40:19.370482: step 2754, loss 0.222263, acc 0.9375, learning_rate 0.000197364\n",
      "2020-12-09T16:40:19.930752: step 2755, loss 0.0992098, acc 1, learning_rate 0.000197234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:40:20.496092: step 2756, loss 0.0326428, acc 1, learning_rate 0.000197104\n",
      "2020-12-09T16:40:21.042590: step 2757, loss 0.247729, acc 0.875, learning_rate 0.000196974\n",
      "2020-12-09T16:40:21.587127: step 2758, loss 0.206516, acc 0.84375, learning_rate 0.000196844\n",
      "2020-12-09T16:40:22.128008: step 2759, loss 0.231474, acc 0.875, learning_rate 0.000196714\n",
      "2020-12-09T16:40:22.692430: step 2760, loss 0.183869, acc 0.875, learning_rate 0.000196584\n",
      "2020-12-09T16:40:23.251381: step 2761, loss 0.433062, acc 0.8125, learning_rate 0.000196455\n",
      "2020-12-09T16:40:23.797417: step 2762, loss 0.188844, acc 0.9375, learning_rate 0.000196326\n",
      "2020-12-09T16:40:24.364719: step 2763, loss 0.179587, acc 0.875, learning_rate 0.000196197\n",
      "2020-12-09T16:40:24.922714: step 2764, loss 0.365251, acc 0.8125, learning_rate 0.000196068\n",
      "2020-12-09T16:40:25.477682: step 2765, loss 0.0858666, acc 0.96875, learning_rate 0.000195939\n",
      "2020-12-09T16:40:26.034218: step 2766, loss 0.194496, acc 0.96875, learning_rate 0.000195811\n",
      "2020-12-09T16:40:26.570612: step 2767, loss 0.166265, acc 0.9375, learning_rate 0.000195682\n",
      "2020-12-09T16:40:27.112138: step 2768, loss 0.145927, acc 0.96875, learning_rate 0.000195554\n",
      "2020-12-09T16:40:27.657909: step 2769, loss 0.215752, acc 0.875, learning_rate 0.000195426\n",
      "2020-12-09T16:40:28.224789: step 2770, loss 0.146639, acc 0.9375, learning_rate 0.000195298\n",
      "2020-12-09T16:40:28.765828: step 2771, loss 0.149827, acc 0.9375, learning_rate 0.000195171\n",
      "2020-12-09T16:40:29.335268: step 2772, loss 0.248924, acc 0.9375, learning_rate 0.000195043\n",
      "2020-12-09T16:40:29.892095: step 2773, loss 0.170862, acc 0.96875, learning_rate 0.000194916\n",
      "2020-12-09T16:40:30.454849: step 2774, loss 0.155837, acc 0.90625, learning_rate 0.000194789\n",
      "2020-12-09T16:40:31.013349: step 2775, loss 0.299326, acc 0.875, learning_rate 0.000194662\n",
      "2020-12-09T16:40:31.556317: step 2776, loss 0.0849103, acc 0.96875, learning_rate 0.000194535\n",
      "2020-12-09T16:40:32.107120: step 2777, loss 0.210154, acc 0.875, learning_rate 0.000194408\n",
      "2020-12-09T16:40:32.659235: step 2778, loss 0.256711, acc 0.90625, learning_rate 0.000194282\n",
      "2020-12-09T16:40:33.213029: step 2779, loss 0.142842, acc 0.90625, learning_rate 0.000194156\n",
      "2020-12-09T16:40:33.779560: step 2780, loss 0.240205, acc 0.9375, learning_rate 0.00019403\n",
      "2020-12-09T16:40:34.336877: step 2781, loss 0.0804711, acc 0.96875, learning_rate 0.000193904\n",
      "2020-12-09T16:40:34.886587: step 2782, loss 0.1015, acc 0.96875, learning_rate 0.000193778\n",
      "2020-12-09T16:40:35.447327: step 2783, loss 0.180275, acc 0.9375, learning_rate 0.000193652\n",
      "2020-12-09T16:40:36.014329: step 2784, loss 0.220999, acc 0.9375, learning_rate 0.000193527\n",
      "2020-12-09T16:40:36.561051: step 2785, loss 0.187872, acc 0.90625, learning_rate 0.000193401\n",
      "2020-12-09T16:40:37.140605: step 2786, loss 0.0496873, acc 1, learning_rate 0.000193276\n",
      "2020-12-09T16:40:37.690093: step 2787, loss 0.254149, acc 0.875, learning_rate 0.000193151\n",
      "2020-12-09T16:40:38.248412: step 2788, loss 0.144222, acc 0.9375, learning_rate 0.000193027\n",
      "2020-12-09T16:40:38.812268: step 2789, loss 0.0612289, acc 1, learning_rate 0.000192902\n",
      "2020-12-09T16:40:39.375192: step 2790, loss 0.126082, acc 0.96875, learning_rate 0.000192778\n",
      "2020-12-09T16:40:39.931668: step 2791, loss 0.11335, acc 0.96875, learning_rate 0.000192653\n",
      "2020-12-09T16:40:40.480224: step 2792, loss 0.185421, acc 0.9375, learning_rate 0.000192529\n",
      "2020-12-09T16:40:41.046050: step 2793, loss 0.118704, acc 0.9375, learning_rate 0.000192405\n",
      "2020-12-09T16:40:41.585015: step 2794, loss 0.310736, acc 0.78125, learning_rate 0.000192281\n",
      "2020-12-09T16:40:42.147110: step 2795, loss 0.304857, acc 0.9375, learning_rate 0.000192158\n",
      "2020-12-09T16:40:42.702233: step 2796, loss 0.10998, acc 0.96875, learning_rate 0.000192034\n",
      "2020-12-09T16:40:43.268580: step 2797, loss 0.178015, acc 0.90625, learning_rate 0.000191911\n",
      "2020-12-09T16:40:43.837623: step 2798, loss 0.284196, acc 0.8125, learning_rate 0.000191788\n",
      "2020-12-09T16:40:44.414786: step 2799, loss 0.194231, acc 0.90625, learning_rate 0.000191665\n",
      "2020-12-09T16:40:44.955816: step 2800, loss 0.233105, acc 0.90625, learning_rate 0.000191542\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:40:48.040387: step 2800, loss 1.00006, acc 0.713448\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2800\n",
      "\n",
      "2020-12-09T16:40:49.463287: step 2801, loss 0.0966732, acc 0.96875, learning_rate 0.00019142\n",
      "2020-12-09T16:40:50.014842: step 2802, loss 0.108072, acc 0.9375, learning_rate 0.000191297\n",
      "2020-12-09T16:40:50.578631: step 2803, loss 0.164605, acc 0.90625, learning_rate 0.000191175\n",
      "2020-12-09T16:40:51.137491: step 2804, loss 0.109443, acc 0.9375, learning_rate 0.000191053\n",
      "2020-12-09T16:40:51.684642: step 2805, loss 0.198813, acc 0.875, learning_rate 0.000190931\n",
      "2020-12-09T16:40:52.257964: step 2806, loss 0.375106, acc 0.90625, learning_rate 0.000190809\n",
      "2020-12-09T16:40:52.817965: step 2807, loss 0.154159, acc 0.9375, learning_rate 0.000190687\n",
      "2020-12-09T16:40:53.374293: step 2808, loss 0.112951, acc 1, learning_rate 0.000190566\n",
      "2020-12-09T16:40:53.928729: step 2809, loss 0.101343, acc 0.96875, learning_rate 0.000190444\n",
      "2020-12-09T16:40:54.491820: step 2810, loss 0.185866, acc 0.90625, learning_rate 0.000190323\n",
      "2020-12-09T16:40:55.099481: step 2811, loss 0.0861634, acc 0.96875, learning_rate 0.000190202\n",
      "2020-12-09T16:40:55.657449: step 2812, loss 0.0605065, acc 1, learning_rate 0.000190081\n",
      "2020-12-09T16:40:56.219766: step 2813, loss 0.202196, acc 0.90625, learning_rate 0.000189961\n",
      "2020-12-09T16:40:56.775142: step 2814, loss 0.082641, acc 0.96875, learning_rate 0.00018984\n",
      "2020-12-09T16:40:57.326223: step 2815, loss 0.189008, acc 0.9375, learning_rate 0.00018972\n",
      "2020-12-09T16:40:57.875878: step 2816, loss 0.151939, acc 0.9375, learning_rate 0.0001896\n",
      "2020-12-09T16:40:58.430099: step 2817, loss 0.0929946, acc 0.96875, learning_rate 0.00018948\n",
      "2020-12-09T16:40:58.998912: step 2818, loss 0.0910034, acc 1, learning_rate 0.00018936\n",
      "2020-12-09T16:40:59.572633: step 2819, loss 0.123982, acc 0.9375, learning_rate 0.00018924\n",
      "2020-12-09T16:41:00.145663: step 2820, loss 0.125839, acc 0.9375, learning_rate 0.000189121\n",
      "2020-12-09T16:41:00.739468: step 2821, loss 0.0893613, acc 0.9375, learning_rate 0.000189001\n",
      "2020-12-09T16:41:01.313501: step 2822, loss 0.142656, acc 0.9375, learning_rate 0.000188882\n",
      "2020-12-09T16:41:01.853922: step 2823, loss 0.144316, acc 0.9375, learning_rate 0.000188763\n",
      "2020-12-09T16:41:02.425066: step 2824, loss 0.225261, acc 0.875, learning_rate 0.000188644\n",
      "2020-12-09T16:41:02.968240: step 2825, loss 0.292224, acc 0.78125, learning_rate 0.000188525\n",
      "2020-12-09T16:41:03.520812: step 2826, loss 0.335099, acc 0.875, learning_rate 0.000188407\n",
      "2020-12-09T16:41:04.112700: step 2827, loss 0.149513, acc 0.90625, learning_rate 0.000188288\n",
      "2020-12-09T16:41:04.669326: step 2828, loss 0.192868, acc 0.875, learning_rate 0.00018817\n",
      "2020-12-09T16:41:05.255032: step 2829, loss 0.314363, acc 0.875, learning_rate 0.000188052\n",
      "2020-12-09T16:41:05.788725: step 2830, loss 0.0967479, acc 0.96875, learning_rate 0.000187934\n",
      "2020-12-09T16:41:06.363616: step 2831, loss 0.0394272, acc 1, learning_rate 0.000187816\n",
      "2020-12-09T16:41:06.926407: step 2832, loss 0.120538, acc 0.96875, learning_rate 0.000187699\n",
      "2020-12-09T16:41:07.460942: step 2833, loss 0.302366, acc 0.875, learning_rate 0.000187581\n",
      "2020-12-09T16:41:08.003787: step 2834, loss 0.091728, acc 1, learning_rate 0.000187464\n",
      "2020-12-09T16:41:08.556167: step 2835, loss 0.17626, acc 0.9375, learning_rate 0.000187347\n",
      "2020-12-09T16:41:09.103071: step 2836, loss 0.162548, acc 0.9375, learning_rate 0.00018723\n",
      "2020-12-09T16:41:09.666489: step 2837, loss 0.117381, acc 0.96875, learning_rate 0.000187113\n",
      "2020-12-09T16:41:10.217724: step 2838, loss 0.211542, acc 0.90625, learning_rate 0.000186996\n",
      "2020-12-09T16:41:10.821570: step 2839, loss 0.0641565, acc 0.96875, learning_rate 0.000186879\n",
      "2020-12-09T16:41:11.391590: step 2840, loss 0.31504, acc 0.875, learning_rate 0.000186763\n",
      "2020-12-09T16:41:11.935088: step 2841, loss 0.237732, acc 0.90625, learning_rate 0.000186647\n",
      "2020-12-09T16:41:12.515414: step 2842, loss 0.0939945, acc 0.9375, learning_rate 0.000186531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:41:13.084112: step 2843, loss 0.154897, acc 0.96875, learning_rate 0.000186415\n",
      "2020-12-09T16:41:13.632371: step 2844, loss 0.163213, acc 0.96875, learning_rate 0.000186299\n",
      "2020-12-09T16:41:14.202839: step 2845, loss 0.463589, acc 0.78125, learning_rate 0.000186184\n",
      "2020-12-09T16:41:14.758762: step 2846, loss 0.355218, acc 0.90625, learning_rate 0.000186068\n",
      "2020-12-09T16:41:15.363244: step 2847, loss 0.21327, acc 0.90625, learning_rate 0.000185953\n",
      "2020-12-09T16:41:15.914220: step 2848, loss 0.447403, acc 0.90625, learning_rate 0.000185838\n",
      "2020-12-09T16:41:16.479580: step 2849, loss 0.22713, acc 0.9375, learning_rate 0.000185723\n",
      "2020-12-09T16:41:17.049184: step 2850, loss 0.171475, acc 0.90625, learning_rate 0.000185608\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:41:20.288319: step 2850, loss 1.01559, acc 0.712191\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2850\n",
      "\n",
      "2020-12-09T16:41:21.761320: step 2851, loss 0.0573668, acc 0.96875, learning_rate 0.000185493\n",
      "2020-12-09T16:41:22.372819: step 2852, loss 0.106982, acc 0.96875, learning_rate 0.000185379\n",
      "2020-12-09T16:41:22.935190: step 2853, loss 0.269309, acc 0.96875, learning_rate 0.000185264\n",
      "2020-12-09T16:41:23.503685: step 2854, loss 0.0883516, acc 0.9375, learning_rate 0.00018515\n",
      "2020-12-09T16:41:24.062446: step 2855, loss 0.102097, acc 0.9375, learning_rate 0.000185036\n",
      "2020-12-09T16:41:24.648444: step 2856, loss 0.142134, acc 0.96875, learning_rate 0.000184922\n",
      "2020-12-09T16:41:25.218128: step 2857, loss 0.255831, acc 0.90625, learning_rate 0.000184808\n",
      "2020-12-09T16:41:25.781628: step 2858, loss 0.149801, acc 0.90625, learning_rate 0.000184695\n",
      "2020-12-09T16:41:26.360628: step 2859, loss 0.178319, acc 0.9375, learning_rate 0.000184581\n",
      "2020-12-09T16:41:26.918512: step 2860, loss 0.421457, acc 0.8125, learning_rate 0.000184468\n",
      "2020-12-09T16:41:27.473847: step 2861, loss 0.310752, acc 0.8125, learning_rate 0.000184355\n",
      "2020-12-09T16:41:28.022315: step 2862, loss 0.303028, acc 0.8125, learning_rate 0.000184242\n",
      "2020-12-09T16:41:28.574228: step 2863, loss 0.149832, acc 0.9375, learning_rate 0.000184129\n",
      "2020-12-09T16:41:29.153782: step 2864, loss 0.0684545, acc 1, learning_rate 0.000184016\n",
      "2020-12-09T16:41:29.706622: step 2865, loss 0.201713, acc 0.9375, learning_rate 0.000183904\n",
      "2020-12-09T16:41:30.257847: step 2866, loss 0.0979592, acc 0.9375, learning_rate 0.000183791\n",
      "2020-12-09T16:41:30.793065: step 2867, loss 0.321962, acc 0.90625, learning_rate 0.000183679\n",
      "2020-12-09T16:41:31.370779: step 2868, loss 0.115077, acc 0.96875, learning_rate 0.000183567\n",
      "2020-12-09T16:41:31.944287: step 2869, loss 0.0495025, acc 1, learning_rate 0.000183455\n",
      "2020-12-09T16:41:32.508109: step 2870, loss 0.0578368, acc 1, learning_rate 0.000183343\n",
      "2020-12-09T16:41:33.096870: step 2871, loss 0.211215, acc 0.90625, learning_rate 0.000183232\n",
      "2020-12-09T16:41:33.660459: step 2872, loss 0.337913, acc 0.875, learning_rate 0.00018312\n",
      "2020-12-09T16:41:34.221432: step 2873, loss 0.232275, acc 0.90625, learning_rate 0.000183009\n",
      "2020-12-09T16:41:34.772400: step 2874, loss 0.248408, acc 0.90625, learning_rate 0.000182898\n",
      "2020-12-09T16:41:35.330118: step 2875, loss 0.251439, acc 0.9375, learning_rate 0.000182787\n",
      "2020-12-09T16:41:35.898852: step 2876, loss 0.162697, acc 0.90625, learning_rate 0.000182676\n",
      "2020-12-09T16:41:36.459012: step 2877, loss 0.146465, acc 0.90625, learning_rate 0.000182565\n",
      "2020-12-09T16:41:37.024054: step 2878, loss 0.147362, acc 0.9375, learning_rate 0.000182454\n",
      "2020-12-09T16:41:37.584728: step 2879, loss 0.163286, acc 0.9375, learning_rate 0.000182344\n",
      "2020-12-09T16:41:38.137227: step 2880, loss 0.237924, acc 0.90625, learning_rate 0.000182234\n",
      "2020-12-09T16:41:38.686261: step 2881, loss 0.0887461, acc 0.9375, learning_rate 0.000182123\n",
      "2020-12-09T16:41:39.231345: step 2882, loss 0.310822, acc 0.84375, learning_rate 0.000182013\n",
      "2020-12-09T16:41:39.780995: step 2883, loss 0.064748, acc 0.96875, learning_rate 0.000181904\n",
      "2020-12-09T16:41:40.330869: step 2884, loss 0.21845, acc 0.875, learning_rate 0.000181794\n",
      "2020-12-09T16:41:40.881542: step 2885, loss 0.0977029, acc 0.96875, learning_rate 0.000181684\n",
      "2020-12-09T16:41:41.425900: step 2886, loss 0.260142, acc 0.84375, learning_rate 0.000181575\n",
      "2020-12-09T16:41:42.003068: step 2887, loss 0.312855, acc 0.875, learning_rate 0.000181466\n",
      "2020-12-09T16:41:42.571102: step 2888, loss 0.31681, acc 0.875, learning_rate 0.000181356\n",
      "2020-12-09T16:41:43.132775: step 2889, loss 0.108175, acc 1, learning_rate 0.000181247\n",
      "2020-12-09T16:41:43.701103: step 2890, loss 0.0206407, acc 1, learning_rate 0.000181139\n",
      "2020-12-09T16:41:44.235115: step 2891, loss 0.100024, acc 0.9375, learning_rate 0.00018103\n",
      "2020-12-09T16:41:44.795482: step 2892, loss 0.282312, acc 0.875, learning_rate 0.000180921\n",
      "2020-12-09T16:41:45.334851: step 2893, loss 0.124205, acc 0.9375, learning_rate 0.000180813\n",
      "2020-12-09T16:41:45.891351: step 2894, loss 0.185905, acc 0.875, learning_rate 0.000180705\n",
      "2020-12-09T16:41:46.448243: step 2895, loss 0.116353, acc 0.90625, learning_rate 0.000180597\n",
      "2020-12-09T16:41:47.019875: step 2896, loss 0.12143, acc 0.9375, learning_rate 0.000180489\n",
      "2020-12-09T16:41:47.560649: step 2897, loss 0.0743911, acc 0.96875, learning_rate 0.000180381\n",
      "2020-12-09T16:41:48.119052: step 2898, loss 0.0824187, acc 0.96875, learning_rate 0.000180273\n",
      "2020-12-09T16:41:48.668551: step 2899, loss 0.337052, acc 0.8125, learning_rate 0.000180166\n",
      "2020-12-09T16:41:49.258464: step 2900, loss 0.0988181, acc 0.9375, learning_rate 0.000180058\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:41:52.369078: step 2900, loss 1.02957, acc 0.705069\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2900\n",
      "\n",
      "2020-12-09T16:41:53.816458: step 2901, loss 0.147863, acc 0.875, learning_rate 0.000179951\n",
      "2020-12-09T16:41:54.360492: step 2902, loss 0.0997367, acc 0.96875, learning_rate 0.000179844\n",
      "2020-12-09T16:41:54.912493: step 2903, loss 0.156132, acc 0.9375, learning_rate 0.000179737\n",
      "2020-12-09T16:41:55.476492: step 2904, loss 0.304278, acc 0.90625, learning_rate 0.00017963\n",
      "2020-12-09T16:41:56.028295: step 2905, loss 0.0858009, acc 0.9375, learning_rate 0.000179523\n",
      "2020-12-09T16:41:56.570024: step 2906, loss 0.419589, acc 0.84375, learning_rate 0.000179417\n",
      "2020-12-09T16:41:57.123924: step 2907, loss 0.112929, acc 0.96875, learning_rate 0.000179311\n",
      "2020-12-09T16:41:57.684075: step 2908, loss 0.160111, acc 0.90625, learning_rate 0.000179204\n",
      "2020-12-09T16:41:58.223579: step 2909, loss 0.269123, acc 0.9375, learning_rate 0.000179098\n",
      "2020-12-09T16:41:58.771726: step 2910, loss 0.126024, acc 0.9375, learning_rate 0.000178992\n",
      "2020-12-09T16:41:59.339981: step 2911, loss 0.0430573, acc 1, learning_rate 0.000178886\n",
      "2020-12-09T16:41:59.888655: step 2912, loss 0.415227, acc 0.875, learning_rate 0.000178781\n",
      "2020-12-09T16:42:00.435136: step 2913, loss 0.111808, acc 0.90625, learning_rate 0.000178675\n",
      "2020-12-09T16:42:00.987451: step 2914, loss 0.0982083, acc 0.96875, learning_rate 0.00017857\n",
      "2020-12-09T16:42:01.583437: step 2915, loss 0.265497, acc 0.875, learning_rate 0.000178465\n",
      "2020-12-09T16:42:02.142400: step 2916, loss 0.322047, acc 0.9375, learning_rate 0.000178359\n",
      "2020-12-09T16:42:02.700936: step 2917, loss 0.106024, acc 0.9375, learning_rate 0.000178255\n",
      "2020-12-09T16:42:03.269018: step 2918, loss 0.0713364, acc 0.9375, learning_rate 0.00017815\n",
      "2020-12-09T16:42:03.807677: step 2919, loss 0.194155, acc 0.90625, learning_rate 0.000178045\n",
      "2020-12-09T16:42:04.360643: step 2920, loss 0.166326, acc 0.96875, learning_rate 0.00017794\n",
      "2020-12-09T16:42:04.903144: step 2921, loss 0.172022, acc 0.9375, learning_rate 0.000177836\n",
      "2020-12-09T16:42:05.476678: step 2922, loss 0.146321, acc 0.9375, learning_rate 0.000177732\n",
      "2020-12-09T16:42:06.025502: step 2923, loss 0.188174, acc 0.90625, learning_rate 0.000177628\n",
      "2020-12-09T16:42:06.584691: step 2924, loss 0.328139, acc 0.90625, learning_rate 0.000177524\n",
      "2020-12-09T16:42:07.142711: step 2925, loss 0.20728, acc 0.875, learning_rate 0.00017742\n",
      "2020-12-09T16:42:07.698332: step 2926, loss 0.21011, acc 0.90625, learning_rate 0.000177316\n",
      "2020-12-09T16:42:08.258326: step 2927, loss 0.126279, acc 0.9375, learning_rate 0.000177213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:42:08.816466: step 2928, loss 0.113411, acc 0.9375, learning_rate 0.000177109\n",
      "2020-12-09T16:42:09.380503: step 2929, loss 0.334181, acc 0.84375, learning_rate 0.000177006\n",
      "2020-12-09T16:42:09.963925: step 2930, loss 0.327443, acc 0.875, learning_rate 0.000176903\n",
      "2020-12-09T16:42:10.509306: step 2931, loss 0.316267, acc 0.90625, learning_rate 0.0001768\n",
      "2020-12-09T16:42:11.050924: step 2932, loss 0.125715, acc 0.9375, learning_rate 0.000176697\n",
      "2020-12-09T16:42:11.597641: step 2933, loss 0.125028, acc 0.96875, learning_rate 0.000176594\n",
      "2020-12-09T16:42:12.159542: step 2934, loss 0.165859, acc 0.875, learning_rate 0.000176491\n",
      "2020-12-09T16:42:12.711542: step 2935, loss 0.204309, acc 0.96875, learning_rate 0.000176389\n",
      "2020-12-09T16:42:13.281343: step 2936, loss 0.189016, acc 0.84375, learning_rate 0.000176287\n",
      "2020-12-09T16:42:13.859503: step 2937, loss 0.208817, acc 0.90625, learning_rate 0.000176184\n",
      "2020-12-09T16:42:14.406998: step 2938, loss 0.0851074, acc 0.96875, learning_rate 0.000176082\n",
      "2020-12-09T16:42:14.961882: step 2939, loss 0.409701, acc 0.875, learning_rate 0.00017598\n",
      "2020-12-09T16:42:15.519884: step 2940, loss 0.0987835, acc 0.96875, learning_rate 0.000175879\n",
      "2020-12-09T16:42:16.083544: step 2941, loss 0.254984, acc 0.90625, learning_rate 0.000175777\n",
      "2020-12-09T16:42:16.630789: step 2942, loss 0.229061, acc 0.84375, learning_rate 0.000175676\n",
      "2020-12-09T16:42:17.186919: step 2943, loss 0.27404, acc 0.875, learning_rate 0.000175574\n",
      "2020-12-09T16:42:17.724912: step 2944, loss 0.0375031, acc 1, learning_rate 0.000175473\n",
      "2020-12-09T16:42:18.281879: step 2945, loss 0.178062, acc 0.9375, learning_rate 0.000175372\n",
      "2020-12-09T16:42:18.842454: step 2946, loss 0.16378, acc 0.90625, learning_rate 0.000175271\n",
      "2020-12-09T16:42:19.406848: step 2947, loss 0.145757, acc 0.875, learning_rate 0.00017517\n",
      "2020-12-09T16:42:19.965269: step 2948, loss 0.100932, acc 1, learning_rate 0.000175069\n",
      "2020-12-09T16:42:20.510164: step 2949, loss 0.107058, acc 0.96875, learning_rate 0.000174969\n",
      "2020-12-09T16:42:21.075407: step 2950, loss 0.0861891, acc 0.9375, learning_rate 0.000174868\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:42:24.490711: step 2950, loss 1.02848, acc 0.708421\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607548227\\checkpoints\\model-2950\n",
      "\n",
      "2020-12-09T16:42:25.933768: step 2951, loss 0.202376, acc 0.9375, learning_rate 0.000174768\n",
      "2020-12-09T16:42:26.479767: step 2952, loss 0.201536, acc 0.90625, learning_rate 0.000174668\n",
      "2020-12-09T16:42:27.033770: step 2953, loss 0.11084, acc 0.96875, learning_rate 0.000174568\n",
      "2020-12-09T16:42:27.599092: step 2954, loss 0.165922, acc 0.90625, learning_rate 0.000174468\n",
      "2020-12-09T16:42:28.151548: step 2955, loss 0.250263, acc 0.875, learning_rate 0.000174368\n",
      "2020-12-09T16:42:28.704752: step 2956, loss 0.152284, acc 0.9375, learning_rate 0.000174269\n",
      "2020-12-09T16:42:29.263632: step 2957, loss 0.163294, acc 0.90625, learning_rate 0.000174169\n",
      "2020-12-09T16:42:29.839158: step 2958, loss 0.176231, acc 0.90625, learning_rate 0.00017407\n",
      "2020-12-09T16:42:30.400922: step 2959, loss 0.122249, acc 0.9375, learning_rate 0.000173971\n",
      "2020-12-09T16:42:30.971954: step 2960, loss 0.073926, acc 1, learning_rate 0.000173871\n",
      "2020-12-09T16:42:31.548647: step 2961, loss 0.154534, acc 0.9375, learning_rate 0.000173773\n",
      "2020-12-09T16:42:32.132186: step 2962, loss 0.207625, acc 0.90625, learning_rate 0.000173674\n",
      "2020-12-09T16:42:32.697719: step 2963, loss 0.301593, acc 0.84375, learning_rate 0.000173575\n",
      "2020-12-09T16:42:33.253380: step 2964, loss 0.161535, acc 0.9375, learning_rate 0.000173476\n",
      "2020-12-09T16:42:33.813566: step 2965, loss 0.260862, acc 0.90625, learning_rate 0.000173378\n",
      "2020-12-09T16:42:34.372278: step 2966, loss 0.293346, acc 0.90625, learning_rate 0.00017328\n",
      "2020-12-09T16:42:34.961276: step 2967, loss 0.0638899, acc 1, learning_rate 0.000173182\n",
      "2020-12-09T16:42:35.565781: step 2968, loss 0.595747, acc 0.8125, learning_rate 0.000173084\n",
      "2020-12-09T16:42:36.121529: step 2969, loss 0.488986, acc 0.90625, learning_rate 0.000172986\n",
      "2020-12-09T16:42:36.681497: step 2970, loss 0.146757, acc 0.90625, learning_rate 0.000172888\n",
      "2020-12-09T16:42:37.236670: step 2971, loss 0.0613495, acc 1, learning_rate 0.00017279\n",
      "2020-12-09T16:42:37.795658: step 2972, loss 0.350916, acc 0.8125, learning_rate 0.000172693\n",
      "2020-12-09T16:42:38.346218: step 2973, loss 0.164753, acc 0.9375, learning_rate 0.000172595\n",
      "2020-12-09T16:42:38.895000: step 2974, loss 0.108339, acc 0.96875, learning_rate 0.000172498\n",
      "2020-12-09T16:42:39.457661: step 2975, loss 0.0938195, acc 0.96875, learning_rate 0.000172401\n",
      "2020-12-09T16:42:40.006160: step 2976, loss 0.189414, acc 0.90625, learning_rate 0.000172304\n",
      "2020-12-09T16:42:40.553088: step 2977, loss 0.0825546, acc 0.96875, learning_rate 0.000172207\n",
      "2020-12-09T16:42:41.106310: step 2978, loss 0.285703, acc 0.875, learning_rate 0.00017211\n",
      "2020-12-09T16:42:41.678264: step 2979, loss 0.128296, acc 0.96875, learning_rate 0.000172014\n",
      "2020-12-09T16:42:42.224060: step 2980, loss 0.162957, acc 0.96875, learning_rate 0.000171917\n",
      "2020-12-09T16:42:42.768059: step 2981, loss 0.0470216, acc 0.96875, learning_rate 0.000171821\n",
      "2020-12-09T16:42:43.322522: step 2982, loss 0.040134, acc 1, learning_rate 0.000171725\n",
      "2020-12-09T16:42:43.891239: step 2983, loss 0.139234, acc 0.9375, learning_rate 0.000171629\n",
      "2020-12-09T16:42:44.453361: step 2984, loss 0.459728, acc 0.8125, learning_rate 0.000171533\n",
      "2020-12-09T16:42:45.018863: step 2985, loss 0.0795305, acc 1, learning_rate 0.000171437\n",
      "2020-12-09T16:42:45.599349: step 2986, loss 0.223113, acc 0.90625, learning_rate 0.000171341\n",
      "2020-12-09T16:42:46.129826: step 2987, loss 0.238712, acc 0.90625, learning_rate 0.000171246\n",
      "2020-12-09T16:42:46.672329: step 2988, loss 0.172895, acc 0.90625, learning_rate 0.00017115\n",
      "2020-12-09T16:42:47.229320: step 2989, loss 0.209354, acc 0.9375, learning_rate 0.000171055\n",
      "2020-12-09T16:42:47.449762: step 2990, loss 0.035519, acc 1, learning_rate 0.00017096\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# Added to fix error\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# ===========================================================================\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "      allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "      log_device_placement=FLAGS.log_device_placement)\n",
    "\n",
    "    sess = tf.compat.v1.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        cnn = TextCNN(\n",
    "            sequence_length=x_train.shape[1],\n",
    "            num_classes=y_train.shape[1],\n",
    "            vocab_size=len(vocab_processor.vocabulary_),\n",
    "            embedding_size=embedding_dimension,\n",
    "            filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n",
    "            num_filters=FLAGS.num_filters,\n",
    "            l2_reg_lambda=FLAGS.l2_reg_lambda)\n",
    "       \n",
    "        global_step = tf.compat.v1.Variable(0, name=\"global_step\", trainable=False)\n",
    "        # ===========================================================================================\n",
    "        # Optimizers\n",
    "        early_train_op= tf.compat.v1.train.AdamOptimizer(cnn.learning_rate)\n",
    "        # late_train_op = tf.compat.v1.train.MomentumOptimizer(cnn.learning_rate,0.9,use_nesterov=True) \n",
    "        late_train_op = tf.compat.v1.train.RMSPropOptimizer(cnn.learning_rate, decay=0.9, momentum=0.0) \n",
    "        # ===========================================================================================\n",
    "        \n",
    "        grads_and_vars_1 = early_train_op.compute_gradients(cnn.loss)\n",
    "        train_op_1 = early_train_op.apply_gradients(grads_and_vars_1, global_step=global_step)\n",
    "        \n",
    "        grads_and_vars_2 = late_train_op.compute_gradients(cnn.loss)\n",
    "        train_op_2 = late_train_op.apply_gradients(grads_and_vars_2, global_step=global_step)  \n",
    "\n",
    "        # Output directory for models and summaries\n",
    "        timestamp = str(int(time.time()))\n",
    "        out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "        print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "        # Summaries for loss and accuracy\n",
    "        loss_summary = tf.compat.v1.summary.scalar(\"loss\", cnn.loss)\n",
    "        acc_summary = tf.compat.v1.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "\n",
    "        # Train Summaries\n",
    "        train_summary_op = tf.compat.v1.summary.merge([loss_summary, acc_summary])\n",
    "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "        train_summary_writer = tf.compat.v1.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "        # Dev summaries\n",
    "        dev_summary_op = tf.compat.v1.summary.merge([loss_summary, acc_summary])\n",
    "        dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
    "        dev_summary_writer = tf.compat.v1.summary.FileWriter(dev_summary_dir, sess.graph)\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.compat.v1.train.Saver(tf.compat.v1.trainable_variables(), max_to_keep=FLAGS.num_checkpoints)\n",
    "\n",
    "        # Write vocabulary\n",
    "        vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "        # Initialize all variables\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        if FLAGS.enable_word_embeddings and cfg['word_embeddings']['default'] is not None:\n",
    "            vocabulary = vocab_processor.vocabulary_\n",
    "            initW = None\n",
    "            if embedding_name == 'word2vec':\n",
    "                # load embedding vectors from the word2vec\n",
    "                print(\"Load word2vec file {}\".format(cfg['word_embeddings']['word2vec']['path']))\n",
    "                initW = data_helpers.load_embedding_vectors_word2vec(vocabulary,\n",
    "                                                                     cfg['word_embeddings']['word2vec']['path'],\n",
    "                                                                     cfg['word_embeddings']['word2vec']['binary'])\n",
    "                print(\"word2vec file has been loaded\")\n",
    "            elif embedding_name == 'glove':\n",
    "                # load embedding vectors from the glove\n",
    "                print(\"Load glove file {}\".format(cfg['word_embeddings']['glove']['path']))\n",
    "                initW = data_helpers.load_embedding_vectors_glove(vocabulary,\n",
    "                                                                  cfg['word_embeddings']['glove']['path'],\n",
    "                                                                  embedding_dimension)\n",
    "                print(\"glove file has been loaded\\n\")\n",
    "            sess.run(cnn.W.assign(initW))\n",
    "\n",
    "        def train_step(x_batch, y_batch, learning_rate):\n",
    "            \"\"\"\n",
    "            A single training step\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: FLAGS.dropout_keep_prob,                \n",
    "              cnn.learning_rate: learning_rate              \n",
    "            }\n",
    "            \n",
    "            #Conditional optimizer switch\n",
    "            train_op = train_op_1 if tf.compat.v1.train.global_step(sess, global_step) <=(train_input_size/FLAGS.batch_size)*3 else train_op_2\n",
    "                        \n",
    "            _, step, summaries, loss, accuracy = sess.run(                \n",
    "                [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy],                \n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            \n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}, learning_rate {:g}\"\n",
    "                  .format(time_str, step, loss, accuracy, learning_rate))\n",
    "            train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "        def dev_step(x_batch, y_batch, writer=None):\n",
    "            \"\"\"\n",
    "            Evaluates model on a dev set\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: 1.0\n",
    "            }\n",
    "            step, summaries, loss, accuracy = sess.run(\n",
    "                [global_step, dev_summary_op, cnn.loss, cnn.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            if writer:\n",
    "                writer.add_summary(summaries, step)\n",
    "                \n",
    "\n",
    "        train_input_size=len(list(zip(x_train, y_train)))\n",
    "        print('Trainning input set: x_train, y_train',train_input_size)\n",
    "        # Generate batches\n",
    "        batches = data_helpers.batch_iter(\n",
    "            list(zip(x_train, y_train)), FLAGS.batch_size, FLAGS.num_epochs)\n",
    "        \n",
    "        # It uses dynamic learning rate with a high value at the beginning to speed up the training\n",
    "        max_learning_rate = 0.004\n",
    "        min_learning_rate = 0.0001        \n",
    "        decay_speed = FLAGS.decay_coefficient*len(y_train)/FLAGS.batch_size\n",
    "        \n",
    "        # Training loop. For each batch...\n",
    "        counter = 0\n",
    "        print(\"*********Trainable PARAMETERS***********\",np.sum([np.prod(v.get_shape().as_list()) for v in \n",
    "                                                                 tf.compat.v1.trainable_variables()]))\n",
    "        for batch in batches:\n",
    "            learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-counter/decay_speed)\n",
    "            counter += 1\n",
    "            x_batch, y_batch = zip(*batch)      \n",
    "            \n",
    "            if tf.compat.v1.train.global_step(sess, global_step) == ((train_input_size/FLAGS.batch_size)*3)+1: ##(2534*3)+1:\n",
    "                min_learning_rate = 0.0035\n",
    "                \n",
    "            train_step(x_batch, y_batch, learning_rate)\n",
    "            \n",
    "            current_step = tf.compat.v1.train.global_step(sess, global_step)\n",
    "            if current_step % FLAGS.evaluate_every == 0:\n",
    "                print(\"\\nEvaluation:\")\n",
    "                dev_step(x_dev, y_dev, writer=dev_summary_writer)\n",
    "                print(\"\")\n",
    "            if current_step % FLAGS.checkpoint_every == 0:\n",
    "                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# Eval.py\n",
    "# ==========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************YML_PATH C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train/helper/config.yml\n",
      "dataset_name:  tobacco\n",
      "Loading data !\n",
      "*************data_path C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\data/tobacco-data/\n",
      "['0.txt', '6.txt', '8.txt']\n",
      "Total number of test examples: 11936\n",
      "Vocabulary Size: 16099\n",
      "Train/Dev split: 9549/2387\n",
      "size of x_dev, y_dev: 2387 2387\n",
      "\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\preprocessing\\text.py:203: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1356, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1341, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1429, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value batch_normalization_3/moving_variance\n",
      "\t [[{{node batch_normalization_3/moving_variance/read}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"eval_SGD_small.py\", line 146, in <module>\n",
      "    batch_predictions_scores = sess.run([predictions, scores], {input_x: x_dev_batch, dropout_keep_prob: 1.0})\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 950, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1173, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1350, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1370, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value batch_normalization_3/moving_variance\n",
      "\t [[node batch_normalization_3/moving_variance/read (defined at eval_SGD_small.py:122) ]]\n",
      "\n",
      "Original stack trace for 'batch_normalization_3/moving_variance/read':\n",
      "  File \"eval_SGD_small.py\", line 122, in <module>\n",
      "    saver = tf.compat.v1.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1449, in import_meta_graph\n",
      "    **kwargs)[0]\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1473, in _import_meta_graph_with_return_elements\n",
      "    **kwargs))\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 857, in import_scoped_meta_graph_with_return_elements\n",
      "    return_elements=return_elements)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 443, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 236, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3751, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3751, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3641, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python eval_SGD_small.py --eval_train --checkpoint_dir=\"./runs/1607548227/checkpoints/\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
