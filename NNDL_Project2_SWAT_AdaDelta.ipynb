{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jessica Gallo\n",
    "# CSC767 Neural Networks & Deep Learning\n",
    "# Project 2\n",
    "# Part E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the original code with Adadelta\n",
    "# This was run with the original dataset under limited data files:\n",
    "# 0.txt, 6.txt and 8.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from helper import data_helpers\n",
    "from text_cnn.LW_text_cnn import TextCNN\n",
    "from tensorflow.contrib import learn\n",
    "import yaml\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x2a8add79ac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data loading params\n",
    "tf.compat.v1.flags.DEFINE_float(\"dev_sample_percentage\", 0.2, \"Percentage of the training data to use for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x2a8a2acc908>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Hyperparameters\n",
    "tf.compat.v1.flags.DEFINE_boolean(\"enable_word_embeddings\", False, \"Enable/disable the word embedding (default: True)\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"embedding_dim\", 200, \"Dimensionality of character embedding (default: 128)\")\n",
    "tf.compat.v1.flags.DEFINE_string(\"filter_sizes\", \"2,3,5\", \"Comma-separated filter sizes (default: '2,3,5')\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"num_filters\", 128, \"Number of filters per filter size (default: 120)\")\n",
    "tf.compat.v1.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n",
    "tf.compat.v1.flags.DEFINE_float(\"l2_reg_lambda\", 0.0001, \"L2 regularization lambda (default: 0.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x2a8a2acc088>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training parameters\n",
    "tf.compat.v1.flags.DEFINE_integer(\"batch_size\", 32, \"Batch Size (default: 64)\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"num_epochs\",10, \"Number of training epochs (default: 10)\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"evaluate_every\", 50, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"checkpoint_every\", 50, \"Save model after this many steps (default: 100)\")\n",
    "tf.compat.v1.flags.DEFINE_integer(\"num_checkpoints\", 5, \"Number of checkpoints to store (default: 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x2a8ae8506c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Misc Parameters\n",
    "tf.compat.v1.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.compat.v1.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "tf.compat.v1.flags.DEFINE_float(\"decay_coefficient\", 2.5, \"Decay coefficient (default: 2.5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.compat.v1.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************YML_PATH C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train/helper/config.yml\n"
     ]
    }
   ],
   "source": [
    "YML_PATH = os.path.join(ROOT_DIR, \"train/helper/config.yml\")\n",
    "print(\"***********************YML_PATH\", YML_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(YML_PATH, 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# added this because of 'Unrecognizable flag error: Unknown command line flag f'\n",
    "tf.compat.v1.flags.DEFINE_string('f','','')\n",
    "# ===================================================================================\n",
    "\n",
    "dataset_name = cfg[\"datasets\"][\"default\"]\n",
    "if FLAGS.enable_word_embeddings and cfg['word_embeddings']['default'] is not None:\n",
    "    embedding_name = cfg['word_embeddings']['default']\n",
    "    embedding_dimension = cfg['word_embeddings'][embedding_name]['dimension']\n",
    "else:\n",
    "    embedding_dimension = FLAGS.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "*************data_path C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\data/tobacco-data/\n",
      "['0.txt', '6.txt', '8.txt']\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "# ==================================================\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "datasets = None\n",
    "if dataset_name == \"tobacco\":\n",
    "    data_path = os.path.join(ROOT_DIR, cfg[\"datasets\"][dataset_name]['parent_dir'] +'/')\n",
    "    print(\"*************data_path\", data_path)    \n",
    "    datasets = data_helpers.get_datasets_tobacco(data_path)\n",
    "\n",
    "elif dataset_name == \"localdata\":\n",
    "    datasets = data_helpers.get_datasets_localdata(container_path=cfg[\"datasets\"][dataset_name][\"container_path\"],\n",
    "                                                     categories=cfg[\"datasets\"][dataset_name][\"categories\"],\n",
    "                                                     shuffle=cfg[\"datasets\"][dataset_name][\"shuffle\"],\n",
    "                                                     random_state=cfg[\"datasets\"][dataset_name][\"random_state\"])\n",
    "\n",
    "x_text, y = data_helpers.load_data_labels(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-59011e463631>:3: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\preprocessing\\text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\preprocessing\\text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "Vocabulary Size: 16099\n",
      "Train/Dev split: 9549/2387\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text)))\n",
    "\n",
    "# Randomly shuffle data\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "# Split train/test set\n",
    "# TODO: This is very crude, should use cross-validation\n",
    "dev_sample_index = -1 * int(FLAGS.dev_sample_percentage * float(len(y)))\n",
    "x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\text_cnn\\LW_text_cnn.py:40: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "(?, 41, 1, 1)\n",
      "(?, 40, 1, 1)\n",
      "(?, 42, 200, 1)\n",
      "(?, 40, 1, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\text_cnn\\LW_text_cnn.py:125: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Writing to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\n",
      "\n",
      "Trainning input set: x_train, y_train 9549\n",
      "*********Trainable PARAMETERS*********** 3224697\n",
      "2020-12-09T16:49:04.503350: step 1, loss 1.29593, acc 0.3125, learning_rate 0.004\n",
      "2020-12-09T16:49:05.143320: step 2, loss 1.10861, acc 0.375, learning_rate 0.00399478\n",
      "2020-12-09T16:49:05.743782: step 3, loss 1.08022, acc 0.59375, learning_rate 0.00398956\n",
      "2020-12-09T16:49:06.347282: step 4, loss 1.46448, acc 0.375, learning_rate 0.00398435\n",
      "2020-12-09T16:49:06.959282: step 5, loss 1.06581, acc 0.4375, learning_rate 0.00397914\n",
      "2020-12-09T16:49:07.557483: step 6, loss 1.26299, acc 0.34375, learning_rate 0.00397395\n",
      "2020-12-09T16:49:08.141804: step 7, loss 1.13561, acc 0.40625, learning_rate 0.00396876\n",
      "2020-12-09T16:49:08.753248: step 8, loss 1.04226, acc 0.34375, learning_rate 0.00396358\n",
      "2020-12-09T16:49:09.352219: step 9, loss 1.12532, acc 0.375, learning_rate 0.0039584\n",
      "2020-12-09T16:49:09.958446: step 10, loss 1.24755, acc 0.3125, learning_rate 0.00395323\n",
      "2020-12-09T16:49:10.538326: step 11, loss 1.14014, acc 0.4375, learning_rate 0.00394807\n",
      "2020-12-09T16:49:11.108847: step 12, loss 1.15611, acc 0.40625, learning_rate 0.00394292\n",
      "2020-12-09T16:49:11.692303: step 13, loss 1.10399, acc 0.375, learning_rate 0.00393777\n",
      "2020-12-09T16:49:12.403768: step 14, loss 0.899468, acc 0.625, learning_rate 0.00393263\n",
      "2020-12-09T16:49:13.058202: step 15, loss 1.15451, acc 0.375, learning_rate 0.00392749\n",
      "2020-12-09T16:49:13.648739: step 16, loss 1.06071, acc 0.46875, learning_rate 0.00392237\n",
      "2020-12-09T16:49:14.240240: step 17, loss 1.12339, acc 0.40625, learning_rate 0.00391725\n",
      "2020-12-09T16:49:14.855209: step 18, loss 0.966519, acc 0.53125, learning_rate 0.00391213\n",
      "2020-12-09T16:49:15.469587: step 19, loss 1.12304, acc 0.375, learning_rate 0.00390703\n",
      "2020-12-09T16:49:16.085681: step 20, loss 1.14279, acc 0.34375, learning_rate 0.00390193\n",
      "2020-12-09T16:49:16.650141: step 21, loss 0.983409, acc 0.4375, learning_rate 0.00389683\n",
      "2020-12-09T16:49:17.236176: step 22, loss 1.16708, acc 0.40625, learning_rate 0.00389175\n",
      "2020-12-09T16:49:17.820947: step 23, loss 0.990885, acc 0.53125, learning_rate 0.00388667\n",
      "2020-12-09T16:49:18.436407: step 24, loss 1.19238, acc 0.25, learning_rate 0.0038816\n",
      "2020-12-09T16:49:19.023204: step 25, loss 0.946202, acc 0.5625, learning_rate 0.00387653\n",
      "2020-12-09T16:49:19.632637: step 26, loss 0.992056, acc 0.53125, learning_rate 0.00387147\n",
      "2020-12-09T16:49:20.223606: step 27, loss 1.07761, acc 0.3125, learning_rate 0.00386642\n",
      "2020-12-09T16:49:20.844050: step 28, loss 0.987679, acc 0.53125, learning_rate 0.00386137\n",
      "2020-12-09T16:49:21.433508: step 29, loss 1.05035, acc 0.46875, learning_rate 0.00385634\n",
      "2020-12-09T16:49:22.039908: step 30, loss 0.973348, acc 0.5, learning_rate 0.0038513\n",
      "2020-12-09T16:49:22.627411: step 31, loss 0.948219, acc 0.5, learning_rate 0.00384628\n",
      "2020-12-09T16:49:23.208941: step 32, loss 0.810903, acc 0.71875, learning_rate 0.00384126\n",
      "2020-12-09T16:49:23.801809: step 33, loss 0.92083, acc 0.59375, learning_rate 0.00383625\n",
      "2020-12-09T16:49:24.373710: step 34, loss 1.16314, acc 0.4375, learning_rate 0.00383124\n",
      "2020-12-09T16:49:24.942840: step 35, loss 1.09645, acc 0.375, learning_rate 0.00382625\n",
      "2020-12-09T16:49:25.545084: step 36, loss 1.13778, acc 0.3125, learning_rate 0.00382125\n",
      "2020-12-09T16:49:26.109713: step 37, loss 0.859254, acc 0.59375, learning_rate 0.00381627\n",
      "2020-12-09T16:49:26.669889: step 38, loss 0.866918, acc 0.53125, learning_rate 0.00381129\n",
      "2020-12-09T16:49:27.254493: step 39, loss 1.01978, acc 0.46875, learning_rate 0.00380632\n",
      "2020-12-09T16:49:27.855134: step 40, loss 0.952202, acc 0.59375, learning_rate 0.00380135\n",
      "2020-12-09T16:49:28.433388: step 41, loss 1.08756, acc 0.4375, learning_rate 0.0037964\n",
      "2020-12-09T16:49:29.037390: step 42, loss 1.03309, acc 0.59375, learning_rate 0.00379144\n",
      "2020-12-09T16:49:29.618772: step 43, loss 1.01712, acc 0.5625, learning_rate 0.0037865\n",
      "2020-12-09T16:49:30.221656: step 44, loss 0.980341, acc 0.4375, learning_rate 0.00378156\n",
      "2020-12-09T16:49:30.801150: step 45, loss 0.856894, acc 0.5625, learning_rate 0.00377663\n",
      "2020-12-09T16:49:31.393236: step 46, loss 0.952021, acc 0.5, learning_rate 0.0037717\n",
      "2020-12-09T16:49:31.991202: step 47, loss 0.937727, acc 0.625, learning_rate 0.00376679\n",
      "2020-12-09T16:49:32.586329: step 48, loss 1.02645, acc 0.53125, learning_rate 0.00376187\n",
      "2020-12-09T16:49:33.178830: step 49, loss 0.971503, acc 0.4375, learning_rate 0.00375697\n",
      "2020-12-09T16:49:33.755989: step 50, loss 1.00521, acc 0.53125, learning_rate 0.00375207\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:49:36.996195: step 50, loss 0.87477, acc 0.562212\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-50\n",
      "\n",
      "2020-12-09T16:49:38.595277: step 51, loss 0.983202, acc 0.53125, learning_rate 0.00374718\n",
      "2020-12-09T16:49:39.175308: step 52, loss 0.757291, acc 0.59375, learning_rate 0.00374229\n",
      "2020-12-09T16:49:39.757016: step 53, loss 0.95686, acc 0.5, learning_rate 0.00373741\n",
      "2020-12-09T16:49:40.344200: step 54, loss 0.843284, acc 0.5625, learning_rate 0.00373254\n",
      "2020-12-09T16:49:40.905350: step 55, loss 0.967533, acc 0.53125, learning_rate 0.00372768\n",
      "2020-12-09T16:49:41.478711: step 56, loss 0.880882, acc 0.59375, learning_rate 0.00372282\n",
      "2020-12-09T16:49:42.082265: step 57, loss 0.94931, acc 0.46875, learning_rate 0.00371796\n",
      "2020-12-09T16:49:42.654734: step 58, loss 0.625325, acc 0.75, learning_rate 0.00371312\n",
      "2020-12-09T16:49:43.241211: step 59, loss 0.807488, acc 0.5625, learning_rate 0.00370828\n",
      "2020-12-09T16:49:43.806260: step 60, loss 1.0263, acc 0.53125, learning_rate 0.00370344\n",
      "2020-12-09T16:49:44.384821: step 61, loss 0.797943, acc 0.59375, learning_rate 0.00369862\n",
      "2020-12-09T16:49:44.959159: step 62, loss 0.763598, acc 0.6875, learning_rate 0.0036938\n",
      "2020-12-09T16:49:45.537342: step 63, loss 0.673269, acc 0.75, learning_rate 0.00368898\n",
      "2020-12-09T16:49:46.121333: step 64, loss 0.777859, acc 0.625, learning_rate 0.00368417\n",
      "2020-12-09T16:49:46.717301: step 65, loss 0.974058, acc 0.5, learning_rate 0.00367937\n",
      "2020-12-09T16:49:47.300955: step 66, loss 0.797429, acc 0.625, learning_rate 0.00367458\n",
      "2020-12-09T16:49:47.906716: step 67, loss 0.828243, acc 0.5, learning_rate 0.00366979\n",
      "2020-12-09T16:49:48.495758: step 68, loss 0.781338, acc 0.5625, learning_rate 0.00366501\n",
      "2020-12-09T16:49:49.067858: step 69, loss 0.768568, acc 0.6875, learning_rate 0.00366023\n",
      "2020-12-09T16:49:49.660118: step 70, loss 0.904932, acc 0.65625, learning_rate 0.00365546\n",
      "2020-12-09T16:49:50.251115: step 71, loss 0.93582, acc 0.59375, learning_rate 0.0036507\n",
      "2020-12-09T16:49:50.823941: step 72, loss 0.813292, acc 0.65625, learning_rate 0.00364594\n",
      "2020-12-09T16:49:51.397937: step 73, loss 0.888665, acc 0.65625, learning_rate 0.00364119\n",
      "2020-12-09T16:49:51.998438: step 74, loss 0.803853, acc 0.625, learning_rate 0.00363645\n",
      "2020-12-09T16:49:52.622749: step 75, loss 0.870637, acc 0.59375, learning_rate 0.00363171\n",
      "2020-12-09T16:49:53.200296: step 76, loss 0.806563, acc 0.6875, learning_rate 0.00362698\n",
      "2020-12-09T16:49:53.833952: step 77, loss 0.743495, acc 0.65625, learning_rate 0.00362226\n",
      "2020-12-09T16:49:54.415870: step 78, loss 0.863575, acc 0.59375, learning_rate 0.00361754\n",
      "2020-12-09T16:49:55.005172: step 79, loss 0.790527, acc 0.5625, learning_rate 0.00361283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:49:55.581416: step 80, loss 0.875997, acc 0.59375, learning_rate 0.00360812\n",
      "2020-12-09T16:49:56.155390: step 81, loss 0.812456, acc 0.53125, learning_rate 0.00360342\n",
      "2020-12-09T16:49:56.737889: step 82, loss 1.12217, acc 0.59375, learning_rate 0.00359873\n",
      "2020-12-09T16:49:57.337164: step 83, loss 0.93291, acc 0.4375, learning_rate 0.00359404\n",
      "2020-12-09T16:49:57.932203: step 84, loss 0.939182, acc 0.5, learning_rate 0.00358936\n",
      "2020-12-09T16:49:58.521288: step 85, loss 0.844904, acc 0.53125, learning_rate 0.00358469\n",
      "2020-12-09T16:49:59.103100: step 86, loss 0.750121, acc 0.59375, learning_rate 0.00358002\n",
      "2020-12-09T16:49:59.679135: step 87, loss 0.744339, acc 0.65625, learning_rate 0.00357536\n",
      "2020-12-09T16:50:00.262602: step 88, loss 0.678971, acc 0.78125, learning_rate 0.0035707\n",
      "2020-12-09T16:50:00.832598: step 89, loss 0.840856, acc 0.59375, learning_rate 0.00356605\n",
      "2020-12-09T16:50:01.392658: step 90, loss 0.59986, acc 0.75, learning_rate 0.00356141\n",
      "2020-12-09T16:50:01.949983: step 91, loss 0.661091, acc 0.6875, learning_rate 0.00355677\n",
      "2020-12-09T16:50:02.539308: step 92, loss 0.837684, acc 0.53125, learning_rate 0.00355214\n",
      "2020-12-09T16:50:03.125908: step 93, loss 0.920094, acc 0.5, learning_rate 0.00354752\n",
      "2020-12-09T16:50:03.708944: step 94, loss 0.980529, acc 0.59375, learning_rate 0.0035429\n",
      "2020-12-09T16:50:04.309016: step 95, loss 0.730703, acc 0.71875, learning_rate 0.00353829\n",
      "2020-12-09T16:50:04.897482: step 96, loss 0.770223, acc 0.65625, learning_rate 0.00353368\n",
      "2020-12-09T16:50:05.465356: step 97, loss 0.721461, acc 0.6875, learning_rate 0.00352908\n",
      "2020-12-09T16:50:06.045339: step 98, loss 0.731475, acc 0.71875, learning_rate 0.00352449\n",
      "2020-12-09T16:50:06.631323: step 99, loss 0.64497, acc 0.75, learning_rate 0.0035199\n",
      "2020-12-09T16:50:07.213302: step 100, loss 0.829334, acc 0.65625, learning_rate 0.00351532\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:50:10.577053: step 100, loss 0.773839, acc 0.651445\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-100\n",
      "\n",
      "2020-12-09T16:50:12.030988: step 101, loss 0.769457, acc 0.625, learning_rate 0.00351075\n",
      "2020-12-09T16:50:12.615448: step 102, loss 0.733676, acc 0.75, learning_rate 0.00350618\n",
      "2020-12-09T16:50:13.194231: step 103, loss 0.634918, acc 0.6875, learning_rate 0.00350161\n",
      "2020-12-09T16:50:13.793936: step 104, loss 0.664422, acc 0.6875, learning_rate 0.00349706\n",
      "2020-12-09T16:50:14.391937: step 105, loss 1.14095, acc 0.53125, learning_rate 0.00349251\n",
      "2020-12-09T16:50:15.014933: step 106, loss 0.926608, acc 0.5625, learning_rate 0.00348796\n",
      "2020-12-09T16:50:15.658935: step 107, loss 0.842272, acc 0.59375, learning_rate 0.00348342\n",
      "2020-12-09T16:50:16.244973: step 108, loss 0.823408, acc 0.5625, learning_rate 0.00347889\n",
      "2020-12-09T16:50:16.821935: step 109, loss 0.622161, acc 0.6875, learning_rate 0.00347437\n",
      "2020-12-09T16:50:17.410458: step 110, loss 0.699335, acc 0.625, learning_rate 0.00346985\n",
      "2020-12-09T16:50:17.990706: step 111, loss 0.592919, acc 0.71875, learning_rate 0.00346533\n",
      "2020-12-09T16:50:18.580209: step 112, loss 0.698335, acc 0.75, learning_rate 0.00346082\n",
      "2020-12-09T16:50:19.157246: step 113, loss 0.859097, acc 0.59375, learning_rate 0.00345632\n",
      "2020-12-09T16:50:19.742750: step 114, loss 0.82929, acc 0.53125, learning_rate 0.00345183\n",
      "2020-12-09T16:50:20.322756: step 115, loss 0.883719, acc 0.59375, learning_rate 0.00344734\n",
      "2020-12-09T16:50:20.906314: step 116, loss 0.737484, acc 0.71875, learning_rate 0.00344285\n",
      "2020-12-09T16:50:21.474781: step 117, loss 0.844514, acc 0.65625, learning_rate 0.00343837\n",
      "2020-12-09T16:50:22.078814: step 118, loss 0.792043, acc 0.59375, learning_rate 0.0034339\n",
      "2020-12-09T16:50:22.672936: step 119, loss 0.671706, acc 0.6875, learning_rate 0.00342944\n",
      "2020-12-09T16:50:23.237109: step 120, loss 0.929871, acc 0.65625, learning_rate 0.00342498\n",
      "2020-12-09T16:50:23.814685: step 121, loss 0.637744, acc 0.78125, learning_rate 0.00342052\n",
      "2020-12-09T16:50:24.402692: step 122, loss 0.869088, acc 0.65625, learning_rate 0.00341607\n",
      "2020-12-09T16:50:24.999092: step 123, loss 0.710558, acc 0.65625, learning_rate 0.00341163\n",
      "2020-12-09T16:50:25.587092: step 124, loss 0.814425, acc 0.59375, learning_rate 0.0034072\n",
      "2020-12-09T16:50:26.184318: step 125, loss 0.890036, acc 0.5, learning_rate 0.00340277\n",
      "2020-12-09T16:50:26.755015: step 126, loss 0.901329, acc 0.53125, learning_rate 0.00339834\n",
      "2020-12-09T16:50:27.329977: step 127, loss 0.718351, acc 0.6875, learning_rate 0.00339392\n",
      "2020-12-09T16:50:27.912636: step 128, loss 0.761633, acc 0.59375, learning_rate 0.00338951\n",
      "2020-12-09T16:50:28.481619: step 129, loss 0.979388, acc 0.5625, learning_rate 0.0033851\n",
      "2020-12-09T16:50:29.051100: step 130, loss 0.80773, acc 0.71875, learning_rate 0.0033807\n",
      "2020-12-09T16:50:29.621134: step 131, loss 0.882662, acc 0.5625, learning_rate 0.00337631\n",
      "2020-12-09T16:50:30.235348: step 132, loss 0.81553, acc 0.59375, learning_rate 0.00337192\n",
      "2020-12-09T16:50:30.813019: step 133, loss 0.673042, acc 0.78125, learning_rate 0.00336754\n",
      "2020-12-09T16:50:31.378521: step 134, loss 0.71592, acc 0.59375, learning_rate 0.00336316\n",
      "2020-12-09T16:50:31.985054: step 135, loss 0.667435, acc 0.75, learning_rate 0.00335879\n",
      "2020-12-09T16:50:32.585507: step 136, loss 0.810764, acc 0.625, learning_rate 0.00335442\n",
      "2020-12-09T16:50:33.160543: step 137, loss 0.626893, acc 0.6875, learning_rate 0.00335006\n",
      "2020-12-09T16:50:33.728838: step 138, loss 0.814355, acc 0.6875, learning_rate 0.00334571\n",
      "2020-12-09T16:50:34.334050: step 139, loss 0.592536, acc 0.71875, learning_rate 0.00334136\n",
      "2020-12-09T16:50:34.929597: step 140, loss 0.744214, acc 0.6875, learning_rate 0.00333702\n",
      "2020-12-09T16:50:35.504543: step 141, loss 0.655472, acc 0.71875, learning_rate 0.00333268\n",
      "2020-12-09T16:50:36.129541: step 142, loss 0.644062, acc 0.75, learning_rate 0.00332835\n",
      "2020-12-09T16:50:36.724245: step 143, loss 0.717601, acc 0.625, learning_rate 0.00332403\n",
      "2020-12-09T16:50:37.289812: step 144, loss 0.546581, acc 0.75, learning_rate 0.00331971\n",
      "2020-12-09T16:50:37.873276: step 145, loss 0.801393, acc 0.59375, learning_rate 0.0033154\n",
      "2020-12-09T16:50:38.480177: step 146, loss 0.721968, acc 0.65625, learning_rate 0.00331109\n",
      "2020-12-09T16:50:39.082683: step 147, loss 0.512336, acc 0.71875, learning_rate 0.00330679\n",
      "2020-12-09T16:50:39.656648: step 148, loss 0.701795, acc 0.65625, learning_rate 0.00330249\n",
      "2020-12-09T16:50:40.246969: step 149, loss 0.791818, acc 0.6875, learning_rate 0.0032982\n",
      "2020-12-09T16:50:40.841698: step 150, loss 0.740631, acc 0.59375, learning_rate 0.00329392\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:50:43.953289: step 150, loss 0.708546, acc 0.671554\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-150\n",
      "\n",
      "2020-12-09T16:50:45.395153: step 151, loss 0.572759, acc 0.78125, learning_rate 0.00328964\n",
      "2020-12-09T16:50:45.971668: step 152, loss 0.464164, acc 0.8125, learning_rate 0.00328537\n",
      "2020-12-09T16:50:46.554189: step 153, loss 0.911622, acc 0.5, learning_rate 0.0032811\n",
      "2020-12-09T16:50:47.134288: step 154, loss 0.720236, acc 0.65625, learning_rate 0.00327684\n",
      "2020-12-09T16:50:47.730268: step 155, loss 0.570563, acc 0.71875, learning_rate 0.00327258\n",
      "2020-12-09T16:50:48.320708: step 156, loss 0.630454, acc 0.71875, learning_rate 0.00326833\n",
      "2020-12-09T16:50:48.912072: step 157, loss 0.622416, acc 0.71875, learning_rate 0.00326409\n",
      "2020-12-09T16:50:49.486530: step 158, loss 0.4701, acc 0.8125, learning_rate 0.00325985\n",
      "2020-12-09T16:50:50.059587: step 159, loss 0.690475, acc 0.71875, learning_rate 0.00325562\n",
      "2020-12-09T16:50:50.649599: step 160, loss 0.696445, acc 0.78125, learning_rate 0.00325139\n",
      "2020-12-09T16:50:51.229579: step 161, loss 0.690876, acc 0.71875, learning_rate 0.00324717\n",
      "2020-12-09T16:50:51.826572: step 162, loss 0.797019, acc 0.71875, learning_rate 0.00324295\n",
      "2020-12-09T16:50:52.423597: step 163, loss 0.48313, acc 0.8125, learning_rate 0.00323874\n",
      "2020-12-09T16:50:53.011851: step 164, loss 0.951844, acc 0.5625, learning_rate 0.00323454\n",
      "2020-12-09T16:50:53.594946: step 165, loss 0.619043, acc 0.65625, learning_rate 0.00323034\n",
      "2020-12-09T16:50:54.194031: step 166, loss 0.580065, acc 0.78125, learning_rate 0.00322615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:50:54.761923: step 167, loss 0.753398, acc 0.65625, learning_rate 0.00322196\n",
      "2020-12-09T16:50:55.342423: step 168, loss 0.703597, acc 0.6875, learning_rate 0.00321778\n",
      "2020-12-09T16:50:55.914316: step 169, loss 0.65576, acc 0.75, learning_rate 0.0032136\n",
      "2020-12-09T16:50:56.480807: step 170, loss 0.675519, acc 0.71875, learning_rate 0.00320943\n",
      "2020-12-09T16:50:57.073723: step 171, loss 0.802467, acc 0.59375, learning_rate 0.00320527\n",
      "2020-12-09T16:50:57.644226: step 172, loss 0.764075, acc 0.75, learning_rate 0.00320111\n",
      "2020-12-09T16:50:58.282137: step 173, loss 0.569573, acc 0.8125, learning_rate 0.00319695\n",
      "2020-12-09T16:50:58.862709: step 174, loss 0.658978, acc 0.65625, learning_rate 0.0031928\n",
      "2020-12-09T16:50:59.434287: step 175, loss 0.672293, acc 0.6875, learning_rate 0.00318866\n",
      "2020-12-09T16:51:00.013785: step 176, loss 0.541843, acc 0.78125, learning_rate 0.00318452\n",
      "2020-12-09T16:51:00.598993: step 177, loss 0.83123, acc 0.625, learning_rate 0.00318039\n",
      "2020-12-09T16:51:01.180948: step 178, loss 0.724619, acc 0.625, learning_rate 0.00317626\n",
      "2020-12-09T16:51:01.749445: step 179, loss 0.609345, acc 0.71875, learning_rate 0.00317214\n",
      "2020-12-09T16:51:02.342663: step 180, loss 0.534365, acc 0.8125, learning_rate 0.00316803\n",
      "2020-12-09T16:51:02.973139: step 181, loss 0.560508, acc 0.8125, learning_rate 0.00316392\n",
      "2020-12-09T16:51:03.553365: step 182, loss 0.656359, acc 0.71875, learning_rate 0.00315981\n",
      "2020-12-09T16:51:04.129088: step 183, loss 0.546123, acc 0.71875, learning_rate 0.00315572\n",
      "2020-12-09T16:51:04.712314: step 184, loss 0.714164, acc 0.625, learning_rate 0.00315162\n",
      "2020-12-09T16:51:05.321385: step 185, loss 0.668817, acc 0.78125, learning_rate 0.00314753\n",
      "2020-12-09T16:51:05.900022: step 186, loss 0.889858, acc 0.65625, learning_rate 0.00314345\n",
      "2020-12-09T16:51:06.487764: step 187, loss 0.835087, acc 0.71875, learning_rate 0.00313938\n",
      "2020-12-09T16:51:07.080575: step 188, loss 0.689565, acc 0.71875, learning_rate 0.0031353\n",
      "2020-12-09T16:51:07.671075: step 189, loss 0.787411, acc 0.78125, learning_rate 0.00313124\n",
      "2020-12-09T16:51:08.242756: step 190, loss 0.911496, acc 0.5625, learning_rate 0.00312718\n",
      "2020-12-09T16:51:08.840204: step 191, loss 0.534528, acc 0.84375, learning_rate 0.00312312\n",
      "2020-12-09T16:51:09.433704: step 192, loss 0.538012, acc 0.78125, learning_rate 0.00311907\n",
      "2020-12-09T16:51:10.001453: step 193, loss 0.819334, acc 0.5625, learning_rate 0.00311503\n",
      "2020-12-09T16:51:10.601915: step 194, loss 0.601297, acc 0.75, learning_rate 0.00311099\n",
      "2020-12-09T16:51:11.209354: step 195, loss 0.493432, acc 0.71875, learning_rate 0.00310696\n",
      "2020-12-09T16:51:11.775319: step 196, loss 0.526952, acc 0.78125, learning_rate 0.00310293\n",
      "2020-12-09T16:51:12.362782: step 197, loss 0.625615, acc 0.75, learning_rate 0.00309891\n",
      "2020-12-09T16:51:12.942518: step 198, loss 0.612795, acc 0.75, learning_rate 0.00309489\n",
      "2020-12-09T16:51:13.519417: step 199, loss 0.461824, acc 0.8125, learning_rate 0.00309088\n",
      "2020-12-09T16:51:14.103783: step 200, loss 0.595857, acc 0.75, learning_rate 0.00308687\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:51:17.403215: step 200, loss 0.66771, acc 0.693339\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-200\n",
      "\n",
      "2020-12-09T16:51:18.860833: step 201, loss 0.621862, acc 0.75, learning_rate 0.00308287\n",
      "2020-12-09T16:51:19.443877: step 202, loss 0.473849, acc 0.8125, learning_rate 0.00307887\n",
      "2020-12-09T16:51:20.046410: step 203, loss 0.733977, acc 0.65625, learning_rate 0.00307488\n",
      "2020-12-09T16:51:20.637301: step 204, loss 0.52363, acc 0.8125, learning_rate 0.0030709\n",
      "2020-12-09T16:51:21.231554: step 205, loss 0.591073, acc 0.6875, learning_rate 0.00306692\n",
      "2020-12-09T16:51:21.831051: step 206, loss 0.727208, acc 0.65625, learning_rate 0.00306294\n",
      "2020-12-09T16:51:22.438094: step 207, loss 0.776218, acc 0.6875, learning_rate 0.00305898\n",
      "2020-12-09T16:51:23.047057: step 208, loss 0.77713, acc 0.6875, learning_rate 0.00305501\n",
      "2020-12-09T16:51:23.632589: step 209, loss 0.447616, acc 0.78125, learning_rate 0.00305105\n",
      "2020-12-09T16:51:24.226055: step 210, loss 0.685979, acc 0.71875, learning_rate 0.0030471\n",
      "2020-12-09T16:51:24.858049: step 211, loss 0.702962, acc 0.5625, learning_rate 0.00304315\n",
      "2020-12-09T16:51:25.470744: step 212, loss 0.798903, acc 0.65625, learning_rate 0.00303921\n",
      "2020-12-09T16:51:26.080549: step 213, loss 0.674095, acc 0.75, learning_rate 0.00303527\n",
      "2020-12-09T16:51:26.676275: step 214, loss 0.483283, acc 0.875, learning_rate 0.00303134\n",
      "2020-12-09T16:51:27.256357: step 215, loss 0.624116, acc 0.6875, learning_rate 0.00302741\n",
      "2020-12-09T16:51:27.836160: step 216, loss 0.549409, acc 0.75, learning_rate 0.00302349\n",
      "2020-12-09T16:51:28.449479: step 217, loss 0.562848, acc 0.78125, learning_rate 0.00301958\n",
      "2020-12-09T16:51:29.023584: step 218, loss 0.847444, acc 0.59375, learning_rate 0.00301567\n",
      "2020-12-09T16:51:29.591110: step 219, loss 0.545184, acc 0.8125, learning_rate 0.00301176\n",
      "2020-12-09T16:51:30.173941: step 220, loss 0.703078, acc 0.65625, learning_rate 0.00300786\n",
      "2020-12-09T16:51:30.774848: step 221, loss 0.733616, acc 0.71875, learning_rate 0.00300396\n",
      "2020-12-09T16:51:31.360018: step 222, loss 0.713717, acc 0.6875, learning_rate 0.00300007\n",
      "2020-12-09T16:51:31.941001: step 223, loss 0.712501, acc 0.625, learning_rate 0.00299619\n",
      "2020-12-09T16:51:32.528787: step 224, loss 0.663488, acc 0.65625, learning_rate 0.00299231\n",
      "2020-12-09T16:51:33.121391: step 225, loss 0.750043, acc 0.65625, learning_rate 0.00298843\n",
      "2020-12-09T16:51:33.691355: step 226, loss 0.527566, acc 0.75, learning_rate 0.00298457\n",
      "2020-12-09T16:51:34.268659: step 227, loss 0.710842, acc 0.71875, learning_rate 0.0029807\n",
      "2020-12-09T16:51:34.850618: step 228, loss 0.761147, acc 0.65625, learning_rate 0.00297684\n",
      "2020-12-09T16:51:35.434347: step 229, loss 0.976178, acc 0.625, learning_rate 0.00297299\n",
      "2020-12-09T16:51:36.006762: step 230, loss 0.565516, acc 0.90625, learning_rate 0.00296914\n",
      "2020-12-09T16:51:36.614585: step 231, loss 0.779012, acc 0.6875, learning_rate 0.0029653\n",
      "2020-12-09T16:51:37.198853: step 232, loss 0.836895, acc 0.65625, learning_rate 0.00296146\n",
      "2020-12-09T16:51:37.768354: step 233, loss 0.560674, acc 0.71875, learning_rate 0.00295763\n",
      "2020-12-09T16:51:38.346355: step 234, loss 0.870121, acc 0.5625, learning_rate 0.0029538\n",
      "2020-12-09T16:51:38.954669: step 235, loss 0.737834, acc 0.59375, learning_rate 0.00294997\n",
      "2020-12-09T16:51:39.530940: step 236, loss 0.739773, acc 0.71875, learning_rate 0.00294616\n",
      "2020-12-09T16:51:40.128473: step 237, loss 0.558019, acc 0.84375, learning_rate 0.00294234\n",
      "2020-12-09T16:51:40.714569: step 238, loss 0.57725, acc 0.75, learning_rate 0.00293854\n",
      "2020-12-09T16:51:41.307561: step 239, loss 0.65314, acc 0.71875, learning_rate 0.00293473\n",
      "2020-12-09T16:51:41.874069: step 240, loss 0.535952, acc 0.78125, learning_rate 0.00293094\n",
      "2020-12-09T16:51:42.456096: step 241, loss 0.521746, acc 0.84375, learning_rate 0.00292715\n",
      "2020-12-09T16:51:43.039328: step 242, loss 0.484445, acc 0.78125, learning_rate 0.00292336\n",
      "2020-12-09T16:51:43.615967: step 243, loss 0.715334, acc 0.71875, learning_rate 0.00291958\n",
      "2020-12-09T16:51:44.200862: step 244, loss 0.765023, acc 0.6875, learning_rate 0.0029158\n",
      "2020-12-09T16:51:44.809829: step 245, loss 0.803959, acc 0.6875, learning_rate 0.00291203\n",
      "2020-12-09T16:51:45.416620: step 246, loss 0.556885, acc 0.78125, learning_rate 0.00290826\n",
      "2020-12-09T16:51:45.999412: step 247, loss 0.685845, acc 0.6875, learning_rate 0.0029045\n",
      "2020-12-09T16:51:46.564071: step 248, loss 0.698182, acc 0.6875, learning_rate 0.00290074\n",
      "2020-12-09T16:51:47.179642: step 249, loss 0.62712, acc 0.6875, learning_rate 0.00289699\n",
      "2020-12-09T16:51:47.762604: step 250, loss 0.648085, acc 0.78125, learning_rate 0.00289324\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:51:51.011551: step 250, loss 0.640331, acc 0.715124\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-250\n",
      "\n",
      "2020-12-09T16:51:52.532810: step 251, loss 0.717117, acc 0.6875, learning_rate 0.0028895\n",
      "2020-12-09T16:51:53.119209: step 252, loss 0.622847, acc 0.6875, learning_rate 0.00288576\n",
      "2020-12-09T16:51:53.695733: step 253, loss 1.01093, acc 0.625, learning_rate 0.00288203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:51:54.303334: step 254, loss 0.674201, acc 0.65625, learning_rate 0.00287831\n",
      "2020-12-09T16:51:54.880236: step 255, loss 0.734341, acc 0.65625, learning_rate 0.00287458\n",
      "2020-12-09T16:51:55.471762: step 256, loss 0.761723, acc 0.75, learning_rate 0.00287087\n",
      "2020-12-09T16:51:56.049268: step 257, loss 0.656903, acc 0.65625, learning_rate 0.00286716\n",
      "2020-12-09T16:51:56.635519: step 258, loss 0.712284, acc 0.75, learning_rate 0.00286345\n",
      "2020-12-09T16:51:57.223507: step 259, loss 0.686968, acc 0.625, learning_rate 0.00285975\n",
      "2020-12-09T16:51:57.798086: step 260, loss 0.788221, acc 0.59375, learning_rate 0.00285605\n",
      "2020-12-09T16:51:58.387599: step 261, loss 0.834849, acc 0.625, learning_rate 0.00285236\n",
      "2020-12-09T16:51:58.975639: step 262, loss 0.756999, acc 0.5625, learning_rate 0.00284867\n",
      "2020-12-09T16:51:59.558610: step 263, loss 0.735828, acc 0.625, learning_rate 0.00284499\n",
      "2020-12-09T16:52:00.145608: step 264, loss 0.684606, acc 0.71875, learning_rate 0.00284131\n",
      "2020-12-09T16:52:00.731333: step 265, loss 0.712098, acc 0.75, learning_rate 0.00283764\n",
      "2020-12-09T16:52:01.324206: step 266, loss 0.698285, acc 0.6875, learning_rate 0.00283397\n",
      "2020-12-09T16:52:01.892156: step 267, loss 0.695495, acc 0.6875, learning_rate 0.00283031\n",
      "2020-12-09T16:52:02.473187: step 268, loss 0.512564, acc 0.6875, learning_rate 0.00282665\n",
      "2020-12-09T16:52:03.061093: step 269, loss 0.695867, acc 0.75, learning_rate 0.002823\n",
      "2020-12-09T16:52:03.662057: step 270, loss 0.72722, acc 0.625, learning_rate 0.00281935\n",
      "2020-12-09T16:52:04.272562: step 271, loss 0.687389, acc 0.625, learning_rate 0.00281571\n",
      "2020-12-09T16:52:04.893535: step 272, loss 0.773419, acc 0.65625, learning_rate 0.00281207\n",
      "2020-12-09T16:52:05.465513: step 273, loss 0.490104, acc 0.875, learning_rate 0.00280844\n",
      "2020-12-09T16:52:06.039457: step 274, loss 0.683259, acc 0.75, learning_rate 0.00280481\n",
      "2020-12-09T16:52:06.624613: step 275, loss 0.585619, acc 0.8125, learning_rate 0.00280119\n",
      "2020-12-09T16:52:07.208891: step 276, loss 0.686537, acc 0.71875, learning_rate 0.00279757\n",
      "2020-12-09T16:52:07.796969: step 277, loss 0.82121, acc 0.65625, learning_rate 0.00279396\n",
      "2020-12-09T16:52:08.377918: step 278, loss 0.947168, acc 0.5625, learning_rate 0.00279035\n",
      "2020-12-09T16:52:08.994771: step 279, loss 0.820042, acc 0.625, learning_rate 0.00278674\n",
      "2020-12-09T16:52:09.594993: step 280, loss 0.572794, acc 0.75, learning_rate 0.00278315\n",
      "2020-12-09T16:52:10.168453: step 281, loss 0.765781, acc 0.75, learning_rate 0.00277955\n",
      "2020-12-09T16:52:10.768709: step 282, loss 0.595516, acc 0.6875, learning_rate 0.00277596\n",
      "2020-12-09T16:52:11.365728: step 283, loss 0.485653, acc 0.84375, learning_rate 0.00277238\n",
      "2020-12-09T16:52:11.943229: step 284, loss 0.583225, acc 0.71875, learning_rate 0.0027688\n",
      "2020-12-09T16:52:12.511738: step 285, loss 0.801307, acc 0.6875, learning_rate 0.00276522\n",
      "2020-12-09T16:52:13.106690: step 286, loss 0.546835, acc 0.71875, learning_rate 0.00276165\n",
      "2020-12-09T16:52:13.695370: step 287, loss 0.731404, acc 0.65625, learning_rate 0.00275809\n",
      "2020-12-09T16:52:14.303907: step 288, loss 0.575755, acc 0.71875, learning_rate 0.00275453\n",
      "2020-12-09T16:52:14.916082: step 289, loss 0.62246, acc 0.6875, learning_rate 0.00275097\n",
      "2020-12-09T16:52:15.561031: step 290, loss 0.567489, acc 0.6875, learning_rate 0.00274742\n",
      "2020-12-09T16:52:16.151568: step 291, loss 0.565369, acc 0.8125, learning_rate 0.00274387\n",
      "2020-12-09T16:52:16.734943: step 292, loss 0.848943, acc 0.59375, learning_rate 0.00274033\n",
      "2020-12-09T16:52:17.332556: step 293, loss 0.458383, acc 0.8125, learning_rate 0.00273679\n",
      "2020-12-09T16:52:17.934027: step 294, loss 0.539672, acc 0.78125, learning_rate 0.00273326\n",
      "2020-12-09T16:52:18.516004: step 295, loss 0.659928, acc 0.71875, learning_rate 0.00272973\n",
      "2020-12-09T16:52:19.099008: step 296, loss 0.73814, acc 0.6875, learning_rate 0.00272621\n",
      "2020-12-09T16:52:19.669100: step 297, loss 0.603654, acc 0.78125, learning_rate 0.00272269\n",
      "2020-12-09T16:52:20.256318: step 298, loss 0.74034, acc 0.65625, learning_rate 0.00271918\n",
      "2020-12-09T16:52:20.505294: step 299, loss 0.621074, acc 0.769231, learning_rate 0.00271567\n",
      "2020-12-09T16:52:21.112138: step 300, loss 0.502443, acc 0.78125, learning_rate 0.00271217\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:52:24.260232: step 300, loss 0.610906, acc 0.71638\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-300\n",
      "\n",
      "2020-12-09T16:52:25.713634: step 301, loss 0.315594, acc 0.90625, learning_rate 0.00270867\n",
      "2020-12-09T16:52:26.295018: step 302, loss 0.477287, acc 0.8125, learning_rate 0.00270517\n",
      "2020-12-09T16:52:26.872978: step 303, loss 0.57361, acc 0.71875, learning_rate 0.00270168\n",
      "2020-12-09T16:52:27.509454: step 304, loss 0.681849, acc 0.65625, learning_rate 0.0026982\n",
      "2020-12-09T16:52:28.104962: step 305, loss 0.371698, acc 0.84375, learning_rate 0.00269472\n",
      "2020-12-09T16:52:28.684484: step 306, loss 0.758893, acc 0.625, learning_rate 0.00269124\n",
      "2020-12-09T16:52:29.262201: step 307, loss 0.592187, acc 0.6875, learning_rate 0.00268777\n",
      "2020-12-09T16:52:29.860586: step 308, loss 0.411427, acc 0.78125, learning_rate 0.00268431\n",
      "2020-12-09T16:52:30.450617: step 309, loss 0.454983, acc 0.84375, learning_rate 0.00268084\n",
      "2020-12-09T16:52:31.035898: step 310, loss 0.451908, acc 0.71875, learning_rate 0.00267739\n",
      "2020-12-09T16:52:31.614108: step 311, loss 0.561358, acc 0.71875, learning_rate 0.00267393\n",
      "2020-12-09T16:52:32.204562: step 312, loss 0.576682, acc 0.65625, learning_rate 0.00267049\n",
      "2020-12-09T16:52:32.806598: step 313, loss 0.803611, acc 0.71875, learning_rate 0.00266704\n",
      "2020-12-09T16:52:33.399598: step 314, loss 0.524284, acc 0.6875, learning_rate 0.0026636\n",
      "2020-12-09T16:52:33.975480: step 315, loss 0.348531, acc 0.8125, learning_rate 0.00266017\n",
      "2020-12-09T16:52:34.549409: step 316, loss 0.642234, acc 0.71875, learning_rate 0.00265674\n",
      "2020-12-09T16:52:35.139817: step 317, loss 0.431312, acc 0.84375, learning_rate 0.00265332\n",
      "2020-12-09T16:52:35.709659: step 318, loss 0.498452, acc 0.75, learning_rate 0.0026499\n",
      "2020-12-09T16:52:36.281658: step 319, loss 0.765756, acc 0.75, learning_rate 0.00264648\n",
      "2020-12-09T16:52:36.870605: step 320, loss 0.419126, acc 0.8125, learning_rate 0.00264307\n",
      "2020-12-09T16:52:37.460026: step 321, loss 0.519444, acc 0.875, learning_rate 0.00263966\n",
      "2020-12-09T16:52:38.042331: step 322, loss 0.439659, acc 0.875, learning_rate 0.00263626\n",
      "2020-12-09T16:52:38.633010: step 323, loss 0.392224, acc 0.84375, learning_rate 0.00263286\n",
      "2020-12-09T16:52:39.215122: step 324, loss 0.421186, acc 0.8125, learning_rate 0.00262947\n",
      "2020-12-09T16:52:39.802144: step 325, loss 0.299561, acc 0.90625, learning_rate 0.00262608\n",
      "2020-12-09T16:52:40.367920: step 326, loss 0.501377, acc 0.78125, learning_rate 0.0026227\n",
      "2020-12-09T16:52:40.946157: step 327, loss 0.47246, acc 0.75, learning_rate 0.00261932\n",
      "2020-12-09T16:52:41.541301: step 328, loss 0.744397, acc 0.6875, learning_rate 0.00261594\n",
      "2020-12-09T16:52:42.151222: step 329, loss 0.449111, acc 0.75, learning_rate 0.00261257\n",
      "2020-12-09T16:52:42.734657: step 330, loss 0.364511, acc 0.84375, learning_rate 0.00260921\n",
      "2020-12-09T16:52:43.370117: step 331, loss 0.425447, acc 0.875, learning_rate 0.00260585\n",
      "2020-12-09T16:52:43.958125: step 332, loss 0.579732, acc 0.71875, learning_rate 0.00260249\n",
      "2020-12-09T16:52:44.510410: step 333, loss 0.374842, acc 0.8125, learning_rate 0.00259914\n",
      "2020-12-09T16:52:45.094357: step 334, loss 0.365394, acc 0.90625, learning_rate 0.00259579\n",
      "2020-12-09T16:52:45.697043: step 335, loss 0.492346, acc 0.6875, learning_rate 0.00259245\n",
      "2020-12-09T16:52:46.278043: step 336, loss 0.510729, acc 0.78125, learning_rate 0.00258911\n",
      "2020-12-09T16:52:46.856009: step 337, loss 0.450539, acc 0.8125, learning_rate 0.00258577\n",
      "2020-12-09T16:52:47.434664: step 338, loss 0.780656, acc 0.6875, learning_rate 0.00258244\n",
      "2020-12-09T16:52:48.018172: step 339, loss 0.488914, acc 0.8125, learning_rate 0.00257912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:52:48.595705: step 340, loss 0.52452, acc 0.78125, learning_rate 0.0025758\n",
      "2020-12-09T16:52:49.183957: step 341, loss 0.600264, acc 0.71875, learning_rate 0.00257248\n",
      "2020-12-09T16:52:49.792335: step 342, loss 0.454243, acc 0.8125, learning_rate 0.00256917\n",
      "2020-12-09T16:52:50.378330: step 343, loss 0.434903, acc 0.84375, learning_rate 0.00256586\n",
      "2020-12-09T16:52:50.961831: step 344, loss 0.323872, acc 0.875, learning_rate 0.00256256\n",
      "2020-12-09T16:52:51.559817: step 345, loss 0.461886, acc 0.8125, learning_rate 0.00255926\n",
      "2020-12-09T16:52:52.137165: step 346, loss 0.477969, acc 0.78125, learning_rate 0.00255596\n",
      "2020-12-09T16:52:52.705055: step 347, loss 0.54999, acc 0.71875, learning_rate 0.00255268\n",
      "2020-12-09T16:52:53.296670: step 348, loss 0.383958, acc 0.84375, learning_rate 0.00254939\n",
      "2020-12-09T16:52:53.894157: step 349, loss 0.567105, acc 0.78125, learning_rate 0.00254611\n",
      "2020-12-09T16:52:54.470548: step 350, loss 0.390768, acc 0.84375, learning_rate 0.00254283\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:52:57.650839: step 350, loss 0.620363, acc 0.718056\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-350\n",
      "\n",
      "2020-12-09T16:52:59.119715: step 351, loss 0.529705, acc 0.78125, learning_rate 0.00253956\n",
      "2020-12-09T16:52:59.703822: step 352, loss 0.507483, acc 0.75, learning_rate 0.00253629\n",
      "2020-12-09T16:53:00.299288: step 353, loss 0.559397, acc 0.71875, learning_rate 0.00253303\n",
      "2020-12-09T16:53:00.891815: step 354, loss 0.630075, acc 0.78125, learning_rate 0.00252977\n",
      "2020-12-09T16:53:01.456821: step 355, loss 0.423532, acc 0.84375, learning_rate 0.00252651\n",
      "2020-12-09T16:53:02.048270: step 356, loss 0.481555, acc 0.84375, learning_rate 0.00252326\n",
      "2020-12-09T16:53:02.622601: step 357, loss 0.605034, acc 0.75, learning_rate 0.00252002\n",
      "2020-12-09T16:53:03.199192: step 358, loss 0.472135, acc 0.75, learning_rate 0.00251678\n",
      "2020-12-09T16:53:03.821429: step 359, loss 0.388746, acc 0.8125, learning_rate 0.00251354\n",
      "2020-12-09T16:53:04.406450: step 360, loss 0.576405, acc 0.6875, learning_rate 0.00251031\n",
      "2020-12-09T16:53:04.989961: step 361, loss 0.450471, acc 0.8125, learning_rate 0.00250708\n",
      "2020-12-09T16:53:05.573167: step 362, loss 0.746118, acc 0.65625, learning_rate 0.00250385\n",
      "2020-12-09T16:53:06.167640: step 363, loss 0.548648, acc 0.71875, learning_rate 0.00250063\n",
      "2020-12-09T16:53:06.738065: step 364, loss 0.342373, acc 0.90625, learning_rate 0.00249742\n",
      "2020-12-09T16:53:07.330934: step 365, loss 0.573446, acc 0.78125, learning_rate 0.0024942\n",
      "2020-12-09T16:53:07.912034: step 366, loss 0.43919, acc 0.875, learning_rate 0.002491\n",
      "2020-12-09T16:53:08.473497: step 367, loss 0.554659, acc 0.75, learning_rate 0.00248779\n",
      "2020-12-09T16:53:09.054626: step 368, loss 0.43374, acc 0.8125, learning_rate 0.0024846\n",
      "2020-12-09T16:53:09.633775: step 369, loss 0.551557, acc 0.65625, learning_rate 0.0024814\n",
      "2020-12-09T16:53:10.216531: step 370, loss 0.604932, acc 0.71875, learning_rate 0.00247821\n",
      "2020-12-09T16:53:10.778503: step 371, loss 0.501048, acc 0.78125, learning_rate 0.00247503\n",
      "2020-12-09T16:53:11.406217: step 372, loss 0.521089, acc 0.75, learning_rate 0.00247184\n",
      "2020-12-09T16:53:12.019267: step 373, loss 0.363396, acc 0.84375, learning_rate 0.00246867\n",
      "2020-12-09T16:53:12.588728: step 374, loss 0.517696, acc 0.75, learning_rate 0.00246549\n",
      "2020-12-09T16:53:13.178689: step 375, loss 0.315337, acc 0.875, learning_rate 0.00246233\n",
      "2020-12-09T16:53:13.775382: step 376, loss 0.681297, acc 0.71875, learning_rate 0.00245916\n",
      "2020-12-09T16:53:14.358659: step 377, loss 0.559758, acc 0.78125, learning_rate 0.002456\n",
      "2020-12-09T16:53:14.938160: step 378, loss 0.576981, acc 0.65625, learning_rate 0.00245284\n",
      "2020-12-09T16:53:15.537915: step 379, loss 0.441924, acc 0.8125, learning_rate 0.00244969\n",
      "2020-12-09T16:53:16.114611: step 380, loss 0.450763, acc 0.71875, learning_rate 0.00244655\n",
      "2020-12-09T16:53:16.688611: step 381, loss 0.499415, acc 0.78125, learning_rate 0.0024434\n",
      "2020-12-09T16:53:17.261499: step 382, loss 0.404783, acc 0.8125, learning_rate 0.00244026\n",
      "2020-12-09T16:53:17.873998: step 383, loss 0.503483, acc 0.78125, learning_rate 0.00243713\n",
      "2020-12-09T16:53:18.469025: step 384, loss 0.378949, acc 0.875, learning_rate 0.002434\n",
      "2020-12-09T16:53:19.059491: step 385, loss 0.456453, acc 0.875, learning_rate 0.00243087\n",
      "2020-12-09T16:53:19.680253: step 386, loss 0.406347, acc 0.78125, learning_rate 0.00242775\n",
      "2020-12-09T16:53:20.279519: step 387, loss 0.425948, acc 0.78125, learning_rate 0.00242463\n",
      "2020-12-09T16:53:20.857002: step 388, loss 0.532818, acc 0.75, learning_rate 0.00242152\n",
      "2020-12-09T16:53:21.455820: step 389, loss 0.387318, acc 0.875, learning_rate 0.00241841\n",
      "2020-12-09T16:53:22.031800: step 390, loss 0.42339, acc 0.6875, learning_rate 0.0024153\n",
      "2020-12-09T16:53:22.616719: step 391, loss 0.450907, acc 0.84375, learning_rate 0.0024122\n",
      "2020-12-09T16:53:23.223095: step 392, loss 0.363573, acc 0.84375, learning_rate 0.0024091\n",
      "2020-12-09T16:53:23.823890: step 393, loss 0.758942, acc 0.65625, learning_rate 0.00240601\n",
      "2020-12-09T16:53:24.405894: step 394, loss 0.611069, acc 0.8125, learning_rate 0.00240292\n",
      "2020-12-09T16:53:24.972400: step 395, loss 0.686192, acc 0.75, learning_rate 0.00239984\n",
      "2020-12-09T16:53:25.560412: step 396, loss 0.659799, acc 0.65625, learning_rate 0.00239675\n",
      "2020-12-09T16:53:26.139491: step 397, loss 0.593111, acc 0.75, learning_rate 0.00239368\n",
      "2020-12-09T16:53:26.718486: step 398, loss 0.513007, acc 0.75, learning_rate 0.00239061\n",
      "2020-12-09T16:53:27.314700: step 399, loss 0.443655, acc 0.78125, learning_rate 0.00238754\n",
      "2020-12-09T16:53:27.913140: step 400, loss 0.58566, acc 0.75, learning_rate 0.00238447\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:53:31.143422: step 400, loss 0.604999, acc 0.726435\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-400\n",
      "\n",
      "2020-12-09T16:53:32.616584: step 401, loss 0.73578, acc 0.78125, learning_rate 0.00238141\n",
      "2020-12-09T16:53:33.187004: step 402, loss 0.31226, acc 0.9375, learning_rate 0.00237836\n",
      "2020-12-09T16:53:33.761368: step 403, loss 0.645994, acc 0.6875, learning_rate 0.0023753\n",
      "2020-12-09T16:53:34.337404: step 404, loss 0.633966, acc 0.65625, learning_rate 0.00237226\n",
      "2020-12-09T16:53:34.961405: step 405, loss 0.562392, acc 0.65625, learning_rate 0.00236921\n",
      "2020-12-09T16:53:35.567762: step 406, loss 0.526523, acc 0.75, learning_rate 0.00236617\n",
      "2020-12-09T16:53:36.138263: step 407, loss 0.368681, acc 0.84375, learning_rate 0.00236314\n",
      "2020-12-09T16:53:36.725760: step 408, loss 0.493569, acc 0.75, learning_rate 0.00236011\n",
      "2020-12-09T16:53:37.326294: step 409, loss 0.554153, acc 0.75, learning_rate 0.00235708\n",
      "2020-12-09T16:53:37.938594: step 410, loss 0.332533, acc 0.875, learning_rate 0.00235405\n",
      "2020-12-09T16:53:38.530057: step 411, loss 0.524412, acc 0.71875, learning_rate 0.00235104\n",
      "2020-12-09T16:53:39.149591: step 412, loss 0.365128, acc 0.8125, learning_rate 0.00234802\n",
      "2020-12-09T16:53:39.748914: step 413, loss 0.375963, acc 0.875, learning_rate 0.00234501\n",
      "2020-12-09T16:53:40.365305: step 414, loss 0.631184, acc 0.625, learning_rate 0.002342\n",
      "2020-12-09T16:53:40.945768: step 415, loss 0.605305, acc 0.6875, learning_rate 0.002339\n",
      "2020-12-09T16:53:41.520900: step 416, loss 0.637812, acc 0.65625, learning_rate 0.002336\n",
      "2020-12-09T16:53:42.147640: step 417, loss 0.539986, acc 0.6875, learning_rate 0.002333\n",
      "2020-12-09T16:53:42.729481: step 418, loss 0.789196, acc 0.65625, learning_rate 0.00233001\n",
      "2020-12-09T16:53:43.310266: step 419, loss 0.485413, acc 0.78125, learning_rate 0.00232702\n",
      "2020-12-09T16:53:43.888695: step 420, loss 0.540396, acc 0.84375, learning_rate 0.00232404\n",
      "2020-12-09T16:53:44.478691: step 421, loss 0.353567, acc 0.875, learning_rate 0.00232106\n",
      "2020-12-09T16:53:45.051301: step 422, loss 0.372187, acc 0.875, learning_rate 0.00231809\n",
      "2020-12-09T16:53:45.617227: step 423, loss 0.469677, acc 0.8125, learning_rate 0.00231512\n",
      "2020-12-09T16:53:46.199218: step 424, loss 0.610131, acc 0.71875, learning_rate 0.00231215\n",
      "2020-12-09T16:53:46.771252: step 425, loss 0.327219, acc 0.84375, learning_rate 0.00230919\n",
      "2020-12-09T16:53:47.357352: step 426, loss 0.419589, acc 0.8125, learning_rate 0.00230623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:53:47.939792: step 427, loss 0.54215, acc 0.75, learning_rate 0.00230327\n",
      "2020-12-09T16:53:48.529332: step 428, loss 0.409806, acc 0.84375, learning_rate 0.00230032\n",
      "2020-12-09T16:53:49.121339: step 429, loss 0.476399, acc 0.75, learning_rate 0.00229737\n",
      "2020-12-09T16:53:49.712753: step 430, loss 0.31068, acc 0.875, learning_rate 0.00229443\n",
      "2020-12-09T16:53:50.313549: step 431, loss 0.316524, acc 0.875, learning_rate 0.00229149\n",
      "2020-12-09T16:53:50.925515: step 432, loss 0.487523, acc 0.71875, learning_rate 0.00228855\n",
      "2020-12-09T16:53:51.574522: step 433, loss 0.538738, acc 0.8125, learning_rate 0.00228562\n",
      "2020-12-09T16:53:52.225026: step 434, loss 0.498406, acc 0.75, learning_rate 0.00228269\n",
      "2020-12-09T16:53:52.878513: step 435, loss 0.422664, acc 0.78125, learning_rate 0.00227977\n",
      "2020-12-09T16:53:53.563369: step 436, loss 0.255494, acc 0.875, learning_rate 0.00227685\n",
      "2020-12-09T16:53:54.365359: step 437, loss 0.636272, acc 0.71875, learning_rate 0.00227393\n",
      "2020-12-09T16:53:55.505348: step 438, loss 0.350717, acc 0.78125, learning_rate 0.00227102\n",
      "2020-12-09T16:53:56.120732: step 439, loss 0.700769, acc 0.71875, learning_rate 0.00226811\n",
      "2020-12-09T16:53:56.747519: step 440, loss 0.472244, acc 0.84375, learning_rate 0.00226521\n",
      "2020-12-09T16:53:57.363632: step 441, loss 0.298377, acc 0.875, learning_rate 0.00226231\n",
      "2020-12-09T16:53:57.956934: step 442, loss 0.670887, acc 0.625, learning_rate 0.00225941\n",
      "2020-12-09T16:53:58.583458: step 443, loss 0.44478, acc 0.8125, learning_rate 0.00225652\n",
      "2020-12-09T16:53:59.186898: step 444, loss 0.554726, acc 0.78125, learning_rate 0.00225363\n",
      "2020-12-09T16:53:59.824636: step 445, loss 0.454636, acc 0.75, learning_rate 0.00225075\n",
      "2020-12-09T16:54:00.440198: step 446, loss 0.500256, acc 0.8125, learning_rate 0.00224786\n",
      "2020-12-09T16:54:01.019230: step 447, loss 0.312467, acc 0.875, learning_rate 0.00224499\n",
      "2020-12-09T16:54:01.629130: step 448, loss 0.425828, acc 0.84375, learning_rate 0.00224211\n",
      "2020-12-09T16:54:02.369714: step 449, loss 0.594097, acc 0.8125, learning_rate 0.00223924\n",
      "2020-12-09T16:54:03.144085: step 450, loss 0.466033, acc 0.8125, learning_rate 0.00223638\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:54:06.863617: step 450, loss 0.626264, acc 0.725597\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-450\n",
      "\n",
      "2020-12-09T16:54:08.584577: step 451, loss 0.483613, acc 0.84375, learning_rate 0.00223352\n",
      "2020-12-09T16:54:09.196215: step 452, loss 0.418223, acc 0.84375, learning_rate 0.00223066\n",
      "2020-12-09T16:54:09.785589: step 453, loss 0.484458, acc 0.75, learning_rate 0.00222781\n",
      "2020-12-09T16:54:10.408561: step 454, loss 0.611948, acc 0.6875, learning_rate 0.00222496\n",
      "2020-12-09T16:54:10.983559: step 455, loss 0.675711, acc 0.71875, learning_rate 0.00222211\n",
      "2020-12-09T16:54:11.591098: step 456, loss 0.381987, acc 0.78125, learning_rate 0.00221927\n",
      "2020-12-09T16:54:12.183093: step 457, loss 0.465124, acc 0.78125, learning_rate 0.00221643\n",
      "2020-12-09T16:54:12.769883: step 458, loss 0.551707, acc 0.78125, learning_rate 0.00221359\n",
      "2020-12-09T16:54:13.337851: step 459, loss 0.700792, acc 0.6875, learning_rate 0.00221076\n",
      "2020-12-09T16:54:13.922836: step 460, loss 0.464013, acc 0.6875, learning_rate 0.00220793\n",
      "2020-12-09T16:54:14.520831: step 461, loss 0.545579, acc 0.71875, learning_rate 0.00220511\n",
      "2020-12-09T16:54:15.127831: step 462, loss 0.479736, acc 0.84375, learning_rate 0.00220229\n",
      "2020-12-09T16:54:15.909832: step 463, loss 0.409264, acc 0.84375, learning_rate 0.00219947\n",
      "2020-12-09T16:54:16.675332: step 464, loss 0.548461, acc 0.65625, learning_rate 0.00219666\n",
      "2020-12-09T16:54:17.399334: step 465, loss 0.619218, acc 0.71875, learning_rate 0.00219385\n",
      "2020-12-09T16:54:18.088652: step 466, loss 0.586084, acc 0.6875, learning_rate 0.00219105\n",
      "2020-12-09T16:54:18.683806: step 467, loss 0.410788, acc 0.875, learning_rate 0.00218825\n",
      "2020-12-09T16:54:19.265917: step 468, loss 0.572727, acc 0.65625, learning_rate 0.00218545\n",
      "2020-12-09T16:54:19.885379: step 469, loss 0.541798, acc 0.75, learning_rate 0.00218266\n",
      "2020-12-09T16:54:20.484267: step 470, loss 0.289587, acc 0.84375, learning_rate 0.00217987\n",
      "2020-12-09T16:54:21.088775: step 471, loss 0.420963, acc 0.8125, learning_rate 0.00217708\n",
      "2020-12-09T16:54:21.885706: step 472, loss 0.395973, acc 0.8125, learning_rate 0.0021743\n",
      "2020-12-09T16:54:22.522551: step 473, loss 0.628366, acc 0.71875, learning_rate 0.00217152\n",
      "2020-12-09T16:54:23.093590: step 474, loss 0.285874, acc 0.84375, learning_rate 0.00216874\n",
      "2020-12-09T16:54:23.679242: step 475, loss 0.243184, acc 0.875, learning_rate 0.00216597\n",
      "2020-12-09T16:54:24.262507: step 476, loss 0.442085, acc 0.8125, learning_rate 0.00216321\n",
      "2020-12-09T16:54:24.862628: step 477, loss 0.403763, acc 0.8125, learning_rate 0.00216044\n",
      "2020-12-09T16:54:25.448866: step 478, loss 0.605358, acc 0.78125, learning_rate 0.00215768\n",
      "2020-12-09T16:54:26.051056: step 479, loss 0.274873, acc 0.9375, learning_rate 0.00215492\n",
      "2020-12-09T16:54:26.647990: step 480, loss 0.498063, acc 0.875, learning_rate 0.00215217\n",
      "2020-12-09T16:54:27.239769: step 481, loss 0.487976, acc 0.78125, learning_rate 0.00214942\n",
      "2020-12-09T16:54:27.827391: step 482, loss 0.305375, acc 0.84375, learning_rate 0.00214668\n",
      "2020-12-09T16:54:28.549381: step 483, loss 0.638399, acc 0.75, learning_rate 0.00214394\n",
      "2020-12-09T16:54:29.385854: step 484, loss 0.456001, acc 0.71875, learning_rate 0.0021412\n",
      "2020-12-09T16:54:30.088865: step 485, loss 0.350963, acc 0.84375, learning_rate 0.00213846\n",
      "2020-12-09T16:54:30.728947: step 486, loss 0.341148, acc 0.8125, learning_rate 0.00213573\n",
      "2020-12-09T16:54:31.314581: step 487, loss 0.443477, acc 0.78125, learning_rate 0.00213301\n",
      "2020-12-09T16:54:31.881086: step 488, loss 0.649998, acc 0.65625, learning_rate 0.00213028\n",
      "2020-12-09T16:54:32.626047: step 489, loss 0.717917, acc 0.6875, learning_rate 0.00212756\n",
      "2020-12-09T16:54:33.445082: step 490, loss 0.581793, acc 0.75, learning_rate 0.00212485\n",
      "2020-12-09T16:54:34.409174: step 491, loss 0.709858, acc 0.65625, learning_rate 0.00212213\n",
      "2020-12-09T16:54:35.222668: step 492, loss 0.338766, acc 0.84375, learning_rate 0.00211943\n",
      "2020-12-09T16:54:36.122707: step 493, loss 0.413848, acc 0.8125, learning_rate 0.00211672\n",
      "2020-12-09T16:54:36.876760: step 494, loss 0.48053, acc 0.78125, learning_rate 0.00211402\n",
      "2020-12-09T16:54:37.555720: step 495, loss 0.624873, acc 0.65625, learning_rate 0.00211132\n",
      "2020-12-09T16:54:38.292754: step 496, loss 0.524188, acc 0.6875, learning_rate 0.00210863\n",
      "2020-12-09T16:54:38.919167: step 497, loss 0.537548, acc 0.8125, learning_rate 0.00210594\n",
      "2020-12-09T16:54:39.587070: step 498, loss 0.506497, acc 0.71875, learning_rate 0.00210325\n",
      "2020-12-09T16:54:40.235036: step 499, loss 0.471954, acc 0.84375, learning_rate 0.00210057\n",
      "2020-12-09T16:54:40.879189: step 500, loss 0.516173, acc 0.75, learning_rate 0.00209789\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:54:44.262741: step 500, loss 0.621748, acc 0.722246\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-500\n",
      "\n",
      "2020-12-09T16:54:45.789739: step 501, loss 0.599686, acc 0.75, learning_rate 0.00209521\n",
      "2020-12-09T16:54:46.363856: step 502, loss 0.378714, acc 0.84375, learning_rate 0.00209254\n",
      "2020-12-09T16:54:46.959842: step 503, loss 0.551292, acc 0.78125, learning_rate 0.00208987\n",
      "2020-12-09T16:54:47.537637: step 504, loss 0.47757, acc 0.75, learning_rate 0.0020872\n",
      "2020-12-09T16:54:48.117260: step 505, loss 0.515449, acc 0.65625, learning_rate 0.00208454\n",
      "2020-12-09T16:54:48.704438: step 506, loss 0.417013, acc 0.90625, learning_rate 0.00208188\n",
      "2020-12-09T16:54:49.279942: step 507, loss 0.513662, acc 0.78125, learning_rate 0.00207923\n",
      "2020-12-09T16:54:49.880437: step 508, loss 0.407995, acc 0.75, learning_rate 0.00207658\n",
      "2020-12-09T16:54:50.650436: step 509, loss 0.493592, acc 0.75, learning_rate 0.00207393\n",
      "2020-12-09T16:54:51.436939: step 510, loss 0.39083, acc 0.8125, learning_rate 0.00207128\n",
      "2020-12-09T16:54:52.023976: step 511, loss 0.519645, acc 0.78125, learning_rate 0.00206864\n",
      "2020-12-09T16:54:52.635301: step 512, loss 0.490171, acc 0.75, learning_rate 0.00206601\n",
      "2020-12-09T16:54:53.213838: step 513, loss 0.5967, acc 0.65625, learning_rate 0.00206337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:54:53.787022: step 514, loss 0.48896, acc 0.8125, learning_rate 0.00206074\n",
      "2020-12-09T16:54:54.367570: step 515, loss 0.518423, acc 0.8125, learning_rate 0.00205812\n",
      "2020-12-09T16:54:54.928420: step 516, loss 0.290856, acc 0.9375, learning_rate 0.00205549\n",
      "2020-12-09T16:54:55.505414: step 517, loss 0.543062, acc 0.75, learning_rate 0.00205287\n",
      "2020-12-09T16:54:56.089378: step 518, loss 0.536879, acc 0.71875, learning_rate 0.00205026\n",
      "2020-12-09T16:54:56.671013: step 519, loss 0.393315, acc 0.84375, learning_rate 0.00204765\n",
      "2020-12-09T16:54:57.234977: step 520, loss 0.670391, acc 0.875, learning_rate 0.00204504\n",
      "2020-12-09T16:54:57.804140: step 521, loss 0.652989, acc 0.6875, learning_rate 0.00204243\n",
      "2020-12-09T16:54:58.393416: step 522, loss 0.533968, acc 0.71875, learning_rate 0.00203983\n",
      "2020-12-09T16:54:58.978946: step 523, loss 0.394534, acc 0.84375, learning_rate 0.00203723\n",
      "2020-12-09T16:54:59.561856: step 524, loss 0.392744, acc 0.75, learning_rate 0.00203464\n",
      "2020-12-09T16:55:00.143886: step 525, loss 0.457255, acc 0.78125, learning_rate 0.00203204\n",
      "2020-12-09T16:55:00.712067: step 526, loss 0.93585, acc 0.59375, learning_rate 0.00202946\n",
      "2020-12-09T16:55:01.291062: step 527, loss 0.562275, acc 0.75, learning_rate 0.00202687\n",
      "2020-12-09T16:55:01.869262: step 528, loss 0.505829, acc 0.8125, learning_rate 0.00202429\n",
      "2020-12-09T16:55:02.461979: step 529, loss 0.366593, acc 0.875, learning_rate 0.00202171\n",
      "2020-12-09T16:55:03.045445: step 530, loss 0.431586, acc 0.90625, learning_rate 0.00201914\n",
      "2020-12-09T16:55:03.611480: step 531, loss 0.516542, acc 0.78125, learning_rate 0.00201657\n",
      "2020-12-09T16:55:04.182682: step 532, loss 0.558406, acc 0.78125, learning_rate 0.002014\n",
      "2020-12-09T16:55:04.740047: step 533, loss 0.190134, acc 0.90625, learning_rate 0.00201144\n",
      "2020-12-09T16:55:05.302150: step 534, loss 0.437911, acc 0.75, learning_rate 0.00200888\n",
      "2020-12-09T16:55:05.880127: step 535, loss 0.574736, acc 0.6875, learning_rate 0.00200632\n",
      "2020-12-09T16:55:06.465261: step 536, loss 0.32458, acc 0.84375, learning_rate 0.00200376\n",
      "2020-12-09T16:55:07.135617: step 537, loss 0.515203, acc 0.75, learning_rate 0.00200121\n",
      "2020-12-09T16:55:07.742139: step 538, loss 0.463484, acc 0.78125, learning_rate 0.00199867\n",
      "2020-12-09T16:55:08.342329: step 539, loss 0.502841, acc 0.75, learning_rate 0.00199612\n",
      "2020-12-09T16:55:08.924101: step 540, loss 0.577259, acc 0.625, learning_rate 0.00199358\n",
      "2020-12-09T16:55:09.497547: step 541, loss 0.606858, acc 0.75, learning_rate 0.00199105\n",
      "2020-12-09T16:55:10.069080: step 542, loss 0.51198, acc 0.78125, learning_rate 0.00198851\n",
      "2020-12-09T16:55:10.644158: step 543, loss 0.522904, acc 0.75, learning_rate 0.00198598\n",
      "2020-12-09T16:55:11.281345: step 544, loss 0.708018, acc 0.625, learning_rate 0.00198346\n",
      "2020-12-09T16:55:12.013845: step 545, loss 0.594175, acc 0.8125, learning_rate 0.00198094\n",
      "2020-12-09T16:55:12.604869: step 546, loss 0.351288, acc 0.84375, learning_rate 0.00197842\n",
      "2020-12-09T16:55:13.178678: step 547, loss 0.828866, acc 0.65625, learning_rate 0.0019759\n",
      "2020-12-09T16:55:13.770152: step 548, loss 0.340009, acc 0.875, learning_rate 0.00197339\n",
      "2020-12-09T16:55:14.364931: step 549, loss 0.414393, acc 0.78125, learning_rate 0.00197088\n",
      "2020-12-09T16:55:14.933218: step 550, loss 0.403625, acc 0.84375, learning_rate 0.00196837\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:55:18.357825: step 550, loss 0.575102, acc 0.742773\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-550\n",
      "\n",
      "2020-12-09T16:55:20.003773: step 551, loss 0.437245, acc 0.8125, learning_rate 0.00196587\n",
      "2020-12-09T16:55:20.632867: step 552, loss 0.426566, acc 0.8125, learning_rate 0.00196337\n",
      "2020-12-09T16:55:21.273813: step 553, loss 0.345473, acc 0.875, learning_rate 0.00196087\n",
      "2020-12-09T16:55:21.852772: step 554, loss 0.356257, acc 0.875, learning_rate 0.00195838\n",
      "2020-12-09T16:55:22.547351: step 555, loss 0.631578, acc 0.71875, learning_rate 0.00195589\n",
      "2020-12-09T16:55:23.157285: step 556, loss 0.720011, acc 0.71875, learning_rate 0.0019534\n",
      "2020-12-09T16:55:23.798423: step 557, loss 0.560363, acc 0.78125, learning_rate 0.00195092\n",
      "2020-12-09T16:55:24.436456: step 558, loss 0.76623, acc 0.65625, learning_rate 0.00194844\n",
      "2020-12-09T16:55:25.039921: step 559, loss 0.458317, acc 0.78125, learning_rate 0.00194597\n",
      "2020-12-09T16:55:25.659916: step 560, loss 0.404851, acc 0.84375, learning_rate 0.00194349\n",
      "2020-12-09T16:55:26.257137: step 561, loss 0.445, acc 0.8125, learning_rate 0.00194102\n",
      "2020-12-09T16:55:26.854847: step 562, loss 0.721109, acc 0.6875, learning_rate 0.00193856\n",
      "2020-12-09T16:55:27.429259: step 563, loss 0.418176, acc 0.78125, learning_rate 0.0019361\n",
      "2020-12-09T16:55:28.014763: step 564, loss 0.460312, acc 0.78125, learning_rate 0.00193364\n",
      "2020-12-09T16:55:28.648773: step 565, loss 0.335758, acc 0.90625, learning_rate 0.00193118\n",
      "2020-12-09T16:55:29.263575: step 566, loss 0.416865, acc 0.84375, learning_rate 0.00192873\n",
      "2020-12-09T16:55:29.853873: step 567, loss 0.498032, acc 0.78125, learning_rate 0.00192628\n",
      "2020-12-09T16:55:30.483034: step 568, loss 0.420722, acc 0.84375, learning_rate 0.00192383\n",
      "2020-12-09T16:55:31.158995: step 569, loss 0.3723, acc 0.75, learning_rate 0.00192139\n",
      "2020-12-09T16:55:31.864527: step 570, loss 0.549673, acc 0.71875, learning_rate 0.00191895\n",
      "2020-12-09T16:55:32.459310: step 571, loss 0.622888, acc 0.75, learning_rate 0.00191651\n",
      "2020-12-09T16:55:33.056349: step 572, loss 0.615968, acc 0.8125, learning_rate 0.00191408\n",
      "2020-12-09T16:55:33.692351: step 573, loss 0.593389, acc 0.78125, learning_rate 0.00191165\n",
      "2020-12-09T16:55:34.288852: step 574, loss 0.569808, acc 0.78125, learning_rate 0.00190922\n",
      "2020-12-09T16:55:34.905414: step 575, loss 0.604577, acc 0.78125, learning_rate 0.0019068\n",
      "2020-12-09T16:55:35.494822: step 576, loss 0.522892, acc 0.8125, learning_rate 0.00190438\n",
      "2020-12-09T16:55:36.193855: step 577, loss 0.551591, acc 0.71875, learning_rate 0.00190196\n",
      "2020-12-09T16:55:36.959322: step 578, loss 0.342933, acc 0.875, learning_rate 0.00189955\n",
      "2020-12-09T16:55:37.738323: step 579, loss 0.364298, acc 0.875, learning_rate 0.00189714\n",
      "2020-12-09T16:55:38.448388: step 580, loss 0.455776, acc 0.8125, learning_rate 0.00189473\n",
      "2020-12-09T16:55:39.034509: step 581, loss 0.394475, acc 0.90625, learning_rate 0.00189232\n",
      "2020-12-09T16:55:39.630008: step 582, loss 0.472787, acc 0.78125, learning_rate 0.00188992\n",
      "2020-12-09T16:55:40.207009: step 583, loss 0.431132, acc 0.75, learning_rate 0.00188753\n",
      "2020-12-09T16:55:40.775242: step 584, loss 0.458615, acc 0.78125, learning_rate 0.00188513\n",
      "2020-12-09T16:55:41.444703: step 585, loss 0.52903, acc 0.8125, learning_rate 0.00188274\n",
      "2020-12-09T16:55:42.020408: step 586, loss 0.680218, acc 0.75, learning_rate 0.00188035\n",
      "2020-12-09T16:55:42.655519: step 587, loss 0.606143, acc 0.75, learning_rate 0.00187797\n",
      "2020-12-09T16:55:43.490361: step 588, loss 0.560728, acc 0.78125, learning_rate 0.00187558\n",
      "2020-12-09T16:55:44.066003: step 589, loss 0.339204, acc 0.84375, learning_rate 0.00187321\n",
      "2020-12-09T16:55:44.697020: step 590, loss 0.527253, acc 0.875, learning_rate 0.00187083\n",
      "2020-12-09T16:55:45.294124: step 591, loss 0.363458, acc 0.90625, learning_rate 0.00186846\n",
      "2020-12-09T16:55:45.879128: step 592, loss 0.41822, acc 0.84375, learning_rate 0.00186609\n",
      "2020-12-09T16:55:46.484761: step 593, loss 0.506468, acc 0.75, learning_rate 0.00186372\n",
      "2020-12-09T16:55:47.074842: step 594, loss 0.513242, acc 0.8125, learning_rate 0.00186136\n",
      "2020-12-09T16:55:47.670900: step 595, loss 0.57859, acc 0.75, learning_rate 0.001859\n",
      "2020-12-09T16:55:48.541398: step 596, loss 0.348314, acc 0.8125, learning_rate 0.00185665\n",
      "2020-12-09T16:55:49.148035: step 597, loss 0.297361, acc 0.875, learning_rate 0.00185429\n",
      "2020-12-09T16:55:49.407032: step 598, loss 0.382789, acc 0.846154, learning_rate 0.00185194\n",
      "2020-12-09T16:55:50.014465: step 599, loss 0.377083, acc 0.875, learning_rate 0.0018496\n",
      "2020-12-09T16:55:50.623806: step 600, loss 0.469881, acc 0.8125, learning_rate 0.00184725\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:55:53.959451: step 600, loss 0.570085, acc 0.747801\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-600\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:55:55.516984: step 601, loss 0.356824, acc 0.875, learning_rate 0.00184491\n",
      "2020-12-09T16:55:56.098374: step 602, loss 0.391314, acc 0.8125, learning_rate 0.00184257\n",
      "2020-12-09T16:55:56.691315: step 603, loss 0.254993, acc 0.875, learning_rate 0.00184024\n",
      "2020-12-09T16:55:57.254101: step 604, loss 0.282315, acc 0.875, learning_rate 0.00183791\n",
      "2020-12-09T16:55:57.920601: step 605, loss 0.466312, acc 0.75, learning_rate 0.00183558\n",
      "2020-12-09T16:55:58.920605: step 606, loss 0.213639, acc 0.9375, learning_rate 0.00183326\n",
      "2020-12-09T16:55:59.572522: step 607, loss 0.171726, acc 0.9375, learning_rate 0.00183093\n",
      "2020-12-09T16:56:00.142859: step 608, loss 0.212872, acc 0.96875, learning_rate 0.00182862\n",
      "2020-12-09T16:56:00.740423: step 609, loss 0.203886, acc 0.96875, learning_rate 0.0018263\n",
      "2020-12-09T16:56:01.325279: step 610, loss 0.299151, acc 0.78125, learning_rate 0.00182399\n",
      "2020-12-09T16:56:01.893236: step 611, loss 0.461927, acc 0.84375, learning_rate 0.00182168\n",
      "2020-12-09T16:56:02.493241: step 612, loss 0.500218, acc 0.6875, learning_rate 0.00181937\n",
      "2020-12-09T16:56:03.077340: step 613, loss 0.39281, acc 0.75, learning_rate 0.00181707\n",
      "2020-12-09T16:56:03.645999: step 614, loss 0.343192, acc 0.8125, learning_rate 0.00181477\n",
      "2020-12-09T16:56:04.229685: step 615, loss 0.303506, acc 0.84375, learning_rate 0.00181247\n",
      "2020-12-09T16:56:04.799309: step 616, loss 0.511544, acc 0.71875, learning_rate 0.00181018\n",
      "2020-12-09T16:56:05.381602: step 617, loss 0.389434, acc 0.78125, learning_rate 0.00180789\n",
      "2020-12-09T16:56:05.951050: step 618, loss 0.233962, acc 0.90625, learning_rate 0.0018056\n",
      "2020-12-09T16:56:06.542079: step 619, loss 0.493322, acc 0.8125, learning_rate 0.00180331\n",
      "2020-12-09T16:56:07.135756: step 620, loss 0.31543, acc 0.84375, learning_rate 0.00180103\n",
      "2020-12-09T16:56:07.775719: step 621, loss 0.472566, acc 0.78125, learning_rate 0.00179875\n",
      "2020-12-09T16:56:08.410750: step 622, loss 0.328613, acc 0.90625, learning_rate 0.00179648\n",
      "2020-12-09T16:56:08.996099: step 623, loss 0.395798, acc 0.78125, learning_rate 0.00179421\n",
      "2020-12-09T16:56:09.668601: step 624, loss 0.246176, acc 0.90625, learning_rate 0.00179194\n",
      "2020-12-09T16:56:10.491568: step 625, loss 0.39987, acc 0.8125, learning_rate 0.00178967\n",
      "2020-12-09T16:56:11.259101: step 626, loss 0.438524, acc 0.78125, learning_rate 0.00178741\n",
      "2020-12-09T16:56:11.838569: step 627, loss 0.300518, acc 0.875, learning_rate 0.00178515\n",
      "2020-12-09T16:56:12.412941: step 628, loss 0.267091, acc 0.875, learning_rate 0.00178289\n",
      "2020-12-09T16:56:13.019802: step 629, loss 0.497156, acc 0.78125, learning_rate 0.00178063\n",
      "2020-12-09T16:56:13.614338: step 630, loss 0.416207, acc 0.78125, learning_rate 0.00177838\n",
      "2020-12-09T16:56:14.301031: step 631, loss 0.437415, acc 0.875, learning_rate 0.00177613\n",
      "2020-12-09T16:56:15.015579: step 632, loss 0.37387, acc 0.84375, learning_rate 0.00177389\n",
      "2020-12-09T16:56:15.637692: step 633, loss 0.300845, acc 0.875, learning_rate 0.00177165\n",
      "2020-12-09T16:56:16.210950: step 634, loss 0.173632, acc 0.9375, learning_rate 0.00176941\n",
      "2020-12-09T16:56:16.786638: step 635, loss 0.195437, acc 0.9375, learning_rate 0.00176717\n",
      "2020-12-09T16:56:17.355113: step 636, loss 0.384739, acc 0.8125, learning_rate 0.00176494\n",
      "2020-12-09T16:56:17.936562: step 637, loss 0.291365, acc 0.84375, learning_rate 0.00176271\n",
      "2020-12-09T16:56:18.513760: step 638, loss 0.181154, acc 0.9375, learning_rate 0.00176048\n",
      "2020-12-09T16:56:19.121935: step 639, loss 0.189017, acc 0.9375, learning_rate 0.00175826\n",
      "2020-12-09T16:56:19.695915: step 640, loss 0.312077, acc 0.8125, learning_rate 0.00175603\n",
      "2020-12-09T16:56:20.275763: step 641, loss 0.478632, acc 0.84375, learning_rate 0.00175382\n",
      "2020-12-09T16:56:20.855357: step 642, loss 0.209663, acc 0.875, learning_rate 0.0017516\n",
      "2020-12-09T16:56:21.435730: step 643, loss 0.252683, acc 0.90625, learning_rate 0.00174939\n",
      "2020-12-09T16:56:22.005150: step 644, loss 0.487132, acc 0.8125, learning_rate 0.00174718\n",
      "2020-12-09T16:56:22.592105: step 645, loss 0.205009, acc 0.9375, learning_rate 0.00174497\n",
      "2020-12-09T16:56:23.201611: step 646, loss 0.432073, acc 0.78125, learning_rate 0.00174277\n",
      "2020-12-09T16:56:23.776945: step 647, loss 0.3751, acc 0.84375, learning_rate 0.00174057\n",
      "2020-12-09T16:56:24.357366: step 648, loss 0.302406, acc 0.875, learning_rate 0.00173837\n",
      "2020-12-09T16:56:24.982272: step 649, loss 0.277158, acc 0.875, learning_rate 0.00173618\n",
      "2020-12-09T16:56:25.820446: step 650, loss 0.240596, acc 0.9375, learning_rate 0.00173398\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:56:29.476851: step 650, loss 0.616106, acc 0.745287\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-650\n",
      "\n",
      "2020-12-09T16:56:31.270701: step 651, loss 0.272838, acc 0.84375, learning_rate 0.0017318\n",
      "2020-12-09T16:56:31.837159: step 652, loss 0.668366, acc 0.65625, learning_rate 0.00172961\n",
      "2020-12-09T16:56:32.422077: step 653, loss 0.242054, acc 0.84375, learning_rate 0.00172743\n",
      "2020-12-09T16:56:32.995983: step 654, loss 0.155937, acc 0.96875, learning_rate 0.00172525\n",
      "2020-12-09T16:56:33.595265: step 655, loss 0.239604, acc 0.8125, learning_rate 0.00172307\n",
      "2020-12-09T16:56:34.164217: step 656, loss 0.333143, acc 0.78125, learning_rate 0.0017209\n",
      "2020-12-09T16:56:34.735288: step 657, loss 0.207167, acc 0.9375, learning_rate 0.00171872\n",
      "2020-12-09T16:56:35.317338: step 658, loss 0.640907, acc 0.84375, learning_rate 0.00171656\n",
      "2020-12-09T16:56:35.891873: step 659, loss 0.327111, acc 0.84375, learning_rate 0.00171439\n",
      "2020-12-09T16:56:36.485878: step 660, loss 0.211128, acc 0.90625, learning_rate 0.00171223\n",
      "2020-12-09T16:56:37.070976: step 661, loss 0.310573, acc 0.8125, learning_rate 0.00171007\n",
      "2020-12-09T16:56:37.670608: step 662, loss 0.18949, acc 0.9375, learning_rate 0.00170791\n",
      "2020-12-09T16:56:38.282570: step 663, loss 0.315848, acc 0.875, learning_rate 0.00170576\n",
      "2020-12-09T16:56:38.877617: step 664, loss 0.76496, acc 0.78125, learning_rate 0.00170361\n",
      "2020-12-09T16:56:39.663040: step 665, loss 0.414322, acc 0.78125, learning_rate 0.00170146\n",
      "2020-12-09T16:56:40.413570: step 666, loss 0.283895, acc 0.9375, learning_rate 0.00169931\n",
      "2020-12-09T16:56:41.131844: step 667, loss 0.185823, acc 0.875, learning_rate 0.00169717\n",
      "2020-12-09T16:56:41.760179: step 668, loss 0.256715, acc 0.8125, learning_rate 0.00169503\n",
      "2020-12-09T16:56:42.379656: step 669, loss 0.293733, acc 0.875, learning_rate 0.00169289\n",
      "2020-12-09T16:56:42.985960: step 670, loss 0.422703, acc 0.78125, learning_rate 0.00169076\n",
      "2020-12-09T16:56:43.634627: step 671, loss 0.347653, acc 0.8125, learning_rate 0.00168863\n",
      "2020-12-09T16:56:44.297597: step 672, loss 0.265336, acc 0.875, learning_rate 0.0016865\n",
      "2020-12-09T16:56:45.059693: step 673, loss 0.279193, acc 0.90625, learning_rate 0.00168438\n",
      "2020-12-09T16:56:45.683032: step 674, loss 0.271279, acc 0.9375, learning_rate 0.00168225\n",
      "2020-12-09T16:56:46.284104: step 675, loss 0.397217, acc 0.84375, learning_rate 0.00168013\n",
      "2020-12-09T16:56:46.977203: step 676, loss 0.304906, acc 0.84375, learning_rate 0.00167802\n",
      "2020-12-09T16:56:47.593283: step 677, loss 0.324179, acc 0.90625, learning_rate 0.0016759\n",
      "2020-12-09T16:56:48.199279: step 678, loss 0.285288, acc 0.8125, learning_rate 0.00167379\n",
      "2020-12-09T16:56:48.777316: step 679, loss 0.45871, acc 0.78125, learning_rate 0.00167169\n",
      "2020-12-09T16:56:49.366192: step 680, loss 0.37599, acc 0.84375, learning_rate 0.00166958\n",
      "2020-12-09T16:56:49.937756: step 681, loss 0.237904, acc 0.90625, learning_rate 0.00166748\n",
      "2020-12-09T16:56:50.518709: step 682, loss 0.247896, acc 0.90625, learning_rate 0.00166538\n",
      "2020-12-09T16:56:51.110608: step 683, loss 0.290051, acc 0.875, learning_rate 0.00166328\n",
      "2020-12-09T16:56:51.722637: step 684, loss 0.22589, acc 0.9375, learning_rate 0.00166119\n",
      "2020-12-09T16:56:52.326136: step 685, loss 0.161371, acc 1, learning_rate 0.0016591\n",
      "2020-12-09T16:56:52.952602: step 686, loss 0.491779, acc 0.78125, learning_rate 0.00165701\n",
      "2020-12-09T16:56:53.574493: step 687, loss 0.367224, acc 0.84375, learning_rate 0.00165492\n",
      "2020-12-09T16:56:54.198489: step 688, loss 0.328512, acc 0.84375, learning_rate 0.00165284\n",
      "2020-12-09T16:56:54.801490: step 689, loss 0.317182, acc 0.9375, learning_rate 0.00165076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:56:55.420491: step 690, loss 0.242797, acc 0.90625, learning_rate 0.00164868\n",
      "2020-12-09T16:56:56.035236: step 691, loss 0.662386, acc 0.6875, learning_rate 0.00164661\n",
      "2020-12-09T16:56:56.640191: step 692, loss 0.280376, acc 0.875, learning_rate 0.00164453\n",
      "2020-12-09T16:56:57.243822: step 693, loss 0.298009, acc 0.90625, learning_rate 0.00164247\n",
      "2020-12-09T16:56:57.842798: step 694, loss 0.325117, acc 0.875, learning_rate 0.0016404\n",
      "2020-12-09T16:56:58.422297: step 695, loss 0.3977, acc 0.75, learning_rate 0.00163834\n",
      "2020-12-09T16:56:59.010484: step 696, loss 0.336339, acc 0.9375, learning_rate 0.00163628\n",
      "2020-12-09T16:56:59.611691: step 697, loss 0.219653, acc 0.9375, learning_rate 0.00163422\n",
      "2020-12-09T16:57:00.194693: step 698, loss 0.245681, acc 0.84375, learning_rate 0.00163216\n",
      "2020-12-09T16:57:00.787694: step 699, loss 0.316772, acc 0.84375, learning_rate 0.00163011\n",
      "2020-12-09T16:57:01.383761: step 700, loss 0.218348, acc 0.84375, learning_rate 0.00162806\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:57:04.764191: step 700, loss 0.62779, acc 0.736908\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-700\n",
      "\n",
      "2020-12-09T16:57:06.336713: step 701, loss 0.641253, acc 0.71875, learning_rate 0.00162601\n",
      "2020-12-09T16:57:06.960095: step 702, loss 0.499251, acc 0.78125, learning_rate 0.00162397\n",
      "2020-12-09T16:57:07.543741: step 703, loss 0.248413, acc 0.9375, learning_rate 0.00162193\n",
      "2020-12-09T16:57:08.258741: step 704, loss 0.357584, acc 0.84375, learning_rate 0.00161989\n",
      "2020-12-09T16:57:09.356653: step 705, loss 0.407175, acc 0.8125, learning_rate 0.00161785\n",
      "2020-12-09T16:57:10.013155: step 706, loss 0.400953, acc 0.8125, learning_rate 0.00161582\n",
      "2020-12-09T16:57:10.820529: step 707, loss 0.213127, acc 0.90625, learning_rate 0.00161379\n",
      "2020-12-09T16:57:11.446600: step 708, loss 0.380073, acc 0.875, learning_rate 0.00161176\n",
      "2020-12-09T16:57:12.032533: step 709, loss 0.493779, acc 0.78125, learning_rate 0.00160974\n",
      "2020-12-09T16:57:12.725533: step 710, loss 0.433487, acc 0.78125, learning_rate 0.00160771\n",
      "2020-12-09T16:57:13.374606: step 711, loss 0.328339, acc 0.8125, learning_rate 0.00160569\n",
      "2020-12-09T16:57:13.975134: step 712, loss 0.203739, acc 0.96875, learning_rate 0.00160368\n",
      "2020-12-09T16:57:14.603637: step 713, loss 0.274446, acc 0.90625, learning_rate 0.00160166\n",
      "2020-12-09T16:57:15.228892: step 714, loss 0.631975, acc 0.71875, learning_rate 0.00159965\n",
      "2020-12-09T16:57:15.832394: step 715, loss 0.372103, acc 0.8125, learning_rate 0.00159764\n",
      "2020-12-09T16:57:16.472361: step 716, loss 0.193046, acc 0.9375, learning_rate 0.00159564\n",
      "2020-12-09T16:57:17.058359: step 717, loss 0.176614, acc 0.90625, learning_rate 0.00159363\n",
      "2020-12-09T16:57:17.630511: step 718, loss 0.433896, acc 0.78125, learning_rate 0.00159163\n",
      "2020-12-09T16:57:18.203868: step 719, loss 0.301329, acc 0.875, learning_rate 0.00158963\n",
      "2020-12-09T16:57:18.790176: step 720, loss 0.332354, acc 0.90625, learning_rate 0.00158764\n",
      "2020-12-09T16:57:19.509899: step 721, loss 0.245431, acc 0.84375, learning_rate 0.00158565\n",
      "2020-12-09T16:57:20.224366: step 722, loss 0.398394, acc 0.84375, learning_rate 0.00158366\n",
      "2020-12-09T16:57:20.834329: step 723, loss 0.24631, acc 0.9375, learning_rate 0.00158167\n",
      "2020-12-09T16:57:21.437519: step 724, loss 0.46774, acc 0.8125, learning_rate 0.00157968\n",
      "2020-12-09T16:57:22.088515: step 725, loss 0.490117, acc 0.875, learning_rate 0.0015777\n",
      "2020-12-09T16:57:22.747519: step 726, loss 0.27202, acc 0.90625, learning_rate 0.00157572\n",
      "2020-12-09T16:57:23.374736: step 727, loss 0.407886, acc 0.84375, learning_rate 0.00157374\n",
      "2020-12-09T16:57:23.979709: step 728, loss 0.210164, acc 0.90625, learning_rate 0.00157177\n",
      "2020-12-09T16:57:24.657756: step 729, loss 0.365281, acc 0.84375, learning_rate 0.0015698\n",
      "2020-12-09T16:57:25.453392: step 730, loss 0.335918, acc 0.78125, learning_rate 0.00156783\n",
      "2020-12-09T16:57:26.116393: step 731, loss 0.212827, acc 0.90625, learning_rate 0.00156586\n",
      "2020-12-09T16:57:26.722592: step 732, loss 0.385386, acc 0.8125, learning_rate 0.0015639\n",
      "2020-12-09T16:57:27.332438: step 733, loss 0.233015, acc 0.90625, learning_rate 0.00156194\n",
      "2020-12-09T16:57:27.912872: step 734, loss 0.428547, acc 0.71875, learning_rate 0.00155998\n",
      "2020-12-09T16:57:28.474877: step 735, loss 0.309176, acc 0.84375, learning_rate 0.00155803\n",
      "2020-12-09T16:57:29.058749: step 736, loss 0.367533, acc 0.84375, learning_rate 0.00155607\n",
      "2020-12-09T16:57:29.659365: step 737, loss 0.239719, acc 0.90625, learning_rate 0.00155412\n",
      "2020-12-09T16:57:30.391682: step 738, loss 0.16797, acc 0.90625, learning_rate 0.00155217\n",
      "2020-12-09T16:57:31.060202: step 739, loss 0.380481, acc 0.84375, learning_rate 0.00155023\n",
      "2020-12-09T16:57:31.672674: step 740, loss 0.252013, acc 0.9375, learning_rate 0.00154829\n",
      "2020-12-09T16:57:32.260649: step 741, loss 0.39306, acc 0.84375, learning_rate 0.00154635\n",
      "2020-12-09T16:57:32.845630: step 742, loss 0.242717, acc 0.875, learning_rate 0.00154441\n",
      "2020-12-09T16:57:33.419653: step 743, loss 0.446663, acc 0.78125, learning_rate 0.00154247\n",
      "2020-12-09T16:57:34.002635: step 744, loss 0.436626, acc 0.84375, learning_rate 0.00154054\n",
      "2020-12-09T16:57:34.580597: step 745, loss 0.406871, acc 0.8125, learning_rate 0.00153861\n",
      "2020-12-09T16:57:35.171636: step 746, loss 0.396704, acc 0.875, learning_rate 0.00153668\n",
      "2020-12-09T16:57:35.881149: step 747, loss 0.420905, acc 0.78125, learning_rate 0.00153476\n",
      "2020-12-09T16:57:36.897105: step 748, loss 0.266315, acc 0.90625, learning_rate 0.00153284\n",
      "2020-12-09T16:57:37.785606: step 749, loss 0.25855, acc 0.90625, learning_rate 0.00153092\n",
      "2020-12-09T16:57:38.440470: step 750, loss 0.332497, acc 0.78125, learning_rate 0.001529\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:57:42.374392: step 750, loss 0.626374, acc 0.750733\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-750\n",
      "\n",
      "2020-12-09T16:57:44.103482: step 751, loss 0.318239, acc 0.90625, learning_rate 0.00152709\n",
      "2020-12-09T16:57:44.740936: step 752, loss 0.349335, acc 0.78125, learning_rate 0.00152518\n",
      "2020-12-09T16:57:45.405733: step 753, loss 0.195154, acc 0.9375, learning_rate 0.00152327\n",
      "2020-12-09T16:57:46.078235: step 754, loss 0.392768, acc 0.78125, learning_rate 0.00152136\n",
      "2020-12-09T16:57:46.829263: step 755, loss 0.210111, acc 0.90625, learning_rate 0.00151946\n",
      "2020-12-09T16:57:47.550752: step 756, loss 0.699541, acc 0.71875, learning_rate 0.00151755\n",
      "2020-12-09T16:57:48.214219: step 757, loss 0.249634, acc 0.84375, learning_rate 0.00151566\n",
      "2020-12-09T16:57:48.835194: step 758, loss 0.285316, acc 0.90625, learning_rate 0.00151376\n",
      "2020-12-09T16:57:49.548191: step 759, loss 0.304862, acc 0.90625, learning_rate 0.00151187\n",
      "2020-12-09T16:57:50.168922: step 760, loss 0.223902, acc 0.875, learning_rate 0.00150997\n",
      "2020-12-09T16:57:50.833889: step 761, loss 0.368799, acc 0.8125, learning_rate 0.00150809\n",
      "2020-12-09T16:57:51.627367: step 762, loss 0.26341, acc 0.84375, learning_rate 0.0015062\n",
      "2020-12-09T16:57:52.236311: step 763, loss 0.222739, acc 0.875, learning_rate 0.00150432\n",
      "2020-12-09T16:57:53.369805: step 764, loss 0.451309, acc 0.875, learning_rate 0.00150243\n",
      "2020-12-09T16:57:54.181577: step 765, loss 0.331484, acc 0.8125, learning_rate 0.00150056\n",
      "2020-12-09T16:57:54.758083: step 766, loss 0.422439, acc 0.84375, learning_rate 0.00149868\n",
      "2020-12-09T16:57:55.522735: step 767, loss 0.239277, acc 0.90625, learning_rate 0.00149681\n",
      "2020-12-09T16:57:56.397242: step 768, loss 0.435078, acc 0.84375, learning_rate 0.00149494\n",
      "2020-12-09T16:57:57.183756: step 769, loss 0.227756, acc 0.90625, learning_rate 0.00149307\n",
      "2020-12-09T16:57:57.946226: step 770, loss 0.348321, acc 0.90625, learning_rate 0.0014912\n",
      "2020-12-09T16:57:58.707904: step 771, loss 0.234712, acc 0.875, learning_rate 0.00148934\n",
      "2020-12-09T16:57:59.614936: step 772, loss 0.324291, acc 0.875, learning_rate 0.00148748\n",
      "2020-12-09T16:58:00.283386: step 773, loss 0.423559, acc 0.875, learning_rate 0.00148562\n",
      "2020-12-09T16:58:00.906268: step 774, loss 0.26578, acc 0.84375, learning_rate 0.00148376\n",
      "2020-12-09T16:58:01.565769: step 775, loss 0.183986, acc 0.84375, learning_rate 0.00148191\n",
      "2020-12-09T16:58:02.160271: step 776, loss 0.206001, acc 0.9375, learning_rate 0.00148006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:58:02.764803: step 777, loss 0.353838, acc 0.84375, learning_rate 0.00147821\n",
      "2020-12-09T16:58:03.499273: step 778, loss 0.29247, acc 0.875, learning_rate 0.00147636\n",
      "2020-12-09T16:58:04.166810: step 779, loss 0.22753, acc 0.875, learning_rate 0.00147452\n",
      "2020-12-09T16:58:04.834770: step 780, loss 0.312543, acc 0.90625, learning_rate 0.00147268\n",
      "2020-12-09T16:58:05.534747: step 781, loss 0.679692, acc 0.75, learning_rate 0.00147084\n",
      "2020-12-09T16:58:06.254717: step 782, loss 0.316742, acc 0.84375, learning_rate 0.001469\n",
      "2020-12-09T16:58:07.021638: step 783, loss 0.515856, acc 0.78125, learning_rate 0.00146717\n",
      "2020-12-09T16:58:07.881675: step 784, loss 0.565182, acc 0.8125, learning_rate 0.00146534\n",
      "2020-12-09T16:58:08.553059: step 785, loss 0.334563, acc 0.78125, learning_rate 0.00146351\n",
      "2020-12-09T16:58:09.207563: step 786, loss 0.127365, acc 1, learning_rate 0.00146168\n",
      "2020-12-09T16:58:09.838224: step 787, loss 0.290924, acc 0.84375, learning_rate 0.00145986\n",
      "2020-12-09T16:58:10.476975: step 788, loss 0.29054, acc 0.875, learning_rate 0.00145804\n",
      "2020-12-09T16:58:11.469482: step 789, loss 0.440454, acc 0.84375, learning_rate 0.00145622\n",
      "2020-12-09T16:58:12.171726: step 790, loss 0.332821, acc 0.84375, learning_rate 0.0014544\n",
      "2020-12-09T16:58:13.075636: step 791, loss 0.622604, acc 0.8125, learning_rate 0.00145258\n",
      "2020-12-09T16:58:13.702640: step 792, loss 0.364911, acc 0.84375, learning_rate 0.00145077\n",
      "2020-12-09T16:58:14.323842: step 793, loss 0.312894, acc 0.875, learning_rate 0.00144896\n",
      "2020-12-09T16:58:15.122339: step 794, loss 0.274295, acc 0.875, learning_rate 0.00144716\n",
      "2020-12-09T16:58:15.715949: step 795, loss 0.333867, acc 0.84375, learning_rate 0.00144535\n",
      "2020-12-09T16:58:16.345646: step 796, loss 0.453264, acc 0.8125, learning_rate 0.00144355\n",
      "2020-12-09T16:58:16.950471: step 797, loss 0.313367, acc 0.875, learning_rate 0.00144175\n",
      "2020-12-09T16:58:17.548940: step 798, loss 0.206181, acc 0.9375, learning_rate 0.00143995\n",
      "2020-12-09T16:58:18.190763: step 799, loss 0.421691, acc 0.75, learning_rate 0.00143816\n",
      "2020-12-09T16:58:18.821059: step 800, loss 0.487824, acc 0.84375, learning_rate 0.00143637\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:58:23.170370: step 800, loss 0.618281, acc 0.745287\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-800\n",
      "\n",
      "2020-12-09T16:58:24.717039: step 801, loss 0.695016, acc 0.71875, learning_rate 0.00143458\n",
      "2020-12-09T16:58:25.363534: step 802, loss 0.499227, acc 0.875, learning_rate 0.00143279\n",
      "2020-12-09T16:58:25.962829: step 803, loss 0.217056, acc 0.84375, learning_rate 0.001431\n",
      "2020-12-09T16:58:26.599641: step 804, loss 0.205006, acc 0.90625, learning_rate 0.00142922\n",
      "2020-12-09T16:58:27.339643: step 805, loss 0.346108, acc 0.78125, learning_rate 0.00142744\n",
      "2020-12-09T16:58:27.930138: step 806, loss 0.42745, acc 0.84375, learning_rate 0.00142566\n",
      "2020-12-09T16:58:28.521483: step 807, loss 0.303098, acc 0.875, learning_rate 0.00142388\n",
      "2020-12-09T16:58:29.130600: step 808, loss 0.196843, acc 0.96875, learning_rate 0.00142211\n",
      "2020-12-09T16:58:29.812826: step 809, loss 0.266187, acc 0.90625, learning_rate 0.00142034\n",
      "2020-12-09T16:58:30.443352: step 810, loss 0.347364, acc 0.84375, learning_rate 0.00141857\n",
      "2020-12-09T16:58:31.070169: step 811, loss 0.419494, acc 0.90625, learning_rate 0.00141681\n",
      "2020-12-09T16:58:31.654174: step 812, loss 0.242501, acc 0.96875, learning_rate 0.00141504\n",
      "2020-12-09T16:58:32.245143: step 813, loss 0.205726, acc 0.90625, learning_rate 0.00141328\n",
      "2020-12-09T16:58:32.858190: step 814, loss 0.363153, acc 0.8125, learning_rate 0.00141152\n",
      "2020-12-09T16:58:33.443649: step 815, loss 0.217078, acc 0.875, learning_rate 0.00140976\n",
      "2020-12-09T16:58:34.015493: step 816, loss 0.383698, acc 0.78125, learning_rate 0.00140801\n",
      "2020-12-09T16:58:34.592478: step 817, loss 0.0797549, acc 0.96875, learning_rate 0.00140626\n",
      "2020-12-09T16:58:35.262471: step 818, loss 0.26853, acc 0.875, learning_rate 0.00140451\n",
      "2020-12-09T16:58:35.879012: step 819, loss 0.435376, acc 0.8125, learning_rate 0.00140276\n",
      "2020-12-09T16:58:36.469057: step 820, loss 0.179591, acc 0.96875, learning_rate 0.00140101\n",
      "2020-12-09T16:58:37.099122: step 821, loss 0.276069, acc 0.8125, learning_rate 0.00139927\n",
      "2020-12-09T16:58:37.682588: step 822, loss 0.354733, acc 0.875, learning_rate 0.00139753\n",
      "2020-12-09T16:58:38.267493: step 823, loss 0.393342, acc 0.875, learning_rate 0.00139579\n",
      "2020-12-09T16:58:38.871758: step 824, loss 0.375818, acc 0.78125, learning_rate 0.00139406\n",
      "2020-12-09T16:58:39.453103: step 825, loss 0.165363, acc 0.9375, learning_rate 0.00139232\n",
      "2020-12-09T16:58:40.034109: step 826, loss 0.388764, acc 0.84375, learning_rate 0.00139059\n",
      "2020-12-09T16:58:40.601935: step 827, loss 0.288997, acc 0.84375, learning_rate 0.00138886\n",
      "2020-12-09T16:58:41.189737: step 828, loss 0.251127, acc 0.875, learning_rate 0.00138714\n",
      "2020-12-09T16:58:41.775188: step 829, loss 0.266603, acc 0.875, learning_rate 0.00138541\n",
      "2020-12-09T16:58:42.374489: step 830, loss 0.229612, acc 0.90625, learning_rate 0.00138369\n",
      "2020-12-09T16:58:42.945662: step 831, loss 0.368396, acc 0.78125, learning_rate 0.00138197\n",
      "2020-12-09T16:58:43.503669: step 832, loss 0.309446, acc 0.8125, learning_rate 0.00138025\n",
      "2020-12-09T16:58:44.076706: step 833, loss 0.3739, acc 0.875, learning_rate 0.00137854\n",
      "2020-12-09T16:58:44.691771: step 834, loss 0.437435, acc 0.84375, learning_rate 0.00137683\n",
      "2020-12-09T16:58:45.351770: step 835, loss 0.532871, acc 0.84375, learning_rate 0.00137512\n",
      "2020-12-09T16:58:46.124241: step 836, loss 0.208035, acc 0.9375, learning_rate 0.00137341\n",
      "2020-12-09T16:58:47.037334: step 837, loss 0.182141, acc 0.9375, learning_rate 0.0013717\n",
      "2020-12-09T16:58:47.987054: step 838, loss 0.151407, acc 0.96875, learning_rate 0.00137\n",
      "2020-12-09T16:58:48.574055: step 839, loss 0.301023, acc 0.90625, learning_rate 0.0013683\n",
      "2020-12-09T16:58:49.163685: step 840, loss 0.45863, acc 0.8125, learning_rate 0.0013666\n",
      "2020-12-09T16:58:49.773703: step 841, loss 0.388897, acc 0.78125, learning_rate 0.0013649\n",
      "2020-12-09T16:58:50.432205: step 842, loss 0.272341, acc 0.84375, learning_rate 0.00136321\n",
      "2020-12-09T16:58:51.066621: step 843, loss 0.345556, acc 0.875, learning_rate 0.00136152\n",
      "2020-12-09T16:58:51.722142: step 844, loss 0.144854, acc 0.96875, learning_rate 0.00135983\n",
      "2020-12-09T16:58:52.345739: step 845, loss 0.192754, acc 0.9375, learning_rate 0.00135814\n",
      "2020-12-09T16:58:52.955169: step 846, loss 0.226535, acc 0.90625, learning_rate 0.00135645\n",
      "2020-12-09T16:58:53.576377: step 847, loss 0.123878, acc 0.96875, learning_rate 0.00135477\n",
      "2020-12-09T16:58:54.153373: step 848, loss 0.335349, acc 0.8125, learning_rate 0.00135309\n",
      "2020-12-09T16:58:54.773633: step 849, loss 0.363874, acc 0.84375, learning_rate 0.00135141\n",
      "2020-12-09T16:58:55.388123: step 850, loss 0.349023, acc 0.875, learning_rate 0.00134973\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:58:59.171205: step 850, loss 0.644803, acc 0.738584\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-850\n",
      "\n",
      "2020-12-09T16:59:00.731094: step 851, loss 0.545344, acc 0.8125, learning_rate 0.00134806\n",
      "2020-12-09T16:59:01.334862: step 852, loss 0.408438, acc 0.8125, learning_rate 0.00134639\n",
      "2020-12-09T16:59:01.936210: step 853, loss 0.229479, acc 0.96875, learning_rate 0.00134472\n",
      "2020-12-09T16:59:02.542060: step 854, loss 0.195894, acc 0.96875, learning_rate 0.00134305\n",
      "2020-12-09T16:59:03.125411: step 855, loss 0.269854, acc 0.875, learning_rate 0.00134139\n",
      "2020-12-09T16:59:03.746868: step 856, loss 0.488623, acc 0.75, learning_rate 0.00133972\n",
      "2020-12-09T16:59:04.360008: step 857, loss 0.304917, acc 0.8125, learning_rate 0.00133806\n",
      "2020-12-09T16:59:04.978819: step 858, loss 0.363754, acc 0.84375, learning_rate 0.0013364\n",
      "2020-12-09T16:59:05.579811: step 859, loss 0.409491, acc 0.8125, learning_rate 0.00133475\n",
      "2020-12-09T16:59:06.172976: step 860, loss 0.221158, acc 0.9375, learning_rate 0.00133309\n",
      "2020-12-09T16:59:06.769489: step 861, loss 0.211595, acc 0.90625, learning_rate 0.00133144\n",
      "2020-12-09T16:59:07.509949: step 862, loss 0.308746, acc 0.90625, learning_rate 0.00132979\n",
      "2020-12-09T16:59:08.275450: step 863, loss 0.190374, acc 0.9375, learning_rate 0.00132814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T16:59:08.922655: step 864, loss 0.400243, acc 0.84375, learning_rate 0.0013265\n",
      "2020-12-09T16:59:09.552678: step 865, loss 0.224878, acc 0.875, learning_rate 0.00132486\n",
      "2020-12-09T16:59:10.195204: step 866, loss 0.159728, acc 0.9375, learning_rate 0.00132322\n",
      "2020-12-09T16:59:10.800039: step 867, loss 0.212358, acc 0.9375, learning_rate 0.00132158\n",
      "2020-12-09T16:59:11.403673: step 868, loss 0.448519, acc 0.8125, learning_rate 0.00131994\n",
      "2020-12-09T16:59:12.021327: step 869, loss 0.24785, acc 0.875, learning_rate 0.00131831\n",
      "2020-12-09T16:59:12.638871: step 870, loss 0.235717, acc 0.875, learning_rate 0.00131667\n",
      "2020-12-09T16:59:13.230298: step 871, loss 0.265478, acc 0.84375, learning_rate 0.00131505\n",
      "2020-12-09T16:59:13.871762: step 872, loss 0.391451, acc 0.8125, learning_rate 0.00131342\n",
      "2020-12-09T16:59:14.601271: step 873, loss 0.456647, acc 0.71875, learning_rate 0.00131179\n",
      "2020-12-09T16:59:15.315293: step 874, loss 0.253241, acc 0.90625, learning_rate 0.00131017\n",
      "2020-12-09T16:59:16.038766: step 875, loss 0.339271, acc 0.90625, learning_rate 0.00130855\n",
      "2020-12-09T16:59:16.825263: step 876, loss 0.348231, acc 0.875, learning_rate 0.00130693\n",
      "2020-12-09T16:59:17.784762: step 877, loss 0.165311, acc 0.9375, learning_rate 0.00130531\n",
      "2020-12-09T16:59:18.417637: step 878, loss 0.106257, acc 0.96875, learning_rate 0.0013037\n",
      "2020-12-09T16:59:19.195198: step 879, loss 0.489871, acc 0.8125, learning_rate 0.00130208\n",
      "2020-12-09T16:59:19.902666: step 880, loss 0.26459, acc 0.96875, learning_rate 0.00130047\n",
      "2020-12-09T16:59:20.616398: step 881, loss 0.375911, acc 0.90625, learning_rate 0.00129887\n",
      "2020-12-09T16:59:21.375401: step 882, loss 0.2392, acc 0.875, learning_rate 0.00129726\n",
      "2020-12-09T16:59:22.306437: step 883, loss 0.317709, acc 0.84375, learning_rate 0.00129566\n",
      "2020-12-09T16:59:22.923424: step 884, loss 0.301254, acc 0.875, learning_rate 0.00129406\n",
      "2020-12-09T16:59:23.574881: step 885, loss 0.206397, acc 0.90625, learning_rate 0.00129246\n",
      "2020-12-09T16:59:24.209417: step 886, loss 0.405333, acc 0.875, learning_rate 0.00129086\n",
      "2020-12-09T16:59:24.851819: step 887, loss 0.315656, acc 0.90625, learning_rate 0.00128926\n",
      "2020-12-09T16:59:25.570089: step 888, loss 0.440243, acc 0.8125, learning_rate 0.00128767\n",
      "2020-12-09T16:59:26.268591: step 889, loss 0.194767, acc 0.90625, learning_rate 0.00128608\n",
      "2020-12-09T16:59:27.012089: step 890, loss 0.114494, acc 0.9375, learning_rate 0.00128449\n",
      "2020-12-09T16:59:27.738589: step 891, loss 0.565332, acc 0.78125, learning_rate 0.0012829\n",
      "2020-12-09T16:59:28.558589: step 892, loss 0.355507, acc 0.8125, learning_rate 0.00128132\n",
      "2020-12-09T16:59:29.367727: step 893, loss 0.375088, acc 0.8125, learning_rate 0.00127974\n",
      "2020-12-09T16:59:29.996763: step 894, loss 0.30862, acc 0.875, learning_rate 0.00127816\n",
      "2020-12-09T16:59:30.690728: step 895, loss 0.315234, acc 0.875, learning_rate 0.00127658\n",
      "2020-12-09T16:59:31.405227: step 896, loss 0.41544, acc 0.8125, learning_rate 0.001275\n",
      "2020-12-09T16:59:31.945726: step 897, loss 0.1704, acc 0.923077, learning_rate 0.00127343\n",
      "2020-12-09T16:59:32.966725: step 898, loss 0.24129, acc 0.90625, learning_rate 0.00127186\n",
      "2020-12-09T16:59:33.672761: step 899, loss 0.262357, acc 0.875, learning_rate 0.00127029\n",
      "2020-12-09T16:59:34.520756: step 900, loss 0.382864, acc 0.8125, learning_rate 0.00126872\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T16:59:38.764793: step 900, loss 0.650874, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-900\n",
      "\n",
      "2020-12-09T16:59:40.644041: step 901, loss 0.256569, acc 0.9375, learning_rate 0.00126715\n",
      "2020-12-09T16:59:41.203058: step 902, loss 0.357167, acc 0.8125, learning_rate 0.00126559\n",
      "2020-12-09T16:59:42.056403: step 903, loss 0.162169, acc 0.90625, learning_rate 0.00126403\n",
      "2020-12-09T16:59:43.094933: step 904, loss 0.205964, acc 0.96875, learning_rate 0.00126247\n",
      "2020-12-09T16:59:44.229401: step 905, loss 0.274393, acc 0.875, learning_rate 0.00126091\n",
      "2020-12-09T16:59:45.119781: step 906, loss 0.239875, acc 0.90625, learning_rate 0.00125936\n",
      "2020-12-09T16:59:45.944644: step 907, loss 0.290677, acc 0.875, learning_rate 0.0012578\n",
      "2020-12-09T16:59:46.780674: step 908, loss 0.30588, acc 0.9375, learning_rate 0.00125625\n",
      "2020-12-09T16:59:47.408255: step 909, loss 0.299649, acc 0.84375, learning_rate 0.0012547\n",
      "2020-12-09T16:59:48.157228: step 910, loss 0.178018, acc 0.9375, learning_rate 0.00125316\n",
      "2020-12-09T16:59:48.811368: step 911, loss 0.171758, acc 0.90625, learning_rate 0.00125161\n",
      "2020-12-09T16:59:49.360053: step 912, loss 0.272537, acc 0.84375, learning_rate 0.00125007\n",
      "2020-12-09T16:59:49.906786: step 913, loss 0.149613, acc 0.90625, learning_rate 0.00124853\n",
      "2020-12-09T16:59:50.464192: step 914, loss 0.172469, acc 0.9375, learning_rate 0.00124699\n",
      "2020-12-09T16:59:51.033325: step 915, loss 0.461332, acc 0.84375, learning_rate 0.00124545\n",
      "2020-12-09T16:59:51.786939: step 916, loss 0.21528, acc 0.9375, learning_rate 0.00124392\n",
      "2020-12-09T16:59:52.651474: step 917, loss 0.2534, acc 0.875, learning_rate 0.00124239\n",
      "2020-12-09T16:59:53.478882: step 918, loss 0.274977, acc 0.90625, learning_rate 0.00124086\n",
      "2020-12-09T16:59:54.486466: step 919, loss 0.136928, acc 0.96875, learning_rate 0.00123933\n",
      "2020-12-09T16:59:55.047363: step 920, loss 0.147448, acc 1, learning_rate 0.0012378\n",
      "2020-12-09T16:59:55.680644: step 921, loss 0.164542, acc 0.96875, learning_rate 0.00123628\n",
      "2020-12-09T16:59:56.359859: step 922, loss 0.268569, acc 0.84375, learning_rate 0.00123476\n",
      "2020-12-09T16:59:57.137357: step 923, loss 0.107451, acc 0.96875, learning_rate 0.00123324\n",
      "2020-12-09T16:59:57.861866: step 924, loss 0.197821, acc 0.9375, learning_rate 0.00123172\n",
      "2020-12-09T16:59:58.577357: step 925, loss 0.259106, acc 0.90625, learning_rate 0.0012302\n",
      "2020-12-09T16:59:59.371859: step 926, loss 0.421675, acc 0.875, learning_rate 0.00122869\n",
      "2020-12-09T17:00:00.086863: step 927, loss 0.1667, acc 0.9375, learning_rate 0.00122718\n",
      "2020-12-09T17:00:00.747359: step 928, loss 0.256155, acc 0.90625, learning_rate 0.00122567\n",
      "2020-12-09T17:00:01.331584: step 929, loss 0.185306, acc 0.9375, learning_rate 0.00122416\n",
      "2020-12-09T17:00:02.012083: step 930, loss 0.0530067, acc 1, learning_rate 0.00122265\n",
      "2020-12-09T17:00:02.805045: step 931, loss 0.213269, acc 0.90625, learning_rate 0.00122115\n",
      "2020-12-09T17:00:03.600540: step 932, loss 0.164353, acc 0.9375, learning_rate 0.00121965\n",
      "2020-12-09T17:00:04.724046: step 933, loss 0.161547, acc 0.9375, learning_rate 0.00121815\n",
      "2020-12-09T17:00:05.911260: step 934, loss 0.153605, acc 0.90625, learning_rate 0.00121665\n",
      "2020-12-09T17:00:06.559227: step 935, loss 0.161032, acc 0.9375, learning_rate 0.00121515\n",
      "2020-12-09T17:00:07.194225: step 936, loss 0.223235, acc 0.9375, learning_rate 0.00121366\n",
      "2020-12-09T17:00:07.806787: step 937, loss 0.348638, acc 0.90625, learning_rate 0.00121217\n",
      "2020-12-09T17:00:08.430570: step 938, loss 0.236273, acc 0.90625, learning_rate 0.00121068\n",
      "2020-12-09T17:00:09.009106: step 939, loss 0.209089, acc 0.9375, learning_rate 0.00120919\n",
      "2020-12-09T17:00:09.566223: step 940, loss 0.210503, acc 0.90625, learning_rate 0.0012077\n",
      "2020-12-09T17:00:10.120257: step 941, loss 0.499456, acc 0.8125, learning_rate 0.00120622\n",
      "2020-12-09T17:00:10.692221: step 942, loss 0.142161, acc 0.96875, learning_rate 0.00120474\n",
      "2020-12-09T17:00:11.341724: step 943, loss 0.141216, acc 1, learning_rate 0.00120326\n",
      "2020-12-09T17:00:12.012513: step 944, loss 0.219096, acc 0.9375, learning_rate 0.00120178\n",
      "2020-12-09T17:00:12.600981: step 945, loss 0.211314, acc 0.9375, learning_rate 0.00120031\n",
      "2020-12-09T17:00:13.215914: step 946, loss 0.192009, acc 0.9375, learning_rate 0.00119883\n",
      "2020-12-09T17:00:13.962235: step 947, loss 0.172561, acc 0.96875, learning_rate 0.00119736\n",
      "2020-12-09T17:00:15.111768: step 948, loss 0.183076, acc 0.9375, learning_rate 0.00119589\n",
      "2020-12-09T17:00:15.792141: step 949, loss 0.292753, acc 0.84375, learning_rate 0.00119442\n",
      "2020-12-09T17:00:16.348679: step 950, loss 0.288665, acc 0.90625, learning_rate 0.00119296\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:00:19.893376: step 950, loss 0.650704, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-950\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:00:21.476376: step 951, loss 0.236406, acc 0.9375, learning_rate 0.00119149\n",
      "2020-12-09T17:00:22.122376: step 952, loss 0.1476, acc 0.90625, learning_rate 0.00119003\n",
      "2020-12-09T17:00:22.729603: step 953, loss 0.52891, acc 0.84375, learning_rate 0.00118857\n",
      "2020-12-09T17:00:23.407105: step 954, loss 0.19584, acc 0.9375, learning_rate 0.00118711\n",
      "2020-12-09T17:00:24.072540: step 955, loss 0.126799, acc 0.96875, learning_rate 0.00118565\n",
      "2020-12-09T17:00:24.913041: step 956, loss 0.234648, acc 0.9375, learning_rate 0.0011842\n",
      "2020-12-09T17:00:25.508898: step 957, loss 0.224205, acc 0.90625, learning_rate 0.00118275\n",
      "2020-12-09T17:00:26.157397: step 958, loss 0.185048, acc 0.9375, learning_rate 0.0011813\n",
      "2020-12-09T17:00:26.712618: step 959, loss 0.493419, acc 0.71875, learning_rate 0.00117985\n",
      "2020-12-09T17:00:27.280563: step 960, loss 0.0651651, acc 0.96875, learning_rate 0.0011784\n",
      "2020-12-09T17:00:27.899546: step 961, loss 0.193521, acc 0.90625, learning_rate 0.00117696\n",
      "2020-12-09T17:00:28.604046: step 962, loss 0.201359, acc 0.96875, learning_rate 0.00117552\n",
      "2020-12-09T17:00:29.339048: step 963, loss 0.192242, acc 0.9375, learning_rate 0.00117407\n",
      "2020-12-09T17:00:30.176546: step 964, loss 0.16776, acc 0.9375, learning_rate 0.00117264\n",
      "2020-12-09T17:00:31.433050: step 965, loss 0.224351, acc 0.90625, learning_rate 0.0011712\n",
      "2020-12-09T17:00:32.211082: step 966, loss 0.134063, acc 0.96875, learning_rate 0.00116976\n",
      "2020-12-09T17:00:32.804913: step 967, loss 0.188878, acc 0.9375, learning_rate 0.00116833\n",
      "2020-12-09T17:00:33.503038: step 968, loss 0.207872, acc 0.9375, learning_rate 0.0011669\n",
      "2020-12-09T17:00:34.255526: step 969, loss 0.139675, acc 0.9375, learning_rate 0.00116547\n",
      "2020-12-09T17:00:34.929361: step 970, loss 0.231804, acc 0.9375, learning_rate 0.00116404\n",
      "2020-12-09T17:00:35.495651: step 971, loss 0.24963, acc 0.90625, learning_rate 0.00116262\n",
      "2020-12-09T17:00:36.173730: step 972, loss 0.187482, acc 0.96875, learning_rate 0.00116119\n",
      "2020-12-09T17:00:36.906228: step 973, loss 0.241076, acc 0.875, learning_rate 0.00115977\n",
      "2020-12-09T17:00:37.458504: step 974, loss 0.307544, acc 0.90625, learning_rate 0.00115835\n",
      "2020-12-09T17:00:38.015705: step 975, loss 0.331949, acc 0.875, learning_rate 0.00115694\n",
      "2020-12-09T17:00:38.959794: step 976, loss 0.182756, acc 0.90625, learning_rate 0.00115552\n",
      "2020-12-09T17:00:39.562151: step 977, loss 0.302302, acc 0.84375, learning_rate 0.00115411\n",
      "2020-12-09T17:00:40.243032: step 978, loss 0.273457, acc 0.875, learning_rate 0.00115269\n",
      "2020-12-09T17:00:40.973030: step 979, loss 0.119154, acc 0.9375, learning_rate 0.00115128\n",
      "2020-12-09T17:00:41.859447: step 980, loss 0.268993, acc 0.84375, learning_rate 0.00114988\n",
      "2020-12-09T17:00:42.516444: step 981, loss 0.210193, acc 0.90625, learning_rate 0.00114847\n",
      "2020-12-09T17:00:43.351912: step 982, loss 0.252719, acc 0.875, learning_rate 0.00114706\n",
      "2020-12-09T17:00:43.955501: step 983, loss 0.18624, acc 0.9375, learning_rate 0.00114566\n",
      "2020-12-09T17:00:44.938535: step 984, loss 0.294577, acc 0.875, learning_rate 0.00114426\n",
      "2020-12-09T17:00:45.666003: step 985, loss 0.182272, acc 0.9375, learning_rate 0.00114286\n",
      "2020-12-09T17:00:46.408533: step 986, loss 0.135395, acc 0.9375, learning_rate 0.00114147\n",
      "2020-12-09T17:00:47.108535: step 987, loss 0.26287, acc 0.90625, learning_rate 0.00114007\n",
      "2020-12-09T17:00:47.705437: step 988, loss 0.180486, acc 0.96875, learning_rate 0.00113868\n",
      "2020-12-09T17:00:48.301092: step 989, loss 0.402665, acc 0.84375, learning_rate 0.00113729\n",
      "2020-12-09T17:00:48.950921: step 990, loss 0.265992, acc 0.875, learning_rate 0.0011359\n",
      "2020-12-09T17:00:49.582431: step 991, loss 0.436119, acc 0.8125, learning_rate 0.00113451\n",
      "2020-12-09T17:00:50.148908: step 992, loss 0.180371, acc 0.9375, learning_rate 0.00113312\n",
      "2020-12-09T17:00:50.768184: step 993, loss 0.113484, acc 0.96875, learning_rate 0.00113174\n",
      "2020-12-09T17:00:51.374228: step 994, loss 0.211963, acc 0.90625, learning_rate 0.00113036\n",
      "2020-12-09T17:00:51.943358: step 995, loss 0.261795, acc 0.84375, learning_rate 0.00112898\n",
      "2020-12-09T17:00:52.499598: step 996, loss 0.212639, acc 0.84375, learning_rate 0.0011276\n",
      "2020-12-09T17:00:53.079097: step 997, loss 0.323349, acc 0.78125, learning_rate 0.00112622\n",
      "2020-12-09T17:00:53.640569: step 998, loss 0.297108, acc 0.90625, learning_rate 0.00112485\n",
      "2020-12-09T17:00:54.178756: step 999, loss 0.355001, acc 0.84375, learning_rate 0.00112347\n",
      "2020-12-09T17:00:54.731257: step 1000, loss 0.320094, acc 0.875, learning_rate 0.0011221\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:00:58.066846: step 1000, loss 0.650615, acc 0.733138\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1000\n",
      "\n",
      "2020-12-09T17:00:59.540584: step 1001, loss 0.218809, acc 0.90625, learning_rate 0.00112073\n",
      "2020-12-09T17:01:00.119674: step 1002, loss 0.175211, acc 0.9375, learning_rate 0.00111937\n",
      "2020-12-09T17:01:00.673724: step 1003, loss 0.197531, acc 0.96875, learning_rate 0.001118\n",
      "2020-12-09T17:01:01.231520: step 1004, loss 0.104279, acc 1, learning_rate 0.00111664\n",
      "2020-12-09T17:01:01.784618: step 1005, loss 0.139827, acc 0.90625, learning_rate 0.00111528\n",
      "2020-12-09T17:01:02.324706: step 1006, loss 0.249467, acc 0.875, learning_rate 0.00111392\n",
      "2020-12-09T17:01:02.891438: step 1007, loss 0.228024, acc 0.90625, learning_rate 0.00111256\n",
      "2020-12-09T17:01:03.431570: step 1008, loss 0.415164, acc 0.78125, learning_rate 0.0011112\n",
      "2020-12-09T17:01:04.000188: step 1009, loss 0.331951, acc 0.875, learning_rate 0.00110985\n",
      "2020-12-09T17:01:04.556986: step 1010, loss 0.167455, acc 0.90625, learning_rate 0.00110849\n",
      "2020-12-09T17:01:05.138520: step 1011, loss 0.229895, acc 0.875, learning_rate 0.00110714\n",
      "2020-12-09T17:01:05.706099: step 1012, loss 0.332162, acc 0.90625, learning_rate 0.00110579\n",
      "2020-12-09T17:01:06.267966: step 1013, loss 0.228079, acc 0.96875, learning_rate 0.00110445\n",
      "2020-12-09T17:01:06.816494: step 1014, loss 0.133775, acc 0.96875, learning_rate 0.0011031\n",
      "2020-12-09T17:01:07.376495: step 1015, loss 0.161728, acc 0.9375, learning_rate 0.00110176\n",
      "2020-12-09T17:01:08.026530: step 1016, loss 0.305702, acc 0.9375, learning_rate 0.00110042\n",
      "2020-12-09T17:01:08.592122: step 1017, loss 0.209123, acc 0.90625, learning_rate 0.00109908\n",
      "2020-12-09T17:01:09.161158: step 1018, loss 0.260215, acc 0.90625, learning_rate 0.00109774\n",
      "2020-12-09T17:01:10.085561: step 1019, loss 0.177225, acc 0.96875, learning_rate 0.0010964\n",
      "2020-12-09T17:01:11.099566: step 1020, loss 0.201795, acc 0.9375, learning_rate 0.00109507\n",
      "2020-12-09T17:01:12.182562: step 1021, loss 0.15622, acc 0.96875, learning_rate 0.00109373\n",
      "2020-12-09T17:01:12.907187: step 1022, loss 0.128429, acc 0.96875, learning_rate 0.0010924\n",
      "2020-12-09T17:01:13.492332: step 1023, loss 0.226267, acc 0.96875, learning_rate 0.00109107\n",
      "2020-12-09T17:01:14.056546: step 1024, loss 0.329485, acc 0.875, learning_rate 0.00108974\n",
      "2020-12-09T17:01:14.630368: step 1025, loss 0.223028, acc 0.96875, learning_rate 0.00108842\n",
      "2020-12-09T17:01:15.333869: step 1026, loss 0.184046, acc 0.90625, learning_rate 0.00108709\n",
      "2020-12-09T17:01:16.341367: step 1027, loss 0.214749, acc 0.9375, learning_rate 0.00108577\n",
      "2020-12-09T17:01:17.289130: step 1028, loss 0.218151, acc 0.90625, learning_rate 0.00108445\n",
      "2020-12-09T17:01:18.222132: step 1029, loss 0.28696, acc 0.90625, learning_rate 0.00108313\n",
      "2020-12-09T17:01:19.272172: step 1030, loss 0.582322, acc 0.78125, learning_rate 0.00108182\n",
      "2020-12-09T17:01:19.951631: step 1031, loss 0.215309, acc 0.9375, learning_rate 0.0010805\n",
      "2020-12-09T17:01:20.708633: step 1032, loss 0.242936, acc 0.90625, learning_rate 0.00107919\n",
      "2020-12-09T17:01:21.377666: step 1033, loss 0.263681, acc 0.90625, learning_rate 0.00107788\n",
      "2020-12-09T17:01:22.084849: step 1034, loss 0.102412, acc 0.96875, learning_rate 0.00107657\n",
      "2020-12-09T17:01:22.714850: step 1035, loss 0.197517, acc 0.90625, learning_rate 0.00107526\n",
      "2020-12-09T17:01:23.404849: step 1036, loss 0.247866, acc 0.9375, learning_rate 0.00107395\n",
      "2020-12-09T17:01:24.123124: step 1037, loss 0.159381, acc 0.9375, learning_rate 0.00107265\n",
      "2020-12-09T17:01:24.784623: step 1038, loss 0.151469, acc 0.9375, learning_rate 0.00107134\n",
      "2020-12-09T17:01:25.438124: step 1039, loss 0.187655, acc 0.90625, learning_rate 0.00107004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:01:26.036156: step 1040, loss 0.196887, acc 0.875, learning_rate 0.00106874\n",
      "2020-12-09T17:01:26.608621: step 1041, loss 0.287221, acc 0.90625, learning_rate 0.00106745\n",
      "2020-12-09T17:01:27.188659: step 1042, loss 0.322237, acc 0.8125, learning_rate 0.00106615\n",
      "2020-12-09T17:01:27.788623: step 1043, loss 0.314628, acc 0.84375, learning_rate 0.00106486\n",
      "2020-12-09T17:01:28.368124: step 1044, loss 0.218162, acc 0.90625, learning_rate 0.00106356\n",
      "2020-12-09T17:01:28.959625: step 1045, loss 0.155129, acc 0.96875, learning_rate 0.00106227\n",
      "2020-12-09T17:01:29.686656: step 1046, loss 0.226281, acc 0.90625, learning_rate 0.00106098\n",
      "2020-12-09T17:01:30.301043: step 1047, loss 0.154435, acc 0.96875, learning_rate 0.0010597\n",
      "2020-12-09T17:01:30.900009: step 1048, loss 0.154653, acc 1, learning_rate 0.00105841\n",
      "2020-12-09T17:01:31.630534: step 1049, loss 0.134533, acc 0.9375, learning_rate 0.00105713\n",
      "2020-12-09T17:01:32.199044: step 1050, loss 0.293168, acc 0.875, learning_rate 0.00105584\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:01:36.678383: step 1050, loss 0.650478, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1050\n",
      "\n",
      "2020-12-09T17:01:38.107750: step 1051, loss 0.366306, acc 0.8125, learning_rate 0.00105456\n",
      "2020-12-09T17:01:38.658195: step 1052, loss 0.194481, acc 0.96875, learning_rate 0.00105329\n",
      "2020-12-09T17:01:39.217656: step 1053, loss 0.314705, acc 0.875, learning_rate 0.00105201\n",
      "2020-12-09T17:01:39.778324: step 1054, loss 0.511327, acc 0.78125, learning_rate 0.00105073\n",
      "2020-12-09T17:01:40.336848: step 1055, loss 0.278333, acc 0.90625, learning_rate 0.00104946\n",
      "2020-12-09T17:01:40.888129: step 1056, loss 0.295573, acc 0.84375, learning_rate 0.00104819\n",
      "2020-12-09T17:01:41.449134: step 1057, loss 0.17111, acc 0.9375, learning_rate 0.00104692\n",
      "2020-12-09T17:01:42.053832: step 1058, loss 0.210372, acc 0.90625, learning_rate 0.00104565\n",
      "2020-12-09T17:01:42.617226: step 1059, loss 0.196231, acc 0.90625, learning_rate 0.00104438\n",
      "2020-12-09T17:01:43.173726: step 1060, loss 0.152876, acc 0.96875, learning_rate 0.00104312\n",
      "2020-12-09T17:01:43.737947: step 1061, loss 0.201505, acc 0.9375, learning_rate 0.00104185\n",
      "2020-12-09T17:01:44.280693: step 1062, loss 0.220964, acc 0.90625, learning_rate 0.00104059\n",
      "2020-12-09T17:01:44.838219: step 1063, loss 0.0938004, acc 1, learning_rate 0.00103933\n",
      "2020-12-09T17:01:45.398965: step 1064, loss 0.193385, acc 0.90625, learning_rate 0.00103807\n",
      "2020-12-09T17:01:45.991613: step 1065, loss 0.195344, acc 0.90625, learning_rate 0.00103682\n",
      "2020-12-09T17:01:46.536263: step 1066, loss 0.208027, acc 0.90625, learning_rate 0.00103556\n",
      "2020-12-09T17:01:47.088096: step 1067, loss 0.141008, acc 0.96875, learning_rate 0.00103431\n",
      "2020-12-09T17:01:47.664095: step 1068, loss 0.267979, acc 0.875, learning_rate 0.00103306\n",
      "2020-12-09T17:01:48.257069: step 1069, loss 0.146582, acc 0.96875, learning_rate 0.00103181\n",
      "2020-12-09T17:01:48.825663: step 1070, loss 0.464866, acc 0.875, learning_rate 0.00103056\n",
      "2020-12-09T17:01:49.374635: step 1071, loss 0.166581, acc 0.9375, learning_rate 0.00102931\n",
      "2020-12-09T17:01:49.935988: step 1072, loss 0.117654, acc 0.96875, learning_rate 0.00102807\n",
      "2020-12-09T17:01:50.493490: step 1073, loss 0.0763505, acc 1, learning_rate 0.00102682\n",
      "2020-12-09T17:01:51.069986: step 1074, loss 0.255494, acc 0.875, learning_rate 0.00102558\n",
      "2020-12-09T17:01:51.628195: step 1075, loss 0.309648, acc 0.8125, learning_rate 0.00102434\n",
      "2020-12-09T17:01:52.195104: step 1076, loss 0.26835, acc 0.84375, learning_rate 0.00102311\n",
      "2020-12-09T17:01:52.751051: step 1077, loss 0.261789, acc 0.9375, learning_rate 0.00102187\n",
      "2020-12-09T17:01:53.311305: step 1078, loss 0.287916, acc 0.8125, learning_rate 0.00102063\n",
      "2020-12-09T17:01:53.881937: step 1079, loss 0.144372, acc 0.9375, learning_rate 0.0010194\n",
      "2020-12-09T17:01:54.469369: step 1080, loss 0.289176, acc 0.84375, learning_rate 0.00101817\n",
      "2020-12-09T17:01:55.034871: step 1081, loss 0.198081, acc 0.875, learning_rate 0.00101694\n",
      "2020-12-09T17:01:55.603758: step 1082, loss 0.25626, acc 0.84375, learning_rate 0.00101571\n",
      "2020-12-09T17:01:56.157451: step 1083, loss 0.376668, acc 0.8125, learning_rate 0.00101448\n",
      "2020-12-09T17:01:56.705178: step 1084, loss 0.20519, acc 0.96875, learning_rate 0.00101326\n",
      "2020-12-09T17:01:57.240191: step 1085, loss 0.159234, acc 0.9375, learning_rate 0.00101204\n",
      "2020-12-09T17:01:57.800180: step 1086, loss 0.117547, acc 0.96875, learning_rate 0.00101081\n",
      "2020-12-09T17:01:58.358121: step 1087, loss 0.222691, acc 0.9375, learning_rate 0.00100959\n",
      "2020-12-09T17:01:58.899988: step 1088, loss 0.16734, acc 0.9375, learning_rate 0.00100838\n",
      "2020-12-09T17:01:59.441321: step 1089, loss 0.299186, acc 0.90625, learning_rate 0.00100716\n",
      "2020-12-09T17:01:59.991903: step 1090, loss 0.300215, acc 0.875, learning_rate 0.00100594\n",
      "2020-12-09T17:02:00.608211: step 1091, loss 0.170326, acc 0.90625, learning_rate 0.00100473\n",
      "2020-12-09T17:02:01.217849: step 1092, loss 0.163783, acc 0.9375, learning_rate 0.00100352\n",
      "2020-12-09T17:02:01.782349: step 1093, loss 0.190998, acc 0.96875, learning_rate 0.00100231\n",
      "2020-12-09T17:02:02.352152: step 1094, loss 0.152682, acc 0.9375, learning_rate 0.0010011\n",
      "2020-12-09T17:02:03.027123: step 1095, loss 0.235282, acc 0.90625, learning_rate 0.000999892\n",
      "2020-12-09T17:02:03.913618: step 1096, loss 0.25336, acc 0.9375, learning_rate 0.000998686\n",
      "2020-12-09T17:02:04.651617: step 1097, loss 0.132722, acc 0.96875, learning_rate 0.000997483\n",
      "2020-12-09T17:02:05.281117: step 1098, loss 0.359885, acc 0.875, learning_rate 0.00099628\n",
      "2020-12-09T17:02:05.861121: step 1099, loss 0.237749, acc 0.875, learning_rate 0.00099508\n",
      "2020-12-09T17:02:06.431933: step 1100, loss 0.28802, acc 0.9375, learning_rate 0.000993881\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:02:10.385364: step 1100, loss 0.650395, acc 0.7323\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1100\n",
      "\n",
      "2020-12-09T17:02:12.053904: step 1101, loss 0.245645, acc 0.875, learning_rate 0.000992683\n",
      "2020-12-09T17:02:12.634747: step 1102, loss 0.413106, acc 0.78125, learning_rate 0.000991488\n",
      "2020-12-09T17:02:13.187782: step 1103, loss 0.267446, acc 0.84375, learning_rate 0.000990293\n",
      "2020-12-09T17:02:13.763670: step 1104, loss 0.295749, acc 0.84375, learning_rate 0.000989101\n",
      "2020-12-09T17:02:14.606372: step 1105, loss 0.215457, acc 0.9375, learning_rate 0.00098791\n",
      "2020-12-09T17:02:15.275070: step 1106, loss 0.226753, acc 0.90625, learning_rate 0.00098672\n",
      "2020-12-09T17:02:16.424577: step 1107, loss 0.135884, acc 0.96875, learning_rate 0.000985532\n",
      "2020-12-09T17:02:17.297042: step 1108, loss 0.16708, acc 0.9375, learning_rate 0.000984346\n",
      "2020-12-09T17:02:17.967039: step 1109, loss 0.261119, acc 0.96875, learning_rate 0.000983162\n",
      "2020-12-09T17:02:18.639574: step 1110, loss 0.0871465, acc 1, learning_rate 0.000981979\n",
      "2020-12-09T17:02:19.209307: step 1111, loss 0.179519, acc 0.90625, learning_rate 0.000980797\n",
      "2020-12-09T17:02:19.795308: step 1112, loss 0.194909, acc 0.90625, learning_rate 0.000979617\n",
      "2020-12-09T17:02:20.370398: step 1113, loss 0.238393, acc 0.90625, learning_rate 0.000978439\n",
      "2020-12-09T17:02:20.943966: step 1114, loss 0.116021, acc 1, learning_rate 0.000977262\n",
      "2020-12-09T17:02:21.486463: step 1115, loss 0.139638, acc 0.96875, learning_rate 0.000976087\n",
      "2020-12-09T17:02:22.091966: step 1116, loss 0.218024, acc 0.96875, learning_rate 0.000974914\n",
      "2020-12-09T17:02:22.731903: step 1117, loss 0.21163, acc 0.9375, learning_rate 0.000973742\n",
      "2020-12-09T17:02:23.387002: step 1118, loss 0.133126, acc 0.9375, learning_rate 0.000972571\n",
      "2020-12-09T17:02:23.950665: step 1119, loss 0.253143, acc 0.9375, learning_rate 0.000971402\n",
      "2020-12-09T17:02:24.498660: step 1120, loss 0.209762, acc 0.90625, learning_rate 0.000970235\n",
      "2020-12-09T17:02:25.055877: step 1121, loss 0.119196, acc 0.96875, learning_rate 0.000969069\n",
      "2020-12-09T17:02:26.091475: step 1122, loss 0.296056, acc 0.90625, learning_rate 0.000967905\n",
      "2020-12-09T17:02:26.717512: step 1123, loss 0.214518, acc 0.9375, learning_rate 0.000966742\n",
      "2020-12-09T17:02:27.279794: step 1124, loss 0.234335, acc 0.96875, learning_rate 0.000965581\n",
      "2020-12-09T17:02:27.841328: step 1125, loss 0.199821, acc 0.875, learning_rate 0.000964422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:02:28.408564: step 1126, loss 0.156953, acc 0.96875, learning_rate 0.000963264\n",
      "2020-12-09T17:02:29.339564: step 1127, loss 0.13899, acc 0.96875, learning_rate 0.000962108\n",
      "2020-12-09T17:02:30.231061: step 1128, loss 0.132829, acc 0.96875, learning_rate 0.000960953\n",
      "2020-12-09T17:02:30.983062: step 1129, loss 0.0800276, acc 1, learning_rate 0.000959799\n",
      "2020-12-09T17:02:31.650562: step 1130, loss 0.324173, acc 0.875, learning_rate 0.000958648\n",
      "2020-12-09T17:02:32.318565: step 1131, loss 0.216502, acc 0.96875, learning_rate 0.000957497\n",
      "2020-12-09T17:02:33.026583: step 1132, loss 0.258783, acc 0.90625, learning_rate 0.000956349\n",
      "2020-12-09T17:02:33.698587: step 1133, loss 0.191678, acc 0.9375, learning_rate 0.000955202\n",
      "2020-12-09T17:02:34.365086: step 1134, loss 0.319043, acc 0.84375, learning_rate 0.000954056\n",
      "2020-12-09T17:02:34.980401: step 1135, loss 0.226745, acc 0.90625, learning_rate 0.000952912\n",
      "2020-12-09T17:02:35.558901: step 1136, loss 0.144055, acc 0.96875, learning_rate 0.00095177\n",
      "2020-12-09T17:02:36.141467: step 1137, loss 0.222026, acc 0.90625, learning_rate 0.000950629\n",
      "2020-12-09T17:02:36.710060: step 1138, loss 0.130784, acc 0.96875, learning_rate 0.000949489\n",
      "2020-12-09T17:02:37.307332: step 1139, loss 0.149608, acc 0.96875, learning_rate 0.000948351\n",
      "2020-12-09T17:02:37.875399: step 1140, loss 0.248751, acc 0.90625, learning_rate 0.000947215\n",
      "2020-12-09T17:02:38.464106: step 1141, loss 0.186013, acc 0.9375, learning_rate 0.00094608\n",
      "2020-12-09T17:02:39.029756: step 1142, loss 0.134091, acc 0.9375, learning_rate 0.000944946\n",
      "2020-12-09T17:02:39.588719: step 1143, loss 0.19011, acc 0.90625, learning_rate 0.000943815\n",
      "2020-12-09T17:02:40.163367: step 1144, loss 0.243807, acc 0.90625, learning_rate 0.000942684\n",
      "2020-12-09T17:02:40.733172: step 1145, loss 0.11513, acc 0.9375, learning_rate 0.000941555\n",
      "2020-12-09T17:02:41.301587: step 1146, loss 0.18445, acc 0.90625, learning_rate 0.000940428\n",
      "2020-12-09T17:02:41.876223: step 1147, loss 0.270691, acc 0.84375, learning_rate 0.000939302\n",
      "2020-12-09T17:02:42.485807: step 1148, loss 0.174965, acc 0.90625, learning_rate 0.000938178\n",
      "2020-12-09T17:02:43.070658: step 1149, loss 0.264111, acc 0.875, learning_rate 0.000937055\n",
      "2020-12-09T17:02:43.653154: step 1150, loss 0.170443, acc 0.9375, learning_rate 0.000935934\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:02:47.095823: step 1150, loss 0.650302, acc 0.7323\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1150\n",
      "\n",
      "2020-12-09T17:02:48.685289: step 1151, loss 0.164685, acc 0.9375, learning_rate 0.000934814\n",
      "2020-12-09T17:02:49.308785: step 1152, loss 0.18971, acc 0.90625, learning_rate 0.000933696\n",
      "2020-12-09T17:02:49.991057: step 1153, loss 0.305314, acc 0.9375, learning_rate 0.000932579\n",
      "2020-12-09T17:02:50.584990: step 1154, loss 0.254722, acc 0.90625, learning_rate 0.000931464\n",
      "2020-12-09T17:02:51.516480: step 1155, loss 0.188192, acc 0.875, learning_rate 0.00093035\n",
      "2020-12-09T17:02:52.241529: step 1156, loss 0.301651, acc 0.90625, learning_rate 0.000929238\n",
      "2020-12-09T17:02:52.825691: step 1157, loss 0.31283, acc 0.90625, learning_rate 0.000928127\n",
      "2020-12-09T17:02:53.402268: step 1158, loss 0.182261, acc 0.90625, learning_rate 0.000927018\n",
      "2020-12-09T17:02:54.110269: step 1159, loss 0.270851, acc 0.875, learning_rate 0.00092591\n",
      "2020-12-09T17:02:54.819627: step 1160, loss 0.237114, acc 0.875, learning_rate 0.000924803\n",
      "2020-12-09T17:02:55.406079: step 1161, loss 0.171991, acc 0.9375, learning_rate 0.000923699\n",
      "2020-12-09T17:02:55.974083: step 1162, loss 0.156042, acc 0.9375, learning_rate 0.000922595\n",
      "2020-12-09T17:02:56.655912: step 1163, loss 0.334661, acc 0.84375, learning_rate 0.000921493\n",
      "2020-12-09T17:02:57.200434: step 1164, loss 0.114932, acc 1, learning_rate 0.000920393\n",
      "2020-12-09T17:02:57.745533: step 1165, loss 0.363135, acc 0.875, learning_rate 0.000919294\n",
      "2020-12-09T17:02:58.345419: step 1166, loss 0.115448, acc 1, learning_rate 0.000918196\n",
      "2020-12-09T17:02:58.896630: step 1167, loss 0.343125, acc 0.90625, learning_rate 0.0009171\n",
      "2020-12-09T17:02:59.462396: step 1168, loss 0.226924, acc 0.9375, learning_rate 0.000916006\n",
      "2020-12-09T17:03:00.065930: step 1169, loss 0.300259, acc 0.875, learning_rate 0.000914913\n",
      "2020-12-09T17:03:00.688274: step 1170, loss 0.0898462, acc 0.9375, learning_rate 0.000913821\n",
      "2020-12-09T17:03:01.275065: step 1171, loss 0.283746, acc 0.9375, learning_rate 0.000912731\n",
      "2020-12-09T17:03:01.861101: step 1172, loss 0.122748, acc 0.96875, learning_rate 0.000911642\n",
      "2020-12-09T17:03:02.431007: step 1173, loss 0.361754, acc 0.875, learning_rate 0.000910555\n",
      "2020-12-09T17:03:03.022733: step 1174, loss 0.30747, acc 0.875, learning_rate 0.000909469\n",
      "2020-12-09T17:03:03.632142: step 1175, loss 0.176863, acc 0.9375, learning_rate 0.000908385\n",
      "2020-12-09T17:03:04.246021: step 1176, loss 0.285577, acc 0.875, learning_rate 0.000907302\n",
      "2020-12-09T17:03:04.850623: step 1177, loss 0.411162, acc 0.84375, learning_rate 0.000906221\n",
      "2020-12-09T17:03:05.452469: step 1178, loss 0.377425, acc 0.875, learning_rate 0.000905141\n",
      "2020-12-09T17:03:06.068689: step 1179, loss 0.108456, acc 0.96875, learning_rate 0.000904062\n",
      "2020-12-09T17:03:06.670641: step 1180, loss 0.216202, acc 0.9375, learning_rate 0.000902985\n",
      "2020-12-09T17:03:07.275713: step 1181, loss 0.2596, acc 0.90625, learning_rate 0.000901909\n",
      "2020-12-09T17:03:07.903493: step 1182, loss 0.248092, acc 0.90625, learning_rate 0.000900835\n",
      "2020-12-09T17:03:08.495372: step 1183, loss 0.327831, acc 0.875, learning_rate 0.000899762\n",
      "2020-12-09T17:03:09.077341: step 1184, loss 0.16004, acc 0.9375, learning_rate 0.000898691\n",
      "2020-12-09T17:03:09.636758: step 1185, loss 0.194643, acc 0.9375, learning_rate 0.000897621\n",
      "2020-12-09T17:03:10.212792: step 1186, loss 0.172199, acc 0.9375, learning_rate 0.000896553\n",
      "2020-12-09T17:03:10.774386: step 1187, loss 0.231017, acc 0.84375, learning_rate 0.000895486\n",
      "2020-12-09T17:03:11.346382: step 1188, loss 0.373438, acc 0.78125, learning_rate 0.00089442\n",
      "2020-12-09T17:03:11.977940: step 1189, loss 0.260764, acc 0.90625, learning_rate 0.000893356\n",
      "2020-12-09T17:03:12.596471: step 1190, loss 0.398571, acc 0.90625, learning_rate 0.000892293\n",
      "2020-12-09T17:03:13.197082: step 1191, loss 0.190212, acc 0.9375, learning_rate 0.000891232\n",
      "2020-12-09T17:03:13.755475: step 1192, loss 0.205274, acc 0.875, learning_rate 0.000890172\n",
      "2020-12-09T17:03:14.360506: step 1193, loss 0.192385, acc 0.90625, learning_rate 0.000889113\n",
      "2020-12-09T17:03:14.946308: step 1194, loss 0.210868, acc 0.90625, learning_rate 0.000888056\n",
      "2020-12-09T17:03:15.575153: step 1195, loss 0.163008, acc 0.90625, learning_rate 0.000887001\n",
      "2020-12-09T17:03:15.917686: step 1196, loss 0.457504, acc 0.846154, learning_rate 0.000885946\n",
      "2020-12-09T17:03:16.513036: step 1197, loss 0.18593, acc 0.90625, learning_rate 0.000884894\n",
      "2020-12-09T17:03:17.077537: step 1198, loss 0.246028, acc 0.90625, learning_rate 0.000883842\n",
      "2020-12-09T17:03:17.658751: step 1199, loss 0.11346, acc 0.96875, learning_rate 0.000882792\n",
      "2020-12-09T17:03:18.279830: step 1200, loss 0.347156, acc 0.84375, learning_rate 0.000881744\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:03:21.535655: step 1200, loss 0.650231, acc 0.7323\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1200\n",
      "\n",
      "2020-12-09T17:03:23.144194: step 1201, loss 0.233529, acc 0.9375, learning_rate 0.000880696\n",
      "2020-12-09T17:03:23.674161: step 1202, loss 0.128393, acc 1, learning_rate 0.000879651\n",
      "2020-12-09T17:03:24.235465: step 1203, loss 0.197086, acc 0.9375, learning_rate 0.000878606\n",
      "2020-12-09T17:03:24.826458: step 1204, loss 0.352025, acc 0.90625, learning_rate 0.000877563\n",
      "2020-12-09T17:03:25.370922: step 1205, loss 0.209262, acc 0.875, learning_rate 0.000876522\n",
      "2020-12-09T17:03:25.926893: step 1206, loss 0.204906, acc 0.9375, learning_rate 0.000875482\n",
      "2020-12-09T17:03:26.514921: step 1207, loss 0.265778, acc 0.875, learning_rate 0.000874443\n",
      "2020-12-09T17:03:27.077817: step 1208, loss 0.248601, acc 0.9375, learning_rate 0.000873405\n",
      "2020-12-09T17:03:27.642748: step 1209, loss 0.487396, acc 0.78125, learning_rate 0.000872369\n",
      "2020-12-09T17:03:28.219246: step 1210, loss 0.129783, acc 0.9375, learning_rate 0.000871335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:03:28.804678: step 1211, loss 0.229119, acc 0.90625, learning_rate 0.000870301\n",
      "2020-12-09T17:03:29.354179: step 1212, loss 0.424575, acc 0.8125, learning_rate 0.00086927\n",
      "2020-12-09T17:03:29.906212: step 1213, loss 0.369663, acc 0.9375, learning_rate 0.000868239\n",
      "2020-12-09T17:03:30.521714: step 1214, loss 0.441327, acc 0.78125, learning_rate 0.00086721\n",
      "2020-12-09T17:03:31.203678: step 1215, loss 0.208914, acc 0.9375, learning_rate 0.000866182\n",
      "2020-12-09T17:03:31.790645: step 1216, loss 0.209854, acc 0.9375, learning_rate 0.000865156\n",
      "2020-12-09T17:03:32.388464: step 1217, loss 0.127606, acc 1, learning_rate 0.000864131\n",
      "2020-12-09T17:03:32.988899: step 1218, loss 0.172, acc 0.96875, learning_rate 0.000863107\n",
      "2020-12-09T17:03:33.584141: step 1219, loss 0.268833, acc 0.84375, learning_rate 0.000862085\n",
      "2020-12-09T17:03:34.141225: step 1220, loss 0.182693, acc 1, learning_rate 0.000861064\n",
      "2020-12-09T17:03:34.740058: step 1221, loss 0.281211, acc 0.84375, learning_rate 0.000860045\n",
      "2020-12-09T17:03:35.354807: step 1222, loss 0.217166, acc 0.90625, learning_rate 0.000859027\n",
      "2020-12-09T17:03:35.967808: step 1223, loss 0.212298, acc 0.90625, learning_rate 0.00085801\n",
      "2020-12-09T17:03:36.591839: step 1224, loss 0.135909, acc 0.90625, learning_rate 0.000856994\n",
      "2020-12-09T17:03:37.215663: step 1225, loss 0.222521, acc 0.9375, learning_rate 0.00085598\n",
      "2020-12-09T17:03:37.823665: step 1226, loss 0.28695, acc 0.875, learning_rate 0.000854968\n",
      "2020-12-09T17:03:38.399549: step 1227, loss 0.24414, acc 0.90625, learning_rate 0.000853956\n",
      "2020-12-09T17:03:39.001569: step 1228, loss 0.163023, acc 0.90625, learning_rate 0.000852946\n",
      "2020-12-09T17:03:39.589066: step 1229, loss 0.186201, acc 0.90625, learning_rate 0.000851938\n",
      "2020-12-09T17:03:40.164101: step 1230, loss 0.383114, acc 0.875, learning_rate 0.000850931\n",
      "2020-12-09T17:03:40.725114: step 1231, loss 0.207189, acc 0.96875, learning_rate 0.000849925\n",
      "2020-12-09T17:03:41.292628: step 1232, loss 0.25205, acc 0.875, learning_rate 0.00084892\n",
      "2020-12-09T17:03:41.861495: step 1233, loss 0.167953, acc 0.96875, learning_rate 0.000847917\n",
      "2020-12-09T17:03:42.437164: step 1234, loss 0.208885, acc 0.96875, learning_rate 0.000846915\n",
      "2020-12-09T17:03:43.121277: step 1235, loss 0.172073, acc 0.90625, learning_rate 0.000845914\n",
      "2020-12-09T17:03:43.696458: step 1236, loss 0.157389, acc 0.9375, learning_rate 0.000844915\n",
      "2020-12-09T17:03:44.261424: step 1237, loss 0.174225, acc 1, learning_rate 0.000843917\n",
      "2020-12-09T17:03:44.836988: step 1238, loss 0.192274, acc 0.9375, learning_rate 0.000842921\n",
      "2020-12-09T17:03:45.413804: step 1239, loss 0.195886, acc 0.9375, learning_rate 0.000841926\n",
      "2020-12-09T17:03:45.989739: step 1240, loss 0.201169, acc 0.90625, learning_rate 0.000840932\n",
      "2020-12-09T17:03:46.558679: step 1241, loss 0.272201, acc 0.90625, learning_rate 0.000839939\n",
      "2020-12-09T17:03:47.146094: step 1242, loss 0.379534, acc 0.90625, learning_rate 0.000838948\n",
      "2020-12-09T17:03:47.727785: step 1243, loss 0.220714, acc 0.9375, learning_rate 0.000837958\n",
      "2020-12-09T17:03:48.299135: step 1244, loss 0.0902332, acc 1, learning_rate 0.00083697\n",
      "2020-12-09T17:03:49.024625: step 1245, loss 0.206039, acc 0.9375, learning_rate 0.000835983\n",
      "2020-12-09T17:03:49.897532: step 1246, loss 0.205865, acc 0.9375, learning_rate 0.000834997\n",
      "2020-12-09T17:03:50.618759: step 1247, loss 0.251328, acc 0.90625, learning_rate 0.000834012\n",
      "2020-12-09T17:03:51.469117: step 1248, loss 0.0954198, acc 0.96875, learning_rate 0.000833029\n",
      "2020-12-09T17:03:52.149621: step 1249, loss 0.21075, acc 0.9375, learning_rate 0.000832047\n",
      "2020-12-09T17:03:52.947260: step 1250, loss 0.215911, acc 0.9375, learning_rate 0.000831066\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:03:57.560313: step 1250, loss 0.650117, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1250\n",
      "\n",
      "2020-12-09T17:03:59.148283: step 1251, loss 0.242989, acc 0.875, learning_rate 0.000830087\n",
      "2020-12-09T17:03:59.724931: step 1252, loss 0.192852, acc 0.90625, learning_rate 0.000829109\n",
      "2020-12-09T17:04:00.507862: step 1253, loss 0.268658, acc 0.875, learning_rate 0.000828132\n",
      "2020-12-09T17:04:01.320864: step 1254, loss 0.199402, acc 0.90625, learning_rate 0.000827157\n",
      "2020-12-09T17:04:01.996680: step 1255, loss 0.265603, acc 0.90625, learning_rate 0.000826183\n",
      "2020-12-09T17:04:02.568689: step 1256, loss 0.114444, acc 0.96875, learning_rate 0.00082521\n",
      "2020-12-09T17:04:03.146860: step 1257, loss 0.169436, acc 0.90625, learning_rate 0.000824239\n",
      "2020-12-09T17:04:03.826737: step 1258, loss 0.297843, acc 0.84375, learning_rate 0.000823269\n",
      "2020-12-09T17:04:04.655695: step 1259, loss 0.254979, acc 0.90625, learning_rate 0.0008223\n",
      "2020-12-09T17:04:05.431411: step 1260, loss 0.193803, acc 0.90625, learning_rate 0.000821332\n",
      "2020-12-09T17:04:06.028391: step 1261, loss 0.184026, acc 0.875, learning_rate 0.000820366\n",
      "2020-12-09T17:04:06.630440: step 1262, loss 0.230877, acc 0.9375, learning_rate 0.000819401\n",
      "2020-12-09T17:04:07.336909: step 1263, loss 0.128251, acc 0.96875, learning_rate 0.000818437\n",
      "2020-12-09T17:04:07.953639: step 1264, loss 0.301814, acc 0.8125, learning_rate 0.000817475\n",
      "2020-12-09T17:04:08.562673: step 1265, loss 0.159759, acc 0.9375, learning_rate 0.000816514\n",
      "2020-12-09T17:04:09.170676: step 1266, loss 0.158313, acc 0.96875, learning_rate 0.000815554\n",
      "2020-12-09T17:04:09.763246: step 1267, loss 0.235835, acc 0.90625, learning_rate 0.000814595\n",
      "2020-12-09T17:04:10.365246: step 1268, loss 0.246386, acc 0.90625, learning_rate 0.000813638\n",
      "2020-12-09T17:04:10.973746: step 1269, loss 0.347766, acc 0.84375, learning_rate 0.000812682\n",
      "2020-12-09T17:04:11.596244: step 1270, loss 0.22501, acc 0.90625, learning_rate 0.000811727\n",
      "2020-12-09T17:04:12.223245: step 1271, loss 0.355804, acc 0.90625, learning_rate 0.000810774\n",
      "2020-12-09T17:04:12.826906: step 1272, loss 0.265844, acc 0.84375, learning_rate 0.000809822\n",
      "2020-12-09T17:04:13.447750: step 1273, loss 0.320888, acc 0.84375, learning_rate 0.000808871\n",
      "2020-12-09T17:04:14.019295: step 1274, loss 0.196936, acc 0.9375, learning_rate 0.000807922\n",
      "2020-12-09T17:04:14.603295: step 1275, loss 0.224104, acc 0.96875, learning_rate 0.000806973\n",
      "2020-12-09T17:04:15.243373: step 1276, loss 0.31297, acc 0.8125, learning_rate 0.000806026\n",
      "2020-12-09T17:04:15.856302: step 1277, loss 0.149114, acc 0.9375, learning_rate 0.00080508\n",
      "2020-12-09T17:04:16.454800: step 1278, loss 0.372341, acc 0.84375, learning_rate 0.000804136\n",
      "2020-12-09T17:04:17.055837: step 1279, loss 0.133413, acc 0.96875, learning_rate 0.000803193\n",
      "2020-12-09T17:04:17.654358: step 1280, loss 0.142581, acc 0.96875, learning_rate 0.000802251\n",
      "2020-12-09T17:04:18.253582: step 1281, loss 0.193757, acc 0.90625, learning_rate 0.00080131\n",
      "2020-12-09T17:04:18.836349: step 1282, loss 0.218976, acc 0.90625, learning_rate 0.000800371\n",
      "2020-12-09T17:04:19.417632: step 1283, loss 0.272858, acc 0.90625, learning_rate 0.000799432\n",
      "2020-12-09T17:04:20.024966: step 1284, loss 0.407376, acc 0.84375, learning_rate 0.000798495\n",
      "2020-12-09T17:04:20.617485: step 1285, loss 0.149617, acc 1, learning_rate 0.00079756\n",
      "2020-12-09T17:04:21.214588: step 1286, loss 0.312451, acc 0.84375, learning_rate 0.000796625\n",
      "2020-12-09T17:04:21.802083: step 1287, loss 0.320242, acc 0.8125, learning_rate 0.000795692\n",
      "2020-12-09T17:04:22.372549: step 1288, loss 0.236439, acc 0.90625, learning_rate 0.00079476\n",
      "2020-12-09T17:04:22.971076: step 1289, loss 0.294009, acc 0.8125, learning_rate 0.00079383\n",
      "2020-12-09T17:04:23.571310: step 1290, loss 0.285226, acc 0.84375, learning_rate 0.0007929\n",
      "2020-12-09T17:04:24.169959: step 1291, loss 0.266239, acc 0.84375, learning_rate 0.000791972\n",
      "2020-12-09T17:04:24.853166: step 1292, loss 0.259624, acc 0.875, learning_rate 0.000791045\n",
      "2020-12-09T17:04:25.458506: step 1293, loss 0.220838, acc 0.90625, learning_rate 0.000790119\n",
      "2020-12-09T17:04:26.041041: step 1294, loss 0.261328, acc 0.875, learning_rate 0.000789195\n",
      "2020-12-09T17:04:26.682037: step 1295, loss 0.167575, acc 0.9375, learning_rate 0.000788272\n",
      "2020-12-09T17:04:27.299405: step 1296, loss 0.218366, acc 0.90625, learning_rate 0.00078735\n",
      "2020-12-09T17:04:27.882409: step 1297, loss 0.289856, acc 0.78125, learning_rate 0.000786429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:04:28.449704: step 1298, loss 0.420108, acc 0.90625, learning_rate 0.000785509\n",
      "2020-12-09T17:04:29.021200: step 1299, loss 0.176993, acc 0.90625, learning_rate 0.000784591\n",
      "2020-12-09T17:04:29.597051: step 1300, loss 0.283139, acc 0.875, learning_rate 0.000783674\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:04:33.190214: step 1300, loss 0.650053, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1300\n",
      "\n",
      "2020-12-09T17:04:34.717209: step 1301, loss 0.0957498, acc 1, learning_rate 0.000782758\n",
      "2020-12-09T17:04:35.324935: step 1302, loss 0.216168, acc 0.875, learning_rate 0.000781844\n",
      "2020-12-09T17:04:35.917160: step 1303, loss 0.24465, acc 0.90625, learning_rate 0.00078093\n",
      "2020-12-09T17:04:36.523601: step 1304, loss 0.144981, acc 0.9375, learning_rate 0.000780018\n",
      "2020-12-09T17:04:37.204073: step 1305, loss 0.112352, acc 0.96875, learning_rate 0.000779107\n",
      "2020-12-09T17:04:37.835112: step 1306, loss 0.131101, acc 0.9375, learning_rate 0.000778198\n",
      "2020-12-09T17:04:38.437500: step 1307, loss 0.337933, acc 0.84375, learning_rate 0.000777289\n",
      "2020-12-09T17:04:39.071999: step 1308, loss 0.253984, acc 0.84375, learning_rate 0.000776382\n",
      "2020-12-09T17:04:39.660559: step 1309, loss 0.230582, acc 0.90625, learning_rate 0.000775476\n",
      "2020-12-09T17:04:40.271784: step 1310, loss 0.183297, acc 0.96875, learning_rate 0.000774571\n",
      "2020-12-09T17:04:41.017284: step 1311, loss 0.362627, acc 0.8125, learning_rate 0.000773667\n",
      "2020-12-09T17:04:41.687832: step 1312, loss 0.18099, acc 0.9375, learning_rate 0.000772765\n",
      "2020-12-09T17:04:42.326796: step 1313, loss 0.17247, acc 0.90625, learning_rate 0.000771864\n",
      "2020-12-09T17:04:42.966417: step 1314, loss 0.242044, acc 0.90625, learning_rate 0.000770964\n",
      "2020-12-09T17:04:43.646418: step 1315, loss 0.19154, acc 0.9375, learning_rate 0.000770065\n",
      "2020-12-09T17:04:44.237115: step 1316, loss 0.222813, acc 0.9375, learning_rate 0.000769167\n",
      "2020-12-09T17:04:44.822135: step 1317, loss 0.213565, acc 0.9375, learning_rate 0.000768271\n",
      "2020-12-09T17:04:45.414271: step 1318, loss 0.0621387, acc 1, learning_rate 0.000767376\n",
      "2020-12-09T17:04:45.985752: step 1319, loss 0.142614, acc 1, learning_rate 0.000766482\n",
      "2020-12-09T17:04:46.571894: step 1320, loss 0.106521, acc 0.96875, learning_rate 0.000765589\n",
      "2020-12-09T17:04:47.204423: step 1321, loss 0.266571, acc 0.90625, learning_rate 0.000764697\n",
      "2020-12-09T17:04:47.800030: step 1322, loss 0.214417, acc 0.9375, learning_rate 0.000763807\n",
      "2020-12-09T17:04:48.406028: step 1323, loss 0.314765, acc 0.8125, learning_rate 0.000762918\n",
      "2020-12-09T17:04:48.977456: step 1324, loss 0.252299, acc 0.9375, learning_rate 0.00076203\n",
      "2020-12-09T17:04:49.576333: step 1325, loss 0.346178, acc 0.875, learning_rate 0.000761143\n",
      "2020-12-09T17:04:50.187585: step 1326, loss 0.160672, acc 0.9375, learning_rate 0.000760257\n",
      "2020-12-09T17:04:50.792293: step 1327, loss 0.158358, acc 0.96875, learning_rate 0.000759373\n",
      "2020-12-09T17:04:51.397291: step 1328, loss 0.314719, acc 0.875, learning_rate 0.00075849\n",
      "2020-12-09T17:04:52.038950: step 1329, loss 0.31553, acc 0.875, learning_rate 0.000757608\n",
      "2020-12-09T17:04:52.667984: step 1330, loss 0.134788, acc 0.96875, learning_rate 0.000756727\n",
      "2020-12-09T17:04:53.250483: step 1331, loss 0.138786, acc 1, learning_rate 0.000755847\n",
      "2020-12-09T17:04:53.955283: step 1332, loss 0.21389, acc 0.90625, learning_rate 0.000754968\n",
      "2020-12-09T17:04:54.534767: step 1333, loss 0.29309, acc 0.84375, learning_rate 0.000754091\n",
      "2020-12-09T17:04:55.110424: step 1334, loss 0.14823, acc 0.96875, learning_rate 0.000753215\n",
      "2020-12-09T17:04:55.688363: step 1335, loss 0.398367, acc 0.8125, learning_rate 0.00075234\n",
      "2020-12-09T17:04:56.251052: step 1336, loss 0.193877, acc 0.96875, learning_rate 0.000751466\n",
      "2020-12-09T17:04:56.814042: step 1337, loss 0.15914, acc 0.9375, learning_rate 0.000750593\n",
      "2020-12-09T17:04:57.493009: step 1338, loss 0.312008, acc 0.90625, learning_rate 0.000749722\n",
      "2020-12-09T17:04:58.103528: step 1339, loss 0.292284, acc 0.90625, learning_rate 0.000748851\n",
      "2020-12-09T17:04:58.681324: step 1340, loss 0.230802, acc 0.8125, learning_rate 0.000747982\n",
      "2020-12-09T17:04:59.269361: step 1341, loss 0.195855, acc 0.9375, learning_rate 0.000747114\n",
      "2020-12-09T17:04:59.853173: step 1342, loss 0.321628, acc 0.8125, learning_rate 0.000746247\n",
      "2020-12-09T17:05:00.440997: step 1343, loss 0.22154, acc 0.90625, learning_rate 0.000745382\n",
      "2020-12-09T17:05:01.024434: step 1344, loss 0.143525, acc 0.9375, learning_rate 0.000744517\n",
      "2020-12-09T17:05:01.579995: step 1345, loss 0.148113, acc 0.90625, learning_rate 0.000743654\n",
      "2020-12-09T17:05:02.186915: step 1346, loss 0.147114, acc 0.9375, learning_rate 0.000742792\n",
      "2020-12-09T17:05:02.882925: step 1347, loss 0.213095, acc 0.90625, learning_rate 0.000741931\n",
      "2020-12-09T17:05:03.469461: step 1348, loss 0.216368, acc 0.90625, learning_rate 0.000741071\n",
      "2020-12-09T17:05:04.044652: step 1349, loss 0.305938, acc 0.84375, learning_rate 0.000740212\n",
      "2020-12-09T17:05:04.619358: step 1350, loss 0.161583, acc 0.96875, learning_rate 0.000739354\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:05:08.012245: step 1350, loss 0.650033, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1350\n",
      "\n",
      "2020-12-09T17:05:09.490316: step 1351, loss 0.0911903, acc 0.96875, learning_rate 0.000738498\n",
      "2020-12-09T17:05:10.054588: step 1352, loss 0.17314, acc 0.9375, learning_rate 0.000737643\n",
      "2020-12-09T17:05:10.611441: step 1353, loss 0.248523, acc 0.9375, learning_rate 0.000736788\n",
      "2020-12-09T17:05:11.191519: step 1354, loss 0.118068, acc 0.96875, learning_rate 0.000735935\n",
      "2020-12-09T17:05:11.764054: step 1355, loss 0.234963, acc 0.90625, learning_rate 0.000735083\n",
      "2020-12-09T17:05:12.350194: step 1356, loss 0.147583, acc 1, learning_rate 0.000734233\n",
      "2020-12-09T17:05:12.911312: step 1357, loss 0.192345, acc 0.90625, learning_rate 0.000733383\n",
      "2020-12-09T17:05:13.480273: step 1358, loss 0.315469, acc 0.90625, learning_rate 0.000732535\n",
      "2020-12-09T17:05:14.056010: step 1359, loss 0.167517, acc 0.90625, learning_rate 0.000731687\n",
      "2020-12-09T17:05:14.630877: step 1360, loss 0.354994, acc 0.90625, learning_rate 0.000730841\n",
      "2020-12-09T17:05:15.177252: step 1361, loss 0.168342, acc 0.9375, learning_rate 0.000729996\n",
      "2020-12-09T17:05:15.755746: step 1362, loss 0.150397, acc 0.9375, learning_rate 0.000729152\n",
      "2020-12-09T17:05:16.306707: step 1363, loss 0.148814, acc 0.96875, learning_rate 0.000728309\n",
      "2020-12-09T17:05:16.861160: step 1364, loss 0.359066, acc 0.8125, learning_rate 0.000727468\n",
      "2020-12-09T17:05:17.430157: step 1365, loss 0.202576, acc 0.96875, learning_rate 0.000726627\n",
      "2020-12-09T17:05:17.988602: step 1366, loss 0.174799, acc 1, learning_rate 0.000725788\n",
      "2020-12-09T17:05:18.554508: step 1367, loss 0.196707, acc 0.9375, learning_rate 0.00072495\n",
      "2020-12-09T17:05:19.105974: step 1368, loss 0.140724, acc 0.96875, learning_rate 0.000724112\n",
      "2020-12-09T17:05:19.678985: step 1369, loss 0.143699, acc 0.96875, learning_rate 0.000723276\n",
      "2020-12-09T17:05:20.228255: step 1370, loss 0.277276, acc 0.84375, learning_rate 0.000722441\n",
      "2020-12-09T17:05:20.796811: step 1371, loss 0.362838, acc 0.8125, learning_rate 0.000721608\n",
      "2020-12-09T17:05:21.350452: step 1372, loss 0.164242, acc 0.9375, learning_rate 0.000720775\n",
      "2020-12-09T17:05:21.916276: step 1373, loss 0.215935, acc 0.90625, learning_rate 0.000719943\n",
      "2020-12-09T17:05:22.465284: step 1374, loss 0.283721, acc 0.90625, learning_rate 0.000719113\n",
      "2020-12-09T17:05:23.030276: step 1375, loss 0.127358, acc 0.96875, learning_rate 0.000718284\n",
      "2020-12-09T17:05:23.618776: step 1376, loss 0.388448, acc 0.8125, learning_rate 0.000717455\n",
      "2020-12-09T17:05:24.179659: step 1377, loss 0.148809, acc 0.9375, learning_rate 0.000716628\n",
      "2020-12-09T17:05:24.746748: step 1378, loss 0.351539, acc 0.84375, learning_rate 0.000715802\n",
      "2020-12-09T17:05:25.327105: step 1379, loss 0.244767, acc 0.875, learning_rate 0.000714977\n",
      "2020-12-09T17:05:25.894633: step 1380, loss 0.18863, acc 0.9375, learning_rate 0.000714154\n",
      "2020-12-09T17:05:26.476120: step 1381, loss 0.283565, acc 0.8125, learning_rate 0.000713331\n",
      "2020-12-09T17:05:27.046119: step 1382, loss 0.400742, acc 0.84375, learning_rate 0.000712509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:05:27.622619: step 1383, loss 0.264058, acc 0.96875, learning_rate 0.000711689\n",
      "2020-12-09T17:05:28.189263: step 1384, loss 0.210728, acc 0.90625, learning_rate 0.000710869\n",
      "2020-12-09T17:05:28.740107: step 1385, loss 0.162039, acc 0.90625, learning_rate 0.000710051\n",
      "2020-12-09T17:05:29.302733: step 1386, loss 0.155872, acc 0.96875, learning_rate 0.000709234\n",
      "2020-12-09T17:05:29.902039: step 1387, loss 0.184635, acc 0.9375, learning_rate 0.000708418\n",
      "2020-12-09T17:05:30.491692: step 1388, loss 0.205924, acc 0.875, learning_rate 0.000707603\n",
      "2020-12-09T17:05:31.056163: step 1389, loss 0.127708, acc 0.96875, learning_rate 0.000706789\n",
      "2020-12-09T17:05:31.644820: step 1390, loss 0.188812, acc 0.96875, learning_rate 0.000705976\n",
      "2020-12-09T17:05:32.217560: step 1391, loss 0.257722, acc 0.90625, learning_rate 0.000705164\n",
      "2020-12-09T17:05:32.777005: step 1392, loss 0.196162, acc 0.9375, learning_rate 0.000704354\n",
      "2020-12-09T17:05:33.339541: step 1393, loss 0.24087, acc 0.875, learning_rate 0.000703544\n",
      "2020-12-09T17:05:33.897869: step 1394, loss 0.226669, acc 0.90625, learning_rate 0.000702736\n",
      "2020-12-09T17:05:34.449542: step 1395, loss 0.182052, acc 0.9375, learning_rate 0.000701928\n",
      "2020-12-09T17:05:35.001735: step 1396, loss 0.171968, acc 0.90625, learning_rate 0.000701122\n",
      "2020-12-09T17:05:35.559579: step 1397, loss 0.340398, acc 0.875, learning_rate 0.000700317\n",
      "2020-12-09T17:05:36.143389: step 1398, loss 0.226263, acc 0.875, learning_rate 0.000699513\n",
      "2020-12-09T17:05:36.693495: step 1399, loss 0.313025, acc 0.875, learning_rate 0.000698709\n",
      "2020-12-09T17:05:37.324995: step 1400, loss 0.294748, acc 0.875, learning_rate 0.000697907\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:05:42.366446: step 1400, loss 0.649967, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1400\n",
      "\n",
      "2020-12-09T17:05:43.902446: step 1401, loss 0.16848, acc 0.90625, learning_rate 0.000697107\n",
      "2020-12-09T17:05:44.443622: step 1402, loss 0.19542, acc 0.96875, learning_rate 0.000696307\n",
      "2020-12-09T17:05:44.991924: step 1403, loss 0.134093, acc 0.9375, learning_rate 0.000695508\n",
      "2020-12-09T17:05:45.552422: step 1404, loss 0.148604, acc 0.96875, learning_rate 0.00069471\n",
      "2020-12-09T17:05:46.147716: step 1405, loss 0.224773, acc 0.9375, learning_rate 0.000693914\n",
      "2020-12-09T17:05:46.732585: step 1406, loss 0.189752, acc 0.90625, learning_rate 0.000693118\n",
      "2020-12-09T17:05:47.285429: step 1407, loss 0.340994, acc 0.84375, learning_rate 0.000692323\n",
      "2020-12-09T17:05:47.852966: step 1408, loss 0.336164, acc 0.90625, learning_rate 0.00069153\n",
      "2020-12-09T17:05:48.413734: step 1409, loss 0.190114, acc 0.96875, learning_rate 0.000690738\n",
      "2020-12-09T17:05:48.970768: step 1410, loss 0.226064, acc 0.84375, learning_rate 0.000689946\n",
      "2020-12-09T17:05:49.546736: step 1411, loss 0.215888, acc 0.84375, learning_rate 0.000689156\n",
      "2020-12-09T17:05:50.147751: step 1412, loss 0.357925, acc 0.8125, learning_rate 0.000688367\n",
      "2020-12-09T17:05:50.724750: step 1413, loss 0.213855, acc 0.90625, learning_rate 0.000687579\n",
      "2020-12-09T17:05:51.319284: step 1414, loss 0.18599, acc 0.96875, learning_rate 0.000686792\n",
      "2020-12-09T17:05:51.911251: step 1415, loss 0.157929, acc 0.9375, learning_rate 0.000686005\n",
      "2020-12-09T17:05:52.518751: step 1416, loss 0.149423, acc 0.90625, learning_rate 0.000685221\n",
      "2020-12-09T17:05:53.106751: step 1417, loss 0.0942511, acc 1, learning_rate 0.000684437\n",
      "2020-12-09T17:05:53.696656: step 1418, loss 0.324282, acc 0.875, learning_rate 0.000683654\n",
      "2020-12-09T17:05:54.269533: step 1419, loss 0.24152, acc 0.9375, learning_rate 0.000682872\n",
      "2020-12-09T17:05:54.823594: step 1420, loss 0.191269, acc 0.90625, learning_rate 0.000682091\n",
      "2020-12-09T17:05:55.390474: step 1421, loss 0.243899, acc 0.90625, learning_rate 0.000681311\n",
      "2020-12-09T17:05:55.959407: step 1422, loss 0.242899, acc 0.9375, learning_rate 0.000680533\n",
      "2020-12-09T17:05:56.536652: step 1423, loss 0.293772, acc 0.84375, learning_rate 0.000679755\n",
      "2020-12-09T17:05:57.116343: step 1424, loss 0.374316, acc 0.875, learning_rate 0.000678978\n",
      "2020-12-09T17:05:57.677855: step 1425, loss 0.127442, acc 0.96875, learning_rate 0.000678203\n",
      "2020-12-09T17:05:58.296719: step 1426, loss 0.185294, acc 0.90625, learning_rate 0.000677428\n",
      "2020-12-09T17:05:58.850165: step 1427, loss 0.143954, acc 0.9375, learning_rate 0.000676655\n",
      "2020-12-09T17:05:59.421568: step 1428, loss 0.259223, acc 0.90625, learning_rate 0.000675882\n",
      "2020-12-09T17:05:59.992922: step 1429, loss 0.2803, acc 0.90625, learning_rate 0.000675111\n",
      "2020-12-09T17:06:00.552789: step 1430, loss 0.2281, acc 0.90625, learning_rate 0.00067434\n",
      "2020-12-09T17:06:01.252083: step 1431, loss 0.135923, acc 1, learning_rate 0.000673571\n",
      "2020-12-09T17:06:02.009582: step 1432, loss 0.266021, acc 0.90625, learning_rate 0.000672803\n",
      "2020-12-09T17:06:02.673581: step 1433, loss 0.293332, acc 0.96875, learning_rate 0.000672035\n",
      "2020-12-09T17:06:03.333584: step 1434, loss 0.204266, acc 0.9375, learning_rate 0.000671269\n",
      "2020-12-09T17:06:04.015617: step 1435, loss 0.202587, acc 0.90625, learning_rate 0.000670504\n",
      "2020-12-09T17:06:04.727083: step 1436, loss 0.124105, acc 1, learning_rate 0.00066974\n",
      "2020-12-09T17:06:05.614082: step 1437, loss 0.157445, acc 0.96875, learning_rate 0.000668977\n",
      "2020-12-09T17:06:06.284084: step 1438, loss 0.171792, acc 0.96875, learning_rate 0.000668214\n",
      "2020-12-09T17:06:07.057617: step 1439, loss 0.460821, acc 0.84375, learning_rate 0.000667453\n",
      "2020-12-09T17:06:07.767586: step 1440, loss 0.18866, acc 0.96875, learning_rate 0.000666693\n",
      "2020-12-09T17:06:08.405115: step 1441, loss 0.198089, acc 0.96875, learning_rate 0.000665934\n",
      "2020-12-09T17:06:09.012083: step 1442, loss 0.186468, acc 0.90625, learning_rate 0.000665176\n",
      "2020-12-09T17:06:09.608117: step 1443, loss 0.107499, acc 1, learning_rate 0.000664419\n",
      "2020-12-09T17:06:10.235116: step 1444, loss 0.164589, acc 0.9375, learning_rate 0.000663663\n",
      "2020-12-09T17:06:10.818583: step 1445, loss 0.281348, acc 0.875, learning_rate 0.000662908\n",
      "2020-12-09T17:06:11.538584: step 1446, loss 0.195129, acc 0.90625, learning_rate 0.000662154\n",
      "2020-12-09T17:06:12.163618: step 1447, loss 0.174305, acc 0.90625, learning_rate 0.000661401\n",
      "2020-12-09T17:06:12.779616: step 1448, loss 0.368999, acc 0.8125, learning_rate 0.000660649\n",
      "2020-12-09T17:06:13.361621: step 1449, loss 0.194056, acc 0.90625, learning_rate 0.000659897\n",
      "2020-12-09T17:06:13.971116: step 1450, loss 0.153595, acc 0.90625, learning_rate 0.000659147\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:06:17.567081: step 1450, loss 0.649877, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1450\n",
      "\n",
      "2020-12-09T17:06:19.159834: step 1451, loss 0.122291, acc 0.96875, learning_rate 0.000658398\n",
      "2020-12-09T17:06:19.733826: step 1452, loss 0.275099, acc 0.84375, learning_rate 0.00065765\n",
      "2020-12-09T17:06:20.288315: step 1453, loss 0.241472, acc 0.90625, learning_rate 0.000656903\n",
      "2020-12-09T17:06:20.832770: step 1454, loss 0.251015, acc 0.9375, learning_rate 0.000656157\n",
      "2020-12-09T17:06:21.395770: step 1455, loss 0.364064, acc 0.9375, learning_rate 0.000655412\n",
      "2020-12-09T17:06:21.960770: step 1456, loss 0.237188, acc 0.96875, learning_rate 0.000654668\n",
      "2020-12-09T17:06:22.534532: step 1457, loss 0.225391, acc 0.90625, learning_rate 0.000653925\n",
      "2020-12-09T17:06:23.115978: step 1458, loss 0.199138, acc 0.90625, learning_rate 0.000653183\n",
      "2020-12-09T17:06:23.779158: step 1459, loss 0.230067, acc 0.90625, learning_rate 0.000652442\n",
      "2020-12-09T17:06:24.385150: step 1460, loss 0.173543, acc 0.90625, learning_rate 0.000651702\n",
      "2020-12-09T17:06:24.993170: step 1461, loss 0.26502, acc 0.875, learning_rate 0.000650963\n",
      "2020-12-09T17:06:25.545169: step 1462, loss 0.145235, acc 0.96875, learning_rate 0.000650225\n",
      "2020-12-09T17:06:26.116358: step 1463, loss 0.188443, acc 0.90625, learning_rate 0.000649488\n",
      "2020-12-09T17:06:26.658979: step 1464, loss 0.266984, acc 0.90625, learning_rate 0.000648752\n",
      "2020-12-09T17:06:27.241253: step 1465, loss 0.171106, acc 0.9375, learning_rate 0.000648017\n",
      "2020-12-09T17:06:27.846454: step 1466, loss 0.286877, acc 0.96875, learning_rate 0.000647283\n",
      "2020-12-09T17:06:28.436598: step 1467, loss 0.197727, acc 0.875, learning_rate 0.00064655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:06:29.044946: step 1468, loss 0.172202, acc 0.96875, learning_rate 0.000645818\n",
      "2020-12-09T17:06:29.646947: step 1469, loss 0.21771, acc 0.9375, learning_rate 0.000645087\n",
      "2020-12-09T17:06:30.213412: step 1470, loss 0.259256, acc 0.9375, learning_rate 0.000644356\n",
      "2020-12-09T17:06:30.886412: step 1471, loss 0.317232, acc 0.9375, learning_rate 0.000643627\n",
      "2020-12-09T17:06:31.531775: step 1472, loss 0.240656, acc 0.9375, learning_rate 0.000642899\n",
      "2020-12-09T17:06:32.184358: step 1473, loss 0.105933, acc 0.96875, learning_rate 0.000642172\n",
      "2020-12-09T17:06:32.821618: step 1474, loss 0.0835963, acc 1, learning_rate 0.000641445\n",
      "2020-12-09T17:06:33.519512: step 1475, loss 0.303892, acc 0.90625, learning_rate 0.00064072\n",
      "2020-12-09T17:06:34.114201: step 1476, loss 0.302668, acc 0.875, learning_rate 0.000639996\n",
      "2020-12-09T17:06:34.716724: step 1477, loss 0.298106, acc 0.875, learning_rate 0.000639272\n",
      "2020-12-09T17:06:35.316222: step 1478, loss 0.265807, acc 0.90625, learning_rate 0.00063855\n",
      "2020-12-09T17:06:35.885688: step 1479, loss 0.153801, acc 0.96875, learning_rate 0.000637829\n",
      "2020-12-09T17:06:36.529224: step 1480, loss 0.15652, acc 0.96875, learning_rate 0.000637108\n",
      "2020-12-09T17:06:37.105695: step 1481, loss 0.246756, acc 0.875, learning_rate 0.000636389\n",
      "2020-12-09T17:06:37.669160: step 1482, loss 0.378509, acc 0.90625, learning_rate 0.00063567\n",
      "2020-12-09T17:06:38.259740: step 1483, loss 0.18966, acc 0.90625, learning_rate 0.000634953\n",
      "2020-12-09T17:06:38.822919: step 1484, loss 0.246001, acc 0.875, learning_rate 0.000634236\n",
      "2020-12-09T17:06:39.428915: step 1485, loss 0.40169, acc 0.875, learning_rate 0.00063352\n",
      "2020-12-09T17:06:39.994986: step 1486, loss 0.198204, acc 0.9375, learning_rate 0.000632806\n",
      "2020-12-09T17:06:40.583227: step 1487, loss 0.258062, acc 0.875, learning_rate 0.000632092\n",
      "2020-12-09T17:06:41.149315: step 1488, loss 0.221743, acc 0.96875, learning_rate 0.000631379\n",
      "2020-12-09T17:06:41.703278: step 1489, loss 0.367342, acc 0.78125, learning_rate 0.000630667\n",
      "2020-12-09T17:06:42.281186: step 1490, loss 0.249266, acc 0.875, learning_rate 0.000629957\n",
      "2020-12-09T17:06:42.847368: step 1491, loss 0.25885, acc 0.84375, learning_rate 0.000629247\n",
      "2020-12-09T17:06:43.470428: step 1492, loss 0.23593, acc 0.84375, learning_rate 0.000628538\n",
      "2020-12-09T17:06:44.082055: step 1493, loss 0.190798, acc 0.90625, learning_rate 0.00062783\n",
      "2020-12-09T17:06:44.740115: step 1494, loss 0.192581, acc 0.90625, learning_rate 0.000627123\n",
      "2020-12-09T17:06:44.986115: step 1495, loss 0.222759, acc 0.923077, learning_rate 0.000626417\n",
      "2020-12-09T17:06:45.594615: step 1496, loss 0.141929, acc 0.96875, learning_rate 0.000625711\n",
      "2020-12-09T17:06:46.213648: step 1497, loss 0.32231, acc 0.90625, learning_rate 0.000625007\n",
      "2020-12-09T17:06:46.827821: step 1498, loss 0.392658, acc 0.875, learning_rate 0.000624304\n",
      "2020-12-09T17:06:47.723820: step 1499, loss 0.180854, acc 0.96875, learning_rate 0.000623602\n",
      "2020-12-09T17:06:48.525421: step 1500, loss 0.175587, acc 0.96875, learning_rate 0.0006229\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:06:51.990968: step 1500, loss 0.649831, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1500\n",
      "\n",
      "2020-12-09T17:06:53.593463: step 1501, loss 0.212849, acc 0.9375, learning_rate 0.0006222\n",
      "2020-12-09T17:06:54.178723: step 1502, loss 0.124098, acc 0.96875, learning_rate 0.0006215\n",
      "2020-12-09T17:06:54.761109: step 1503, loss 0.28719, acc 0.875, learning_rate 0.000620802\n",
      "2020-12-09T17:06:55.372574: step 1504, loss 0.318053, acc 0.78125, learning_rate 0.000620104\n",
      "2020-12-09T17:06:55.980074: step 1505, loss 0.261945, acc 0.875, learning_rate 0.000619407\n",
      "2020-12-09T17:06:56.604073: step 1506, loss 0.435624, acc 0.78125, learning_rate 0.000618711\n",
      "2020-12-09T17:06:57.214572: step 1507, loss 0.160814, acc 0.9375, learning_rate 0.000618017\n",
      "2020-12-09T17:06:57.799607: step 1508, loss 0.255854, acc 0.90625, learning_rate 0.000617323\n",
      "2020-12-09T17:06:58.392107: step 1509, loss 0.183074, acc 0.90625, learning_rate 0.00061663\n",
      "2020-12-09T17:06:58.962529: step 1510, loss 0.215195, acc 0.9375, learning_rate 0.000615938\n",
      "2020-12-09T17:06:59.571225: step 1511, loss 0.211195, acc 0.90625, learning_rate 0.000615247\n",
      "2020-12-09T17:07:00.161454: step 1512, loss 0.246517, acc 0.96875, learning_rate 0.000614556\n",
      "2020-12-09T17:07:00.757878: step 1513, loss 0.252288, acc 0.96875, learning_rate 0.000613867\n",
      "2020-12-09T17:07:01.332346: step 1514, loss 0.140908, acc 0.90625, learning_rate 0.000613179\n",
      "2020-12-09T17:07:01.902079: step 1515, loss 0.260397, acc 0.875, learning_rate 0.000612491\n",
      "2020-12-09T17:07:02.475008: step 1516, loss 0.23699, acc 0.875, learning_rate 0.000611805\n",
      "2020-12-09T17:07:03.081424: step 1517, loss 0.147147, acc 0.96875, learning_rate 0.000611119\n",
      "2020-12-09T17:07:03.685680: step 1518, loss 0.147688, acc 0.9375, learning_rate 0.000610435\n",
      "2020-12-09T17:07:04.274825: step 1519, loss 0.155446, acc 0.9375, learning_rate 0.000609751\n",
      "2020-12-09T17:07:04.872574: step 1520, loss 0.216174, acc 0.9375, learning_rate 0.000609068\n",
      "2020-12-09T17:07:05.423574: step 1521, loss 0.237449, acc 0.84375, learning_rate 0.000608386\n",
      "2020-12-09T17:07:05.972039: step 1522, loss 0.280847, acc 0.84375, learning_rate 0.000607705\n",
      "2020-12-09T17:07:06.550624: step 1523, loss 0.106326, acc 1, learning_rate 0.000607025\n",
      "2020-12-09T17:07:07.128967: step 1524, loss 0.19228, acc 0.90625, learning_rate 0.000606346\n",
      "2020-12-09T17:07:07.693246: step 1525, loss 0.112674, acc 0.96875, learning_rate 0.000605667\n",
      "2020-12-09T17:07:08.259128: step 1526, loss 0.216592, acc 0.90625, learning_rate 0.00060499\n",
      "2020-12-09T17:07:08.846815: step 1527, loss 0.404313, acc 0.8125, learning_rate 0.000604314\n",
      "2020-12-09T17:07:09.442846: step 1528, loss 0.235166, acc 0.9375, learning_rate 0.000603638\n",
      "2020-12-09T17:07:09.999849: step 1529, loss 0.0820412, acc 1, learning_rate 0.000602963\n",
      "2020-12-09T17:07:10.601776: step 1530, loss 0.129852, acc 0.9375, learning_rate 0.00060229\n",
      "2020-12-09T17:07:11.185684: step 1531, loss 0.425134, acc 0.84375, learning_rate 0.000601617\n",
      "2020-12-09T17:07:11.772586: step 1532, loss 0.0782707, acc 0.96875, learning_rate 0.000600945\n",
      "2020-12-09T17:07:12.400513: step 1533, loss 0.197858, acc 0.96875, learning_rate 0.000600274\n",
      "2020-12-09T17:07:13.010791: step 1534, loss 0.207665, acc 0.9375, learning_rate 0.000599604\n",
      "2020-12-09T17:07:13.588985: step 1535, loss 0.222481, acc 0.90625, learning_rate 0.000598934\n",
      "2020-12-09T17:07:14.148004: step 1536, loss 0.403183, acc 0.875, learning_rate 0.000598266\n",
      "2020-12-09T17:07:14.729820: step 1537, loss 0.123175, acc 0.9375, learning_rate 0.000597599\n",
      "2020-12-09T17:07:15.305930: step 1538, loss 0.0820703, acc 0.96875, learning_rate 0.000596932\n",
      "2020-12-09T17:07:15.860928: step 1539, loss 0.246153, acc 0.9375, learning_rate 0.000596266\n",
      "2020-12-09T17:07:16.443865: step 1540, loss 0.276082, acc 0.875, learning_rate 0.000595602\n",
      "2020-12-09T17:07:17.005278: step 1541, loss 0.2195, acc 0.90625, learning_rate 0.000594938\n",
      "2020-12-09T17:07:17.577285: step 1542, loss 0.127292, acc 1, learning_rate 0.000594275\n",
      "2020-12-09T17:07:18.158962: step 1543, loss 0.152725, acc 0.9375, learning_rate 0.000593613\n",
      "2020-12-09T17:07:18.709559: step 1544, loss 0.119035, acc 0.96875, learning_rate 0.000592951\n",
      "2020-12-09T17:07:19.289009: step 1545, loss 0.271014, acc 0.9375, learning_rate 0.000592291\n",
      "2020-12-09T17:07:19.830937: step 1546, loss 0.264048, acc 0.875, learning_rate 0.000591632\n",
      "2020-12-09T17:07:20.391930: step 1547, loss 0.229617, acc 0.90625, learning_rate 0.000590973\n",
      "2020-12-09T17:07:20.946084: step 1548, loss 0.150051, acc 0.9375, learning_rate 0.000590315\n",
      "2020-12-09T17:07:21.518393: step 1549, loss 0.220017, acc 0.90625, learning_rate 0.000589659\n",
      "2020-12-09T17:07:22.067893: step 1550, loss 0.330979, acc 0.84375, learning_rate 0.000589003\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:07:25.313640: step 1550, loss 0.649772, acc 0.7323\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1550\n",
      "\n",
      "2020-12-09T17:07:26.797160: step 1551, loss 0.262278, acc 0.90625, learning_rate 0.000588348\n",
      "2020-12-09T17:07:27.344693: step 1552, loss 0.249671, acc 0.90625, learning_rate 0.000587693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:07:27.905541: step 1553, loss 0.268024, acc 0.84375, learning_rate 0.00058704\n",
      "2020-12-09T17:07:28.462541: step 1554, loss 0.320288, acc 0.84375, learning_rate 0.000586388\n",
      "2020-12-09T17:07:29.020661: step 1555, loss 0.183126, acc 0.9375, learning_rate 0.000585736\n",
      "2020-12-09T17:07:29.603697: step 1556, loss 0.148503, acc 0.96875, learning_rate 0.000585085\n",
      "2020-12-09T17:07:30.164545: step 1557, loss 0.291016, acc 0.875, learning_rate 0.000584436\n",
      "2020-12-09T17:07:30.722048: step 1558, loss 0.288136, acc 0.875, learning_rate 0.000583787\n",
      "2020-12-09T17:07:31.270091: step 1559, loss 0.223941, acc 0.875, learning_rate 0.000583139\n",
      "2020-12-09T17:07:31.839911: step 1560, loss 0.229168, acc 0.9375, learning_rate 0.000582491\n",
      "2020-12-09T17:07:32.394576: step 1561, loss 0.182613, acc 0.9375, learning_rate 0.000581845\n",
      "2020-12-09T17:07:33.006149: step 1562, loss 0.25069, acc 0.90625, learning_rate 0.0005812\n",
      "2020-12-09T17:07:33.561133: step 1563, loss 0.181059, acc 0.96875, learning_rate 0.000580555\n",
      "2020-12-09T17:07:34.105133: step 1564, loss 0.166873, acc 0.96875, learning_rate 0.000579911\n",
      "2020-12-09T17:07:34.668087: step 1565, loss 0.191728, acc 0.9375, learning_rate 0.000579269\n",
      "2020-12-09T17:07:35.225499: step 1566, loss 0.259324, acc 0.96875, learning_rate 0.000578626\n",
      "2020-12-09T17:07:35.800462: step 1567, loss 0.276227, acc 0.875, learning_rate 0.000577985\n",
      "2020-12-09T17:07:36.364460: step 1568, loss 0.213864, acc 0.90625, learning_rate 0.000577345\n",
      "2020-12-09T17:07:36.958959: step 1569, loss 0.167322, acc 0.96875, learning_rate 0.000576706\n",
      "2020-12-09T17:07:37.503467: step 1570, loss 0.168756, acc 0.96875, learning_rate 0.000576067\n",
      "2020-12-09T17:07:38.068957: step 1571, loss 0.145022, acc 0.96875, learning_rate 0.000575429\n",
      "2020-12-09T17:07:38.646560: step 1572, loss 0.159411, acc 0.9375, learning_rate 0.000574792\n",
      "2020-12-09T17:07:39.206842: step 1573, loss 0.135952, acc 0.9375, learning_rate 0.000574156\n",
      "2020-12-09T17:07:39.767976: step 1574, loss 0.223597, acc 0.90625, learning_rate 0.000573521\n",
      "2020-12-09T17:07:40.322448: step 1575, loss 0.257147, acc 0.9375, learning_rate 0.000572887\n",
      "2020-12-09T17:07:40.878477: step 1576, loss 0.144296, acc 1, learning_rate 0.000572254\n",
      "2020-12-09T17:07:41.465967: step 1577, loss 0.109724, acc 0.96875, learning_rate 0.000571621\n",
      "2020-12-09T17:07:42.038459: step 1578, loss 0.184703, acc 0.96875, learning_rate 0.000570989\n",
      "2020-12-09T17:07:42.607376: step 1579, loss 0.166463, acc 0.96875, learning_rate 0.000570358\n",
      "2020-12-09T17:07:43.161347: step 1580, loss 0.129378, acc 0.96875, learning_rate 0.000569728\n",
      "2020-12-09T17:07:43.711308: step 1581, loss 0.137427, acc 0.9375, learning_rate 0.000569099\n",
      "2020-12-09T17:07:44.261176: step 1582, loss 0.183563, acc 0.96875, learning_rate 0.000568471\n",
      "2020-12-09T17:07:45.046213: step 1583, loss 0.159199, acc 0.96875, learning_rate 0.000567843\n",
      "2020-12-09T17:07:45.858783: step 1584, loss 0.300548, acc 0.875, learning_rate 0.000567216\n",
      "2020-12-09T17:07:46.462129: step 1585, loss 0.299225, acc 0.90625, learning_rate 0.00056659\n",
      "2020-12-09T17:07:47.077884: step 1586, loss 0.182323, acc 0.96875, learning_rate 0.000565965\n",
      "2020-12-09T17:07:47.682866: step 1587, loss 0.130499, acc 1, learning_rate 0.000565341\n",
      "2020-12-09T17:07:48.253369: step 1588, loss 0.297396, acc 0.875, learning_rate 0.000564718\n",
      "2020-12-09T17:07:48.830831: step 1589, loss 0.225562, acc 0.9375, learning_rate 0.000564095\n",
      "2020-12-09T17:07:49.424074: step 1590, loss 0.12395, acc 0.9375, learning_rate 0.000563474\n",
      "2020-12-09T17:07:50.004189: step 1591, loss 0.192531, acc 0.9375, learning_rate 0.000562853\n",
      "2020-12-09T17:07:50.588193: step 1592, loss 0.147198, acc 0.96875, learning_rate 0.000562233\n",
      "2020-12-09T17:07:51.184016: step 1593, loss 0.221138, acc 0.90625, learning_rate 0.000561614\n",
      "2020-12-09T17:07:51.742897: step 1594, loss 0.312776, acc 0.84375, learning_rate 0.000560995\n",
      "2020-12-09T17:07:52.342680: step 1595, loss 0.208457, acc 0.9375, learning_rate 0.000560378\n",
      "2020-12-09T17:07:52.914765: step 1596, loss 0.305077, acc 0.84375, learning_rate 0.000559761\n",
      "2020-12-09T17:07:53.522645: step 1597, loss 0.383447, acc 0.8125, learning_rate 0.000559145\n",
      "2020-12-09T17:07:54.081827: step 1598, loss 0.22766, acc 0.9375, learning_rate 0.00055853\n",
      "2020-12-09T17:07:54.688363: step 1599, loss 0.139528, acc 0.9375, learning_rate 0.000557916\n",
      "2020-12-09T17:07:55.264309: step 1600, loss 0.303365, acc 0.84375, learning_rate 0.000557302\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:07:58.535363: step 1600, loss 0.649735, acc 0.7323\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1600\n",
      "\n",
      "2020-12-09T17:08:00.045477: step 1601, loss 0.275217, acc 0.90625, learning_rate 0.00055669\n",
      "2020-12-09T17:08:00.622485: step 1602, loss 0.223384, acc 0.96875, learning_rate 0.000556078\n",
      "2020-12-09T17:08:01.233227: step 1603, loss 0.157342, acc 0.96875, learning_rate 0.000555467\n",
      "2020-12-09T17:08:01.803901: step 1604, loss 0.159571, acc 0.9375, learning_rate 0.000554857\n",
      "2020-12-09T17:08:02.345867: step 1605, loss 0.186425, acc 0.875, learning_rate 0.000554248\n",
      "2020-12-09T17:08:02.901898: step 1606, loss 0.314835, acc 0.8125, learning_rate 0.000553639\n",
      "2020-12-09T17:08:03.488398: step 1607, loss 0.31705, acc 0.8125, learning_rate 0.000553032\n",
      "2020-12-09T17:08:04.056086: step 1608, loss 0.140731, acc 0.9375, learning_rate 0.000552425\n",
      "2020-12-09T17:08:04.666993: step 1609, loss 0.32754, acc 0.84375, learning_rate 0.000551819\n",
      "2020-12-09T17:08:05.491837: step 1610, loss 0.187026, acc 0.9375, learning_rate 0.000551213\n",
      "2020-12-09T17:08:06.244836: step 1611, loss 0.169387, acc 0.9375, learning_rate 0.000550609\n",
      "2020-12-09T17:08:06.917523: step 1612, loss 0.202188, acc 0.9375, learning_rate 0.000550005\n",
      "2020-12-09T17:08:07.566070: step 1613, loss 0.323773, acc 0.875, learning_rate 0.000549403\n",
      "2020-12-09T17:08:08.180071: step 1614, loss 0.118848, acc 0.96875, learning_rate 0.000548801\n",
      "2020-12-09T17:08:08.804103: step 1615, loss 0.456521, acc 0.875, learning_rate 0.000548199\n",
      "2020-12-09T17:08:09.398355: step 1616, loss 0.275163, acc 0.84375, learning_rate 0.000547599\n",
      "2020-12-09T17:08:10.004073: step 1617, loss 0.111542, acc 0.9375, learning_rate 0.000546999\n",
      "2020-12-09T17:08:10.579777: step 1618, loss 0.192815, acc 0.9375, learning_rate 0.000546401\n",
      "2020-12-09T17:08:11.209013: step 1619, loss 0.476749, acc 0.8125, learning_rate 0.000545803\n",
      "2020-12-09T17:08:11.813987: step 1620, loss 0.261095, acc 0.875, learning_rate 0.000545206\n",
      "2020-12-09T17:08:12.374636: step 1621, loss 0.343175, acc 0.875, learning_rate 0.000544609\n",
      "2020-12-09T17:08:12.937002: step 1622, loss 0.267697, acc 0.875, learning_rate 0.000544014\n",
      "2020-12-09T17:08:13.491502: step 1623, loss 0.211414, acc 0.875, learning_rate 0.000543419\n",
      "2020-12-09T17:08:14.062093: step 1624, loss 0.233593, acc 0.875, learning_rate 0.000542825\n",
      "2020-12-09T17:08:14.620465: step 1625, loss 0.350702, acc 0.875, learning_rate 0.000542232\n",
      "2020-12-09T17:08:15.187095: step 1626, loss 0.174002, acc 0.96875, learning_rate 0.000541639\n",
      "2020-12-09T17:08:15.746818: step 1627, loss 0.0874775, acc 1, learning_rate 0.000541048\n",
      "2020-12-09T17:08:16.295949: step 1628, loss 0.174266, acc 0.90625, learning_rate 0.000540457\n",
      "2020-12-09T17:08:16.987728: step 1629, loss 0.194202, acc 0.90625, learning_rate 0.000539867\n",
      "2020-12-09T17:08:17.642412: step 1630, loss 0.222953, acc 0.9375, learning_rate 0.000539278\n",
      "2020-12-09T17:08:18.193153: step 1631, loss 0.102297, acc 0.96875, learning_rate 0.000538689\n",
      "2020-12-09T17:08:18.758546: step 1632, loss 0.283238, acc 0.875, learning_rate 0.000538101\n",
      "2020-12-09T17:08:19.318514: step 1633, loss 0.220919, acc 0.90625, learning_rate 0.000537515\n",
      "2020-12-09T17:08:19.896484: step 1634, loss 0.257343, acc 0.90625, learning_rate 0.000536929\n",
      "2020-12-09T17:08:20.431486: step 1635, loss 0.232987, acc 0.90625, learning_rate 0.000536343\n",
      "2020-12-09T17:08:20.991919: step 1636, loss 0.217022, acc 0.90625, learning_rate 0.000535759\n",
      "2020-12-09T17:08:21.540954: step 1637, loss 0.264413, acc 0.875, learning_rate 0.000535175\n",
      "2020-12-09T17:08:22.097957: step 1638, loss 0.120163, acc 0.9375, learning_rate 0.000534592\n",
      "2020-12-09T17:08:22.665954: step 1639, loss 0.254342, acc 0.84375, learning_rate 0.00053401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:08:23.248761: step 1640, loss 0.175689, acc 0.96875, learning_rate 0.000533429\n",
      "2020-12-09T17:08:23.827947: step 1641, loss 0.126298, acc 1, learning_rate 0.000532848\n",
      "2020-12-09T17:08:24.410735: step 1642, loss 0.176373, acc 0.9375, learning_rate 0.000532268\n",
      "2020-12-09T17:08:24.978204: step 1643, loss 0.194501, acc 0.9375, learning_rate 0.000531689\n",
      "2020-12-09T17:08:25.555939: step 1644, loss 0.227567, acc 0.875, learning_rate 0.000531111\n",
      "2020-12-09T17:08:26.098120: step 1645, loss 0.260826, acc 0.90625, learning_rate 0.000530533\n",
      "2020-12-09T17:08:26.644183: step 1646, loss 0.297291, acc 0.90625, learning_rate 0.000529957\n",
      "2020-12-09T17:08:27.216142: step 1647, loss 0.231725, acc 0.9375, learning_rate 0.000529381\n",
      "2020-12-09T17:08:27.809709: step 1648, loss 0.148207, acc 0.9375, learning_rate 0.000528805\n",
      "2020-12-09T17:08:28.374723: step 1649, loss 0.484387, acc 0.84375, learning_rate 0.000528231\n",
      "2020-12-09T17:08:28.939464: step 1650, loss 0.310188, acc 0.84375, learning_rate 0.000527657\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:08:32.176004: step 1650, loss 0.649669, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1650\n",
      "\n",
      "2020-12-09T17:08:33.669703: step 1651, loss 0.244557, acc 0.90625, learning_rate 0.000527085\n",
      "2020-12-09T17:08:34.240799: step 1652, loss 0.133679, acc 0.96875, learning_rate 0.000526512\n",
      "2020-12-09T17:08:34.790279: step 1653, loss 0.375694, acc 0.84375, learning_rate 0.000525941\n",
      "2020-12-09T17:08:35.344328: step 1654, loss 0.189912, acc 0.90625, learning_rate 0.00052537\n",
      "2020-12-09T17:08:35.903398: step 1655, loss 0.0874786, acc 0.96875, learning_rate 0.000524801\n",
      "2020-12-09T17:08:36.481353: step 1656, loss 0.139608, acc 0.96875, learning_rate 0.000524232\n",
      "2020-12-09T17:08:37.041687: step 1657, loss 0.225954, acc 0.9375, learning_rate 0.000523663\n",
      "2020-12-09T17:08:37.625403: step 1658, loss 0.246248, acc 0.9375, learning_rate 0.000523096\n",
      "2020-12-09T17:08:38.171907: step 1659, loss 0.283145, acc 0.84375, learning_rate 0.000522529\n",
      "2020-12-09T17:08:38.721227: step 1660, loss 0.278529, acc 0.90625, learning_rate 0.000521963\n",
      "2020-12-09T17:08:39.288808: step 1661, loss 0.137067, acc 0.9375, learning_rate 0.000521398\n",
      "2020-12-09T17:08:39.847459: step 1662, loss 0.270107, acc 0.90625, learning_rate 0.000520833\n",
      "2020-12-09T17:08:40.396746: step 1663, loss 0.155131, acc 0.96875, learning_rate 0.00052027\n",
      "2020-12-09T17:08:40.961156: step 1664, loss 0.313481, acc 0.9375, learning_rate 0.000519707\n",
      "2020-12-09T17:08:41.567746: step 1665, loss 0.174764, acc 0.9375, learning_rate 0.000519144\n",
      "2020-12-09T17:08:42.124609: step 1666, loss 0.420029, acc 0.71875, learning_rate 0.000518583\n",
      "2020-12-09T17:08:42.677608: step 1667, loss 0.184303, acc 0.90625, learning_rate 0.000518022\n",
      "2020-12-09T17:08:43.267108: step 1668, loss 0.209604, acc 0.9375, learning_rate 0.000517462\n",
      "2020-12-09T17:08:44.128608: step 1669, loss 0.216308, acc 0.9375, learning_rate 0.000516903\n",
      "2020-12-09T17:08:44.785608: step 1670, loss 0.328148, acc 0.875, learning_rate 0.000516345\n",
      "2020-12-09T17:08:45.382643: step 1671, loss 0.219243, acc 0.9375, learning_rate 0.000515787\n",
      "2020-12-09T17:08:45.925112: step 1672, loss 0.218845, acc 0.96875, learning_rate 0.00051523\n",
      "2020-12-09T17:08:46.512607: step 1673, loss 0.172171, acc 0.96875, learning_rate 0.000514674\n",
      "2020-12-09T17:08:47.084605: step 1674, loss 0.169942, acc 0.9375, learning_rate 0.000514118\n",
      "2020-12-09T17:08:47.734605: step 1675, loss 0.425109, acc 0.875, learning_rate 0.000513563\n",
      "2020-12-09T17:08:48.468942: step 1676, loss 0.22845, acc 0.96875, learning_rate 0.000513009\n",
      "2020-12-09T17:08:49.033939: step 1677, loss 0.101583, acc 1, learning_rate 0.000512456\n",
      "2020-12-09T17:08:49.850935: step 1678, loss 0.136444, acc 0.96875, learning_rate 0.000511904\n",
      "2020-12-09T17:08:50.458931: step 1679, loss 0.16972, acc 0.9375, learning_rate 0.000511352\n",
      "2020-12-09T17:08:51.022274: step 1680, loss 0.174452, acc 0.96875, learning_rate 0.000510801\n",
      "2020-12-09T17:08:51.623452: step 1681, loss 0.184461, acc 0.9375, learning_rate 0.000510251\n",
      "2020-12-09T17:08:52.204556: step 1682, loss 0.34249, acc 0.8125, learning_rate 0.000509701\n",
      "2020-12-09T17:08:52.755042: step 1683, loss 0.19963, acc 0.9375, learning_rate 0.000509152\n",
      "2020-12-09T17:08:53.352076: step 1684, loss 0.318085, acc 0.90625, learning_rate 0.000508604\n",
      "2020-12-09T17:08:53.925050: step 1685, loss 0.170604, acc 0.9375, learning_rate 0.000508057\n",
      "2020-12-09T17:08:54.492254: step 1686, loss 0.243755, acc 0.90625, learning_rate 0.00050751\n",
      "2020-12-09T17:08:55.067722: step 1687, loss 0.421662, acc 0.84375, learning_rate 0.000506964\n",
      "2020-12-09T17:08:55.647484: step 1688, loss 0.211166, acc 0.90625, learning_rate 0.000506419\n",
      "2020-12-09T17:08:56.206009: step 1689, loss 0.190564, acc 0.9375, learning_rate 0.000505875\n",
      "2020-12-09T17:08:56.757476: step 1690, loss 0.20407, acc 0.90625, learning_rate 0.000505331\n",
      "2020-12-09T17:08:57.319385: step 1691, loss 0.101438, acc 1, learning_rate 0.000504788\n",
      "2020-12-09T17:08:57.901526: step 1692, loss 0.18306, acc 0.9375, learning_rate 0.000504246\n",
      "2020-12-09T17:08:58.457095: step 1693, loss 0.303569, acc 0.875, learning_rate 0.000503704\n",
      "2020-12-09T17:08:59.030972: step 1694, loss 0.104473, acc 0.9375, learning_rate 0.000503164\n",
      "2020-12-09T17:08:59.605817: step 1695, loss 0.142953, acc 0.90625, learning_rate 0.000502624\n",
      "2020-12-09T17:09:00.188665: step 1696, loss 0.109696, acc 0.96875, learning_rate 0.000502084\n",
      "2020-12-09T17:09:00.734656: step 1697, loss 0.25146, acc 0.8125, learning_rate 0.000501546\n",
      "2020-12-09T17:09:01.390155: step 1698, loss 0.31215, acc 0.875, learning_rate 0.000501008\n",
      "2020-12-09T17:09:01.995027: step 1699, loss 0.142554, acc 0.96875, learning_rate 0.00050047\n",
      "2020-12-09T17:09:02.554576: step 1700, loss 0.230103, acc 0.875, learning_rate 0.000499934\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:09:05.752593: step 1700, loss 0.64962, acc 0.733138\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1700\n",
      "\n",
      "2020-12-09T17:09:07.372776: step 1701, loss 0.439727, acc 0.875, learning_rate 0.000499398\n",
      "2020-12-09T17:09:07.910952: step 1702, loss 0.135814, acc 0.96875, learning_rate 0.000498863\n",
      "2020-12-09T17:09:08.480594: step 1703, loss 0.233262, acc 0.90625, learning_rate 0.000498329\n",
      "2020-12-09T17:09:09.018011: step 1704, loss 0.254156, acc 0.90625, learning_rate 0.000497795\n",
      "2020-12-09T17:09:09.741981: step 1705, loss 0.177327, acc 0.90625, learning_rate 0.000497263\n",
      "2020-12-09T17:09:10.493979: step 1706, loss 0.301396, acc 0.84375, learning_rate 0.00049673\n",
      "2020-12-09T17:09:11.074224: step 1707, loss 0.228586, acc 0.9375, learning_rate 0.000496199\n",
      "2020-12-09T17:09:11.638318: step 1708, loss 0.2682, acc 0.875, learning_rate 0.000495668\n",
      "2020-12-09T17:09:12.207404: step 1709, loss 0.16809, acc 0.96875, learning_rate 0.000495138\n",
      "2020-12-09T17:09:12.760887: step 1710, loss 0.304811, acc 0.84375, learning_rate 0.000494609\n",
      "2020-12-09T17:09:13.329026: step 1711, loss 0.354679, acc 0.84375, learning_rate 0.00049408\n",
      "2020-12-09T17:09:13.909621: step 1712, loss 0.156096, acc 0.9375, learning_rate 0.000493552\n",
      "2020-12-09T17:09:14.509499: step 1713, loss 0.118792, acc 0.96875, learning_rate 0.000493025\n",
      "2020-12-09T17:09:15.101999: step 1714, loss 0.211186, acc 0.96875, learning_rate 0.000492499\n",
      "2020-12-09T17:09:15.721499: step 1715, loss 0.250789, acc 0.9375, learning_rate 0.000491973\n",
      "2020-12-09T17:09:16.317497: step 1716, loss 0.143871, acc 0.96875, learning_rate 0.000491448\n",
      "2020-12-09T17:09:16.881998: step 1717, loss 0.254814, acc 0.84375, learning_rate 0.000490924\n",
      "2020-12-09T17:09:17.510033: step 1718, loss 0.400739, acc 0.875, learning_rate 0.0004904\n",
      "2020-12-09T17:09:18.079695: step 1719, loss 0.275068, acc 0.84375, learning_rate 0.000489877\n",
      "2020-12-09T17:09:18.692925: step 1720, loss 0.159805, acc 0.9375, learning_rate 0.000489355\n",
      "2020-12-09T17:09:19.268078: step 1721, loss 0.262547, acc 0.875, learning_rate 0.000488833\n",
      "2020-12-09T17:09:19.871958: step 1722, loss 0.233316, acc 0.90625, learning_rate 0.000488312\n",
      "2020-12-09T17:09:20.438908: step 1723, loss 0.18585, acc 0.9375, learning_rate 0.000487792\n",
      "2020-12-09T17:09:20.990379: step 1724, loss 0.497922, acc 0.8125, learning_rate 0.000487273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:09:21.563292: step 1725, loss 0.153524, acc 0.90625, learning_rate 0.000486754\n",
      "2020-12-09T17:09:22.141217: step 1726, loss 0.160367, acc 0.90625, learning_rate 0.000486236\n",
      "2020-12-09T17:09:22.727161: step 1727, loss 0.165595, acc 0.96875, learning_rate 0.000485718\n",
      "2020-12-09T17:09:23.285664: step 1728, loss 0.275134, acc 0.875, learning_rate 0.000485202\n",
      "2020-12-09T17:09:23.845663: step 1729, loss 0.225898, acc 0.875, learning_rate 0.000484686\n",
      "2020-12-09T17:09:24.413582: step 1730, loss 0.326715, acc 0.78125, learning_rate 0.00048417\n",
      "2020-12-09T17:09:24.963486: step 1731, loss 0.146468, acc 1, learning_rate 0.000483656\n",
      "2020-12-09T17:09:25.527162: step 1732, loss 0.276569, acc 0.84375, learning_rate 0.000483142\n",
      "2020-12-09T17:09:26.088109: step 1733, loss 0.217229, acc 0.96875, learning_rate 0.000482629\n",
      "2020-12-09T17:09:26.656853: step 1734, loss 0.296727, acc 0.90625, learning_rate 0.000482116\n",
      "2020-12-09T17:09:27.206998: step 1735, loss 0.189637, acc 0.9375, learning_rate 0.000481604\n",
      "2020-12-09T17:09:27.768433: step 1736, loss 0.282243, acc 0.84375, learning_rate 0.000481093\n",
      "2020-12-09T17:09:28.319145: step 1737, loss 0.199848, acc 0.9375, learning_rate 0.000480582\n",
      "2020-12-09T17:09:28.932754: step 1738, loss 0.25488, acc 0.875, learning_rate 0.000480073\n",
      "2020-12-09T17:09:29.496291: step 1739, loss 0.180999, acc 0.9375, learning_rate 0.000479564\n",
      "2020-12-09T17:09:30.088836: step 1740, loss 0.146821, acc 0.9375, learning_rate 0.000479055\n",
      "2020-12-09T17:09:30.657576: step 1741, loss 0.189554, acc 0.96875, learning_rate 0.000478547\n",
      "2020-12-09T17:09:31.200109: step 1742, loss 0.229987, acc 0.90625, learning_rate 0.00047804\n",
      "2020-12-09T17:09:31.757885: step 1743, loss 0.511667, acc 0.75, learning_rate 0.000477534\n",
      "2020-12-09T17:09:32.308886: step 1744, loss 0.259963, acc 0.9375, learning_rate 0.000477028\n",
      "2020-12-09T17:09:32.895808: step 1745, loss 0.311185, acc 0.8125, learning_rate 0.000476523\n",
      "2020-12-09T17:09:33.447459: step 1746, loss 0.290498, acc 0.75, learning_rate 0.000476019\n",
      "2020-12-09T17:09:34.051802: step 1747, loss 0.136218, acc 0.96875, learning_rate 0.000475515\n",
      "2020-12-09T17:09:34.618419: step 1748, loss 0.0708578, acc 0.96875, learning_rate 0.000475012\n",
      "2020-12-09T17:09:35.171220: step 1749, loss 0.221293, acc 0.90625, learning_rate 0.00047451\n",
      "2020-12-09T17:09:35.752683: step 1750, loss 0.143708, acc 0.96875, learning_rate 0.000474008\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:09:39.367167: step 1750, loss 0.649576, acc 0.733138\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1750\n",
      "\n",
      "2020-12-09T17:09:40.803991: step 1751, loss 0.254743, acc 0.90625, learning_rate 0.000473507\n",
      "2020-12-09T17:09:41.365690: step 1752, loss 0.127216, acc 0.96875, learning_rate 0.000473007\n",
      "2020-12-09T17:09:41.914744: step 1753, loss 0.179652, acc 0.90625, learning_rate 0.000472507\n",
      "2020-12-09T17:09:42.487787: step 1754, loss 0.185126, acc 0.90625, learning_rate 0.000472008\n",
      "2020-12-09T17:09:43.026750: step 1755, loss 0.206036, acc 0.96875, learning_rate 0.00047151\n",
      "2020-12-09T17:09:43.609286: step 1756, loss 0.140839, acc 0.9375, learning_rate 0.000471012\n",
      "2020-12-09T17:09:44.178286: step 1757, loss 0.201231, acc 0.9375, learning_rate 0.000470515\n",
      "2020-12-09T17:09:44.758338: step 1758, loss 0.255321, acc 0.90625, learning_rate 0.000470019\n",
      "2020-12-09T17:09:45.316875: step 1759, loss 0.23146, acc 0.9375, learning_rate 0.000469523\n",
      "2020-12-09T17:09:45.875870: step 1760, loss 0.287669, acc 0.90625, learning_rate 0.000469028\n",
      "2020-12-09T17:09:46.436653: step 1761, loss 0.210122, acc 0.90625, learning_rate 0.000468534\n",
      "2020-12-09T17:09:47.008785: step 1762, loss 0.255601, acc 0.90625, learning_rate 0.00046804\n",
      "2020-12-09T17:09:47.581251: step 1763, loss 0.318699, acc 0.875, learning_rate 0.000467547\n",
      "2020-12-09T17:09:48.142940: step 1764, loss 0.326475, acc 0.875, learning_rate 0.000467055\n",
      "2020-12-09T17:09:48.730739: step 1765, loss 0.186846, acc 0.9375, learning_rate 0.000466563\n",
      "2020-12-09T17:09:49.265599: step 1766, loss 0.411715, acc 0.8125, learning_rate 0.000466072\n",
      "2020-12-09T17:09:49.839601: step 1767, loss 0.193606, acc 0.875, learning_rate 0.000465581\n",
      "2020-12-09T17:09:50.396912: step 1768, loss 0.281271, acc 0.875, learning_rate 0.000465092\n",
      "2020-12-09T17:09:50.951403: step 1769, loss 0.373015, acc 0.8125, learning_rate 0.000464603\n",
      "2020-12-09T17:09:51.510588: step 1770, loss 0.293479, acc 0.9375, learning_rate 0.000464114\n",
      "2020-12-09T17:09:52.091089: step 1771, loss 0.319208, acc 0.875, learning_rate 0.000463627\n",
      "2020-12-09T17:09:52.658304: step 1772, loss 0.131982, acc 0.96875, learning_rate 0.000463139\n",
      "2020-12-09T17:09:53.200269: step 1773, loss 0.157459, acc 0.90625, learning_rate 0.000462653\n",
      "2020-12-09T17:09:53.761567: step 1774, loss 0.410485, acc 0.71875, learning_rate 0.000462167\n",
      "2020-12-09T17:09:54.345136: step 1775, loss 0.136466, acc 0.96875, learning_rate 0.000461682\n",
      "2020-12-09T17:09:54.912620: step 1776, loss 0.230793, acc 0.90625, learning_rate 0.000461198\n",
      "2020-12-09T17:09:55.487940: step 1777, loss 0.12429, acc 1, learning_rate 0.000460714\n",
      "2020-12-09T17:09:56.033862: step 1778, loss 0.310604, acc 0.84375, learning_rate 0.000460231\n",
      "2020-12-09T17:09:56.603398: step 1779, loss 0.209572, acc 0.9375, learning_rate 0.000459748\n",
      "2020-12-09T17:09:57.159979: step 1780, loss 0.182884, acc 0.9375, learning_rate 0.000459266\n",
      "2020-12-09T17:09:57.740512: step 1781, loss 0.107386, acc 1, learning_rate 0.000458785\n",
      "2020-12-09T17:09:58.290498: step 1782, loss 0.167886, acc 0.96875, learning_rate 0.000458304\n",
      "2020-12-09T17:09:58.867531: step 1783, loss 0.162742, acc 0.9375, learning_rate 0.000457824\n",
      "2020-12-09T17:09:59.414025: step 1784, loss 0.188566, acc 0.9375, learning_rate 0.000457345\n",
      "2020-12-09T17:09:59.995027: step 1785, loss 0.219456, acc 0.9375, learning_rate 0.000456866\n",
      "2020-12-09T17:10:00.566198: step 1786, loss 0.235576, acc 0.90625, learning_rate 0.000456388\n",
      "2020-12-09T17:10:01.146180: step 1787, loss 0.318115, acc 0.84375, learning_rate 0.000455911\n",
      "2020-12-09T17:10:01.709380: step 1788, loss 0.40683, acc 0.78125, learning_rate 0.000455434\n",
      "2020-12-09T17:10:02.282660: step 1789, loss 0.315292, acc 0.8125, learning_rate 0.000454958\n",
      "2020-12-09T17:10:02.835833: step 1790, loss 0.238613, acc 0.90625, learning_rate 0.000454482\n",
      "2020-12-09T17:10:03.386332: step 1791, loss 0.225907, acc 0.90625, learning_rate 0.000454008\n",
      "2020-12-09T17:10:03.945834: step 1792, loss 0.163572, acc 0.9375, learning_rate 0.000453533\n",
      "2020-12-09T17:10:04.522734: step 1793, loss 0.561487, acc 0.84375, learning_rate 0.00045306\n",
      "2020-12-09T17:10:04.742735: step 1794, loss 0.398857, acc 0.846154, learning_rate 0.000452587\n",
      "2020-12-09T17:10:05.296230: step 1795, loss 0.135701, acc 0.96875, learning_rate 0.000452115\n",
      "2020-12-09T17:10:05.866104: step 1796, loss 0.125289, acc 0.96875, learning_rate 0.000451643\n",
      "2020-12-09T17:10:06.432593: step 1797, loss 0.147602, acc 0.96875, learning_rate 0.000451172\n",
      "2020-12-09T17:10:07.012394: step 1798, loss 0.269009, acc 0.90625, learning_rate 0.000450701\n",
      "2020-12-09T17:10:07.565146: step 1799, loss 0.219797, acc 0.9375, learning_rate 0.000450232\n",
      "2020-12-09T17:10:08.114168: step 1800, loss 0.121322, acc 0.96875, learning_rate 0.000449762\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:10:11.416530: step 1800, loss 0.649558, acc 0.733138\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1800\n",
      "\n",
      "2020-12-09T17:10:12.875474: step 1801, loss 0.226946, acc 0.90625, learning_rate 0.000449294\n",
      "2020-12-09T17:10:13.430975: step 1802, loss 0.191922, acc 0.90625, learning_rate 0.000448826\n",
      "2020-12-09T17:10:13.984389: step 1803, loss 0.403153, acc 0.875, learning_rate 0.000448359\n",
      "2020-12-09T17:10:14.571686: step 1804, loss 0.173795, acc 0.96875, learning_rate 0.000447892\n",
      "2020-12-09T17:10:15.158456: step 1805, loss 0.0715102, acc 0.96875, learning_rate 0.000447426\n",
      "2020-12-09T17:10:15.739624: step 1806, loss 0.200289, acc 0.9375, learning_rate 0.000446961\n",
      "2020-12-09T17:10:16.317619: step 1807, loss 0.2957, acc 0.8125, learning_rate 0.000446496\n",
      "2020-12-09T17:10:16.891138: step 1808, loss 0.154114, acc 0.90625, learning_rate 0.000446032\n",
      "2020-12-09T17:10:17.428447: step 1809, loss 0.184858, acc 0.90625, learning_rate 0.000445568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:10:17.991206: step 1810, loss 0.261095, acc 0.90625, learning_rate 0.000445105\n",
      "2020-12-09T17:10:18.544673: step 1811, loss 0.326369, acc 0.875, learning_rate 0.000444643\n",
      "2020-12-09T17:10:19.108864: step 1812, loss 0.120136, acc 1, learning_rate 0.000444181\n",
      "2020-12-09T17:10:19.671393: step 1813, loss 0.112995, acc 1, learning_rate 0.00044372\n",
      "2020-12-09T17:10:20.227222: step 1814, loss 0.252295, acc 0.9375, learning_rate 0.00044326\n",
      "2020-12-09T17:10:20.835220: step 1815, loss 0.226361, acc 0.90625, learning_rate 0.0004428\n",
      "2020-12-09T17:10:21.386137: step 1816, loss 0.371202, acc 0.84375, learning_rate 0.000442341\n",
      "2020-12-09T17:10:21.969172: step 1817, loss 0.192828, acc 0.9375, learning_rate 0.000441882\n",
      "2020-12-09T17:10:22.542047: step 1818, loss 0.264196, acc 0.84375, learning_rate 0.000441424\n",
      "2020-12-09T17:10:23.126005: step 1819, loss 0.292666, acc 0.8125, learning_rate 0.000440967\n",
      "2020-12-09T17:10:23.721827: step 1820, loss 0.231793, acc 0.875, learning_rate 0.00044051\n",
      "2020-12-09T17:10:24.330481: step 1821, loss 0.123513, acc 1, learning_rate 0.000440054\n",
      "2020-12-09T17:10:24.912594: step 1822, loss 0.18118, acc 0.90625, learning_rate 0.000439599\n",
      "2020-12-09T17:10:25.492274: step 1823, loss 0.147895, acc 1, learning_rate 0.000439144\n",
      "2020-12-09T17:10:26.138271: step 1824, loss 0.196161, acc 0.9375, learning_rate 0.000438689\n",
      "2020-12-09T17:10:26.705605: step 1825, loss 0.135162, acc 0.9375, learning_rate 0.000438236\n",
      "2020-12-09T17:10:27.289916: step 1826, loss 0.342006, acc 0.8125, learning_rate 0.000437783\n",
      "2020-12-09T17:10:27.868449: step 1827, loss 0.352998, acc 0.84375, learning_rate 0.00043733\n",
      "2020-12-09T17:10:28.441217: step 1828, loss 0.20823, acc 0.9375, learning_rate 0.000436878\n",
      "2020-12-09T17:10:29.008359: step 1829, loss 0.256231, acc 0.875, learning_rate 0.000436427\n",
      "2020-12-09T17:10:29.550998: step 1830, loss 0.194165, acc 0.9375, learning_rate 0.000435976\n",
      "2020-12-09T17:10:30.128998: step 1831, loss 0.144009, acc 0.90625, learning_rate 0.000435526\n",
      "2020-12-09T17:10:30.685453: step 1832, loss 0.354766, acc 0.8125, learning_rate 0.000435077\n",
      "2020-12-09T17:10:31.240654: step 1833, loss 0.366537, acc 0.84375, learning_rate 0.000434628\n",
      "2020-12-09T17:10:31.797320: step 1834, loss 0.26461, acc 0.875, learning_rate 0.00043418\n",
      "2020-12-09T17:10:32.343032: step 1835, loss 0.118036, acc 1, learning_rate 0.000433732\n",
      "2020-12-09T17:10:32.925796: step 1836, loss 0.126939, acc 0.96875, learning_rate 0.000433285\n",
      "2020-12-09T17:10:33.471391: step 1837, loss 0.20423, acc 0.90625, learning_rate 0.000432838\n",
      "2020-12-09T17:10:34.058357: step 1838, loss 0.445309, acc 0.84375, learning_rate 0.000432393\n",
      "2020-12-09T17:10:34.627841: step 1839, loss 0.356843, acc 0.9375, learning_rate 0.000431947\n",
      "2020-12-09T17:10:35.183670: step 1840, loss 0.371706, acc 0.90625, learning_rate 0.000431503\n",
      "2020-12-09T17:10:35.730222: step 1841, loss 0.194549, acc 0.90625, learning_rate 0.000431059\n",
      "2020-12-09T17:10:36.306710: step 1842, loss 0.336596, acc 0.84375, learning_rate 0.000430615\n",
      "2020-12-09T17:10:36.864786: step 1843, loss 0.312244, acc 0.84375, learning_rate 0.000430172\n",
      "2020-12-09T17:10:37.421153: step 1844, loss 0.293776, acc 0.8125, learning_rate 0.00042973\n",
      "2020-12-09T17:10:37.981653: step 1845, loss 0.422905, acc 0.875, learning_rate 0.000429288\n",
      "2020-12-09T17:10:38.599336: step 1846, loss 0.249849, acc 0.90625, learning_rate 0.000428847\n",
      "2020-12-09T17:10:39.128684: step 1847, loss 0.152239, acc 0.9375, learning_rate 0.000428407\n",
      "2020-12-09T17:10:39.673685: step 1848, loss 0.190967, acc 0.90625, learning_rate 0.000427967\n",
      "2020-12-09T17:10:40.247082: step 1849, loss 0.307079, acc 0.84375, learning_rate 0.000427527\n",
      "2020-12-09T17:10:40.798526: step 1850, loss 0.0819627, acc 1, learning_rate 0.000427089\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:10:43.982895: step 1850, loss 0.649525, acc 0.733138\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1850\n",
      "\n",
      "2020-12-09T17:10:45.421915: step 1851, loss 0.147117, acc 1, learning_rate 0.000426651\n",
      "2020-12-09T17:10:45.993825: step 1852, loss 0.268171, acc 0.90625, learning_rate 0.000426213\n",
      "2020-12-09T17:10:46.563247: step 1853, loss 0.0910409, acc 1, learning_rate 0.000425776\n",
      "2020-12-09T17:10:47.119185: step 1854, loss 0.267789, acc 0.90625, learning_rate 0.00042534\n",
      "2020-12-09T17:10:47.919684: step 1855, loss 0.171223, acc 0.96875, learning_rate 0.000424904\n",
      "2020-12-09T17:10:48.807202: step 1856, loss 0.172484, acc 0.9375, learning_rate 0.000424469\n",
      "2020-12-09T17:10:49.431792: step 1857, loss 0.163839, acc 0.9375, learning_rate 0.000424034\n",
      "2020-12-09T17:10:50.311261: step 1858, loss 0.334199, acc 0.875, learning_rate 0.0004236\n",
      "2020-12-09T17:10:50.902486: step 1859, loss 0.186699, acc 0.96875, learning_rate 0.000423166\n",
      "2020-12-09T17:10:51.546974: step 1860, loss 0.233249, acc 0.90625, learning_rate 0.000422734\n",
      "2020-12-09T17:10:52.440473: step 1861, loss 0.16964, acc 0.90625, learning_rate 0.000422301\n",
      "2020-12-09T17:10:53.271976: step 1862, loss 0.194334, acc 0.90625, learning_rate 0.000421869\n",
      "2020-12-09T17:10:54.002945: step 1863, loss 0.302821, acc 0.84375, learning_rate 0.000421438\n",
      "2020-12-09T17:10:54.760940: step 1864, loss 0.18424, acc 0.90625, learning_rate 0.000421008\n",
      "2020-12-09T17:10:55.526474: step 1865, loss 0.218416, acc 0.90625, learning_rate 0.000420578\n",
      "2020-12-09T17:10:56.176484: step 1866, loss 0.361898, acc 0.875, learning_rate 0.000420148\n",
      "2020-12-09T17:10:56.793521: step 1867, loss 0.198832, acc 0.90625, learning_rate 0.000419719\n",
      "2020-12-09T17:10:57.691489: step 1868, loss 0.217927, acc 0.9375, learning_rate 0.000419291\n",
      "2020-12-09T17:10:58.471868: step 1869, loss 0.340395, acc 0.8125, learning_rate 0.000418863\n",
      "2020-12-09T17:10:59.067602: step 1870, loss 0.385448, acc 0.78125, learning_rate 0.000418436\n",
      "2020-12-09T17:10:59.623285: step 1871, loss 0.267368, acc 0.875, learning_rate 0.00041801\n",
      "2020-12-09T17:11:00.194786: step 1872, loss 0.160505, acc 0.96875, learning_rate 0.000417584\n",
      "2020-12-09T17:11:00.802064: step 1873, loss 0.255186, acc 0.875, learning_rate 0.000417158\n",
      "2020-12-09T17:11:01.362405: step 1874, loss 0.113857, acc 0.96875, learning_rate 0.000416733\n",
      "2020-12-09T17:11:01.908641: step 1875, loss 0.0796026, acc 0.96875, learning_rate 0.000416309\n",
      "2020-12-09T17:11:02.482173: step 1876, loss 0.164408, acc 0.9375, learning_rate 0.000415885\n",
      "2020-12-09T17:11:03.057186: step 1877, loss 0.328148, acc 0.875, learning_rate 0.000415462\n",
      "2020-12-09T17:11:03.621684: step 1878, loss 0.166089, acc 0.90625, learning_rate 0.00041504\n",
      "2020-12-09T17:11:04.193112: step 1879, loss 0.300426, acc 0.875, learning_rate 0.000414618\n",
      "2020-12-09T17:11:04.773963: step 1880, loss 0.0995882, acc 1, learning_rate 0.000414196\n",
      "2020-12-09T17:11:05.316740: step 1881, loss 0.132297, acc 0.96875, learning_rate 0.000413775\n",
      "2020-12-09T17:11:05.873745: step 1882, loss 0.20539, acc 0.90625, learning_rate 0.000413355\n",
      "2020-12-09T17:11:06.440207: step 1883, loss 0.19945, acc 0.875, learning_rate 0.000412935\n",
      "2020-12-09T17:11:07.000760: step 1884, loss 0.441892, acc 0.84375, learning_rate 0.000412516\n",
      "2020-12-09T17:11:07.563586: step 1885, loss 0.371497, acc 0.875, learning_rate 0.000412097\n",
      "2020-12-09T17:11:08.114617: step 1886, loss 0.300884, acc 0.84375, learning_rate 0.000411679\n",
      "2020-12-09T17:11:08.688513: step 1887, loss 0.125559, acc 1, learning_rate 0.000411262\n",
      "2020-12-09T17:11:09.287341: step 1888, loss 0.33608, acc 0.875, learning_rate 0.000410845\n",
      "2020-12-09T17:11:09.837503: step 1889, loss 0.198218, acc 0.90625, learning_rate 0.000410429\n",
      "2020-12-09T17:11:10.395538: step 1890, loss 0.24517, acc 0.96875, learning_rate 0.000410013\n",
      "2020-12-09T17:11:10.963317: step 1891, loss 0.192927, acc 0.96875, learning_rate 0.000409597\n",
      "2020-12-09T17:11:11.539845: step 1892, loss 0.178623, acc 0.9375, learning_rate 0.000409183\n",
      "2020-12-09T17:11:12.089666: step 1893, loss 0.120063, acc 1, learning_rate 0.000408769\n",
      "2020-12-09T17:11:12.676892: step 1894, loss 0.0837853, acc 1, learning_rate 0.000408355\n",
      "2020-12-09T17:11:13.248819: step 1895, loss 0.202011, acc 0.875, learning_rate 0.000407942\n",
      "2020-12-09T17:11:14.042393: step 1896, loss 0.370528, acc 0.78125, learning_rate 0.000407529\n",
      "2020-12-09T17:11:14.682392: step 1897, loss 0.232009, acc 0.96875, learning_rate 0.000407117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:11:15.271997: step 1898, loss 0.300131, acc 0.84375, learning_rate 0.000406706\n",
      "2020-12-09T17:11:15.822351: step 1899, loss 0.167007, acc 0.9375, learning_rate 0.000406295\n",
      "2020-12-09T17:11:16.388825: step 1900, loss 0.241688, acc 0.84375, learning_rate 0.000405885\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:11:19.745080: step 1900, loss 0.649497, acc 0.733138\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1900\n",
      "\n",
      "2020-12-09T17:11:21.260868: step 1901, loss 0.139837, acc 0.96875, learning_rate 0.000405475\n",
      "2020-12-09T17:11:21.814936: step 1902, loss 0.439183, acc 0.8125, learning_rate 0.000405066\n",
      "2020-12-09T17:11:22.417936: step 1903, loss 0.145723, acc 0.96875, learning_rate 0.000404657\n",
      "2020-12-09T17:11:23.007971: step 1904, loss 0.297941, acc 0.90625, learning_rate 0.000404249\n",
      "2020-12-09T17:11:23.585424: step 1905, loss 0.172193, acc 0.9375, learning_rate 0.000403842\n",
      "2020-12-09T17:11:24.143612: step 1906, loss 0.175242, acc 0.90625, learning_rate 0.000403435\n",
      "2020-12-09T17:11:24.707232: step 1907, loss 0.182361, acc 0.96875, learning_rate 0.000403028\n",
      "2020-12-09T17:11:25.272866: step 1908, loss 0.202823, acc 1, learning_rate 0.000402622\n",
      "2020-12-09T17:11:25.835946: step 1909, loss 0.174038, acc 0.96875, learning_rate 0.000402217\n",
      "2020-12-09T17:11:26.401903: step 1910, loss 0.256116, acc 0.875, learning_rate 0.000401812\n",
      "2020-12-09T17:11:26.999031: step 1911, loss 0.181843, acc 0.9375, learning_rate 0.000401408\n",
      "2020-12-09T17:11:27.562437: step 1912, loss 0.198497, acc 0.96875, learning_rate 0.000401004\n",
      "2020-12-09T17:11:28.147138: step 1913, loss 0.137047, acc 0.9375, learning_rate 0.000400601\n",
      "2020-12-09T17:11:28.732141: step 1914, loss 0.188023, acc 0.9375, learning_rate 0.000400198\n",
      "2020-12-09T17:11:29.306177: step 1915, loss 0.122902, acc 0.9375, learning_rate 0.000399796\n",
      "2020-12-09T17:11:29.870137: step 1916, loss 0.106485, acc 0.96875, learning_rate 0.000399394\n",
      "2020-12-09T17:11:30.464640: step 1917, loss 0.203659, acc 0.90625, learning_rate 0.000398993\n",
      "2020-12-09T17:11:31.058550: step 1918, loss 0.201506, acc 0.90625, learning_rate 0.000398593\n",
      "2020-12-09T17:11:31.647515: step 1919, loss 0.223934, acc 0.875, learning_rate 0.000398193\n",
      "2020-12-09T17:11:32.208050: step 1920, loss 0.198266, acc 0.9375, learning_rate 0.000397793\n",
      "2020-12-09T17:11:32.966048: step 1921, loss 0.196407, acc 0.875, learning_rate 0.000397394\n",
      "2020-12-09T17:11:33.533470: step 1922, loss 0.346225, acc 0.875, learning_rate 0.000396996\n",
      "2020-12-09T17:11:34.081934: step 1923, loss 0.215464, acc 0.9375, learning_rate 0.000396598\n",
      "2020-12-09T17:11:34.654470: step 1924, loss 0.167997, acc 0.96875, learning_rate 0.000396201\n",
      "2020-12-09T17:11:35.204934: step 1925, loss 0.111828, acc 0.96875, learning_rate 0.000395804\n",
      "2020-12-09T17:11:35.764409: step 1926, loss 0.326945, acc 0.9375, learning_rate 0.000395408\n",
      "2020-12-09T17:11:36.324946: step 1927, loss 0.162489, acc 1, learning_rate 0.000395012\n",
      "2020-12-09T17:11:36.875941: step 1928, loss 0.246372, acc 0.90625, learning_rate 0.000394617\n",
      "2020-12-09T17:11:37.439964: step 1929, loss 0.237282, acc 0.875, learning_rate 0.000394222\n",
      "2020-12-09T17:11:37.994961: step 1930, loss 0.194306, acc 0.9375, learning_rate 0.000393828\n",
      "2020-12-09T17:11:38.548460: step 1931, loss 0.239648, acc 0.90625, learning_rate 0.000393435\n",
      "2020-12-09T17:11:39.101653: step 1932, loss 0.18278, acc 0.9375, learning_rate 0.000393041\n",
      "2020-12-09T17:11:39.679657: step 1933, loss 0.153044, acc 0.96875, learning_rate 0.000392649\n",
      "2020-12-09T17:11:40.235156: step 1934, loss 0.328443, acc 0.875, learning_rate 0.000392257\n",
      "2020-12-09T17:11:40.810773: step 1935, loss 0.26662, acc 0.875, learning_rate 0.000391865\n",
      "2020-12-09T17:11:41.359760: step 1936, loss 0.186057, acc 0.875, learning_rate 0.000391474\n",
      "2020-12-09T17:11:41.934563: step 1937, loss 0.329866, acc 0.875, learning_rate 0.000391084\n",
      "2020-12-09T17:11:42.490702: step 1938, loss 0.312402, acc 0.875, learning_rate 0.000390694\n",
      "2020-12-09T17:11:43.067684: step 1939, loss 0.133124, acc 0.96875, learning_rate 0.000390305\n",
      "2020-12-09T17:11:43.624906: step 1940, loss 0.153885, acc 0.96875, learning_rate 0.000389916\n",
      "2020-12-09T17:11:44.183923: step 1941, loss 0.429854, acc 0.8125, learning_rate 0.000389527\n",
      "2020-12-09T17:11:44.762178: step 1942, loss 0.291313, acc 0.84375, learning_rate 0.00038914\n",
      "2020-12-09T17:11:45.317702: step 1943, loss 0.147166, acc 0.9375, learning_rate 0.000388752\n",
      "2020-12-09T17:11:45.870939: step 1944, loss 0.126818, acc 0.96875, learning_rate 0.000388365\n",
      "2020-12-09T17:11:46.410045: step 1945, loss 0.203248, acc 0.96875, learning_rate 0.000387979\n",
      "2020-12-09T17:11:46.983016: step 1946, loss 0.209378, acc 0.90625, learning_rate 0.000387593\n",
      "2020-12-09T17:11:47.559593: step 1947, loss 0.233881, acc 0.9375, learning_rate 0.000387208\n",
      "2020-12-09T17:11:48.124467: step 1948, loss 0.212246, acc 0.90625, learning_rate 0.000386823\n",
      "2020-12-09T17:11:48.697999: step 1949, loss 0.202416, acc 0.9375, learning_rate 0.000386439\n",
      "2020-12-09T17:11:49.262442: step 1950, loss 0.350738, acc 0.84375, learning_rate 0.000386056\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:11:52.558731: step 1950, loss 0.649454, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-1950\n",
      "\n",
      "2020-12-09T17:11:53.977166: step 1951, loss 0.251008, acc 0.875, learning_rate 0.000385672\n",
      "2020-12-09T17:11:54.549796: step 1952, loss 0.164856, acc 0.96875, learning_rate 0.00038529\n",
      "2020-12-09T17:11:55.122796: step 1953, loss 0.215787, acc 0.875, learning_rate 0.000384908\n",
      "2020-12-09T17:11:55.676679: step 1954, loss 0.116857, acc 1, learning_rate 0.000384526\n",
      "2020-12-09T17:11:56.245183: step 1955, loss 0.284046, acc 0.84375, learning_rate 0.000384145\n",
      "2020-12-09T17:11:56.821365: step 1956, loss 0.338111, acc 0.875, learning_rate 0.000383764\n",
      "2020-12-09T17:11:57.396862: step 1957, loss 0.24815, acc 0.90625, learning_rate 0.000383384\n",
      "2020-12-09T17:11:57.944506: step 1958, loss 0.301528, acc 0.875, learning_rate 0.000383004\n",
      "2020-12-09T17:11:58.505734: step 1959, loss 0.147296, acc 0.9375, learning_rate 0.000382625\n",
      "2020-12-09T17:11:59.076622: step 1960, loss 0.105285, acc 0.96875, learning_rate 0.000382247\n",
      "2020-12-09T17:11:59.658093: step 1961, loss 0.2504, acc 0.90625, learning_rate 0.000381869\n",
      "2020-12-09T17:12:00.208037: step 1962, loss 0.205647, acc 0.90625, learning_rate 0.000381491\n",
      "2020-12-09T17:12:00.782568: step 1963, loss 0.206607, acc 0.9375, learning_rate 0.000381114\n",
      "2020-12-09T17:12:01.324067: step 1964, loss 0.369003, acc 0.9375, learning_rate 0.000380737\n",
      "2020-12-09T17:12:01.891568: step 1965, loss 0.135346, acc 0.9375, learning_rate 0.000380361\n",
      "2020-12-09T17:12:02.441033: step 1966, loss 0.0915348, acc 0.96875, learning_rate 0.000379986\n",
      "2020-12-09T17:12:03.011328: step 1967, loss 0.299518, acc 0.8125, learning_rate 0.000379611\n",
      "2020-12-09T17:12:03.560282: step 1968, loss 0.263406, acc 0.90625, learning_rate 0.000379236\n",
      "2020-12-09T17:12:04.117359: step 1969, loss 0.18046, acc 0.90625, learning_rate 0.000378862\n",
      "2020-12-09T17:12:04.685934: step 1970, loss 0.230451, acc 0.90625, learning_rate 0.000378489\n",
      "2020-12-09T17:12:05.258754: step 1971, loss 0.148268, acc 0.9375, learning_rate 0.000378115\n",
      "2020-12-09T17:12:05.822169: step 1972, loss 0.052936, acc 1, learning_rate 0.000377743\n",
      "2020-12-09T17:12:06.371636: step 1973, loss 0.155744, acc 1, learning_rate 0.000377371\n",
      "2020-12-09T17:12:06.931131: step 1974, loss 0.193454, acc 1, learning_rate 0.000376999\n",
      "2020-12-09T17:12:07.513613: step 1975, loss 0.358938, acc 0.78125, learning_rate 0.000376628\n",
      "2020-12-09T17:12:08.089456: step 1976, loss 0.238328, acc 0.90625, learning_rate 0.000376258\n",
      "2020-12-09T17:12:08.662894: step 1977, loss 0.215194, acc 0.875, learning_rate 0.000375888\n",
      "2020-12-09T17:12:09.224870: step 1978, loss 0.160894, acc 0.96875, learning_rate 0.000375518\n",
      "2020-12-09T17:12:09.802332: step 1979, loss 0.213269, acc 0.90625, learning_rate 0.000375149\n",
      "2020-12-09T17:12:10.352298: step 1980, loss 0.197141, acc 0.9375, learning_rate 0.00037478\n",
      "2020-12-09T17:12:10.935465: step 1981, loss 0.25401, acc 0.84375, learning_rate 0.000374412\n",
      "2020-12-09T17:12:11.513429: step 1982, loss 0.165671, acc 0.9375, learning_rate 0.000374045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:12:12.080488: step 1983, loss 0.353612, acc 0.875, learning_rate 0.000373678\n",
      "2020-12-09T17:12:12.636661: step 1984, loss 0.250887, acc 0.9375, learning_rate 0.000373311\n",
      "2020-12-09T17:12:13.189746: step 1985, loss 0.136413, acc 1, learning_rate 0.000372945\n",
      "2020-12-09T17:12:13.747649: step 1986, loss 0.216717, acc 0.96875, learning_rate 0.000372579\n",
      "2020-12-09T17:12:14.309894: step 1987, loss 0.14926, acc 0.96875, learning_rate 0.000372214\n",
      "2020-12-09T17:12:14.881412: step 1988, loss 0.140146, acc 0.96875, learning_rate 0.00037185\n",
      "2020-12-09T17:12:15.471086: step 1989, loss 0.22982, acc 0.90625, learning_rate 0.000371485\n",
      "2020-12-09T17:12:16.056594: step 1990, loss 0.34679, acc 0.875, learning_rate 0.000371122\n",
      "2020-12-09T17:12:16.599809: step 1991, loss 0.205429, acc 0.875, learning_rate 0.000370759\n",
      "2020-12-09T17:12:17.178708: step 1992, loss 0.32236, acc 0.84375, learning_rate 0.000370396\n",
      "2020-12-09T17:12:17.744800: step 1993, loss 0.186352, acc 0.9375, learning_rate 0.000370034\n",
      "2020-12-09T17:12:18.284658: step 1994, loss 0.189023, acc 0.875, learning_rate 0.000369672\n",
      "2020-12-09T17:12:18.859647: step 1995, loss 0.164764, acc 1, learning_rate 0.000369311\n",
      "2020-12-09T17:12:19.435154: step 1996, loss 0.17527, acc 0.96875, learning_rate 0.00036895\n",
      "2020-12-09T17:12:19.994129: step 1997, loss 0.236035, acc 0.875, learning_rate 0.00036859\n",
      "2020-12-09T17:12:20.545073: step 1998, loss 0.200549, acc 0.90625, learning_rate 0.00036823\n",
      "2020-12-09T17:12:21.183061: step 1999, loss 0.293497, acc 0.90625, learning_rate 0.000367871\n",
      "2020-12-09T17:12:22.077224: step 2000, loss 0.140931, acc 0.9375, learning_rate 0.000367512\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:12:26.063799: step 2000, loss 0.649418, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2000\n",
      "\n",
      "2020-12-09T17:12:27.580258: step 2001, loss 0.183444, acc 0.90625, learning_rate 0.000367153\n",
      "2020-12-09T17:12:28.135338: step 2002, loss 0.180999, acc 1, learning_rate 0.000366795\n",
      "2020-12-09T17:12:28.707335: step 2003, loss 0.190641, acc 0.96875, learning_rate 0.000366438\n",
      "2020-12-09T17:12:29.268839: step 2004, loss 0.190395, acc 0.9375, learning_rate 0.000366081\n",
      "2020-12-09T17:12:29.839488: step 2005, loss 0.415386, acc 0.875, learning_rate 0.000365725\n",
      "2020-12-09T17:12:30.379212: step 2006, loss 0.603682, acc 0.8125, learning_rate 0.000365369\n",
      "2020-12-09T17:12:30.937294: step 2007, loss 0.246732, acc 0.90625, learning_rate 0.000365013\n",
      "2020-12-09T17:12:31.538873: step 2008, loss 0.216714, acc 0.90625, learning_rate 0.000364658\n",
      "2020-12-09T17:12:32.092207: step 2009, loss 0.303749, acc 0.875, learning_rate 0.000364304\n",
      "2020-12-09T17:12:32.639716: step 2010, loss 0.170613, acc 0.9375, learning_rate 0.00036395\n",
      "2020-12-09T17:12:33.200124: step 2011, loss 0.138821, acc 0.9375, learning_rate 0.000363596\n",
      "2020-12-09T17:12:33.777019: step 2012, loss 0.10354, acc 0.96875, learning_rate 0.000363243\n",
      "2020-12-09T17:12:34.360642: step 2013, loss 0.268903, acc 0.84375, learning_rate 0.00036289\n",
      "2020-12-09T17:12:34.959082: step 2014, loss 0.0905055, acc 1, learning_rate 0.000362538\n",
      "2020-12-09T17:12:35.555616: step 2015, loss 0.155376, acc 0.9375, learning_rate 0.000362187\n",
      "2020-12-09T17:12:36.198583: step 2016, loss 0.244244, acc 0.875, learning_rate 0.000361835\n",
      "2020-12-09T17:12:36.817582: step 2017, loss 0.454778, acc 0.875, learning_rate 0.000361485\n",
      "2020-12-09T17:12:37.456105: step 2018, loss 0.199857, acc 0.875, learning_rate 0.000361134\n",
      "2020-12-09T17:12:38.097718: step 2019, loss 0.20577, acc 0.875, learning_rate 0.000360785\n",
      "2020-12-09T17:12:38.780221: step 2020, loss 0.0997162, acc 0.96875, learning_rate 0.000360435\n",
      "2020-12-09T17:12:39.460145: step 2021, loss 0.218716, acc 0.9375, learning_rate 0.000360086\n",
      "2020-12-09T17:12:40.284178: step 2022, loss 0.190053, acc 0.9375, learning_rate 0.000359738\n",
      "2020-12-09T17:12:41.048686: step 2023, loss 0.129668, acc 0.9375, learning_rate 0.00035939\n",
      "2020-12-09T17:12:41.817896: step 2024, loss 0.234433, acc 0.9375, learning_rate 0.000359043\n",
      "2020-12-09T17:12:42.402192: step 2025, loss 0.135504, acc 0.96875, learning_rate 0.000358696\n",
      "2020-12-09T17:12:43.019813: step 2026, loss 0.253618, acc 0.96875, learning_rate 0.000358349\n",
      "2020-12-09T17:12:43.659395: step 2027, loss 0.22147, acc 0.90625, learning_rate 0.000358003\n",
      "2020-12-09T17:12:44.238857: step 2028, loss 0.202764, acc 0.90625, learning_rate 0.000357657\n",
      "2020-12-09T17:12:44.812550: step 2029, loss 0.183252, acc 0.9375, learning_rate 0.000357312\n",
      "2020-12-09T17:12:45.456787: step 2030, loss 0.237477, acc 0.9375, learning_rate 0.000356968\n",
      "2020-12-09T17:12:46.022627: step 2031, loss 0.44775, acc 0.90625, learning_rate 0.000356623\n",
      "2020-12-09T17:12:46.626313: step 2032, loss 0.134444, acc 0.96875, learning_rate 0.00035628\n",
      "2020-12-09T17:12:47.251312: step 2033, loss 0.189171, acc 0.9375, learning_rate 0.000355936\n",
      "2020-12-09T17:12:47.866320: step 2034, loss 0.191105, acc 0.90625, learning_rate 0.000355593\n",
      "2020-12-09T17:12:48.464435: step 2035, loss 0.131828, acc 0.90625, learning_rate 0.000355251\n",
      "2020-12-09T17:12:49.068441: step 2036, loss 0.106222, acc 0.96875, learning_rate 0.000354909\n",
      "2020-12-09T17:12:49.703436: step 2037, loss 0.356739, acc 0.84375, learning_rate 0.000354568\n",
      "2020-12-09T17:12:50.346184: step 2038, loss 0.238804, acc 0.875, learning_rate 0.000354227\n",
      "2020-12-09T17:12:50.965186: step 2039, loss 0.191015, acc 0.96875, learning_rate 0.000353886\n",
      "2020-12-09T17:12:51.579686: step 2040, loss 0.275687, acc 0.875, learning_rate 0.000353546\n",
      "2020-12-09T17:12:52.196616: step 2041, loss 0.337707, acc 0.84375, learning_rate 0.000353206\n",
      "2020-12-09T17:12:52.792618: step 2042, loss 0.308493, acc 0.96875, learning_rate 0.000352867\n",
      "2020-12-09T17:12:53.403113: step 2043, loss 0.247524, acc 0.875, learning_rate 0.000352528\n",
      "2020-12-09T17:12:54.010518: step 2044, loss 0.247436, acc 0.9375, learning_rate 0.00035219\n",
      "2020-12-09T17:12:54.615470: step 2045, loss 0.242316, acc 0.9375, learning_rate 0.000351852\n",
      "2020-12-09T17:12:55.232476: step 2046, loss 0.139594, acc 0.9375, learning_rate 0.000351515\n",
      "2020-12-09T17:12:55.840476: step 2047, loss 0.156822, acc 0.96875, learning_rate 0.000351178\n",
      "2020-12-09T17:12:56.514094: step 2048, loss 0.406709, acc 0.84375, learning_rate 0.000350842\n",
      "2020-12-09T17:12:57.109571: step 2049, loss 0.206756, acc 0.90625, learning_rate 0.000350506\n",
      "2020-12-09T17:12:57.704326: step 2050, loss 0.172866, acc 0.9375, learning_rate 0.00035017\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:13:01.358311: step 2050, loss 0.649391, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2050\n",
      "\n",
      "2020-12-09T17:13:02.969345: step 2051, loss 0.209407, acc 0.9375, learning_rate 0.000349835\n",
      "2020-12-09T17:13:03.560535: step 2052, loss 0.406274, acc 0.8125, learning_rate 0.0003495\n",
      "2020-12-09T17:13:04.157467: step 2053, loss 0.198237, acc 0.90625, learning_rate 0.000349166\n",
      "2020-12-09T17:13:04.747830: step 2054, loss 0.396002, acc 0.8125, learning_rate 0.000348832\n",
      "2020-12-09T17:13:05.328368: step 2055, loss 0.162996, acc 0.96875, learning_rate 0.000348499\n",
      "2020-12-09T17:13:05.901365: step 2056, loss 0.15866, acc 0.9375, learning_rate 0.000348166\n",
      "2020-12-09T17:13:06.497611: step 2057, loss 0.269324, acc 0.9375, learning_rate 0.000347834\n",
      "2020-12-09T17:13:07.114309: step 2058, loss 0.336443, acc 0.84375, learning_rate 0.000347502\n",
      "2020-12-09T17:13:07.715553: step 2059, loss 0.369389, acc 0.84375, learning_rate 0.00034717\n",
      "2020-12-09T17:13:08.295198: step 2060, loss 0.288076, acc 0.8125, learning_rate 0.000346839\n",
      "2020-12-09T17:13:08.859040: step 2061, loss 0.226498, acc 0.9375, learning_rate 0.000346508\n",
      "2020-12-09T17:13:09.438545: step 2062, loss 0.162489, acc 0.90625, learning_rate 0.000346178\n",
      "2020-12-09T17:13:10.002658: step 2063, loss 0.366978, acc 0.8125, learning_rate 0.000345848\n",
      "2020-12-09T17:13:10.574944: step 2064, loss 0.438152, acc 0.75, learning_rate 0.000345519\n",
      "2020-12-09T17:13:11.194685: step 2065, loss 0.125046, acc 1, learning_rate 0.00034519\n",
      "2020-12-09T17:13:11.799150: step 2066, loss 0.286268, acc 0.875, learning_rate 0.000344862\n",
      "2020-12-09T17:13:12.408590: step 2067, loss 0.236796, acc 0.90625, learning_rate 0.000344534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:13:13.002566: step 2068, loss 0.217813, acc 0.90625, learning_rate 0.000344206\n",
      "2020-12-09T17:13:13.595502: step 2069, loss 0.359595, acc 0.8125, learning_rate 0.000343879\n",
      "2020-12-09T17:13:14.197522: step 2070, loss 0.260229, acc 0.875, learning_rate 0.000343552\n",
      "2020-12-09T17:13:14.831743: step 2071, loss 0.223788, acc 0.90625, learning_rate 0.000343226\n",
      "2020-12-09T17:13:15.414742: step 2072, loss 0.223238, acc 0.875, learning_rate 0.0003429\n",
      "2020-12-09T17:13:15.983014: step 2073, loss 0.27675, acc 0.84375, learning_rate 0.000342575\n",
      "2020-12-09T17:13:16.548014: step 2074, loss 0.141709, acc 0.9375, learning_rate 0.00034225\n",
      "2020-12-09T17:13:17.094541: step 2075, loss 0.174464, acc 0.96875, learning_rate 0.000341925\n",
      "2020-12-09T17:13:17.675576: step 2076, loss 0.221824, acc 0.9375, learning_rate 0.000341601\n",
      "2020-12-09T17:13:18.232462: step 2077, loss 0.114414, acc 0.96875, learning_rate 0.000341278\n",
      "2020-12-09T17:13:18.789394: step 2078, loss 0.233004, acc 0.875, learning_rate 0.000340954\n",
      "2020-12-09T17:13:19.360397: step 2079, loss 0.236163, acc 0.875, learning_rate 0.000340632\n",
      "2020-12-09T17:13:19.993581: step 2080, loss 0.372633, acc 0.75, learning_rate 0.000340309\n",
      "2020-12-09T17:13:20.695348: step 2081, loss 0.210923, acc 0.90625, learning_rate 0.000339987\n",
      "2020-12-09T17:13:21.299796: step 2082, loss 0.255041, acc 0.9375, learning_rate 0.000339666\n",
      "2020-12-09T17:13:21.930483: step 2083, loss 0.325561, acc 0.84375, learning_rate 0.000339345\n",
      "2020-12-09T17:13:22.490920: step 2084, loss 0.148864, acc 0.9375, learning_rate 0.000339024\n",
      "2020-12-09T17:13:23.041376: step 2085, loss 0.228922, acc 0.90625, learning_rate 0.000338704\n",
      "2020-12-09T17:13:23.635959: step 2086, loss 0.182937, acc 0.9375, learning_rate 0.000338384\n",
      "2020-12-09T17:13:24.211109: step 2087, loss 0.447764, acc 0.875, learning_rate 0.000338065\n",
      "2020-12-09T17:13:24.783598: step 2088, loss 0.305399, acc 0.84375, learning_rate 0.000337746\n",
      "2020-12-09T17:13:25.340856: step 2089, loss 0.144575, acc 0.9375, learning_rate 0.000337428\n",
      "2020-12-09T17:13:25.932478: step 2090, loss 0.286053, acc 0.9375, learning_rate 0.00033711\n",
      "2020-12-09T17:13:26.486464: step 2091, loss 0.257188, acc 0.90625, learning_rate 0.000336792\n",
      "2020-12-09T17:13:27.045802: step 2092, loss 0.274401, acc 0.84375, learning_rate 0.000336475\n",
      "2020-12-09T17:13:27.272804: step 2093, loss 0.282944, acc 0.846154, learning_rate 0.000336158\n",
      "2020-12-09T17:13:27.886811: step 2094, loss 0.176253, acc 0.96875, learning_rate 0.000335842\n",
      "2020-12-09T17:13:28.469524: step 2095, loss 0.187605, acc 0.9375, learning_rate 0.000335526\n",
      "2020-12-09T17:13:29.016863: step 2096, loss 0.170472, acc 0.90625, learning_rate 0.00033521\n",
      "2020-12-09T17:13:29.587248: step 2097, loss 0.136409, acc 1, learning_rate 0.000334895\n",
      "2020-12-09T17:13:30.162749: step 2098, loss 0.117282, acc 0.96875, learning_rate 0.00033458\n",
      "2020-12-09T17:13:30.721135: step 2099, loss 0.11172, acc 0.96875, learning_rate 0.000334266\n",
      "2020-12-09T17:13:31.288283: step 2100, loss 0.350438, acc 0.84375, learning_rate 0.000333952\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:13:34.672125: step 2100, loss 0.649372, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2100\n",
      "\n",
      "2020-12-09T17:13:36.311522: step 2101, loss 0.139756, acc 0.96875, learning_rate 0.000333639\n",
      "2020-12-09T17:13:36.882507: step 2102, loss 0.172246, acc 0.9375, learning_rate 0.000333326\n",
      "2020-12-09T17:13:37.464217: step 2103, loss 0.266913, acc 0.84375, learning_rate 0.000333014\n",
      "2020-12-09T17:13:38.052573: step 2104, loss 0.283386, acc 0.875, learning_rate 0.000332701\n",
      "2020-12-09T17:13:38.646893: step 2105, loss 0.224763, acc 0.90625, learning_rate 0.00033239\n",
      "2020-12-09T17:13:39.209095: step 2106, loss 0.245854, acc 0.90625, learning_rate 0.000332078\n",
      "2020-12-09T17:13:39.784593: step 2107, loss 0.228246, acc 0.875, learning_rate 0.000331767\n",
      "2020-12-09T17:13:40.356374: step 2108, loss 0.179105, acc 0.9375, learning_rate 0.000331457\n",
      "2020-12-09T17:13:40.920935: step 2109, loss 0.0767619, acc 1, learning_rate 0.000331147\n",
      "2020-12-09T17:13:41.491726: step 2110, loss 0.178741, acc 0.875, learning_rate 0.000330837\n",
      "2020-12-09T17:13:42.067764: step 2111, loss 0.25987, acc 0.875, learning_rate 0.000330528\n",
      "2020-12-09T17:13:42.634227: step 2112, loss 0.392706, acc 0.78125, learning_rate 0.000330219\n",
      "2020-12-09T17:13:43.227725: step 2113, loss 0.551098, acc 0.75, learning_rate 0.000329911\n",
      "2020-12-09T17:13:43.855725: step 2114, loss 0.185084, acc 0.9375, learning_rate 0.000329603\n",
      "2020-12-09T17:13:44.433314: step 2115, loss 0.183172, acc 0.90625, learning_rate 0.000329295\n",
      "2020-12-09T17:13:45.042906: step 2116, loss 0.230998, acc 0.90625, learning_rate 0.000328988\n",
      "2020-12-09T17:13:45.629943: step 2117, loss 0.240563, acc 0.90625, learning_rate 0.000328681\n",
      "2020-12-09T17:13:46.204943: step 2118, loss 0.11567, acc 0.96875, learning_rate 0.000328375\n",
      "2020-12-09T17:13:46.801383: step 2119, loss 0.234705, acc 0.90625, learning_rate 0.000328069\n",
      "2020-12-09T17:13:47.381419: step 2120, loss 0.200036, acc 0.9375, learning_rate 0.000327764\n",
      "2020-12-09T17:13:47.952869: step 2121, loss 0.172711, acc 0.9375, learning_rate 0.000327459\n",
      "2020-12-09T17:13:48.573091: step 2122, loss 0.0857756, acc 1, learning_rate 0.000327154\n",
      "2020-12-09T17:13:49.146044: step 2123, loss 0.305763, acc 0.90625, learning_rate 0.00032685\n",
      "2020-12-09T17:13:49.726065: step 2124, loss 0.155885, acc 0.96875, learning_rate 0.000326546\n",
      "2020-12-09T17:13:50.307586: step 2125, loss 0.183037, acc 0.90625, learning_rate 0.000326242\n",
      "2020-12-09T17:13:50.883614: step 2126, loss 0.25977, acc 0.90625, learning_rate 0.000325939\n",
      "2020-12-09T17:13:51.452621: step 2127, loss 0.275339, acc 0.90625, learning_rate 0.000325637\n",
      "2020-12-09T17:13:52.018161: step 2128, loss 0.113491, acc 0.96875, learning_rate 0.000325334\n",
      "2020-12-09T17:13:52.645614: step 2129, loss 0.245607, acc 0.875, learning_rate 0.000325032\n",
      "2020-12-09T17:13:53.214151: step 2130, loss 0.337312, acc 0.875, learning_rate 0.000324731\n",
      "2020-12-09T17:13:53.797650: step 2131, loss 0.27258, acc 0.90625, learning_rate 0.00032443\n",
      "2020-12-09T17:13:54.378149: step 2132, loss 0.127975, acc 1, learning_rate 0.000324129\n",
      "2020-12-09T17:13:54.927037: step 2133, loss 0.356516, acc 0.8125, learning_rate 0.000323829\n",
      "2020-12-09T17:13:55.478574: step 2134, loss 0.271754, acc 0.8125, learning_rate 0.000323529\n",
      "2020-12-09T17:13:56.043066: step 2135, loss 0.223738, acc 0.90625, learning_rate 0.00032323\n",
      "2020-12-09T17:13:56.592434: step 2136, loss 0.167327, acc 0.9375, learning_rate 0.000322931\n",
      "2020-12-09T17:13:57.148934: step 2137, loss 0.252114, acc 0.90625, learning_rate 0.000322632\n",
      "2020-12-09T17:13:57.722817: step 2138, loss 0.317728, acc 0.875, learning_rate 0.000322334\n",
      "2020-12-09T17:13:58.332355: step 2139, loss 0.223105, acc 0.9375, learning_rate 0.000322036\n",
      "2020-12-09T17:13:58.919504: step 2140, loss 0.291111, acc 0.875, learning_rate 0.000321739\n",
      "2020-12-09T17:13:59.451601: step 2141, loss 0.251116, acc 0.875, learning_rate 0.000321442\n",
      "2020-12-09T17:14:00.042603: step 2142, loss 0.186501, acc 0.9375, learning_rate 0.000321145\n",
      "2020-12-09T17:14:00.588766: step 2143, loss 0.305206, acc 0.875, learning_rate 0.000320849\n",
      "2020-12-09T17:14:01.153382: step 2144, loss 0.264463, acc 0.90625, learning_rate 0.000320553\n",
      "2020-12-09T17:14:01.725382: step 2145, loss 0.287578, acc 0.9375, learning_rate 0.000320258\n",
      "2020-12-09T17:14:02.298043: step 2146, loss 0.283302, acc 0.8125, learning_rate 0.000319962\n",
      "2020-12-09T17:14:02.859647: step 2147, loss 0.148941, acc 0.96875, learning_rate 0.000319668\n",
      "2020-12-09T17:14:03.406969: step 2148, loss 0.186208, acc 0.90625, learning_rate 0.000319374\n",
      "2020-12-09T17:14:03.973505: step 2149, loss 0.21061, acc 0.90625, learning_rate 0.00031908\n",
      "2020-12-09T17:14:04.566399: step 2150, loss 0.399757, acc 0.9375, learning_rate 0.000318786\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:14:07.865645: step 2150, loss 0.649347, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2150\n",
      "\n",
      "2020-12-09T17:14:09.346437: step 2151, loss 0.201822, acc 0.9375, learning_rate 0.000318493\n",
      "2020-12-09T17:14:09.907733: step 2152, loss 0.296234, acc 0.875, learning_rate 0.0003182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:14:10.471942: step 2153, loss 0.295667, acc 0.84375, learning_rate 0.000317908\n",
      "2020-12-09T17:14:11.044324: step 2154, loss 0.28855, acc 0.84375, learning_rate 0.000317616\n",
      "2020-12-09T17:14:11.576827: step 2155, loss 0.187842, acc 0.9375, learning_rate 0.000317325\n",
      "2020-12-09T17:14:12.165327: step 2156, loss 0.174415, acc 0.9375, learning_rate 0.000317034\n",
      "2020-12-09T17:14:12.805291: step 2157, loss 0.368431, acc 0.90625, learning_rate 0.000316743\n",
      "2020-12-09T17:14:13.425766: step 2158, loss 0.286936, acc 0.9375, learning_rate 0.000316453\n",
      "2020-12-09T17:14:14.012551: step 2159, loss 0.292786, acc 0.84375, learning_rate 0.000316163\n",
      "2020-12-09T17:14:14.567563: step 2160, loss 0.232891, acc 0.90625, learning_rate 0.000315873\n",
      "2020-12-09T17:14:15.133531: step 2161, loss 0.348636, acc 0.875, learning_rate 0.000315584\n",
      "2020-12-09T17:14:15.729574: step 2162, loss 0.149319, acc 1, learning_rate 0.000315295\n",
      "2020-12-09T17:14:16.330087: step 2163, loss 0.208518, acc 0.96875, learning_rate 0.000315007\n",
      "2020-12-09T17:14:16.943203: step 2164, loss 0.190197, acc 0.90625, learning_rate 0.000314719\n",
      "2020-12-09T17:14:17.538277: step 2165, loss 0.346326, acc 0.78125, learning_rate 0.000314431\n",
      "2020-12-09T17:14:18.147246: step 2166, loss 0.224552, acc 0.90625, learning_rate 0.000314144\n",
      "2020-12-09T17:14:18.757747: step 2167, loss 0.622622, acc 0.6875, learning_rate 0.000313857\n",
      "2020-12-09T17:14:19.319723: step 2168, loss 0.173126, acc 0.90625, learning_rate 0.00031357\n",
      "2020-12-09T17:14:19.919748: step 2169, loss 0.335926, acc 0.90625, learning_rate 0.000313284\n",
      "2020-12-09T17:14:20.546055: step 2170, loss 0.166478, acc 0.96875, learning_rate 0.000312999\n",
      "2020-12-09T17:14:21.136399: step 2171, loss 0.115997, acc 1, learning_rate 0.000312713\n",
      "2020-12-09T17:14:21.766937: step 2172, loss 0.195199, acc 0.90625, learning_rate 0.000312428\n",
      "2020-12-09T17:14:22.351428: step 2173, loss 0.241772, acc 0.9375, learning_rate 0.000312144\n",
      "2020-12-09T17:14:22.937312: step 2174, loss 0.226229, acc 0.90625, learning_rate 0.00031186\n",
      "2020-12-09T17:14:23.495803: step 2175, loss 0.201307, acc 0.9375, learning_rate 0.000311576\n",
      "2020-12-09T17:14:24.058675: step 2176, loss 0.289992, acc 0.875, learning_rate 0.000311292\n",
      "2020-12-09T17:14:24.627693: step 2177, loss 0.108606, acc 0.9375, learning_rate 0.000311009\n",
      "2020-12-09T17:14:25.208726: step 2178, loss 0.104823, acc 1, learning_rate 0.000310727\n",
      "2020-12-09T17:14:25.765048: step 2179, loss 0.310953, acc 0.84375, learning_rate 0.000310444\n",
      "2020-12-09T17:14:26.314042: step 2180, loss 0.17328, acc 0.90625, learning_rate 0.000310163\n",
      "2020-12-09T17:14:26.885477: step 2181, loss 0.332127, acc 0.875, learning_rate 0.000309881\n",
      "2020-12-09T17:14:27.483509: step 2182, loss 0.186646, acc 0.90625, learning_rate 0.0003096\n",
      "2020-12-09T17:14:28.095979: step 2183, loss 0.147585, acc 0.90625, learning_rate 0.000309319\n",
      "2020-12-09T17:14:28.697088: step 2184, loss 0.243016, acc 0.90625, learning_rate 0.000309039\n",
      "2020-12-09T17:14:29.301103: step 2185, loss 0.303954, acc 0.84375, learning_rate 0.000308759\n",
      "2020-12-09T17:14:29.933956: step 2186, loss 0.208561, acc 0.9375, learning_rate 0.000308479\n",
      "2020-12-09T17:14:30.518421: step 2187, loss 0.281233, acc 0.90625, learning_rate 0.0003082\n",
      "2020-12-09T17:14:31.104829: step 2188, loss 0.25164, acc 0.84375, learning_rate 0.000307921\n",
      "2020-12-09T17:14:31.666044: step 2189, loss 0.132724, acc 0.96875, learning_rate 0.000307642\n",
      "2020-12-09T17:14:32.244019: step 2190, loss 0.201358, acc 0.90625, learning_rate 0.000307364\n",
      "2020-12-09T17:14:32.817344: step 2191, loss 0.19906, acc 0.90625, learning_rate 0.000307086\n",
      "2020-12-09T17:14:33.510845: step 2192, loss 0.291235, acc 0.90625, learning_rate 0.000306809\n",
      "2020-12-09T17:14:34.154845: step 2193, loss 0.292517, acc 0.90625, learning_rate 0.000306532\n",
      "2020-12-09T17:14:34.792343: step 2194, loss 0.247166, acc 0.875, learning_rate 0.000306255\n",
      "2020-12-09T17:14:35.523879: step 2195, loss 0.155346, acc 0.9375, learning_rate 0.000305979\n",
      "2020-12-09T17:14:36.202845: step 2196, loss 0.181, acc 0.9375, learning_rate 0.000305703\n",
      "2020-12-09T17:14:36.885845: step 2197, loss 0.22932, acc 0.9375, learning_rate 0.000305428\n",
      "2020-12-09T17:14:37.564878: step 2198, loss 0.315667, acc 0.875, learning_rate 0.000305152\n",
      "2020-12-09T17:14:38.275345: step 2199, loss 0.201762, acc 0.96875, learning_rate 0.000304878\n",
      "2020-12-09T17:14:39.020342: step 2200, loss 0.258217, acc 0.875, learning_rate 0.000304603\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:14:43.129847: step 2200, loss 0.649314, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2200\n",
      "\n",
      "2020-12-09T17:14:44.872844: step 2201, loss 0.1457, acc 0.9375, learning_rate 0.000304329\n",
      "2020-12-09T17:14:45.492376: step 2202, loss 0.10128, acc 0.9375, learning_rate 0.000304055\n",
      "2020-12-09T17:14:46.195844: step 2203, loss 0.178994, acc 0.9375, learning_rate 0.000303782\n",
      "2020-12-09T17:14:46.939778: step 2204, loss 0.280284, acc 0.84375, learning_rate 0.000303509\n",
      "2020-12-09T17:14:47.523048: step 2205, loss 0.27459, acc 0.84375, learning_rate 0.000303236\n",
      "2020-12-09T17:14:48.140726: step 2206, loss 0.102078, acc 0.96875, learning_rate 0.000302964\n",
      "2020-12-09T17:14:48.747515: step 2207, loss 0.221552, acc 0.90625, learning_rate 0.000302692\n",
      "2020-12-09T17:14:49.319716: step 2208, loss 0.328391, acc 0.875, learning_rate 0.000302421\n",
      "2020-12-09T17:14:49.874179: step 2209, loss 0.485492, acc 0.8125, learning_rate 0.00030215\n",
      "2020-12-09T17:14:50.440638: step 2210, loss 0.281595, acc 0.90625, learning_rate 0.000301879\n",
      "2020-12-09T17:14:51.036330: step 2211, loss 0.169145, acc 0.9375, learning_rate 0.000301608\n",
      "2020-12-09T17:14:51.669871: step 2212, loss 0.189309, acc 0.9375, learning_rate 0.000301338\n",
      "2020-12-09T17:14:52.485853: step 2213, loss 0.281274, acc 0.90625, learning_rate 0.000301069\n",
      "2020-12-09T17:14:53.074551: step 2214, loss 0.152097, acc 0.9375, learning_rate 0.000300799\n",
      "2020-12-09T17:14:53.638050: step 2215, loss 0.104885, acc 0.96875, learning_rate 0.00030053\n",
      "2020-12-09T17:14:54.256052: step 2216, loss 0.0394668, acc 1, learning_rate 0.000300262\n",
      "2020-12-09T17:14:54.872585: step 2217, loss 0.220119, acc 0.90625, learning_rate 0.000299993\n",
      "2020-12-09T17:14:55.517100: step 2218, loss 0.240378, acc 0.875, learning_rate 0.000299726\n",
      "2020-12-09T17:14:56.102178: step 2219, loss 0.316636, acc 0.84375, learning_rate 0.000299458\n",
      "2020-12-09T17:14:56.651610: step 2220, loss 0.297867, acc 0.84375, learning_rate 0.000299191\n",
      "2020-12-09T17:14:57.192301: step 2221, loss 0.154522, acc 0.9375, learning_rate 0.000298924\n",
      "2020-12-09T17:14:57.742790: step 2222, loss 0.463361, acc 0.84375, learning_rate 0.000298658\n",
      "2020-12-09T17:14:58.312291: step 2223, loss 0.271599, acc 0.90625, learning_rate 0.000298391\n",
      "2020-12-09T17:14:58.885859: step 2224, loss 0.408661, acc 0.875, learning_rate 0.000298126\n",
      "2020-12-09T17:14:59.431036: step 2225, loss 0.166319, acc 0.9375, learning_rate 0.00029786\n",
      "2020-12-09T17:14:59.985153: step 2226, loss 0.281885, acc 0.84375, learning_rate 0.000297595\n",
      "2020-12-09T17:15:00.568619: step 2227, loss 0.262402, acc 0.90625, learning_rate 0.000297331\n",
      "2020-12-09T17:15:01.142607: step 2228, loss 0.266633, acc 0.90625, learning_rate 0.000297066\n",
      "2020-12-09T17:15:01.685848: step 2229, loss 0.156239, acc 0.9375, learning_rate 0.000296802\n",
      "2020-12-09T17:15:02.236373: step 2230, loss 0.282617, acc 0.90625, learning_rate 0.000296539\n",
      "2020-12-09T17:15:02.781352: step 2231, loss 0.323644, acc 0.875, learning_rate 0.000296275\n",
      "2020-12-09T17:15:03.348493: step 2232, loss 0.204207, acc 0.9375, learning_rate 0.000296012\n",
      "2020-12-09T17:15:03.891558: step 2233, loss 0.17279, acc 0.96875, learning_rate 0.00029575\n",
      "2020-12-09T17:15:04.462559: step 2234, loss 0.140322, acc 0.96875, learning_rate 0.000295488\n",
      "2020-12-09T17:15:05.008769: step 2235, loss 0.252412, acc 0.875, learning_rate 0.000295226\n",
      "2020-12-09T17:15:05.558459: step 2236, loss 0.251345, acc 0.84375, learning_rate 0.000294964\n",
      "2020-12-09T17:15:06.116279: step 2237, loss 0.274556, acc 0.84375, learning_rate 0.000294703\n",
      "2020-12-09T17:15:06.673782: step 2238, loss 0.285332, acc 0.9375, learning_rate 0.000294442\n",
      "2020-12-09T17:15:07.238682: step 2239, loss 0.150889, acc 0.96875, learning_rate 0.000294182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:15:07.818824: step 2240, loss 0.256295, acc 0.84375, learning_rate 0.000293922\n",
      "2020-12-09T17:15:08.386825: step 2241, loss 0.346283, acc 0.875, learning_rate 0.000293662\n",
      "2020-12-09T17:15:08.950257: step 2242, loss 0.157255, acc 0.96875, learning_rate 0.000293402\n",
      "2020-12-09T17:15:09.483102: step 2243, loss 0.160216, acc 0.96875, learning_rate 0.000293143\n",
      "2020-12-09T17:15:10.038729: step 2244, loss 0.164752, acc 0.96875, learning_rate 0.000292885\n",
      "2020-12-09T17:15:10.607193: step 2245, loss 0.366443, acc 0.875, learning_rate 0.000292626\n",
      "2020-12-09T17:15:11.167660: step 2246, loss 0.113204, acc 0.96875, learning_rate 0.000292368\n",
      "2020-12-09T17:15:11.708508: step 2247, loss 0.270587, acc 0.84375, learning_rate 0.000292111\n",
      "2020-12-09T17:15:12.279000: step 2248, loss 0.169406, acc 0.96875, learning_rate 0.000291853\n",
      "2020-12-09T17:15:12.827946: step 2249, loss 0.208215, acc 0.90625, learning_rate 0.000291596\n",
      "2020-12-09T17:15:13.404599: step 2250, loss 0.276169, acc 0.875, learning_rate 0.00029134\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:15:16.723529: step 2250, loss 0.649292, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2250\n",
      "\n",
      "2020-12-09T17:15:18.167059: step 2251, loss 0.201564, acc 0.96875, learning_rate 0.000291083\n",
      "2020-12-09T17:15:18.731339: step 2252, loss 0.458486, acc 0.75, learning_rate 0.000290827\n",
      "2020-12-09T17:15:19.280329: step 2253, loss 0.154591, acc 0.9375, learning_rate 0.000290572\n",
      "2020-12-09T17:15:19.825128: step 2254, loss 0.158324, acc 0.9375, learning_rate 0.000290316\n",
      "2020-12-09T17:15:20.389271: step 2255, loss 0.212411, acc 0.9375, learning_rate 0.000290061\n",
      "2020-12-09T17:15:20.952602: step 2256, loss 0.208377, acc 0.96875, learning_rate 0.000289807\n",
      "2020-12-09T17:15:21.490120: step 2257, loss 0.264932, acc 0.9375, learning_rate 0.000289553\n",
      "2020-12-09T17:15:22.030817: step 2258, loss 0.390927, acc 0.78125, learning_rate 0.000289299\n",
      "2020-12-09T17:15:22.594318: step 2259, loss 0.19751, acc 0.9375, learning_rate 0.000289045\n",
      "2020-12-09T17:15:23.170819: step 2260, loss 0.212181, acc 0.90625, learning_rate 0.000288792\n",
      "2020-12-09T17:15:23.726843: step 2261, loss 0.284298, acc 0.90625, learning_rate 0.000288539\n",
      "2020-12-09T17:15:24.273064: step 2262, loss 0.417434, acc 0.875, learning_rate 0.000288286\n",
      "2020-12-09T17:15:24.838335: step 2263, loss 0.18801, acc 0.90625, learning_rate 0.000288034\n",
      "2020-12-09T17:15:25.391444: step 2264, loss 0.207564, acc 0.90625, learning_rate 0.000287782\n",
      "2020-12-09T17:15:25.954942: step 2265, loss 0.207971, acc 0.96875, learning_rate 0.000287531\n",
      "2020-12-09T17:15:26.513670: step 2266, loss 0.140087, acc 0.9375, learning_rate 0.00028728\n",
      "2020-12-09T17:15:27.101247: step 2267, loss 0.152722, acc 0.90625, learning_rate 0.000287029\n",
      "2020-12-09T17:15:27.647244: step 2268, loss 0.216138, acc 0.90625, learning_rate 0.000286778\n",
      "2020-12-09T17:15:28.188245: step 2269, loss 0.256804, acc 0.9375, learning_rate 0.000286528\n",
      "2020-12-09T17:15:28.742245: step 2270, loss 0.192346, acc 0.90625, learning_rate 0.000286278\n",
      "2020-12-09T17:15:29.289229: step 2271, loss 0.190697, acc 0.9375, learning_rate 0.000286029\n",
      "2020-12-09T17:15:29.823729: step 2272, loss 0.243033, acc 0.875, learning_rate 0.000285779\n",
      "2020-12-09T17:15:30.366383: step 2273, loss 0.21681, acc 0.9375, learning_rate 0.00028553\n",
      "2020-12-09T17:15:30.972525: step 2274, loss 0.173425, acc 0.90625, learning_rate 0.000285282\n",
      "2020-12-09T17:15:31.527520: step 2275, loss 0.303523, acc 0.875, learning_rate 0.000285034\n",
      "2020-12-09T17:15:32.093022: step 2276, loss 0.112206, acc 0.9375, learning_rate 0.000284786\n",
      "2020-12-09T17:15:32.663253: step 2277, loss 0.161768, acc 1, learning_rate 0.000284538\n",
      "2020-12-09T17:15:33.256474: step 2278, loss 0.271946, acc 0.9375, learning_rate 0.000284291\n",
      "2020-12-09T17:15:33.811639: step 2279, loss 0.324776, acc 0.84375, learning_rate 0.000284044\n",
      "2020-12-09T17:15:34.419639: step 2280, loss 0.183007, acc 0.90625, learning_rate 0.000283798\n",
      "2020-12-09T17:15:35.025711: step 2281, loss 0.159666, acc 0.96875, learning_rate 0.000283552\n",
      "2020-12-09T17:15:35.563104: step 2282, loss 0.299436, acc 0.875, learning_rate 0.000283306\n",
      "2020-12-09T17:15:36.114098: step 2283, loss 0.229471, acc 0.9375, learning_rate 0.00028306\n",
      "2020-12-09T17:15:36.690550: step 2284, loss 0.216331, acc 0.9375, learning_rate 0.000282815\n",
      "2020-12-09T17:15:37.298333: step 2285, loss 0.215036, acc 0.9375, learning_rate 0.00028257\n",
      "2020-12-09T17:15:37.899479: step 2286, loss 0.252484, acc 0.90625, learning_rate 0.000282325\n",
      "2020-12-09T17:15:38.540907: step 2287, loss 0.238619, acc 0.875, learning_rate 0.000282081\n",
      "2020-12-09T17:15:39.181995: step 2288, loss 0.338446, acc 0.8125, learning_rate 0.000281837\n",
      "2020-12-09T17:15:39.736519: step 2289, loss 0.288395, acc 0.90625, learning_rate 0.000281594\n",
      "2020-12-09T17:15:40.379519: step 2290, loss 0.230787, acc 0.9375, learning_rate 0.00028135\n",
      "2020-12-09T17:15:41.208058: step 2291, loss 0.229191, acc 0.875, learning_rate 0.000281108\n",
      "2020-12-09T17:15:41.799555: step 2292, loss 0.245972, acc 0.84375, learning_rate 0.000280865\n",
      "2020-12-09T17:15:42.429562: step 2293, loss 0.120959, acc 0.96875, learning_rate 0.000280623\n",
      "2020-12-09T17:15:43.216979: step 2294, loss 0.267602, acc 0.875, learning_rate 0.000280381\n",
      "2020-12-09T17:15:43.805308: step 2295, loss 0.166638, acc 0.90625, learning_rate 0.000280139\n",
      "2020-12-09T17:15:44.360661: step 2296, loss 0.311948, acc 0.90625, learning_rate 0.000279898\n",
      "2020-12-09T17:15:45.120537: step 2297, loss 0.321205, acc 0.875, learning_rate 0.000279657\n",
      "2020-12-09T17:15:45.763640: step 2298, loss 0.154591, acc 0.96875, learning_rate 0.000279416\n",
      "2020-12-09T17:15:46.344141: step 2299, loss 0.22842, acc 0.90625, learning_rate 0.000279176\n",
      "2020-12-09T17:15:46.983661: step 2300, loss 0.161641, acc 0.96875, learning_rate 0.000278936\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:15:50.284649: step 2300, loss 0.649274, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2300\n",
      "\n",
      "2020-12-09T17:15:51.755061: step 2301, loss 0.214939, acc 0.90625, learning_rate 0.000278696\n",
      "2020-12-09T17:15:52.308060: step 2302, loss 0.156626, acc 0.90625, learning_rate 0.000278457\n",
      "2020-12-09T17:15:52.878597: step 2303, loss 0.224544, acc 0.875, learning_rate 0.000278218\n",
      "2020-12-09T17:15:53.487654: step 2304, loss 0.257833, acc 0.90625, learning_rate 0.000277979\n",
      "2020-12-09T17:15:54.045885: step 2305, loss 0.221887, acc 0.9375, learning_rate 0.000277741\n",
      "2020-12-09T17:15:54.596876: step 2306, loss 0.376886, acc 0.84375, learning_rate 0.000277502\n",
      "2020-12-09T17:15:55.160262: step 2307, loss 0.357094, acc 0.84375, learning_rate 0.000277265\n",
      "2020-12-09T17:15:55.709762: step 2308, loss 0.142215, acc 0.96875, learning_rate 0.000277027\n",
      "2020-12-09T17:15:56.276756: step 2309, loss 0.221167, acc 0.90625, learning_rate 0.00027679\n",
      "2020-12-09T17:15:56.859953: step 2310, loss 0.166825, acc 0.9375, learning_rate 0.000276553\n",
      "2020-12-09T17:15:57.410472: step 2311, loss 0.61048, acc 0.84375, learning_rate 0.000276317\n",
      "2020-12-09T17:15:57.976863: step 2312, loss 0.0785846, acc 1, learning_rate 0.000276081\n",
      "2020-12-09T17:15:58.565810: step 2313, loss 0.256116, acc 0.875, learning_rate 0.000275845\n",
      "2020-12-09T17:15:59.158275: step 2314, loss 0.259626, acc 0.84375, learning_rate 0.000275609\n",
      "2020-12-09T17:15:59.752683: step 2315, loss 0.272386, acc 0.875, learning_rate 0.000275374\n",
      "2020-12-09T17:16:00.344169: step 2316, loss 0.180975, acc 0.96875, learning_rate 0.000275139\n",
      "2020-12-09T17:16:00.928171: step 2317, loss 0.149312, acc 0.9375, learning_rate 0.000274904\n",
      "2020-12-09T17:16:01.499200: step 2318, loss 0.241332, acc 0.9375, learning_rate 0.00027467\n",
      "2020-12-09T17:16:02.081124: step 2319, loss 0.0702202, acc 1, learning_rate 0.000274436\n",
      "2020-12-09T17:16:02.639544: step 2320, loss 0.253189, acc 0.90625, learning_rate 0.000274202\n",
      "2020-12-09T17:16:03.238003: step 2321, loss 0.409164, acc 0.8125, learning_rate 0.000273969\n",
      "2020-12-09T17:16:03.816307: step 2322, loss 0.195851, acc 0.9375, learning_rate 0.000273736\n",
      "2020-12-09T17:16:04.356238: step 2323, loss 0.123378, acc 0.96875, learning_rate 0.000273503\n",
      "2020-12-09T17:16:04.928176: step 2324, loss 0.188395, acc 0.9375, learning_rate 0.000273271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:16:05.499215: step 2325, loss 0.166468, acc 0.9375, learning_rate 0.000273039\n",
      "2020-12-09T17:16:06.051521: step 2326, loss 0.15437, acc 0.96875, learning_rate 0.000272807\n",
      "2020-12-09T17:16:06.597959: step 2327, loss 0.161349, acc 0.9375, learning_rate 0.000272575\n",
      "2020-12-09T17:16:07.151497: step 2328, loss 0.169526, acc 0.96875, learning_rate 0.000272344\n",
      "2020-12-09T17:16:07.693031: step 2329, loss 0.23481, acc 0.90625, learning_rate 0.000272113\n",
      "2020-12-09T17:16:08.248702: step 2330, loss 0.16785, acc 0.96875, learning_rate 0.000271883\n",
      "2020-12-09T17:16:08.808819: step 2331, loss 0.175301, acc 0.9375, learning_rate 0.000271653\n",
      "2020-12-09T17:16:09.370421: step 2332, loss 0.206234, acc 0.90625, learning_rate 0.000271423\n",
      "2020-12-09T17:16:09.914090: step 2333, loss 0.21558, acc 0.9375, learning_rate 0.000271193\n",
      "2020-12-09T17:16:10.460374: step 2334, loss 0.097274, acc 1, learning_rate 0.000270964\n",
      "2020-12-09T17:16:11.025371: step 2335, loss 0.315312, acc 0.90625, learning_rate 0.000270735\n",
      "2020-12-09T17:16:11.568337: step 2336, loss 0.225491, acc 0.875, learning_rate 0.000270506\n",
      "2020-12-09T17:16:12.125867: step 2337, loss 0.262699, acc 0.9375, learning_rate 0.000270278\n",
      "2020-12-09T17:16:12.664960: step 2338, loss 0.208335, acc 0.875, learning_rate 0.00027005\n",
      "2020-12-09T17:16:13.206800: step 2339, loss 0.194518, acc 0.9375, learning_rate 0.000269822\n",
      "2020-12-09T17:16:13.761300: step 2340, loss 0.263025, acc 0.875, learning_rate 0.000269594\n",
      "2020-12-09T17:16:14.329775: step 2341, loss 0.223045, acc 0.96875, learning_rate 0.000269367\n",
      "2020-12-09T17:16:14.891668: step 2342, loss 0.169485, acc 0.9375, learning_rate 0.00026914\n",
      "2020-12-09T17:16:15.467763: step 2343, loss 0.250465, acc 0.875, learning_rate 0.000268914\n",
      "2020-12-09T17:16:16.046839: step 2344, loss 0.348057, acc 0.875, learning_rate 0.000268687\n",
      "2020-12-09T17:16:16.587838: step 2345, loss 0.161312, acc 0.90625, learning_rate 0.000268461\n",
      "2020-12-09T17:16:17.161250: step 2346, loss 0.13066, acc 0.90625, learning_rate 0.000268236\n",
      "2020-12-09T17:16:17.723217: step 2347, loss 0.286458, acc 0.875, learning_rate 0.00026801\n",
      "2020-12-09T17:16:18.332104: step 2348, loss 0.234996, acc 0.875, learning_rate 0.000267785\n",
      "2020-12-09T17:16:18.936602: step 2349, loss 0.153791, acc 0.9375, learning_rate 0.000267561\n",
      "2020-12-09T17:16:19.643603: step 2350, loss 0.263463, acc 0.875, learning_rate 0.000267336\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:16:24.336128: step 2350, loss 0.649248, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2350\n",
      "\n",
      "2020-12-09T17:16:25.877907: step 2351, loss 0.1714, acc 0.90625, learning_rate 0.000267112\n",
      "2020-12-09T17:16:26.448552: step 2352, loss 0.196486, acc 0.90625, learning_rate 0.000266888\n",
      "2020-12-09T17:16:27.012051: step 2353, loss 0.23662, acc 0.875, learning_rate 0.000266665\n",
      "2020-12-09T17:16:27.562191: step 2354, loss 0.203251, acc 0.96875, learning_rate 0.000266441\n",
      "2020-12-09T17:16:28.114072: step 2355, loss 0.133731, acc 1, learning_rate 0.000266218\n",
      "2020-12-09T17:16:28.660662: step 2356, loss 0.316235, acc 0.875, learning_rate 0.000265996\n",
      "2020-12-09T17:16:29.226180: step 2357, loss 0.154116, acc 0.96875, learning_rate 0.000265773\n",
      "2020-12-09T17:16:29.762665: step 2358, loss 0.236504, acc 0.9375, learning_rate 0.000265551\n",
      "2020-12-09T17:16:30.305518: step 2359, loss 0.210138, acc 0.9375, learning_rate 0.000265329\n",
      "2020-12-09T17:16:30.858681: step 2360, loss 0.116605, acc 0.96875, learning_rate 0.000265108\n",
      "2020-12-09T17:16:31.418332: step 2361, loss 0.213788, acc 0.9375, learning_rate 0.000264887\n",
      "2020-12-09T17:16:31.976129: step 2362, loss 0.186237, acc 0.90625, learning_rate 0.000264666\n",
      "2020-12-09T17:16:32.526684: step 2363, loss 0.169643, acc 0.9375, learning_rate 0.000264445\n",
      "2020-12-09T17:16:33.084217: step 2364, loss 0.379904, acc 0.84375, learning_rate 0.000264225\n",
      "2020-12-09T17:16:33.653718: step 2365, loss 0.157003, acc 0.96875, learning_rate 0.000264005\n",
      "2020-12-09T17:16:34.204610: step 2366, loss 0.207717, acc 0.875, learning_rate 0.000263785\n",
      "2020-12-09T17:16:34.757575: step 2367, loss 0.150345, acc 1, learning_rate 0.000263566\n",
      "2020-12-09T17:16:35.340150: step 2368, loss 0.190088, acc 0.96875, learning_rate 0.000263347\n",
      "2020-12-09T17:16:35.909962: step 2369, loss 0.159027, acc 0.9375, learning_rate 0.000263128\n",
      "2020-12-09T17:16:36.485176: step 2370, loss 0.159174, acc 0.90625, learning_rate 0.00026291\n",
      "2020-12-09T17:16:37.053182: step 2371, loss 0.396738, acc 0.8125, learning_rate 0.000262691\n",
      "2020-12-09T17:16:37.660685: step 2372, loss 0.223136, acc 0.9375, learning_rate 0.000262473\n",
      "2020-12-09T17:16:38.219274: step 2373, loss 0.122891, acc 1, learning_rate 0.000262256\n",
      "2020-12-09T17:16:38.770923: step 2374, loss 0.243665, acc 0.875, learning_rate 0.000262038\n",
      "2020-12-09T17:16:39.328923: step 2375, loss 0.198635, acc 0.9375, learning_rate 0.000261821\n",
      "2020-12-09T17:16:39.910696: step 2376, loss 0.169928, acc 0.9375, learning_rate 0.000261605\n",
      "2020-12-09T17:16:40.454215: step 2377, loss 0.171111, acc 0.9375, learning_rate 0.000261388\n",
      "2020-12-09T17:16:41.016177: step 2378, loss 0.26283, acc 0.84375, learning_rate 0.000261172\n",
      "2020-12-09T17:16:41.586999: step 2379, loss 0.270018, acc 0.84375, learning_rate 0.000260956\n",
      "2020-12-09T17:16:42.129014: step 2380, loss 0.100576, acc 1, learning_rate 0.00026074\n",
      "2020-12-09T17:16:42.700980: step 2381, loss 0.197056, acc 0.90625, learning_rate 0.000260525\n",
      "2020-12-09T17:16:43.261991: step 2382, loss 0.281124, acc 0.84375, learning_rate 0.00026031\n",
      "2020-12-09T17:16:43.855607: step 2383, loss 0.187056, acc 0.9375, learning_rate 0.000260095\n",
      "2020-12-09T17:16:44.406306: step 2384, loss 0.377024, acc 0.84375, learning_rate 0.000259881\n",
      "2020-12-09T17:16:44.978042: step 2385, loss 0.152078, acc 0.96875, learning_rate 0.000259667\n",
      "2020-12-09T17:16:45.553543: step 2386, loss 0.19963, acc 0.875, learning_rate 0.000259453\n",
      "2020-12-09T17:16:46.105545: step 2387, loss 0.134144, acc 0.9375, learning_rate 0.000259239\n",
      "2020-12-09T17:16:46.666546: step 2388, loss 0.207609, acc 0.875, learning_rate 0.000259026\n",
      "2020-12-09T17:16:47.229063: step 2389, loss 0.142706, acc 0.9375, learning_rate 0.000258813\n",
      "2020-12-09T17:16:47.798328: step 2390, loss 0.300192, acc 0.90625, learning_rate 0.0002586\n",
      "2020-12-09T17:16:48.365457: step 2391, loss 0.149299, acc 0.9375, learning_rate 0.000258388\n",
      "2020-12-09T17:16:48.581956: step 2392, loss 0.143236, acc 1, learning_rate 0.000258175\n",
      "2020-12-09T17:16:49.165987: step 2393, loss 0.165613, acc 0.9375, learning_rate 0.000257964\n",
      "2020-12-09T17:16:49.736688: step 2394, loss 0.364393, acc 0.875, learning_rate 0.000257752\n",
      "2020-12-09T17:16:50.305154: step 2395, loss 0.392929, acc 0.8125, learning_rate 0.000257541\n",
      "2020-12-09T17:16:50.855187: step 2396, loss 0.290968, acc 0.875, learning_rate 0.00025733\n",
      "2020-12-09T17:16:51.415187: step 2397, loss 0.129482, acc 1, learning_rate 0.000257119\n",
      "2020-12-09T17:16:51.974930: step 2398, loss 0.151132, acc 0.9375, learning_rate 0.000256908\n",
      "2020-12-09T17:16:52.552125: step 2399, loss 0.2669, acc 0.84375, learning_rate 0.000256698\n",
      "2020-12-09T17:16:53.117393: step 2400, loss 0.297663, acc 0.84375, learning_rate 0.000256488\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:16:56.417502: step 2400, loss 0.649228, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2400\n",
      "\n",
      "2020-12-09T17:16:57.893138: step 2401, loss 0.21864, acc 0.9375, learning_rate 0.000256279\n",
      "2020-12-09T17:16:58.444462: step 2402, loss 0.231007, acc 0.875, learning_rate 0.000256069\n",
      "2020-12-09T17:16:58.997018: step 2403, loss 0.21746, acc 0.9375, learning_rate 0.00025586\n",
      "2020-12-09T17:16:59.557210: step 2404, loss 0.307857, acc 0.875, learning_rate 0.000255652\n",
      "2020-12-09T17:17:00.126993: step 2405, loss 0.429113, acc 0.84375, learning_rate 0.000255443\n",
      "2020-12-09T17:17:00.665824: step 2406, loss 0.133546, acc 0.96875, learning_rate 0.000255235\n",
      "2020-12-09T17:17:01.226732: step 2407, loss 0.234102, acc 0.90625, learning_rate 0.000255027\n",
      "2020-12-09T17:17:01.789829: step 2408, loss 0.20664, acc 0.9375, learning_rate 0.000254819\n",
      "2020-12-09T17:17:02.357157: step 2409, loss 0.181932, acc 0.9375, learning_rate 0.000254612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:17:02.929602: step 2410, loss 0.24788, acc 0.875, learning_rate 0.000254405\n",
      "2020-12-09T17:17:03.727291: step 2411, loss 0.21677, acc 0.9375, learning_rate 0.000254198\n",
      "2020-12-09T17:17:04.321304: step 2412, loss 0.188326, acc 0.96875, learning_rate 0.000253991\n",
      "2020-12-09T17:17:04.912305: step 2413, loss 0.185124, acc 0.90625, learning_rate 0.000253785\n",
      "2020-12-09T17:17:05.528341: step 2414, loss 0.254533, acc 0.9375, learning_rate 0.000253579\n",
      "2020-12-09T17:17:06.123311: step 2415, loss 0.311252, acc 0.84375, learning_rate 0.000253373\n",
      "2020-12-09T17:17:06.725311: step 2416, loss 0.224968, acc 0.875, learning_rate 0.000253168\n",
      "2020-12-09T17:17:07.582844: step 2417, loss 0.247877, acc 0.875, learning_rate 0.000252963\n",
      "2020-12-09T17:17:08.200601: step 2418, loss 0.255631, acc 0.9375, learning_rate 0.000252758\n",
      "2020-12-09T17:17:08.948209: step 2419, loss 0.112739, acc 1, learning_rate 0.000252553\n",
      "2020-12-09T17:17:09.754708: step 2420, loss 0.335186, acc 0.78125, learning_rate 0.000252349\n",
      "2020-12-09T17:17:10.459750: step 2421, loss 0.230034, acc 0.875, learning_rate 0.000252145\n",
      "2020-12-09T17:17:11.224710: step 2422, loss 0.2678, acc 0.84375, learning_rate 0.000251941\n",
      "2020-12-09T17:17:11.952740: step 2423, loss 0.323348, acc 0.875, learning_rate 0.000251737\n",
      "2020-12-09T17:17:12.749210: step 2424, loss 0.156428, acc 0.9375, learning_rate 0.000251534\n",
      "2020-12-09T17:17:13.452210: step 2425, loss 0.204818, acc 0.9375, learning_rate 0.000251331\n",
      "2020-12-09T17:17:14.142960: step 2426, loss 0.256037, acc 0.90625, learning_rate 0.000251128\n",
      "2020-12-09T17:17:14.904447: step 2427, loss 0.16117, acc 0.9375, learning_rate 0.000250926\n",
      "2020-12-09T17:17:15.647373: step 2428, loss 0.301128, acc 0.90625, learning_rate 0.000250724\n",
      "2020-12-09T17:17:16.236907: step 2429, loss 0.558991, acc 0.8125, learning_rate 0.000250522\n",
      "2020-12-09T17:17:16.855937: step 2430, loss 0.0910874, acc 1, learning_rate 0.00025032\n",
      "2020-12-09T17:17:17.793403: step 2431, loss 0.128244, acc 0.96875, learning_rate 0.000250119\n",
      "2020-12-09T17:17:18.732900: step 2432, loss 0.224935, acc 0.875, learning_rate 0.000249918\n",
      "2020-12-09T17:17:19.566934: step 2433, loss 0.281002, acc 0.90625, learning_rate 0.000249717\n",
      "2020-12-09T17:17:20.259405: step 2434, loss 0.236716, acc 0.875, learning_rate 0.000249516\n",
      "2020-12-09T17:17:20.998901: step 2435, loss 0.0879156, acc 0.96875, learning_rate 0.000249316\n",
      "2020-12-09T17:17:21.588398: step 2436, loss 0.16226, acc 0.96875, learning_rate 0.000249116\n",
      "2020-12-09T17:17:22.217438: step 2437, loss 0.274551, acc 0.90625, learning_rate 0.000248916\n",
      "2020-12-09T17:17:23.016404: step 2438, loss 0.267958, acc 0.90625, learning_rate 0.000248717\n",
      "2020-12-09T17:17:23.677406: step 2439, loss 0.254431, acc 0.875, learning_rate 0.000248518\n",
      "2020-12-09T17:17:24.467401: step 2440, loss 0.242834, acc 0.84375, learning_rate 0.000248319\n",
      "2020-12-09T17:17:25.034902: step 2441, loss 0.187048, acc 0.90625, learning_rate 0.00024812\n",
      "2020-12-09T17:17:25.618320: step 2442, loss 0.261024, acc 0.90625, learning_rate 0.000247922\n",
      "2020-12-09T17:17:26.207559: step 2443, loss 0.228193, acc 0.90625, learning_rate 0.000247723\n",
      "2020-12-09T17:17:26.832923: step 2444, loss 0.150187, acc 0.96875, learning_rate 0.000247526\n",
      "2020-12-09T17:17:27.791425: step 2445, loss 0.192377, acc 0.90625, learning_rate 0.000247328\n",
      "2020-12-09T17:17:28.483900: step 2446, loss 0.171698, acc 0.96875, learning_rate 0.000247131\n",
      "2020-12-09T17:17:29.052866: step 2447, loss 0.228213, acc 0.875, learning_rate 0.000246934\n",
      "2020-12-09T17:17:29.612680: step 2448, loss 0.324376, acc 0.90625, learning_rate 0.000246737\n",
      "2020-12-09T17:17:30.174144: step 2449, loss 0.223856, acc 0.96875, learning_rate 0.00024654\n",
      "2020-12-09T17:17:30.724913: step 2450, loss 0.160705, acc 0.9375, learning_rate 0.000246344\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:17:34.257928: step 2450, loss 0.649213, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2450\n",
      "\n",
      "2020-12-09T17:17:35.726928: step 2451, loss 0.274562, acc 0.90625, learning_rate 0.000246148\n",
      "2020-12-09T17:17:36.287392: step 2452, loss 0.258812, acc 0.9375, learning_rate 0.000245952\n",
      "2020-12-09T17:17:36.837342: step 2453, loss 0.200237, acc 0.96875, learning_rate 0.000245756\n",
      "2020-12-09T17:17:37.378942: step 2454, loss 0.118269, acc 0.96875, learning_rate 0.000245561\n",
      "2020-12-09T17:17:37.932442: step 2455, loss 0.22216, acc 0.9375, learning_rate 0.000245366\n",
      "2020-12-09T17:17:38.496033: step 2456, loss 0.274728, acc 0.90625, learning_rate 0.000245172\n",
      "2020-12-09T17:17:39.050294: step 2457, loss 0.236002, acc 0.875, learning_rate 0.000244977\n",
      "2020-12-09T17:17:39.617519: step 2458, loss 0.286086, acc 0.90625, learning_rate 0.000244783\n",
      "2020-12-09T17:17:40.234546: step 2459, loss 0.0571496, acc 1, learning_rate 0.000244589\n",
      "2020-12-09T17:17:40.797039: step 2460, loss 0.155708, acc 0.96875, learning_rate 0.000244395\n",
      "2020-12-09T17:17:41.357658: step 2461, loss 0.388606, acc 0.78125, learning_rate 0.000244202\n",
      "2020-12-09T17:17:41.898146: step 2462, loss 0.256108, acc 0.875, learning_rate 0.000244009\n",
      "2020-12-09T17:17:42.489408: step 2463, loss 0.143391, acc 0.96875, learning_rate 0.000243816\n",
      "2020-12-09T17:17:43.025462: step 2464, loss 0.320406, acc 0.875, learning_rate 0.000243623\n",
      "2020-12-09T17:17:43.580467: step 2465, loss 0.147217, acc 0.96875, learning_rate 0.000243431\n",
      "2020-12-09T17:17:44.223653: step 2466, loss 0.165143, acc 0.96875, learning_rate 0.000243239\n",
      "2020-12-09T17:17:44.853596: step 2467, loss 0.289948, acc 0.875, learning_rate 0.000243047\n",
      "2020-12-09T17:17:45.802560: step 2468, loss 0.158421, acc 0.96875, learning_rate 0.000242855\n",
      "2020-12-09T17:17:46.693559: step 2469, loss 0.224083, acc 0.90625, learning_rate 0.000242664\n",
      "2020-12-09T17:17:47.311090: step 2470, loss 0.284943, acc 0.9375, learning_rate 0.000242473\n",
      "2020-12-09T17:17:47.882593: step 2471, loss 0.269081, acc 0.9375, learning_rate 0.000242282\n",
      "2020-12-09T17:17:48.468092: step 2472, loss 0.157548, acc 0.9375, learning_rate 0.000242091\n",
      "2020-12-09T17:17:49.035787: step 2473, loss 0.330432, acc 0.875, learning_rate 0.000241901\n",
      "2020-12-09T17:17:49.615167: step 2474, loss 0.197521, acc 0.96875, learning_rate 0.000241711\n",
      "2020-12-09T17:17:50.198765: step 2475, loss 0.27411, acc 0.90625, learning_rate 0.000241521\n",
      "2020-12-09T17:17:50.761228: step 2476, loss 0.11639, acc 0.9375, learning_rate 0.000241331\n",
      "2020-12-09T17:17:51.309645: step 2477, loss 0.169728, acc 0.9375, learning_rate 0.000241142\n",
      "2020-12-09T17:17:51.871179: step 2478, loss 0.0932257, acc 1, learning_rate 0.000240953\n",
      "2020-12-09T17:17:52.477356: step 2479, loss 0.232945, acc 0.90625, learning_rate 0.000240764\n",
      "2020-12-09T17:17:53.025425: step 2480, loss 0.113939, acc 0.96875, learning_rate 0.000240576\n",
      "2020-12-09T17:17:53.592433: step 2481, loss 0.285074, acc 0.90625, learning_rate 0.000240387\n",
      "2020-12-09T17:17:54.173110: step 2482, loss 0.1939, acc 0.90625, learning_rate 0.000240199\n",
      "2020-12-09T17:17:54.756740: step 2483, loss 0.135253, acc 0.90625, learning_rate 0.000240011\n",
      "2020-12-09T17:17:55.349746: step 2484, loss 0.18031, acc 0.90625, learning_rate 0.000239824\n",
      "2020-12-09T17:17:56.056175: step 2485, loss 0.282924, acc 0.8125, learning_rate 0.000239637\n",
      "2020-12-09T17:17:56.619969: step 2486, loss 0.183484, acc 0.875, learning_rate 0.000239449\n",
      "2020-12-09T17:17:57.172892: step 2487, loss 0.108523, acc 1, learning_rate 0.000239263\n",
      "2020-12-09T17:17:57.726932: step 2488, loss 0.421164, acc 0.84375, learning_rate 0.000239076\n",
      "2020-12-09T17:17:58.291846: step 2489, loss 0.465262, acc 0.84375, learning_rate 0.00023889\n",
      "2020-12-09T17:17:58.829837: step 2490, loss 0.231625, acc 0.90625, learning_rate 0.000238704\n",
      "2020-12-09T17:17:59.390371: step 2491, loss 0.318119, acc 0.875, learning_rate 0.000238518\n",
      "2020-12-09T17:17:59.959938: step 2492, loss 0.129981, acc 0.96875, learning_rate 0.000238332\n",
      "2020-12-09T17:18:00.515755: step 2493, loss 0.23356, acc 0.90625, learning_rate 0.000238147\n",
      "2020-12-09T17:18:01.089275: step 2494, loss 0.256915, acc 0.84375, learning_rate 0.000237962\n",
      "2020-12-09T17:18:01.640274: step 2495, loss 0.21782, acc 0.90625, learning_rate 0.000237777\n",
      "2020-12-09T17:18:02.204738: step 2496, loss 0.190158, acc 0.875, learning_rate 0.000237593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:18:02.748271: step 2497, loss 0.141317, acc 0.9375, learning_rate 0.000237408\n",
      "2020-12-09T17:18:03.309777: step 2498, loss 0.205054, acc 0.90625, learning_rate 0.000237224\n",
      "2020-12-09T17:18:03.880162: step 2499, loss 0.210867, acc 0.90625, learning_rate 0.00023704\n",
      "2020-12-09T17:18:04.438507: step 2500, loss 0.119607, acc 0.90625, learning_rate 0.000236857\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:18:07.732551: step 2500, loss 0.649195, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2500\n",
      "\n",
      "2020-12-09T17:18:09.224158: step 2501, loss 0.131991, acc 1, learning_rate 0.000236674\n",
      "2020-12-09T17:18:09.770223: step 2502, loss 0.165425, acc 0.9375, learning_rate 0.000236491\n",
      "2020-12-09T17:18:10.377445: step 2503, loss 0.150694, acc 0.9375, learning_rate 0.000236308\n",
      "2020-12-09T17:18:11.030144: step 2504, loss 0.390416, acc 0.84375, learning_rate 0.000236125\n",
      "2020-12-09T17:18:11.599177: step 2505, loss 0.199129, acc 1, learning_rate 0.000235943\n",
      "2020-12-09T17:18:12.176684: step 2506, loss 0.233417, acc 0.84375, learning_rate 0.000235761\n",
      "2020-12-09T17:18:12.751038: step 2507, loss 0.14767, acc 0.96875, learning_rate 0.000235579\n",
      "2020-12-09T17:18:13.322092: step 2508, loss 0.148082, acc 0.9375, learning_rate 0.000235397\n",
      "2020-12-09T17:18:13.930592: step 2509, loss 0.168105, acc 0.9375, learning_rate 0.000235216\n",
      "2020-12-09T17:18:14.560396: step 2510, loss 0.202255, acc 0.9375, learning_rate 0.000235035\n",
      "2020-12-09T17:18:15.142771: step 2511, loss 0.228894, acc 0.875, learning_rate 0.000234854\n",
      "2020-12-09T17:18:15.744854: step 2512, loss 0.370431, acc 0.78125, learning_rate 0.000234673\n",
      "2020-12-09T17:18:16.345855: step 2513, loss 0.143552, acc 0.9375, learning_rate 0.000234493\n",
      "2020-12-09T17:18:16.907903: step 2514, loss 0.239716, acc 0.9375, learning_rate 0.000234313\n",
      "2020-12-09T17:18:17.475853: step 2515, loss 0.229626, acc 0.90625, learning_rate 0.000234133\n",
      "2020-12-09T17:18:18.060929: step 2516, loss 0.128436, acc 0.96875, learning_rate 0.000233953\n",
      "2020-12-09T17:18:18.640381: step 2517, loss 0.147718, acc 0.96875, learning_rate 0.000233774\n",
      "2020-12-09T17:18:19.200672: step 2518, loss 0.103318, acc 1, learning_rate 0.000233594\n",
      "2020-12-09T17:18:19.759607: step 2519, loss 0.179246, acc 0.9375, learning_rate 0.000233415\n",
      "2020-12-09T17:18:20.313606: step 2520, loss 0.25149, acc 0.875, learning_rate 0.000233237\n",
      "2020-12-09T17:18:20.879876: step 2521, loss 0.0525942, acc 1, learning_rate 0.000233058\n",
      "2020-12-09T17:18:21.445356: step 2522, loss 0.176057, acc 0.96875, learning_rate 0.00023288\n",
      "2020-12-09T17:18:22.016463: step 2523, loss 0.197501, acc 0.9375, learning_rate 0.000232702\n",
      "2020-12-09T17:18:22.566185: step 2524, loss 0.197389, acc 0.84375, learning_rate 0.000232524\n",
      "2020-12-09T17:18:23.119335: step 2525, loss 0.178597, acc 0.875, learning_rate 0.000232347\n",
      "2020-12-09T17:18:23.678665: step 2526, loss 0.210807, acc 0.9375, learning_rate 0.000232169\n",
      "2020-12-09T17:18:24.233106: step 2527, loss 0.230195, acc 0.875, learning_rate 0.000231992\n",
      "2020-12-09T17:18:24.788556: step 2528, loss 0.338712, acc 0.9375, learning_rate 0.000231816\n",
      "2020-12-09T17:18:25.341076: step 2529, loss 0.144617, acc 0.96875, learning_rate 0.000231639\n",
      "2020-12-09T17:18:25.915076: step 2530, loss 0.35125, acc 0.875, learning_rate 0.000231463\n",
      "2020-12-09T17:18:26.506324: step 2531, loss 0.141936, acc 0.96875, learning_rate 0.000231286\n",
      "2020-12-09T17:18:27.055997: step 2532, loss 0.190658, acc 0.96875, learning_rate 0.000231111\n",
      "2020-12-09T17:18:27.603535: step 2533, loss 0.243344, acc 0.875, learning_rate 0.000230935\n",
      "2020-12-09T17:18:28.177547: step 2534, loss 0.230486, acc 0.9375, learning_rate 0.00023076\n",
      "2020-12-09T17:18:28.731440: step 2535, loss 0.246211, acc 0.875, learning_rate 0.000230584\n",
      "2020-12-09T17:18:29.322654: step 2536, loss 0.158557, acc 0.96875, learning_rate 0.00023041\n",
      "2020-12-09T17:18:29.892881: step 2537, loss 0.174048, acc 0.90625, learning_rate 0.000230235\n",
      "2020-12-09T17:18:30.459321: step 2538, loss 0.317808, acc 0.84375, learning_rate 0.00023006\n",
      "2020-12-09T17:18:31.013366: step 2539, loss 0.210337, acc 0.9375, learning_rate 0.000229886\n",
      "2020-12-09T17:18:31.570907: step 2540, loss 0.204022, acc 0.90625, learning_rate 0.000229712\n",
      "2020-12-09T17:18:32.143295: step 2541, loss 0.253887, acc 0.9375, learning_rate 0.000229538\n",
      "2020-12-09T17:18:32.708974: step 2542, loss 0.192273, acc 0.96875, learning_rate 0.000229365\n",
      "2020-12-09T17:18:33.282591: step 2543, loss 0.245674, acc 0.90625, learning_rate 0.000229192\n",
      "2020-12-09T17:18:33.837742: step 2544, loss 0.250383, acc 0.84375, learning_rate 0.000229019\n",
      "2020-12-09T17:18:34.399421: step 2545, loss 0.157979, acc 0.96875, learning_rate 0.000228846\n",
      "2020-12-09T17:18:34.947441: step 2546, loss 0.262204, acc 0.90625, learning_rate 0.000228673\n",
      "2020-12-09T17:18:35.505568: step 2547, loss 0.203585, acc 0.9375, learning_rate 0.000228501\n",
      "2020-12-09T17:18:36.081140: step 2548, loss 0.347871, acc 0.84375, learning_rate 0.000228329\n",
      "2020-12-09T17:18:36.636775: step 2549, loss 0.353378, acc 0.84375, learning_rate 0.000228157\n",
      "2020-12-09T17:18:37.186816: step 2550, loss 0.254348, acc 0.875, learning_rate 0.000227985\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:18:40.450322: step 2550, loss 0.649169, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2550\n",
      "\n",
      "2020-12-09T17:18:41.877865: step 2551, loss 0.327801, acc 0.875, learning_rate 0.000227814\n",
      "2020-12-09T17:18:42.437538: step 2552, loss 0.11922, acc 0.96875, learning_rate 0.000227642\n",
      "2020-12-09T17:18:43.012105: step 2553, loss 0.295166, acc 0.9375, learning_rate 0.000227471\n",
      "2020-12-09T17:18:43.566623: step 2554, loss 0.165781, acc 0.9375, learning_rate 0.000227301\n",
      "2020-12-09T17:18:44.135581: step 2555, loss 0.143331, acc 0.9375, learning_rate 0.00022713\n",
      "2020-12-09T17:18:44.716879: step 2556, loss 0.254075, acc 0.90625, learning_rate 0.00022696\n",
      "2020-12-09T17:18:45.267833: step 2557, loss 0.24263, acc 0.9375, learning_rate 0.00022679\n",
      "2020-12-09T17:18:45.806839: step 2558, loss 0.222544, acc 0.90625, learning_rate 0.00022662\n",
      "2020-12-09T17:18:46.375004: step 2559, loss 0.143921, acc 0.96875, learning_rate 0.00022645\n",
      "2020-12-09T17:18:46.934988: step 2560, loss 0.188959, acc 0.9375, learning_rate 0.000226281\n",
      "2020-12-09T17:18:47.487012: step 2561, loss 0.303858, acc 0.875, learning_rate 0.000226112\n",
      "2020-12-09T17:18:48.284012: step 2562, loss 0.2898, acc 0.84375, learning_rate 0.000225943\n",
      "2020-12-09T17:18:48.899961: step 2563, loss 0.0854721, acc 1, learning_rate 0.000225774\n",
      "2020-12-09T17:18:49.478171: step 2564, loss 0.342668, acc 0.84375, learning_rate 0.000225606\n",
      "2020-12-09T17:18:50.046463: step 2565, loss 0.261489, acc 0.9375, learning_rate 0.000225437\n",
      "2020-12-09T17:18:50.617379: step 2566, loss 0.0555683, acc 1, learning_rate 0.000225269\n",
      "2020-12-09T17:18:51.198610: step 2567, loss 0.244396, acc 0.875, learning_rate 0.000225102\n",
      "2020-12-09T17:18:51.750071: step 2568, loss 0.228735, acc 0.9375, learning_rate 0.000224934\n",
      "2020-12-09T17:18:52.296268: step 2569, loss 0.160845, acc 0.90625, learning_rate 0.000224767\n",
      "2020-12-09T17:18:52.894869: step 2570, loss 0.310873, acc 0.84375, learning_rate 0.000224599\n",
      "2020-12-09T17:18:53.462714: step 2571, loss 0.20627, acc 0.875, learning_rate 0.000224433\n",
      "2020-12-09T17:18:54.011734: step 2572, loss 0.2727, acc 0.84375, learning_rate 0.000224266\n",
      "2020-12-09T17:18:54.878195: step 2573, loss 0.126915, acc 0.96875, learning_rate 0.000224099\n",
      "2020-12-09T17:18:55.522075: step 2574, loss 0.32932, acc 0.84375, learning_rate 0.000223933\n",
      "2020-12-09T17:18:56.415304: step 2575, loss 0.223061, acc 0.90625, learning_rate 0.000223767\n",
      "2020-12-09T17:18:57.350804: step 2576, loss 0.203742, acc 0.9375, learning_rate 0.000223601\n",
      "2020-12-09T17:18:58.268804: step 2577, loss 0.174566, acc 0.96875, learning_rate 0.000223436\n",
      "2020-12-09T17:18:59.103803: step 2578, loss 0.232937, acc 0.90625, learning_rate 0.00022327\n",
      "2020-12-09T17:18:59.916304: step 2579, loss 0.267325, acc 0.9375, learning_rate 0.000223105\n",
      "2020-12-09T17:19:00.769805: step 2580, loss 0.191576, acc 0.90625, learning_rate 0.00022294\n",
      "2020-12-09T17:19:01.447304: step 2581, loss 0.193909, acc 0.90625, learning_rate 0.000222776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:19:02.214803: step 2582, loss 0.150824, acc 0.90625, learning_rate 0.000222611\n",
      "2020-12-09T17:19:03.040304: step 2583, loss 0.166162, acc 0.90625, learning_rate 0.000222447\n",
      "2020-12-09T17:19:03.804806: step 2584, loss 0.120558, acc 1, learning_rate 0.000222283\n",
      "2020-12-09T17:19:04.764306: step 2585, loss 0.18928, acc 0.9375, learning_rate 0.000222119\n",
      "2020-12-09T17:19:05.654310: step 2586, loss 0.135714, acc 0.96875, learning_rate 0.000221956\n",
      "2020-12-09T17:19:06.516305: step 2587, loss 0.178912, acc 0.9375, learning_rate 0.000221792\n",
      "2020-12-09T17:19:07.424304: step 2588, loss 0.23465, acc 0.875, learning_rate 0.000221629\n",
      "2020-12-09T17:19:08.373803: step 2589, loss 0.124697, acc 0.9375, learning_rate 0.000221466\n",
      "2020-12-09T17:19:09.261837: step 2590, loss 0.272896, acc 0.875, learning_rate 0.000221303\n",
      "2020-12-09T17:19:10.173307: step 2591, loss 0.191326, acc 0.90625, learning_rate 0.000221141\n",
      "2020-12-09T17:19:11.109848: step 2592, loss 0.151651, acc 0.96875, learning_rate 0.000220979\n",
      "2020-12-09T17:19:11.927802: step 2593, loss 0.20592, acc 0.9375, learning_rate 0.000220817\n",
      "2020-12-09T17:19:12.514009: step 2594, loss 0.324051, acc 0.84375, learning_rate 0.000220655\n",
      "2020-12-09T17:19:13.128333: step 2595, loss 0.241016, acc 0.84375, learning_rate 0.000220493\n",
      "2020-12-09T17:19:13.722832: step 2596, loss 0.275554, acc 0.875, learning_rate 0.000220332\n",
      "2020-12-09T17:19:14.276832: step 2597, loss 0.225509, acc 0.875, learning_rate 0.000220171\n",
      "2020-12-09T17:19:14.851013: step 2598, loss 0.197945, acc 0.90625, learning_rate 0.00022001\n",
      "2020-12-09T17:19:15.433985: step 2599, loss 0.100125, acc 1, learning_rate 0.000219849\n",
      "2020-12-09T17:19:15.976993: step 2600, loss 0.246269, acc 0.90625, learning_rate 0.000219688\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:19:19.089741: step 2600, loss 0.64915, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2600\n",
      "\n",
      "2020-12-09T17:19:20.521774: step 2601, loss 0.18122, acc 0.90625, learning_rate 0.000219528\n",
      "2020-12-09T17:19:21.085270: step 2602, loss 0.183136, acc 0.9375, learning_rate 0.000219368\n",
      "2020-12-09T17:19:21.656165: step 2603, loss 0.189024, acc 0.90625, learning_rate 0.000219208\n",
      "2020-12-09T17:19:22.228495: step 2604, loss 0.164088, acc 0.90625, learning_rate 0.000219048\n",
      "2020-12-09T17:19:22.814132: step 2605, loss 0.272864, acc 0.875, learning_rate 0.000218889\n",
      "2020-12-09T17:19:23.390204: step 2606, loss 0.240213, acc 0.9375, learning_rate 0.00021873\n",
      "2020-12-09T17:19:23.952192: step 2607, loss 0.140039, acc 0.96875, learning_rate 0.00021857\n",
      "2020-12-09T17:19:24.622191: step 2608, loss 0.414751, acc 0.75, learning_rate 0.000218412\n",
      "2020-12-09T17:19:25.201190: step 2609, loss 0.191809, acc 0.875, learning_rate 0.000218253\n",
      "2020-12-09T17:19:25.773723: step 2610, loss 0.347082, acc 0.875, learning_rate 0.000218095\n",
      "2020-12-09T17:19:26.357112: step 2611, loss 0.368952, acc 0.9375, learning_rate 0.000217936\n",
      "2020-12-09T17:19:26.963708: step 2612, loss 0.195351, acc 0.9375, learning_rate 0.000217778\n",
      "2020-12-09T17:19:27.562211: step 2613, loss 0.354391, acc 0.8125, learning_rate 0.000217621\n",
      "2020-12-09T17:19:28.098177: step 2614, loss 0.166757, acc 0.90625, learning_rate 0.000217463\n",
      "2020-12-09T17:19:28.681154: step 2615, loss 0.196506, acc 0.9375, learning_rate 0.000217306\n",
      "2020-12-09T17:19:29.248148: step 2616, loss 0.234422, acc 0.90625, learning_rate 0.000217149\n",
      "2020-12-09T17:19:29.780564: step 2617, loss 0.235919, acc 0.9375, learning_rate 0.000216992\n",
      "2020-12-09T17:19:30.348564: step 2618, loss 0.261069, acc 0.875, learning_rate 0.000216835\n",
      "2020-12-09T17:19:30.897565: step 2619, loss 0.261946, acc 0.90625, learning_rate 0.000216678\n",
      "2020-12-09T17:19:31.445228: step 2620, loss 0.265816, acc 0.9375, learning_rate 0.000216522\n",
      "2020-12-09T17:19:32.011521: step 2621, loss 0.182768, acc 0.875, learning_rate 0.000216366\n",
      "2020-12-09T17:19:32.597661: step 2622, loss 0.116036, acc 0.96875, learning_rate 0.00021621\n",
      "2020-12-09T17:19:33.185755: step 2623, loss 0.293746, acc 0.90625, learning_rate 0.000216055\n",
      "2020-12-09T17:19:33.768821: step 2624, loss 0.212757, acc 0.90625, learning_rate 0.000215899\n",
      "2020-12-09T17:19:34.309322: step 2625, loss 0.127988, acc 0.9375, learning_rate 0.000215744\n",
      "2020-12-09T17:19:34.873093: step 2626, loss 0.368782, acc 0.78125, learning_rate 0.000215589\n",
      "2020-12-09T17:19:35.437059: step 2627, loss 0.149801, acc 0.96875, learning_rate 0.000215434\n",
      "2020-12-09T17:19:35.993925: step 2628, loss 0.158946, acc 1, learning_rate 0.000215279\n",
      "2020-12-09T17:19:36.560436: step 2629, loss 0.265053, acc 0.90625, learning_rate 0.000215125\n",
      "2020-12-09T17:19:37.157823: step 2630, loss 0.348321, acc 0.84375, learning_rate 0.000214971\n",
      "2020-12-09T17:19:37.726180: step 2631, loss 0.188356, acc 0.90625, learning_rate 0.000214817\n",
      "2020-12-09T17:19:38.275076: step 2632, loss 0.311255, acc 0.90625, learning_rate 0.000214663\n",
      "2020-12-09T17:19:38.863970: step 2633, loss 0.284827, acc 0.9375, learning_rate 0.000214509\n",
      "2020-12-09T17:19:39.420697: step 2634, loss 0.329136, acc 0.8125, learning_rate 0.000214356\n",
      "2020-12-09T17:19:40.023439: step 2635, loss 0.249599, acc 0.90625, learning_rate 0.000214203\n",
      "2020-12-09T17:19:40.573558: step 2636, loss 0.338437, acc 0.875, learning_rate 0.00021405\n",
      "2020-12-09T17:19:41.144113: step 2637, loss 0.28719, acc 0.84375, learning_rate 0.000213897\n",
      "2020-12-09T17:19:41.702844: step 2638, loss 0.181556, acc 0.90625, learning_rate 0.000213744\n",
      "2020-12-09T17:19:42.241614: step 2639, loss 0.197587, acc 0.90625, learning_rate 0.000213592\n",
      "2020-12-09T17:19:42.819079: step 2640, loss 0.253012, acc 0.9375, learning_rate 0.00021344\n",
      "2020-12-09T17:19:43.382267: step 2641, loss 0.227922, acc 0.90625, learning_rate 0.000213288\n",
      "2020-12-09T17:19:43.951177: step 2642, loss 0.197725, acc 0.96875, learning_rate 0.000213136\n",
      "2020-12-09T17:19:44.523319: step 2643, loss 0.395065, acc 0.84375, learning_rate 0.000212985\n",
      "2020-12-09T17:19:45.092494: step 2644, loss 0.184973, acc 0.9375, learning_rate 0.000212833\n",
      "2020-12-09T17:19:45.639299: step 2645, loss 0.286715, acc 0.90625, learning_rate 0.000212682\n",
      "2020-12-09T17:19:46.188892: step 2646, loss 0.290858, acc 0.875, learning_rate 0.000212531\n",
      "2020-12-09T17:19:46.779434: step 2647, loss 0.127017, acc 0.96875, learning_rate 0.00021238\n",
      "2020-12-09T17:19:47.338756: step 2648, loss 0.272191, acc 0.875, learning_rate 0.00021223\n",
      "2020-12-09T17:19:47.896221: step 2649, loss 0.154989, acc 0.9375, learning_rate 0.000212079\n",
      "2020-12-09T17:19:48.456757: step 2650, loss 0.125131, acc 0.96875, learning_rate 0.000211929\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:19:51.714425: step 2650, loss 0.649136, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2650\n",
      "\n",
      "2020-12-09T17:19:53.219889: step 2651, loss 0.159247, acc 0.90625, learning_rate 0.000211779\n",
      "2020-12-09T17:19:53.796664: step 2652, loss 0.283207, acc 0.875, learning_rate 0.00021163\n",
      "2020-12-09T17:19:54.382957: step 2653, loss 0.377756, acc 0.84375, learning_rate 0.00021148\n",
      "2020-12-09T17:19:54.928454: step 2654, loss 0.311599, acc 0.84375, learning_rate 0.000211331\n",
      "2020-12-09T17:19:55.498393: step 2655, loss 0.169116, acc 0.9375, learning_rate 0.000211182\n",
      "2020-12-09T17:19:56.068251: step 2656, loss 0.14723, acc 0.96875, learning_rate 0.000211033\n",
      "2020-12-09T17:19:56.666365: step 2657, loss 0.172519, acc 0.9375, learning_rate 0.000210884\n",
      "2020-12-09T17:19:57.249010: step 2658, loss 0.232479, acc 0.875, learning_rate 0.000210735\n",
      "2020-12-09T17:19:57.798184: step 2659, loss 0.209706, acc 0.9375, learning_rate 0.000210587\n",
      "2020-12-09T17:19:58.348944: step 2660, loss 0.106116, acc 0.96875, learning_rate 0.000210439\n",
      "2020-12-09T17:19:58.927545: step 2661, loss 0.262126, acc 0.90625, learning_rate 0.000210291\n",
      "2020-12-09T17:19:59.489260: step 2662, loss 0.255165, acc 0.90625, learning_rate 0.000210143\n",
      "2020-12-09T17:20:00.054277: step 2663, loss 0.46817, acc 0.71875, learning_rate 0.000209996\n",
      "2020-12-09T17:20:00.636084: step 2664, loss 0.202094, acc 0.90625, learning_rate 0.000209848\n",
      "2020-12-09T17:20:01.211336: step 2665, loss 0.286756, acc 0.875, learning_rate 0.000209701\n",
      "2020-12-09T17:20:01.774893: step 2666, loss 0.29225, acc 0.9375, learning_rate 0.000209554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:20:02.317399: step 2667, loss 0.461965, acc 0.78125, learning_rate 0.000209408\n",
      "2020-12-09T17:20:02.877810: step 2668, loss 0.244043, acc 0.90625, learning_rate 0.000209261\n",
      "2020-12-09T17:20:03.423705: step 2669, loss 0.247304, acc 0.90625, learning_rate 0.000209115\n",
      "2020-12-09T17:20:03.979472: step 2670, loss 0.159107, acc 0.9375, learning_rate 0.000208968\n",
      "2020-12-09T17:20:04.537216: step 2671, loss 0.107272, acc 0.96875, learning_rate 0.000208823\n",
      "2020-12-09T17:20:05.079687: step 2672, loss 0.200441, acc 0.875, learning_rate 0.000208677\n",
      "2020-12-09T17:20:05.644205: step 2673, loss 0.323558, acc 0.84375, learning_rate 0.000208531\n",
      "2020-12-09T17:20:06.189736: step 2674, loss 0.300995, acc 0.875, learning_rate 0.000208386\n",
      "2020-12-09T17:20:06.742236: step 2675, loss 0.119707, acc 0.96875, learning_rate 0.000208241\n",
      "2020-12-09T17:20:07.312920: step 2676, loss 0.135605, acc 0.96875, learning_rate 0.000208096\n",
      "2020-12-09T17:20:07.878903: step 2677, loss 0.157674, acc 0.96875, learning_rate 0.000207951\n",
      "2020-12-09T17:20:08.424408: step 2678, loss 0.163638, acc 0.9375, learning_rate 0.000207806\n",
      "2020-12-09T17:20:09.001903: step 2679, loss 0.217359, acc 0.9375, learning_rate 0.000207662\n",
      "2020-12-09T17:20:09.577865: step 2680, loss 0.157799, acc 0.96875, learning_rate 0.000207518\n",
      "2020-12-09T17:20:10.145362: step 2681, loss 0.280849, acc 0.8125, learning_rate 0.000207374\n",
      "2020-12-09T17:20:10.718799: step 2682, loss 0.250675, acc 0.90625, learning_rate 0.00020723\n",
      "2020-12-09T17:20:11.263527: step 2683, loss 0.20122, acc 0.90625, learning_rate 0.000207086\n",
      "2020-12-09T17:20:11.833204: step 2684, loss 0.357068, acc 0.9375, learning_rate 0.000206943\n",
      "2020-12-09T17:20:12.381025: step 2685, loss 0.24088, acc 0.90625, learning_rate 0.000206799\n",
      "2020-12-09T17:20:12.959559: step 2686, loss 0.416296, acc 0.8125, learning_rate 0.000206656\n",
      "2020-12-09T17:20:13.564746: step 2687, loss 0.206163, acc 0.90625, learning_rate 0.000206513\n",
      "2020-12-09T17:20:14.165293: step 2688, loss 0.235221, acc 0.90625, learning_rate 0.000206371\n",
      "2020-12-09T17:20:14.712644: step 2689, loss 0.287838, acc 0.875, learning_rate 0.000206228\n",
      "2020-12-09T17:20:15.273148: step 2690, loss 0.332317, acc 0.875, learning_rate 0.000206086\n",
      "2020-12-09T17:20:15.479605: step 2691, loss 0.261198, acc 0.846154, learning_rate 0.000205944\n",
      "2020-12-09T17:20:16.065031: step 2692, loss 0.265144, acc 0.90625, learning_rate 0.000205802\n",
      "2020-12-09T17:20:16.616968: step 2693, loss 0.292061, acc 0.90625, learning_rate 0.00020566\n",
      "2020-12-09T17:20:17.177562: step 2694, loss 0.144385, acc 0.9375, learning_rate 0.000205519\n",
      "2020-12-09T17:20:17.736173: step 2695, loss 0.245676, acc 0.875, learning_rate 0.000205377\n",
      "2020-12-09T17:20:18.301846: step 2696, loss 0.149693, acc 0.9375, learning_rate 0.000205236\n",
      "2020-12-09T17:20:18.868174: step 2697, loss 0.112561, acc 0.96875, learning_rate 0.000205095\n",
      "2020-12-09T17:20:19.508776: step 2698, loss 0.342904, acc 0.84375, learning_rate 0.000204954\n",
      "2020-12-09T17:20:20.063797: step 2699, loss 0.244743, acc 0.90625, learning_rate 0.000204814\n",
      "2020-12-09T17:20:20.611942: step 2700, loss 0.219771, acc 0.9375, learning_rate 0.000204673\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:20:23.933907: step 2700, loss 0.649126, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2700\n",
      "\n",
      "2020-12-09T17:20:25.547274: step 2701, loss 0.185113, acc 1, learning_rate 0.000204533\n",
      "2020-12-09T17:20:26.102449: step 2702, loss 0.192425, acc 0.90625, learning_rate 0.000204393\n",
      "2020-12-09T17:20:26.651933: step 2703, loss 0.267184, acc 0.96875, learning_rate 0.000204253\n",
      "2020-12-09T17:20:27.209779: step 2704, loss 0.269763, acc 0.875, learning_rate 0.000204114\n",
      "2020-12-09T17:20:27.790687: step 2705, loss 0.321196, acc 0.8125, learning_rate 0.000203974\n",
      "2020-12-09T17:20:28.367779: step 2706, loss 0.169529, acc 0.9375, learning_rate 0.000203835\n",
      "2020-12-09T17:20:28.920295: step 2707, loss 0.22926, acc 0.9375, learning_rate 0.000203696\n",
      "2020-12-09T17:20:29.483836: step 2708, loss 0.271192, acc 0.90625, learning_rate 0.000203557\n",
      "2020-12-09T17:20:30.022448: step 2709, loss 0.280922, acc 0.84375, learning_rate 0.000203418\n",
      "2020-12-09T17:20:30.576898: step 2710, loss 0.179882, acc 0.875, learning_rate 0.00020328\n",
      "2020-12-09T17:20:31.132899: step 2711, loss 0.151231, acc 0.9375, learning_rate 0.000203141\n",
      "2020-12-09T17:20:31.682241: step 2712, loss 0.255602, acc 0.96875, learning_rate 0.000203003\n",
      "2020-12-09T17:20:32.243215: step 2713, loss 0.200093, acc 0.9375, learning_rate 0.000202865\n",
      "2020-12-09T17:20:32.836209: step 2714, loss 0.213932, acc 0.9375, learning_rate 0.000202727\n",
      "2020-12-09T17:20:33.426710: step 2715, loss 0.189279, acc 0.9375, learning_rate 0.00020259\n",
      "2020-12-09T17:20:33.999008: step 2716, loss 0.0600253, acc 1, learning_rate 0.000202452\n",
      "2020-12-09T17:20:34.571533: step 2717, loss 0.140356, acc 0.9375, learning_rate 0.000202315\n",
      "2020-12-09T17:20:35.167627: step 2718, loss 0.339806, acc 0.8125, learning_rate 0.000202178\n",
      "2020-12-09T17:20:35.750815: step 2719, loss 0.222491, acc 0.875, learning_rate 0.000202041\n",
      "2020-12-09T17:20:36.317331: step 2720, loss 0.150755, acc 0.9375, learning_rate 0.000201904\n",
      "2020-12-09T17:20:36.914274: step 2721, loss 0.216313, acc 0.9375, learning_rate 0.000201768\n",
      "2020-12-09T17:20:37.497588: step 2722, loss 0.191413, acc 0.90625, learning_rate 0.000201632\n",
      "2020-12-09T17:20:38.066453: step 2723, loss 0.207704, acc 0.9375, learning_rate 0.000201496\n",
      "2020-12-09T17:20:38.610418: step 2724, loss 0.155109, acc 0.9375, learning_rate 0.00020136\n",
      "2020-12-09T17:20:39.190754: step 2725, loss 0.137127, acc 0.96875, learning_rate 0.000201224\n",
      "2020-12-09T17:20:39.765827: step 2726, loss 0.201828, acc 0.875, learning_rate 0.000201088\n",
      "2020-12-09T17:20:40.335364: step 2727, loss 0.253795, acc 0.9375, learning_rate 0.000200953\n",
      "2020-12-09T17:20:40.886865: step 2728, loss 0.186558, acc 0.90625, learning_rate 0.000200818\n",
      "2020-12-09T17:20:41.440982: step 2729, loss 0.296703, acc 0.90625, learning_rate 0.000200682\n",
      "2020-12-09T17:20:42.005282: step 2730, loss 0.443799, acc 0.84375, learning_rate 0.000200548\n",
      "2020-12-09T17:20:42.584343: step 2731, loss 0.345139, acc 0.8125, learning_rate 0.000200413\n",
      "2020-12-09T17:20:43.145128: step 2732, loss 0.212612, acc 0.875, learning_rate 0.000200278\n",
      "2020-12-09T17:20:43.737450: step 2733, loss 0.164135, acc 0.90625, learning_rate 0.000200144\n",
      "2020-12-09T17:20:44.306598: step 2734, loss 0.369562, acc 0.84375, learning_rate 0.00020001\n",
      "2020-12-09T17:20:44.848659: step 2735, loss 0.135899, acc 0.96875, learning_rate 0.000199876\n",
      "2020-12-09T17:20:45.414737: step 2736, loss 0.207135, acc 0.9375, learning_rate 0.000199742\n",
      "2020-12-09T17:20:45.960645: step 2737, loss 0.277532, acc 0.875, learning_rate 0.000199609\n",
      "2020-12-09T17:20:46.532827: step 2738, loss 0.178614, acc 0.9375, learning_rate 0.000199475\n",
      "2020-12-09T17:20:47.095788: step 2739, loss 0.241713, acc 0.9375, learning_rate 0.000199342\n",
      "2020-12-09T17:20:47.673323: step 2740, loss 0.301246, acc 0.90625, learning_rate 0.000199209\n",
      "2020-12-09T17:20:48.249038: step 2741, loss 0.267341, acc 0.875, learning_rate 0.000199076\n",
      "2020-12-09T17:20:48.800038: step 2742, loss 0.143687, acc 0.96875, learning_rate 0.000198943\n",
      "2020-12-09T17:20:49.370810: step 2743, loss 0.168309, acc 0.96875, learning_rate 0.000198811\n",
      "2020-12-09T17:20:49.919257: step 2744, loss 0.204874, acc 0.9375, learning_rate 0.000198678\n",
      "2020-12-09T17:20:50.482336: step 2745, loss 0.44477, acc 0.875, learning_rate 0.000198546\n",
      "2020-12-09T17:20:51.038450: step 2746, loss 0.303508, acc 0.90625, learning_rate 0.000198414\n",
      "2020-12-09T17:20:51.628005: step 2747, loss 0.170251, acc 0.9375, learning_rate 0.000198282\n",
      "2020-12-09T17:20:52.204590: step 2748, loss 0.321663, acc 0.84375, learning_rate 0.000198151\n",
      "2020-12-09T17:20:52.756554: step 2749, loss 0.27512, acc 0.90625, learning_rate 0.000198019\n",
      "2020-12-09T17:20:53.333850: step 2750, loss 0.27362, acc 0.84375, learning_rate 0.000197888\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:20:56.671159: step 2750, loss 0.649105, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2750\n",
      "\n",
      "2020-12-09T17:20:58.183784: step 2751, loss 0.127428, acc 0.96875, learning_rate 0.000197757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:20:58.741128: step 2752, loss 0.218854, acc 0.875, learning_rate 0.000197626\n",
      "2020-12-09T17:20:59.304025: step 2753, loss 0.190196, acc 0.9375, learning_rate 0.000197495\n",
      "2020-12-09T17:20:59.860115: step 2754, loss 0.317911, acc 0.875, learning_rate 0.000197364\n",
      "2020-12-09T17:21:00.402176: step 2755, loss 0.108527, acc 0.96875, learning_rate 0.000197234\n",
      "2020-12-09T17:21:00.956174: step 2756, loss 0.224075, acc 0.9375, learning_rate 0.000197104\n",
      "2020-12-09T17:21:01.514173: step 2757, loss 0.259599, acc 0.90625, learning_rate 0.000196974\n",
      "2020-12-09T17:21:02.076597: step 2758, loss 0.242463, acc 0.90625, learning_rate 0.000196844\n",
      "2020-12-09T17:21:02.634356: step 2759, loss 0.370637, acc 0.875, learning_rate 0.000196714\n",
      "2020-12-09T17:21:03.298571: step 2760, loss 0.229667, acc 0.90625, learning_rate 0.000196584\n",
      "2020-12-09T17:21:04.080609: step 2761, loss 0.447801, acc 0.84375, learning_rate 0.000196455\n",
      "2020-12-09T17:21:04.743002: step 2762, loss 0.168072, acc 0.9375, learning_rate 0.000196326\n",
      "2020-12-09T17:21:05.676470: step 2763, loss 0.347104, acc 0.84375, learning_rate 0.000196197\n",
      "2020-12-09T17:21:06.388325: step 2764, loss 0.39082, acc 0.71875, learning_rate 0.000196068\n",
      "2020-12-09T17:21:06.970448: step 2765, loss 0.202026, acc 0.9375, learning_rate 0.000195939\n",
      "2020-12-09T17:21:07.554979: step 2766, loss 0.199027, acc 0.9375, learning_rate 0.000195811\n",
      "2020-12-09T17:21:08.106927: step 2767, loss 0.17956, acc 0.90625, learning_rate 0.000195682\n",
      "2020-12-09T17:21:08.663573: step 2768, loss 0.29268, acc 0.90625, learning_rate 0.000195554\n",
      "2020-12-09T17:21:09.220528: step 2769, loss 0.30091, acc 0.8125, learning_rate 0.000195426\n",
      "2020-12-09T17:21:09.787707: step 2770, loss 0.153511, acc 1, learning_rate 0.000195298\n",
      "2020-12-09T17:21:10.350589: step 2771, loss 0.198678, acc 0.875, learning_rate 0.000195171\n",
      "2020-12-09T17:21:10.895557: step 2772, loss 0.341979, acc 0.875, learning_rate 0.000195043\n",
      "2020-12-09T17:21:11.458174: step 2773, loss 0.0697798, acc 0.96875, learning_rate 0.000194916\n",
      "2020-12-09T17:21:12.008400: step 2774, loss 0.281757, acc 0.875, learning_rate 0.000194789\n",
      "2020-12-09T17:21:12.590153: step 2775, loss 0.200423, acc 0.9375, learning_rate 0.000194662\n",
      "2020-12-09T17:21:13.149009: step 2776, loss 0.129451, acc 0.96875, learning_rate 0.000194535\n",
      "2020-12-09T17:21:13.704746: step 2777, loss 0.105379, acc 0.96875, learning_rate 0.000194408\n",
      "2020-12-09T17:21:14.260168: step 2778, loss 0.265197, acc 0.90625, learning_rate 0.000194282\n",
      "2020-12-09T17:21:14.821749: step 2779, loss 0.172177, acc 0.90625, learning_rate 0.000194156\n",
      "2020-12-09T17:21:15.394186: step 2780, loss 0.30221, acc 0.90625, learning_rate 0.00019403\n",
      "2020-12-09T17:21:15.968547: step 2781, loss 0.196992, acc 0.9375, learning_rate 0.000193904\n",
      "2020-12-09T17:21:16.523458: step 2782, loss 0.246651, acc 0.90625, learning_rate 0.000193778\n",
      "2020-12-09T17:21:17.081956: step 2783, loss 0.313744, acc 0.875, learning_rate 0.000193652\n",
      "2020-12-09T17:21:17.634491: step 2784, loss 0.216068, acc 0.90625, learning_rate 0.000193527\n",
      "2020-12-09T17:21:18.193051: step 2785, loss 0.328836, acc 0.9375, learning_rate 0.000193401\n",
      "2020-12-09T17:21:18.761384: step 2786, loss 0.108143, acc 1, learning_rate 0.000193276\n",
      "2020-12-09T17:21:19.325882: step 2787, loss 0.363, acc 0.78125, learning_rate 0.000193151\n",
      "2020-12-09T17:21:19.901805: step 2788, loss 0.221702, acc 0.84375, learning_rate 0.000193027\n",
      "2020-12-09T17:21:20.465120: step 2789, loss 0.156206, acc 0.96875, learning_rate 0.000192902\n",
      "2020-12-09T17:21:21.014921: step 2790, loss 0.159556, acc 0.96875, learning_rate 0.000192778\n",
      "2020-12-09T17:21:21.592919: step 2791, loss 0.137434, acc 0.9375, learning_rate 0.000192653\n",
      "2020-12-09T17:21:22.127198: step 2792, loss 0.379504, acc 0.84375, learning_rate 0.000192529\n",
      "2020-12-09T17:21:22.709002: step 2793, loss 0.189914, acc 0.90625, learning_rate 0.000192405\n",
      "2020-12-09T17:21:23.261112: step 2794, loss 0.27203, acc 0.875, learning_rate 0.000192281\n",
      "2020-12-09T17:21:23.818387: step 2795, loss 0.285302, acc 0.90625, learning_rate 0.000192158\n",
      "2020-12-09T17:21:24.381548: step 2796, loss 0.309975, acc 0.90625, learning_rate 0.000192034\n",
      "2020-12-09T17:21:24.933548: step 2797, loss 0.235757, acc 0.90625, learning_rate 0.000191911\n",
      "2020-12-09T17:21:25.493583: step 2798, loss 0.392409, acc 0.875, learning_rate 0.000191788\n",
      "2020-12-09T17:21:26.077749: step 2799, loss 0.270973, acc 0.90625, learning_rate 0.000191665\n",
      "2020-12-09T17:21:26.635747: step 2800, loss 0.225404, acc 0.90625, learning_rate 0.000191542\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:21:30.245574: step 2800, loss 0.649089, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2800\n",
      "\n",
      "2020-12-09T17:21:31.807260: step 2801, loss 0.266211, acc 0.90625, learning_rate 0.00019142\n",
      "2020-12-09T17:21:32.372359: step 2802, loss 0.156205, acc 0.9375, learning_rate 0.000191297\n",
      "2020-12-09T17:21:32.902810: step 2803, loss 0.17804, acc 0.96875, learning_rate 0.000191175\n",
      "2020-12-09T17:21:33.484125: step 2804, loss 0.166795, acc 0.9375, learning_rate 0.000191053\n",
      "2020-12-09T17:21:34.079159: step 2805, loss 0.241046, acc 0.9375, learning_rate 0.000190931\n",
      "2020-12-09T17:21:34.644095: step 2806, loss 0.38327, acc 0.875, learning_rate 0.000190809\n",
      "2020-12-09T17:21:35.198292: step 2807, loss 0.160949, acc 0.9375, learning_rate 0.000190687\n",
      "2020-12-09T17:21:35.836280: step 2808, loss 0.202838, acc 0.9375, learning_rate 0.000190566\n",
      "2020-12-09T17:21:36.560633: step 2809, loss 0.16382, acc 0.9375, learning_rate 0.000190444\n",
      "2020-12-09T17:21:37.196131: step 2810, loss 0.212062, acc 0.90625, learning_rate 0.000190323\n",
      "2020-12-09T17:21:37.782195: step 2811, loss 0.16583, acc 0.875, learning_rate 0.000190202\n",
      "2020-12-09T17:21:38.368786: step 2812, loss 0.142097, acc 0.96875, learning_rate 0.000190081\n",
      "2020-12-09T17:21:38.955753: step 2813, loss 0.230833, acc 0.90625, learning_rate 0.000189961\n",
      "2020-12-09T17:21:39.610252: step 2814, loss 0.185485, acc 0.96875, learning_rate 0.00018984\n",
      "2020-12-09T17:21:40.215253: step 2815, loss 0.26557, acc 0.9375, learning_rate 0.00018972\n",
      "2020-12-09T17:21:40.767254: step 2816, loss 0.168604, acc 0.9375, learning_rate 0.0001896\n",
      "2020-12-09T17:21:41.352253: step 2817, loss 0.122484, acc 1, learning_rate 0.00018948\n",
      "2020-12-09T17:21:41.966737: step 2818, loss 0.244117, acc 0.875, learning_rate 0.00018936\n",
      "2020-12-09T17:21:42.528558: step 2819, loss 0.19768, acc 0.90625, learning_rate 0.00018924\n",
      "2020-12-09T17:21:43.105020: step 2820, loss 0.23276, acc 0.84375, learning_rate 0.000189121\n",
      "2020-12-09T17:21:43.667055: step 2821, loss 0.0751344, acc 1, learning_rate 0.000189001\n",
      "2020-12-09T17:21:44.226889: step 2822, loss 0.190922, acc 1, learning_rate 0.000188882\n",
      "2020-12-09T17:21:44.800397: step 2823, loss 0.193439, acc 0.90625, learning_rate 0.000188763\n",
      "2020-12-09T17:21:45.345092: step 2824, loss 0.266969, acc 0.90625, learning_rate 0.000188644\n",
      "2020-12-09T17:21:45.907788: step 2825, loss 0.408046, acc 0.75, learning_rate 0.000188525\n",
      "2020-12-09T17:21:46.459395: step 2826, loss 0.33917, acc 0.875, learning_rate 0.000188407\n",
      "2020-12-09T17:21:47.036173: step 2827, loss 0.187306, acc 0.90625, learning_rate 0.000188288\n",
      "2020-12-09T17:21:47.582208: step 2828, loss 0.263533, acc 0.9375, learning_rate 0.00018817\n",
      "2020-12-09T17:21:48.177925: step 2829, loss 0.268385, acc 0.9375, learning_rate 0.000188052\n",
      "2020-12-09T17:21:48.720277: step 2830, loss 0.17178, acc 0.90625, learning_rate 0.000187934\n",
      "2020-12-09T17:21:49.268502: step 2831, loss 0.0775171, acc 1, learning_rate 0.000187816\n",
      "2020-12-09T17:21:49.833548: step 2832, loss 0.190337, acc 0.90625, learning_rate 0.000187699\n",
      "2020-12-09T17:21:50.387877: step 2833, loss 0.346356, acc 0.78125, learning_rate 0.000187581\n",
      "2020-12-09T17:21:50.972840: step 2834, loss 0.193707, acc 0.84375, learning_rate 0.000187464\n",
      "2020-12-09T17:21:51.556816: step 2835, loss 0.253478, acc 0.90625, learning_rate 0.000187347\n",
      "2020-12-09T17:21:52.155989: step 2836, loss 0.218247, acc 0.9375, learning_rate 0.00018723\n",
      "2020-12-09T17:21:52.740032: step 2837, loss 0.248155, acc 0.84375, learning_rate 0.000187113\n",
      "2020-12-09T17:21:53.293438: step 2838, loss 0.309763, acc 0.90625, learning_rate 0.000186996\n",
      "2020-12-09T17:21:53.853995: step 2839, loss 0.159468, acc 0.9375, learning_rate 0.000186879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:21:54.443997: step 2840, loss 0.185344, acc 0.90625, learning_rate 0.000186763\n",
      "2020-12-09T17:21:54.991497: step 2841, loss 0.187532, acc 0.9375, learning_rate 0.000186647\n",
      "2020-12-09T17:21:55.546699: step 2842, loss 0.059085, acc 0.96875, learning_rate 0.000186531\n",
      "2020-12-09T17:21:56.103100: step 2843, loss 0.251168, acc 0.9375, learning_rate 0.000186415\n",
      "2020-12-09T17:21:56.666052: step 2844, loss 0.312737, acc 0.875, learning_rate 0.000186299\n",
      "2020-12-09T17:21:57.228013: step 2845, loss 0.328907, acc 0.78125, learning_rate 0.000186184\n",
      "2020-12-09T17:21:57.809019: step 2846, loss 0.310713, acc 0.84375, learning_rate 0.000186068\n",
      "2020-12-09T17:21:58.383019: step 2847, loss 0.31178, acc 0.90625, learning_rate 0.000185953\n",
      "2020-12-09T17:21:58.942073: step 2848, loss 0.323198, acc 0.84375, learning_rate 0.000185838\n",
      "2020-12-09T17:21:59.482111: step 2849, loss 0.385643, acc 0.8125, learning_rate 0.000185723\n",
      "2020-12-09T17:22:00.055491: step 2850, loss 0.202576, acc 0.90625, learning_rate 0.000185608\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:22:03.410461: step 2850, loss 0.649078, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2850\n",
      "\n",
      "2020-12-09T17:22:04.958132: step 2851, loss 0.130334, acc 0.96875, learning_rate 0.000185493\n",
      "2020-12-09T17:22:05.501515: step 2852, loss 0.144897, acc 0.90625, learning_rate 0.000185379\n",
      "2020-12-09T17:22:06.053767: step 2853, loss 0.342797, acc 0.90625, learning_rate 0.000185264\n",
      "2020-12-09T17:22:06.617273: step 2854, loss 0.239315, acc 0.90625, learning_rate 0.00018515\n",
      "2020-12-09T17:22:07.172771: step 2855, loss 0.272071, acc 0.9375, learning_rate 0.000185036\n",
      "2020-12-09T17:22:07.738317: step 2856, loss 0.158911, acc 0.90625, learning_rate 0.000184922\n",
      "2020-12-09T17:22:08.296506: step 2857, loss 0.190439, acc 0.90625, learning_rate 0.000184808\n",
      "2020-12-09T17:22:08.848947: step 2858, loss 0.185752, acc 0.96875, learning_rate 0.000184695\n",
      "2020-12-09T17:22:09.396060: step 2859, loss 0.24885, acc 0.875, learning_rate 0.000184581\n",
      "2020-12-09T17:22:09.960064: step 2860, loss 0.355363, acc 0.90625, learning_rate 0.000184468\n",
      "2020-12-09T17:22:10.526160: step 2861, loss 0.313938, acc 0.78125, learning_rate 0.000184355\n",
      "2020-12-09T17:22:11.082055: step 2862, loss 0.270262, acc 0.90625, learning_rate 0.000184242\n",
      "2020-12-09T17:22:11.645090: step 2863, loss 0.311009, acc 0.8125, learning_rate 0.000184129\n",
      "2020-12-09T17:22:12.220011: step 2864, loss 0.154026, acc 0.9375, learning_rate 0.000184016\n",
      "2020-12-09T17:22:12.776104: step 2865, loss 0.221008, acc 0.9375, learning_rate 0.000183904\n",
      "2020-12-09T17:22:13.331120: step 2866, loss 0.153809, acc 0.96875, learning_rate 0.000183791\n",
      "2020-12-09T17:22:13.893119: step 2867, loss 0.291403, acc 0.8125, learning_rate 0.000183679\n",
      "2020-12-09T17:22:14.464047: step 2868, loss 0.13572, acc 0.96875, learning_rate 0.000183567\n",
      "2020-12-09T17:22:15.003381: step 2869, loss 0.077716, acc 1, learning_rate 0.000183455\n",
      "2020-12-09T17:22:15.553384: step 2870, loss 0.138254, acc 0.90625, learning_rate 0.000183343\n",
      "2020-12-09T17:22:16.125381: step 2871, loss 0.460005, acc 0.875, learning_rate 0.000183232\n",
      "2020-12-09T17:22:16.703914: step 2872, loss 0.328618, acc 0.90625, learning_rate 0.00018312\n",
      "2020-12-09T17:22:17.254384: step 2873, loss 0.273189, acc 0.875, learning_rate 0.000183009\n",
      "2020-12-09T17:22:17.804231: step 2874, loss 0.20484, acc 0.875, learning_rate 0.000182898\n",
      "2020-12-09T17:22:18.389467: step 2875, loss 0.29323, acc 0.875, learning_rate 0.000182787\n",
      "2020-12-09T17:22:18.937419: step 2876, loss 0.142288, acc 0.9375, learning_rate 0.000182676\n",
      "2020-12-09T17:22:19.490418: step 2877, loss 0.212407, acc 0.90625, learning_rate 0.000182565\n",
      "2020-12-09T17:22:20.152954: step 2878, loss 0.177941, acc 0.90625, learning_rate 0.000182454\n",
      "2020-12-09T17:22:20.770466: step 2879, loss 0.322169, acc 0.8125, learning_rate 0.000182344\n",
      "2020-12-09T17:22:21.353033: step 2880, loss 0.246342, acc 0.90625, learning_rate 0.000182234\n",
      "2020-12-09T17:22:21.922898: step 2881, loss 0.199555, acc 0.96875, learning_rate 0.000182123\n",
      "2020-12-09T17:22:22.484433: step 2882, loss 0.262511, acc 0.9375, learning_rate 0.000182013\n",
      "2020-12-09T17:22:23.021656: step 2883, loss 0.123321, acc 0.96875, learning_rate 0.000181904\n",
      "2020-12-09T17:22:23.566657: step 2884, loss 0.21147, acc 0.875, learning_rate 0.000181794\n",
      "2020-12-09T17:22:24.136028: step 2885, loss 0.122446, acc 0.9375, learning_rate 0.000181684\n",
      "2020-12-09T17:22:24.698237: step 2886, loss 0.378464, acc 0.8125, learning_rate 0.000181575\n",
      "2020-12-09T17:22:25.255299: step 2887, loss 0.385252, acc 0.90625, learning_rate 0.000181466\n",
      "2020-12-09T17:22:25.812143: step 2888, loss 0.338506, acc 0.90625, learning_rate 0.000181356\n",
      "2020-12-09T17:22:26.419287: step 2889, loss 0.139939, acc 0.9375, learning_rate 0.000181247\n",
      "2020-12-09T17:22:27.009931: step 2890, loss 0.0628127, acc 1, learning_rate 0.000181139\n",
      "2020-12-09T17:22:27.552890: step 2891, loss 0.213394, acc 0.90625, learning_rate 0.00018103\n",
      "2020-12-09T17:22:28.125858: step 2892, loss 0.139613, acc 0.96875, learning_rate 0.000180921\n",
      "2020-12-09T17:22:28.697825: step 2893, loss 0.167036, acc 0.96875, learning_rate 0.000180813\n",
      "2020-12-09T17:22:29.272375: step 2894, loss 0.152233, acc 0.96875, learning_rate 0.000180705\n",
      "2020-12-09T17:22:29.836624: step 2895, loss 0.135413, acc 0.96875, learning_rate 0.000180597\n",
      "2020-12-09T17:22:30.390625: step 2896, loss 0.103839, acc 1, learning_rate 0.000180489\n",
      "2020-12-09T17:22:30.946398: step 2897, loss 0.231818, acc 0.9375, learning_rate 0.000180381\n",
      "2020-12-09T17:22:31.486319: step 2898, loss 0.103582, acc 0.96875, learning_rate 0.000180273\n",
      "2020-12-09T17:22:32.049856: step 2899, loss 0.260068, acc 0.875, learning_rate 0.000180166\n",
      "2020-12-09T17:22:32.631354: step 2900, loss 0.127679, acc 0.96875, learning_rate 0.000180058\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:22:36.179058: step 2900, loss 0.649062, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2900\n",
      "\n",
      "2020-12-09T17:22:37.642899: step 2901, loss 0.16362, acc 0.9375, learning_rate 0.000179951\n",
      "2020-12-09T17:22:38.236733: step 2902, loss 0.156583, acc 0.9375, learning_rate 0.000179844\n",
      "2020-12-09T17:22:38.797386: step 2903, loss 0.256863, acc 0.875, learning_rate 0.000179737\n",
      "2020-12-09T17:22:39.363265: step 2904, loss 0.273928, acc 0.90625, learning_rate 0.00017963\n",
      "2020-12-09T17:22:39.964392: step 2905, loss 0.262082, acc 0.875, learning_rate 0.000179523\n",
      "2020-12-09T17:22:40.558803: step 2906, loss 0.325917, acc 0.9375, learning_rate 0.000179417\n",
      "2020-12-09T17:22:41.126310: step 2907, loss 0.155252, acc 0.96875, learning_rate 0.000179311\n",
      "2020-12-09T17:22:41.696308: step 2908, loss 0.212762, acc 0.875, learning_rate 0.000179204\n",
      "2020-12-09T17:22:42.271805: step 2909, loss 0.168587, acc 0.9375, learning_rate 0.000179098\n",
      "2020-12-09T17:22:42.813271: step 2910, loss 0.187654, acc 0.9375, learning_rate 0.000178992\n",
      "2020-12-09T17:22:43.393506: step 2911, loss 0.119906, acc 1, learning_rate 0.000178886\n",
      "2020-12-09T17:22:43.948255: step 2912, loss 0.35618, acc 0.8125, learning_rate 0.000178781\n",
      "2020-12-09T17:22:44.570252: step 2913, loss 0.129182, acc 0.9375, learning_rate 0.000178675\n",
      "2020-12-09T17:22:45.151254: step 2914, loss 0.124774, acc 0.96875, learning_rate 0.00017857\n",
      "2020-12-09T17:22:45.749251: step 2915, loss 0.310424, acc 0.875, learning_rate 0.000178465\n",
      "2020-12-09T17:22:46.351985: step 2916, loss 0.419976, acc 0.84375, learning_rate 0.000178359\n",
      "2020-12-09T17:22:46.921627: step 2917, loss 0.263312, acc 0.90625, learning_rate 0.000178255\n",
      "2020-12-09T17:22:47.509493: step 2918, loss 0.0781923, acc 0.96875, learning_rate 0.00017815\n",
      "2020-12-09T17:22:48.091294: step 2919, loss 0.289372, acc 0.90625, learning_rate 0.000178045\n",
      "2020-12-09T17:22:48.714828: step 2920, loss 0.21007, acc 0.90625, learning_rate 0.00017794\n",
      "2020-12-09T17:22:49.266020: step 2921, loss 0.3886, acc 0.8125, learning_rate 0.000177836\n",
      "2020-12-09T17:22:49.827521: step 2922, loss 0.183887, acc 0.875, learning_rate 0.000177732\n",
      "2020-12-09T17:22:50.386727: step 2923, loss 0.374456, acc 0.75, learning_rate 0.000177628\n",
      "2020-12-09T17:22:50.952704: step 2924, loss 0.35088, acc 0.9375, learning_rate 0.000177524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-09T17:22:51.525906: step 2925, loss 0.173928, acc 0.90625, learning_rate 0.00017742\n",
      "2020-12-09T17:22:52.091614: step 2926, loss 0.33863, acc 0.84375, learning_rate 0.000177316\n",
      "2020-12-09T17:22:52.654820: step 2927, loss 0.17663, acc 0.9375, learning_rate 0.000177213\n",
      "2020-12-09T17:22:53.202624: step 2928, loss 0.20038, acc 0.875, learning_rate 0.000177109\n",
      "2020-12-09T17:22:53.771115: step 2929, loss 0.28523, acc 0.875, learning_rate 0.000177006\n",
      "2020-12-09T17:22:54.332715: step 2930, loss 0.22428, acc 0.9375, learning_rate 0.000176903\n",
      "2020-12-09T17:22:54.892715: step 2931, loss 0.18864, acc 0.90625, learning_rate 0.0001768\n",
      "2020-12-09T17:22:55.446834: step 2932, loss 0.188744, acc 0.96875, learning_rate 0.000176697\n",
      "2020-12-09T17:22:56.010435: step 2933, loss 0.152655, acc 0.96875, learning_rate 0.000176594\n",
      "2020-12-09T17:22:56.577442: step 2934, loss 0.227432, acc 0.875, learning_rate 0.000176491\n",
      "2020-12-09T17:22:57.127861: step 2935, loss 0.161167, acc 0.96875, learning_rate 0.000176389\n",
      "2020-12-09T17:22:57.690956: step 2936, loss 0.230923, acc 0.90625, learning_rate 0.000176287\n",
      "2020-12-09T17:22:58.260457: step 2937, loss 0.32143, acc 0.9375, learning_rate 0.000176184\n",
      "2020-12-09T17:22:58.830966: step 2938, loss 0.17154, acc 0.96875, learning_rate 0.000176082\n",
      "2020-12-09T17:22:59.393425: step 2939, loss 0.340969, acc 0.90625, learning_rate 0.00017598\n",
      "2020-12-09T17:22:59.931425: step 2940, loss 0.148971, acc 0.96875, learning_rate 0.000175879\n",
      "2020-12-09T17:23:00.492109: step 2941, loss 0.136299, acc 0.96875, learning_rate 0.000175777\n",
      "2020-12-09T17:23:01.065522: step 2942, loss 0.250119, acc 0.84375, learning_rate 0.000175676\n",
      "2020-12-09T17:23:01.639449: step 2943, loss 0.328406, acc 0.875, learning_rate 0.000175574\n",
      "2020-12-09T17:23:02.201385: step 2944, loss 0.0773426, acc 1, learning_rate 0.000175473\n",
      "2020-12-09T17:23:02.763081: step 2945, loss 0.262203, acc 0.875, learning_rate 0.000175372\n",
      "2020-12-09T17:23:03.338842: step 2946, loss 0.193429, acc 0.9375, learning_rate 0.000175271\n",
      "2020-12-09T17:23:03.879230: step 2947, loss 0.153117, acc 0.96875, learning_rate 0.00017517\n",
      "2020-12-09T17:23:04.454356: step 2948, loss 0.178504, acc 0.96875, learning_rate 0.000175069\n",
      "2020-12-09T17:23:05.001323: step 2949, loss 0.174694, acc 0.96875, learning_rate 0.000174969\n",
      "2020-12-09T17:23:05.546323: step 2950, loss 0.277843, acc 0.875, learning_rate 0.000174868\n",
      "\n",
      "Evaluation:\n",
      "2020-12-09T17:23:09.622825: step 2950, loss 0.649049, acc 0.732719\n",
      "\n",
      "Saved model checkpoint to C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train\\runs\\1607550540\\checkpoints\\model-2950\n",
      "\n",
      "2020-12-09T17:23:11.184759: step 2951, loss 0.214242, acc 0.875, learning_rate 0.000174768\n",
      "2020-12-09T17:23:11.801329: step 2952, loss 0.181359, acc 0.9375, learning_rate 0.000174668\n",
      "2020-12-09T17:23:12.370864: step 2953, loss 0.195461, acc 0.9375, learning_rate 0.000174568\n",
      "2020-12-09T17:23:12.943891: step 2954, loss 0.184225, acc 0.9375, learning_rate 0.000174468\n",
      "2020-12-09T17:23:13.504630: step 2955, loss 0.252212, acc 0.84375, learning_rate 0.000174368\n",
      "2020-12-09T17:23:14.055665: step 2956, loss 0.231973, acc 0.84375, learning_rate 0.000174269\n",
      "2020-12-09T17:23:14.611166: step 2957, loss 0.18451, acc 0.9375, learning_rate 0.000174169\n",
      "2020-12-09T17:23:15.171706: step 2958, loss 0.338441, acc 0.84375, learning_rate 0.00017407\n",
      "2020-12-09T17:23:15.792743: step 2959, loss 0.222469, acc 0.875, learning_rate 0.000173971\n",
      "2020-12-09T17:23:16.396484: step 2960, loss 0.0811395, acc 1, learning_rate 0.000173871\n",
      "2020-12-09T17:23:17.103157: step 2961, loss 0.158878, acc 0.9375, learning_rate 0.000173773\n",
      "2020-12-09T17:23:17.676219: step 2962, loss 0.195362, acc 0.90625, learning_rate 0.000173674\n",
      "2020-12-09T17:23:18.226885: step 2963, loss 0.377438, acc 0.78125, learning_rate 0.000173575\n",
      "2020-12-09T17:23:18.802471: step 2964, loss 0.201563, acc 0.9375, learning_rate 0.000173476\n",
      "2020-12-09T17:23:19.357921: step 2965, loss 0.332024, acc 0.875, learning_rate 0.000173378\n",
      "2020-12-09T17:23:19.916538: step 2966, loss 0.231981, acc 0.90625, learning_rate 0.00017328\n",
      "2020-12-09T17:23:20.481309: step 2967, loss 0.177169, acc 0.9375, learning_rate 0.000173182\n",
      "2020-12-09T17:23:21.051912: step 2968, loss 0.403996, acc 0.84375, learning_rate 0.000173084\n",
      "2020-12-09T17:23:21.611765: step 2969, loss 0.326831, acc 0.90625, learning_rate 0.000172986\n",
      "2020-12-09T17:23:22.166764: step 2970, loss 0.299642, acc 0.90625, learning_rate 0.000172888\n",
      "2020-12-09T17:23:22.733756: step 2971, loss 0.117936, acc 0.96875, learning_rate 0.00017279\n",
      "2020-12-09T17:23:23.312253: step 2972, loss 0.267481, acc 0.9375, learning_rate 0.000172693\n",
      "2020-12-09T17:23:23.865725: step 2973, loss 0.173248, acc 1, learning_rate 0.000172595\n",
      "2020-12-09T17:23:24.441361: step 2974, loss 0.102854, acc 1, learning_rate 0.000172498\n",
      "2020-12-09T17:23:25.025395: step 2975, loss 0.203349, acc 0.9375, learning_rate 0.000172401\n",
      "2020-12-09T17:23:25.586835: step 2976, loss 0.223007, acc 0.9375, learning_rate 0.000172304\n",
      "2020-12-09T17:23:26.146800: step 2977, loss 0.103028, acc 0.9375, learning_rate 0.000172207\n",
      "2020-12-09T17:23:26.724779: step 2978, loss 0.278717, acc 0.84375, learning_rate 0.00017211\n",
      "2020-12-09T17:23:27.282935: step 2979, loss 0.12954, acc 0.9375, learning_rate 0.000172014\n",
      "2020-12-09T17:23:27.863430: step 2980, loss 0.294847, acc 0.875, learning_rate 0.000171917\n",
      "2020-12-09T17:23:28.414671: step 2981, loss 0.163993, acc 0.96875, learning_rate 0.000171821\n",
      "2020-12-09T17:23:28.972015: step 2982, loss 0.184115, acc 0.9375, learning_rate 0.000171725\n",
      "2020-12-09T17:23:29.516717: step 2983, loss 0.202441, acc 0.9375, learning_rate 0.000171629\n",
      "2020-12-09T17:23:30.081187: step 2984, loss 0.348478, acc 0.84375, learning_rate 0.000171533\n",
      "2020-12-09T17:23:30.639232: step 2985, loss 0.129137, acc 0.96875, learning_rate 0.000171437\n",
      "2020-12-09T17:23:31.206125: step 2986, loss 0.267391, acc 0.90625, learning_rate 0.000171341\n",
      "2020-12-09T17:23:31.756318: step 2987, loss 0.282543, acc 0.84375, learning_rate 0.000171246\n",
      "2020-12-09T17:23:32.318852: step 2988, loss 0.294565, acc 0.84375, learning_rate 0.00017115\n",
      "2020-12-09T17:23:32.876352: step 2989, loss 0.272038, acc 0.875, learning_rate 0.000171055\n",
      "2020-12-09T17:23:33.094316: step 2990, loss 0.12253, acc 1, learning_rate 0.00017096\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# Added to fix error\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# ===========================================================================\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "      allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "      log_device_placement=FLAGS.log_device_placement)\n",
    "\n",
    "    sess = tf.compat.v1.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        cnn = TextCNN(\n",
    "            sequence_length=x_train.shape[1],\n",
    "            num_classes=y_train.shape[1],\n",
    "            vocab_size=len(vocab_processor.vocabulary_),\n",
    "            embedding_size=embedding_dimension,\n",
    "            filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n",
    "            num_filters=FLAGS.num_filters,\n",
    "            l2_reg_lambda=FLAGS.l2_reg_lambda)\n",
    "       \n",
    "        global_step = tf.compat.v1.Variable(0, name=\"global_step\", trainable=False)\n",
    "        # ===========================================================================================\n",
    "        # Optimizers\n",
    "        early_train_op= tf.compat.v1.train.AdamOptimizer(cnn.learning_rate)\n",
    "        # late_train_op = tf.compat.v1.train.MomentumOptimizer(cnn.learning_rate,0.9,use_nesterov=True) \n",
    "        late_train_op = tf.compat.v1.train.AdadeltaOptimizer(cnn.learning_rate, rho=0.95) \n",
    "        # ===========================================================================================\n",
    "        \n",
    "        grads_and_vars_1 = early_train_op.compute_gradients(cnn.loss)\n",
    "        train_op_1 = early_train_op.apply_gradients(grads_and_vars_1, global_step=global_step)\n",
    "        \n",
    "        grads_and_vars_2 = late_train_op.compute_gradients(cnn.loss)\n",
    "        train_op_2 = late_train_op.apply_gradients(grads_and_vars_2, global_step=global_step)  \n",
    "\n",
    "        # Output directory for models and summaries\n",
    "        timestamp = str(int(time.time()))\n",
    "        out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "        print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "        # Summaries for loss and accuracy\n",
    "        loss_summary = tf.compat.v1.summary.scalar(\"loss\", cnn.loss)\n",
    "        acc_summary = tf.compat.v1.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "\n",
    "        # Train Summaries\n",
    "        train_summary_op = tf.compat.v1.summary.merge([loss_summary, acc_summary])\n",
    "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "        train_summary_writer = tf.compat.v1.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "        # Dev summaries\n",
    "        dev_summary_op = tf.compat.v1.summary.merge([loss_summary, acc_summary])\n",
    "        dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
    "        dev_summary_writer = tf.compat.v1.summary.FileWriter(dev_summary_dir, sess.graph)\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.compat.v1.train.Saver(tf.compat.v1.trainable_variables(), max_to_keep=FLAGS.num_checkpoints)\n",
    "\n",
    "        # Write vocabulary\n",
    "        vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "        # Initialize all variables\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        if FLAGS.enable_word_embeddings and cfg['word_embeddings']['default'] is not None:\n",
    "            vocabulary = vocab_processor.vocabulary_\n",
    "            initW = None\n",
    "            if embedding_name == 'word2vec':\n",
    "                # load embedding vectors from the word2vec\n",
    "                print(\"Load word2vec file {}\".format(cfg['word_embeddings']['word2vec']['path']))\n",
    "                initW = data_helpers.load_embedding_vectors_word2vec(vocabulary,\n",
    "                                                                     cfg['word_embeddings']['word2vec']['path'],\n",
    "                                                                     cfg['word_embeddings']['word2vec']['binary'])\n",
    "                print(\"word2vec file has been loaded\")\n",
    "            elif embedding_name == 'glove':\n",
    "                # load embedding vectors from the glove\n",
    "                print(\"Load glove file {}\".format(cfg['word_embeddings']['glove']['path']))\n",
    "                initW = data_helpers.load_embedding_vectors_glove(vocabulary,\n",
    "                                                                  cfg['word_embeddings']['glove']['path'],\n",
    "                                                                  embedding_dimension)\n",
    "                print(\"glove file has been loaded\\n\")\n",
    "            sess.run(cnn.W.assign(initW))\n",
    "\n",
    "        def train_step(x_batch, y_batch, learning_rate):\n",
    "            \"\"\"\n",
    "            A single training step\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: FLAGS.dropout_keep_prob,                \n",
    "              cnn.learning_rate: learning_rate              \n",
    "            }\n",
    "            \n",
    "            #Conditional optimizer switch\n",
    "            train_op = train_op_1 if tf.compat.v1.train.global_step(sess, global_step) <=(train_input_size/FLAGS.batch_size)*3 else train_op_2\n",
    "                        \n",
    "            _, step, summaries, loss, accuracy = sess.run(                \n",
    "                [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy],                \n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            \n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}, learning_rate {:g}\"\n",
    "                  .format(time_str, step, loss, accuracy, learning_rate))\n",
    "            train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "        def dev_step(x_batch, y_batch, writer=None):\n",
    "            \"\"\"\n",
    "            Evaluates model on a dev set\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: 1.0\n",
    "            }\n",
    "            step, summaries, loss, accuracy = sess.run(\n",
    "                [global_step, dev_summary_op, cnn.loss, cnn.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            if writer:\n",
    "                writer.add_summary(summaries, step)\n",
    "                \n",
    "\n",
    "        train_input_size=len(list(zip(x_train, y_train)))\n",
    "        print('Trainning input set: x_train, y_train',train_input_size)\n",
    "        # Generate batches\n",
    "        batches = data_helpers.batch_iter(\n",
    "            list(zip(x_train, y_train)), FLAGS.batch_size, FLAGS.num_epochs)\n",
    "        \n",
    "        # It uses dynamic learning rate with a high value at the beginning to speed up the training\n",
    "        max_learning_rate = 0.004\n",
    "        min_learning_rate = 0.0001        \n",
    "        decay_speed = FLAGS.decay_coefficient*len(y_train)/FLAGS.batch_size\n",
    "        \n",
    "        # Training loop. For each batch...\n",
    "        counter = 0\n",
    "        print(\"*********Trainable PARAMETERS***********\",np.sum([np.prod(v.get_shape().as_list()) for v in \n",
    "                                                                 tf.compat.v1.trainable_variables()]))\n",
    "        for batch in batches:\n",
    "            learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-counter/decay_speed)\n",
    "            counter += 1\n",
    "            x_batch, y_batch = zip(*batch)      \n",
    "            \n",
    "            if tf.compat.v1.train.global_step(sess, global_step) == ((train_input_size/FLAGS.batch_size)*3)+1: ##(2534*3)+1:\n",
    "                min_learning_rate = 0.0035\n",
    "                \n",
    "            train_step(x_batch, y_batch, learning_rate)\n",
    "            \n",
    "            current_step = tf.compat.v1.train.global_step(sess, global_step)\n",
    "            if current_step % FLAGS.evaluate_every == 0:\n",
    "                print(\"\\nEvaluation:\")\n",
    "                dev_step(x_dev, y_dev, writer=dev_summary_writer)\n",
    "                print(\"\")\n",
    "            if current_step % FLAGS.checkpoint_every == 0:\n",
    "                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# Eval.py\n",
    "# ==========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************YML_PATH C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\train/helper/config.yml\n",
      "dataset_name:  tobacco\n",
      "Loading data !\n",
      "*************data_path C:\\Users\\User\\Lightweighted-CNN-for-Document-Classification\\data/tobacco-data/\n",
      "['0.txt', '6.txt', '8.txt']\n",
      "Total number of test examples: 11936\n",
      "Vocabulary Size: 16099\n",
      "Train/Dev split: 9549/2387\n",
      "size of x_dev, y_dev: 2387 2387\n",
      "\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\preprocessing\\text.py:203: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1356, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1341, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1429, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value batch_normalization_4/moving_mean\n",
      "\t [[{{node batch_normalization_4/moving_mean/read}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"eval_SGD_small.py\", line 146, in <module>\n",
      "    batch_predictions_scores = sess.run([predictions, scores], {input_x: x_dev_batch, dropout_keep_prob: 1.0})\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 950, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1173, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1350, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1370, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value batch_normalization_4/moving_mean\n",
      "\t [[node batch_normalization_4/moving_mean/read (defined at eval_SGD_small.py:122) ]]\n",
      "\n",
      "Original stack trace for 'batch_normalization_4/moving_mean/read':\n",
      "  File \"eval_SGD_small.py\", line 122, in <module>\n",
      "    saver = tf.compat.v1.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1449, in import_meta_graph\n",
      "    **kwargs)[0]\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1473, in _import_meta_graph_with_return_elements\n",
      "    **kwargs))\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 857, in import_scoped_meta_graph_with_return_elements\n",
      "    return_elements=return_elements)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 443, in import_graph_def\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 236, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3751, in _add_new_tf_operations\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3751, in <listcomp>\n",
      "    for c_op in c_api_util.new_tf_operations(self)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3641, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python eval_SGD_small.py --eval_train --checkpoint_dir=\"./runs/1607550540/checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
